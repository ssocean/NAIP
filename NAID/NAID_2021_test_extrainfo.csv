id,title,cites,TNCSI,TNCSI_SP,abstract,OA,is_practical,new_task,new_dataset,SOTA,is_broad,RQM,SMP,ARQ,Ref_num
95d4eeb8-61d8-4da8-9f94-06ba20b82858,Fixed Viewpoint Mirror Surface Reconstruction under an Uncalibrated Camera,2,0.0134142,0.104732,"This paper addresses the problem of mirror surface reconstruction, and
proposes a solution based on observing the reflections of a moving reference
plane on the mirror surface. Unlike previous approaches which require tedious
calibration, our method can recover the camera intrinsics, the poses of the
reference plane, as well as the mirror surface from the observed reflections of
the reference plane under at least three unknown distinct poses. We first show
that the 3D poses of the reference plane can be estimated from the reflection
correspondences established between the images and the reference plane. We then
form a bunch of 3D lines from the reflection correspondences, and derive an
analytical solution to recover the line projection matrix. We transform the
line projection matrix to its equivalent camera projection matrix, and propose
a cross-ratio based formulation to optimize the camera projection matrix by
minimizing reprojection errors. The mirror surface is then reconstructed based
on the optimized cross-ratio constraint. Experimental results on both synthetic
and real data are presented, which demonstrate the feasibility and accuracy of
our method.",1,0,0,0,0,0,2.71779e-05,22.0,0.448976,38
75e7521f-df63-4468-967f-5672b8625ea1,GANs for Urban Design,3,0.0210703,0.187688,"Development and diffusion of machine learning and big data tools provide a
new tool for architects and urban planners that could be used as analytical or
design instruments. The topic investigated in this paper is the application of
Generative Adversarial Networks to the design of an urban block. The research
presents a flexible model able to adapt to the morphological characteristics of
a city. This method does not define explicitly any of the parameters of an
urban block typical for a city, the algorithm learns them from the existing
urban context. This approach has been applied to the cities with different
morphology: Milan, Amsterdam, Tallinn, Turin, and Bengaluru in order to see the
performance of the model and the possibility of style translation between
different cities. The data are gathered from Openstreetmap and Open Data
portals of the cities. This research presents the results of the experiments
and their quantitative and qualitative evaluation.",0,1,0,0,0,0,0.122682,7.0,0.47959,21
556785dc-06b3-4d89-8aaf-7dcbc87e97c2,CTAL: Pre-training Cross-modal Transformer for Audio-and-Language Representations,11,0.0682476,0.265372,"Existing audio-language task-specific predictive approaches focus on building
complicated late-fusion mechanisms. However, these models are facing challenges
of overfitting with limited labels and low model generalization abilities. In
this paper, we present a Cross-modal Transformer for Audio-and-Language, i.e.,
CTAL, which aims to learn the intra-modality and inter-modality connections
between audio and language through two proxy tasks on a large amount of
audio-and-language pairs: masked language modeling and masked cross-modal
acoustic modeling. After fine-tuning our pre-trained model on multiple
downstream audio-and-language tasks, we observe significant improvements across
various tasks, such as, emotion classification, sentiment analysis, and speaker
verification. On this basis, we further propose a specially-designed fusion
mechanism that can be used in fine-tuning phase, which allows our pre-trained
model to achieve better performance. Lastly, we demonstrate detailed ablation
studies to prove that both our novel cross-modality fusion component and
audio-language pre-training methods significantly contribute to the promising
results.",1,0,1,0,0,0,0.853963,6.0,0.840819,47
f8c76517-775c-4e73-a92e-35fa333a7d11,Cooperative Multi-Agent Transfer Learning with Level-Adaptive Credit Assignment,13,0.216896,0.56647,"Extending transfer learning to cooperative multi-agent reinforcement learning
(MARL) has recently received much attention. In contrast to the single-agent
setting, the coordination indispensable in cooperative MARL constrains each
agent's policy. However, existing transfer methods focus exclusively on agent
policy and ignores coordination knowledge. We propose a new architecture that
realizes robust coordination knowledge transfer through appropriate
decomposition of the overall coordination into several coordination patterns.
We use a novel mixing network named level-adaptive QTransformer
(LA-QTransformer) to realize agent coordination that considers credit
assignment, with appropriate coordination patterns for different agents
realized by a novel level-adaptive Transformer (LA-Transformer) dedicated to
the transfer of coordination knowledge. In addition, we use a novel agent
network named Population Invariant agent with Transformer (PIT) to realize the
coordination transfer in more varieties of scenarios. Extensive experiments in
StarCraft II micro-management show that LA-QTransformer together with PIT
achieves superior performance compared with state-of-the-art baselines.",0,0,0,0,1,0,0.947331,6.0,0.911706,35
a95b89b4-a53c-4134-ab0a-aa80e998addf,Zero-Shot Learning Based on Knowledge Sharing,1,0.00528856,0.013663,"Zero-Shot Learning (ZSL) is an emerging research that aims to solve the
classification problems with very few training data. The present works on ZSL
mainly focus on the mapping of learning semantic space to visual space. It
encounters many challenges that obstruct the progress of ZSL research. First,
the representation of the semantic feature is inadequate to represent all
features of the categories. Second, the domain drift problem still exists
during the transfer from semantic space to visual space. In this paper, we
introduce knowledge sharing (KS) to enrich the representation of semantic
features. Based on KS, we apply a generative adversarial network to generate
pseudo visual features from semantic features that are very close to the real
visual features. Abundant experimental results from two benchmark datasets of
ZSL show that the proposed approach has a consistent improvement.",0,1,0,0,0,0,0.145307,12.0,0.711595,34
3b9d6c39-5cd6-4f1b-a261-18c0b45f01b7,LU-BZU at SemEval-2021 Task 2: Word2Vec and Lemma2Vec performance in Arabic Word-in-Context disambiguation,11,0.491822,0.664089,"This paper presents a set of experiments to evaluate and compare between the
performance of using CBOW Word2Vec and Lemma2Vec models for Arabic
Word-in-Context (WiC) disambiguation without using sense inventories or sense
embeddings. As part of the SemEval-2021 Shared Task 2 on WiC disambiguation, we
used the dev.ar-ar dataset (2k sentence pairs) to decide whether two words in a
given sentence pair carry the same meaning. We used two Word2Vec models:
Wiki-CBOW, a pre-trained model on Arabic Wikipedia, and another model we
trained on large Arabic corpora of about 3 billion tokens. Two Lemma2Vec models
was also constructed based on the two Word2Vec models. Each of the four models
was then used in the WiC disambiguation task, and then evaluated on the
SemEval-2021 test.ar-ar dataset. At the end, we reported the performance of
different models and compared between using lemma-based and word-based models.",0,1,0,0,0,0,0.851231,7.0,0.862176,37
8ad63ca2-9a5b-426d-bf97-07c53be30d6c,Learning Statistical Texture for Semantic Segmentation,95,0.168851,0.674201,"Existing semantic segmentation works mainly focus on learning the contextual
information in high-level semantic features with CNNs. In order to maintain a
precise boundary, low-level texture features are directly skip-connected into
the deeper layers. Nevertheless, texture features are not only about local
structure, but also include global statistical knowledge of the input image. In
this paper, we fully take advantages of the low-level texture features and
propose a novel Statistical Texture Learning Network (STLNet) for semantic
segmentation. For the first time, STLNet analyzes the distribution of low level
information and efficiently utilizes them for the task. Specifically, a novel
Quantization and Counting Operator (QCO) is designed to describe the texture
information in a statistical manner. Based on QCO, two modules are introduced:
(1) Texture Enhance Module (TEM), to capture texture-related information and
enhance the texture details; (2) Pyramid Texture Feature Extraction Module
(PTFEM), to effectively extract the statistical texture features from multiple
scales. Through extensive experiments, we show that the proposed STLNet
achieves state-of-the-art performance on three semantic segmentation
benchmarks: Cityscapes, PASCAL Context and ADE20K.",0,1,1,0,1,0,0.327515,6.0,0.577696,39
5d208276-3790-4795-99d5-5779a7498f06,Will bots take over the supply chain? Revisiting Agent-based supply chain automation,24,0.443791,0.874585,"Agent-based systems have the capability to fuse information from many
distributed sources and create better plans faster. This feature makes
agent-based systems naturally suitable to address the challenges in Supply
Chain Management (SCM). Although agent-based supply chains systems have been
proposed since early 2000; industrial uptake of them has been lagging. The
reasons quoted include the immaturity of the technology, a lack of
interoperability with supply chain information systems, and a lack of trust in
Artificial Intelligence (AI). In this paper, we revisit the agent-based supply
chain and review the state of the art. We find that agent-based technology has
matured, and other supporting technologies that are penetrating supply chains;
are filling in gaps, leaving the concept applicable to a wider range of
functions. For example, the ubiquity of IoT technology helps agents ""sense"" the
state of affairs in a supply chain and opens up new possibilities for
automation. Digital ledgers help securely transfer data between third parties,
making agent-based information sharing possible, without the need to integrate
Enterprise Resource Planning (ERP) systems. Learning functionality in agents
enables agents to move beyond automation and towards autonomy. We note this
convergence effect through conceptualising an agent-based supply chain
framework, reviewing its components, and highlighting research challenges that
need to be addressed in moving forward.",0,1,0,0,0,0,0.0053926,28.0,0.756091,161
5e2b9f37-dd0c-4339-a114-dbdd7b8e0c44,Detecting Small Objects in Thermal Images Using Single-Shot Detector,10,0.00873929,0.0785974,"SSD (Single Shot Multibox Detector) is one of the most successful object
detectors for its high accuracy and fast speed. However, the features from
shallow layer (mainly Conv4_3) of SSD lack semantic information, resulting in
poor performance in small objects. In this paper, we proposed DDSSD (Dilation
and Deconvolution Single Shot Multibox Detector), an enhanced SSD with a novel
feature fusion module which can improve the performance over SSD for small
object detection. In the feature fusion module, dilation convolution module is
utilized to enlarge the receptive field of features from shallow layer and
deconvolution module is adopted to increase the size of feature maps from high
layer. Our network achieves 79.7% mAP on PASCAL VOC2007 test and 28.3% mmAP on
MS COCO test-dev at 41 FPS with only 300x300 input using a single Nvidia 1080
GPU. Especially, for small objects, DDSSD achieves 10.5% on MS COCO and 22.8%
on FLIR thermal dataset, outperforming a lot of state-of-the-art object
detection algorithms in both aspects of accuracy and speed.",0,1,0,0,1,0,0.171944,11.0,0.702075,34
2264b8d8-56c6-4298-8e15-c6bf58005ad4,Corpus and Models for Lemmatisation and POS-tagging of Old French,5,0.320866,0.674518,"Old French is a typical example of an under-resourced historic languages,
that furtherly displays animportant amount of linguistic variation. In this
paper, we present the current results of a long going project (2015-...) and
describe how we broached the difficult question of providing lemmatisation
andPOS models for Old French with the help of neural taggers and the
progressive constitution of dedicated corpora.",1,1,0,0,0,0,0.0806461,11.0,0.628602,46
fd1f67f1-f227-4b8d-906e-1f358b1c1d04,Bandits Don't Follow Rules: Balancing Multi-Facet Machine Translation with Multi-Armed Bandits,13,0.021682,0.398572,"Training data for machine translation (MT) is often sourced from a multitude
of large corpora that are multi-faceted in nature, e.g. containing contents
from multiple domains or different levels of quality or complexity. Naturally,
these facets do not occur with equal frequency, nor are they equally important
for the test scenario at hand. In this work, we propose to optimize this
balance jointly with MT model parameters to relieve system developers from
manual schedule design. A multi-armed bandit is trained to dynamically choose
between facets in a way that is most beneficial for the MT system. We evaluate
it on three different multi-facet applications: balancing translationese and
natural training data, or data from multiple domains or multiple language
pairs. We find that bandit learning leads to competitive MT systems across
tasks, and our analysis provides insights into its learned strategies and the
underlying data sets.",0,1,0,0,0,0,0.083891,7.0,0.422259,66
9729788f-da40-4505-92b1-2dfe25f84f53,Sicilian Translator: A Recipe for Low-Resource NMT,1,0.0292001,0.0841914,"With 17,000 pairs of Sicilian-English translated sentences, Arba Sicula
developed the first neural machine translator for the Sicilian language. Using
small subword vocabularies, we trained small Transformer models with high
dropout parameters and achieved BLEU scores in the upper 20s. Then we
supplemented our dataset with backtranslation and multilingual translation and
pushed our scores into the mid 30s. We also attribute our success to
incorporating theoretical information in our dataset. Prior to training, we
biased the subword vocabulary towards the desinences one finds in a textbook.
And we included textbook exercises in our dataset.",0,1,0,1,0,0,0.992306,9.0,0.997013,15
e2254438-2cae-40eb-883a-b39f453126be,Sequence-to-Sequence Learning with Latent Neural Grammars,36,0.0577572,0.339736,"Sequence-to-sequence learning with neural networks has become the de facto
standard for sequence prediction tasks. This approach typically models the
local distribution over the next word with a powerful neural network that can
condition on arbitrary context. While flexible and performant, these models
often require large datasets for training and can fail spectacularly on
benchmarks designed to test for compositional generalization. This work
explores an alternative, hierarchical approach to sequence-to-sequence learning
with quasi-synchronous grammars, where each node in the target tree is
transduced by a node in the source tree. Both the source and target trees are
treated as latent and induced during training. We develop a neural
parameterization of the grammar which enables parameter sharing over the
combinatorial space of derivation rules without the need for manual feature
engineering. We apply this latent neural grammar to various domains -- a
diagnostic language navigation task designed to test for compositional
generalization (SCAN), style transfer, and small-scale machine translation --
and find that it performs respectably compared to standard baselines.",1,0,0,0,0,0,0.00785838,9.0,0.283148,134
5cfb6e1c-236f-484f-88ae-90e95ed8e8ce,Text-Aware Predictive Monitoring of Business Processes,9,0.110674,0.560974,"The real-time prediction of business processes using historical event data is
an important capability of modern business process monitoring systems. Existing
process prediction methods are able to also exploit the data perspective of
recorded events, in addition to the control-flow perspective. However, while
well-structured numerical or categorical attributes are considered in many
prediction techniques, almost no technique is able to utilize text documents
written in natural language, which can hold information critical to the
prediction task. In this paper, we illustrate the design, implementation, and
evaluation of a novel text-aware process prediction model based on Long
Short-Term Memory (LSTM) neural networks and natural language models. The
proposed model can take categorical, numerical and textual attributes in event
data into account to predict the activity and timestamp of the next event, the
outcome, and the cycle time of a running process instance. Experiments show
that the text-aware model is able to outperform state-of-the-art process
prediction methods on simulated and real-world event logs containing textual
data.",0,1,0,0,1,0,0.434739,10.0,0.782926,18
bc98a2a5-e2ee-4334-8a5e-a239b8682e6c,Biomedical Data-to-Text Generation via Fine-Tuning Transformers,9,0.415365,0.819908,"Data-to-text (D2T) generation in the biomedical domain is a promising - yet
mostly unexplored - field of research. Here, we apply neural models for D2T
generation to a real-world dataset consisting of package leaflets of European
medicines. We show that fine-tuned transformers are able to generate realistic,
multisentence text from data in the biomedical domain, yet have important
limitations. We also release a new dataset (BioLeaflets) for benchmarking D2T
generation models in the biomedical domain.",1,1,0,1,0,0,0.988301,7.0,0.983297,28
1fe1db34-d2a8-48b2-87c8-63985fe3ed36,Machine-in-the-Loop Rewriting for Creative Image Captioning,11,0.0389833,0.225719,"Machine-in-the-loop writing aims to enable humans to collaborate with models
to complete their writing tasks more effectively. Prior work has found that
providing humans a machine-written draft or sentence-level continuations has
limited success since the generated text tends to deviate from humans'
intention. To allow the user to retain control over the content, we train a
rewriting model that, when prompted, modifies specified spans of text within
the user's original draft to introduce descriptive and figurative elements
locally in the text. We evaluate the model on its ability to collaborate with
humans on the task of creative image captioning. On a user study through Amazon
Mechanical Turk, our model is rated to be more helpful than a baseline
infilling language model. In addition, third-party evaluation shows that users
write more descriptive and figurative captions when collaborating with our
model compared to completing the task alone.",0,1,0,0,0,0,0.119111,6.0,0.387601,34
608be26c-318a-452d-b51f-b4e80a6ebbfa,What Context Features Can Transformer Language Models Use?,62,0.134251,0.557388,"Transformer-based language models benefit from conditioning on contexts of
hundreds to thousands of previous tokens. What aspects of these contexts
contribute to accurate model prediction? We describe a series of experiments
that measure usable information by selectively ablating lexical and structural
information in transformer language models trained on English Wikipedia. In
both mid- and long-range contexts, we find that several extremely destructive
context manipulations -- including shuffling word order within sentences and
deleting all words other than nouns -- remove less than 15% of the usable
information. Our results suggest that long contexts, but not their detailed
syntactic and propositional content, are important for the low perplexity of
current transformer language models.",1,0,0,0,0,1,0.653386,5.0,0.68968,40
3abae262-b68c-428c-82ed-43e5b9fed26d,Blockchain-Based Federated Learning in Mobile Edge Networks with Application in Internet of Vehicles,9,0.1109,0.213211,"The rapid increase of the data scale in Internet of Vehicles (IoV) system
paradigm, hews out new possibilities in boosting the service quality for the
emerging applications through data sharing. Nevertheless, privacy concerns are
major bottlenecks for data providers to share private data in traditional IoV
networks. To this end, federated learning (FL) as an emerging learning
paradigm, where data providers only send local model updates trained on their
local raw data rather than upload any raw data, has been recently proposed to
build a privacy-preserving data sharing models. Unfortunately, by analyzing on
the differences of uploaded local model updates from data providers, private
information can still be divulged, and performance of the system cannot be
guaranteed when partial federated nodes executes malicious behavior.
Additionally, traditional cloud-based FL poses challenges to the communication
overhead with the rapid increase of terminal equipment in IoV system. All these
issues inspire us to propose an autonomous blockchain empowered
privacy-preserving FL framework in this paper, where the mobile edge computing
(MEC) technology was naturally integrated in IoV system.",0,1,0,0,0,0,0.938945,6.0,0.903124,31
cedfd3d9-975c-424b-bf02-f017332dcaf6,Efficient large-scale image retrieval with deep feature orthogonality and Hybrid-Swin-Transformers,12,0.030004,0.375123,"We present an efficient end-to-end pipeline for largescale landmark
recognition and retrieval. We show how to combine and enhance concepts from
recent research in image retrieval and introduce two architectures especially
suited for large-scale landmark identification. A model with deep orthogonal
fusion of local and global features (DOLG) using an EfficientNet backbone as
well as a novel Hybrid-Swin-Transformer is discussed and details how to train
both architectures efficiently using a step-wise approach and a sub-center
arcface loss with dynamic margins are provided. Furthermore, we elaborate a
novel discriminative re-ranking methodology for image retrieval. The
superiority of our approach was demonstrated by winning the recognition and
retrieval track of the Google Landmark Competition 2021.",1,1,0,0,0,0,0.300691,5.0,0.472479,18
416e5cad-d807-47b1-be86-3d2282a2f96c,Rationales for Sequential Predictions,20,0.0582698,0.534854,"Sequence models are a critical component of modern NLP systems, but their
predictions are difficult to explain. We consider model explanations though
rationales, subsets of context that can explain individual model predictions.
We find sequential rationales by solving a combinatorial optimization: the best
rationale is the smallest subset of input tokens that would predict the same
output as the full sequence. Enumerating all subsets is intractable, so we
propose an efficient greedy algorithm to approximate this objective. The
algorithm, which is called greedy rationalization, applies to any model. For
this approach to be effective, the model should form compatible conditional
distributions when making predictions on incomplete subsets of the context.
This condition can be enforced with a short fine-tuning step. We study greedy
rationalization on language modeling and machine translation. Compared to
existing baselines, greedy rationalization is best at optimizing the
combinatorial objective and provides the most faithful rationales. On a new
dataset of annotated sequential rationales, greedy rationales are most similar
to human rationales.",0,0,0,0,0,1,0.379529,8.0,0.706363,54
0a0465ac-0cb8-4ca6-8f4e-76cee5dc1376,Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation,57,0.24901,0.879749,"We propose a method for object-aware 3D egocentric pose estimation that
tightly integrates kinematics modeling, dynamics modeling, and scene object
information. Unlike prior kinematics or dynamics-based approaches where the two
components are used disjointly, we synergize the two approaches via
dynamics-regulated training. At each timestep, a kinematic model is used to
provide a target pose using video evidence and simulation state. Then, a
prelearned dynamics model attempts to mimic the kinematic pose in a physics
simulator. By comparing the pose instructed by the kinematic model against the
pose generated by the dynamics model, we can use their misalignment to further
improve the kinematic model. By factoring in the 6DoF pose of objects (e.g.,
chairs, boxes) in the scene, we demonstrate for the first time, the ability to
estimate physically-plausible 3D human-object interactions using a single
wearable camera. We evaluate our egocentric pose estimation method in both
controlled laboratory settings and real-world scenarios.",0,1,0,0,0,0,0.503002,5.0,0.60654,68
6cc3fa4c-785c-4ffd-b0e6-34eb7b3ed76f,BuildingNet: Learning to Label 3D Buildings,25,0.490091,0.629788,"We introduce BuildingNet: (a) a large-scale dataset of 3D building models
whose exteriors are consistently labeled, (b) a graph neural network that
labels building meshes by analyzing spatial and structural relations of their
geometric primitives. To create our dataset, we used crowdsourcing combined
with expert guidance, resulting in 513K annotated mesh primitives, grouped into
292K semantic part components across 2K building models. The dataset covers
several building categories, such as houses, churches, skyscrapers, town halls,
libraries, and castles. We include a benchmark for evaluating mesh and point
cloud labeling. Buildings have more challenging structural complexity compared
to objects in existing benchmarks (e.g., ShapeNet, PartNet), thus, we hope that
our dataset can nurture the development of algorithms that are able to cope
with such large-scale geometric data for both vision and graphics tasks e.g.,
3D semantic segmentation, part-based generative models, correspondences,
texturing, and analysis of point cloud data acquired from real-world buildings.
Finally, we show that our mesh-based graph neural network significantly
improves performance over several baselines for labeling 3D meshes.",1,1,1,1,0,0,0.801437,9.0,0.874546,69
33842264-c9a9-4f43-9709-51cb70a80bc1,Is Multi-Hop Reasoning Really Explainable? Towards Benchmarking Reasoning Interpretability,12,0.161617,0.395769,"Multi-hop reasoning has been widely studied in recent years to obtain more
interpretable link prediction. However, we find in experiments that many paths
given by these models are actually unreasonable, while little works have been
done on interpretability evaluation for them. In this paper, we propose a
unified framework to quantitatively evaluate the interpretability of multi-hop
reasoning models so as to advance their development. In specific, we define
three metrics including path recall, local interpretability, and global
interpretability for evaluation, and design an approximate strategy to
calculate them using the interpretability scores of rules. Furthermore, we
manually annotate all possible rules and establish a Benchmark to detect the
Interpretability of Multi-hop Reasoning (BIMR). In experiments, we run nine
baselines on our benchmark. The experimental results show that the
interpretability of current multi-hop reasoning models is less satisfactory and
is still far from the upper bound given by our benchmark. Moreover, the
rule-based models outperform the multi-hop reasoning models in terms of
performance and interpretability, which points to a direction for future
research, i.e., we should investigate how to better incorporate rule
information into the multi-hop reasoning model. Our codes and datasets can be
obtained from https://github.com/THU-KEG/BIMR.",1,0,0,0,0,0,0.655879,6.0,0.742532,27
164e4382-7e36-44df-b5d7-1881f4ea8705,Robust Model-based Reinforcement Learning for Autonomous Greenhouse Control,10,0.135688,0.402269,"Due to the high efficiency and less weather dependency, autonomous
greenhouses provide an ideal solution to meet the increasing demand for fresh
food. However, managers are faced with some challenges in finding appropriate
control strategies for crop growth, since the decision space of the greenhouse
control problem is an astronomical number. Therefore, an intelligent
closed-loop control framework is highly desired to generate an automatic
control policy. As a powerful tool for optimal control, reinforcement learning
(RL) algorithms can surpass human beings' decision-making and can also be
seamlessly integrated into the closed-loop control framework. However, in
complex real-world scenarios such as agricultural automation control, where the
interaction with the environment is time-consuming and expensive, the
application of RL algorithms encounters two main challenges, i.e., sample
efficiency and safety. Although model-based RL methods can greatly mitigate the
efficiency problem of greenhouse control, the safety problem has not got too
much attention. In this paper, we present a model-based robust RL framework for
autonomous greenhouse control to meet the sample efficiency and safety
challenges. Specifically, our framework introduces an ensemble of environment
models to work as a simulator and assist in policy optimization, thereby
addressing the low sample efficiency problem. As for the safety concern, we
propose a sample dropout module to focus more on worst-case samples, which can
help improve the adaptability of the greenhouse planting policy in extreme
cases. Experimental results demonstrate that our approach can learn a more
effective greenhouse planting policy with better robustness than existing
methods.",0,1,0,0,0,0,0.376144,10.0,0.763944,37
c7e71d8a-50f8-453b-b1cd-3e843ce4bc18,FFAVOD: Feature Fusion Architecture for Video Object Detection,15,0.0699811,0.568029,"A significant amount of redundancy exists between consecutive frames of a
video. Object detectors typically produce detections for one image at a time,
without any capabilities for taking advantage of this redundancy. Meanwhile,
many applications for object detection work with videos, including intelligent
transportation systems, advanced driver assistance systems and video
surveillance. Our work aims at taking advantage of the similarity between video
frames to produce better detections. We propose FFAVOD, standing for feature
fusion architecture for video object detection. We first introduce a novel
video object detection architecture that allows a network to share feature maps
between nearby frames. Second, we propose a feature fusion module that learns
to merge feature maps to enhance them. We show that using the proposed
architecture and the fusion module can improve the performance of three base
object detectors on two object detection benchmarks containing sequences of
moving road users. Additionally, to further increase performance, we propose an
improvement to the SpotNet attention module. Using our architecture on the
improved SpotNet detector, we obtain the state-of-the-art performance on the
UA-DETRAC public benchmark as well as on the UAVDT dataset. Code is available
at https://github.com/hu64/FFAVOD.",1,1,0,0,1,0,0.220588,8.0,0.625141,46
51af03d9-176b-4b92-8aa7-e9e959582bf8,Consistency Regularization for Cross-Lingual Fine-Tuning,49,0.620055,0.899287,"Fine-tuning pre-trained cross-lingual language models can transfer
task-specific supervision from one language to the others. In this work, we
propose to improve cross-lingual fine-tuning with consistency regularization.
Specifically, we use example consistency regularization to penalize the
prediction sensitivity to four types of data augmentations, i.e., subword
sampling, Gaussian noise, code-switch substitution, and machine translation. In
addition, we employ model consistency to regularize the models trained with two
augmented versions of the same training set. Experimental results on the XTREME
benchmark show that our method significantly improves cross-lingual fine-tuning
across various tasks, including text classification, question answering, and
sequence labeling.",0,1,0,0,0,0,0.977599,4.0,0.931302,43
2be259fe-a39f-47fa-a360-4ac55eefb9a6,A Pilot Study For Fragment Identification Using 2D NMR and Deep Learning,10,0.352289,0.602329,"This paper presents a method to identify substructures in NMR spectra of
mixtures, specifically 2D spectra, using a bespoke image-based Convolutional
Neural Network application. This is done using HSQC and HMBC spectra separately
and in combination. The application can reliably detect substructures in pure
compounds, using a simple network. It can work for mixtures when trained on
pure compounds only. HMBC data and the combination of HMBC and HSQC show better
results than HSQC alone.",1,1,0,0,0,0,0.896502,4.0,0.802387,47
e6ed5197-4bc5-476a-83e7-52595ce4ec2f,Towards Safer Transportation: a self-supervised learning approach for traffic video deraining,1,0.0100605,0.140064,"Video monitoring of traffic is useful for traffic management and control,
traffic counting, and traffic law enforcement. However, traffic monitoring
during inclement weather such as rain is a challenging task because video
quality is corrupted by streaks of falling rain on the video image, and this
hinders reliable characterization not only of the road environment but also of
road-user behavior during such adverse weather events. This study proposes a
two-stage self-supervised learning method to remove rain streaks in traffic
videos. The first and second stages address intra- and inter-frame noise,
respectively. The results indicated that the model exhibits satisfactory
performance in terms of the image visual quality and the Peak Signal-Noise
Ratio value.",0,1,0,0,0,0,0.47899,11.0,0.814803,46
d5ef170d-83a2-4c5f-93c8-e65af2446740,First and Second Order Dynamics in a Hierarchical SOM system for Action Recognition,23,0.0673063,0.223632,"Human recognition of the actions of other humans is very efficient and is
based on patterns of movements. Our theoretical starting point is that the
dynamics of the joint movements is important to action categorization. On the
basis of this theory, we present a novel action recognition system that employs
a hierarchy of Self-Organizing Maps together with a custom supervised neural
network that learns to categorize actions. The system preprocesses the input
from a Kinect like 3D camera to exploit the information not only about joint
positions, but also their first and second order dynamics. We evaluate our
system in two experiments with publicly available data sets, and compare its
performance to the performance with less sophisticated preprocessing of the
input. The results show that including the dynamics of the actions improves the
performance. We also apply an attention mechanism that focuses on the parts of
the body that are the most involved in performing the actions.",0,0,0,0,0,0,0.000466586,16.0,0.420045,44
4f71e544-9ea3-41e3-af08-f4a92c82f7a6,Eyes Tell All: Irregular Pupil Shapes Reveal GAN-generated Faces,50,0.482364,0.984628,"Generative adversary network (GAN) generated high-realistic human faces have
been used as profile images for fake social media accounts and are visually
challenging to discern from real ones. In this work, we show that GAN-generated
faces can be exposed via irregular pupil shapes. This phenomenon is caused by
the lack of physiological constraints in the GAN models. We demonstrate that
such artifacts exist widely in high-quality GAN-generated faces and further
describe an automatic method to extract the pupils from two eyes and analysis
their shapes for exposing the GAN-generated faces. Qualitative and quantitative
evaluations of our method suggest its simplicity and effectiveness in
distinguishing GAN-generated faces.",1,1,0,0,0,0,0.770561,4.0,0.694316,40
7f3c8d67-b6a3-451a-a4b9-9a527fa94ab4,Few-Shot Keyword Spotting in Any Language,30,0.850231,0.840963,"We introduce a few-shot transfer learning method for keyword spotting in any
language. Leveraging open speech corpora in nine languages, we automate the
extraction of a large multilingual keyword bank and use it to train an
embedding model. With just five training examples, we fine-tune the embedding
model for keyword spotting and achieve an average F1 score of 0.75 on keyword
classification for 180 new keywords unseen by the embedding model in these nine
languages. This embedding model also generalizes to new languages. We achieve
an average F1 score of 0.65 on 5-shot models for 260 keywords sampled across 13
new languages unseen by the embedding model. We investigate streaming accuracy
for our 5-shot models in two contexts: keyword spotting and keyword search.
Across 440 keywords in 22 languages, we achieve an average streaming keyword
spotting accuracy of 87.4% with a false acceptance rate of 4.3%, and observe
promising initial results on keyword search.",0,1,1,0,0,0,0.918721,6.0,0.885132,23
224fa701-c94c-4b1c-8a6f-f5c22f18e5c7,Semantic Host-free Trojan Attack,1,0.023218,0.0302,"In this paper, we propose a novel host-free Trojan attack with triggers that
are fixed in the semantic space but not necessarily in the pixel space. In
contrast to existing Trojan attacks which use clean input images as hosts to
carry small, meaningless trigger patterns, our attack considers triggers as
full-sized images belonging to a semantically meaningful object class. Since in
our attack, the backdoored classifier is encouraged to memorize the abstract
semantics of the trigger images than any specific fixed pattern, it can be
later triggered by semantically similar but different looking images. This
makes our attack more practical to be applied in the real-world and harder to
defend against. Extensive experimental results demonstrate that with only a
small number of Trojan patterns for training, our attack can generalize well to
new patterns of the same Trojan class and can bypass state-of-the-art defense
methods.",0,0,0,0,1,0,0.980435,6.0,0.960037,16
76d450ea-263a-4a9b-90b9-2e2242e88d9b,ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods,10,0.28183,0.441261,"Climate change is a major threat to humanity, and the actions required to
prevent its catastrophic consequences include changes in both policy-making and
individual behaviour. However, taking action requires understanding the effects
of climate change, even though they may seem abstract and distant. Projecting
the potential consequences of extreme climate events such as flooding in
familiar places can help make the abstract impacts of climate change more
concrete and encourage action. As part of a larger initiative to build a
website that projects extreme climate events onto user-chosen photos, we
present our solution to simulate photo-realistic floods on authentic images. To
address this complex task in the absence of suitable training data, we propose
ClimateGAN, a model that leverages both simulated and real data for
unsupervised domain adaptation and conditional image generation. In this paper,
we describe the details of our framework, thoroughly evaluate components of our
architecture and demonstrate that our model is capable of robustly generating
photo-realistic flooding.",0,1,0,1,0,0,0.960346,8.0,0.945286,65
ce01da97-fcc8-48a7-bc49-63e40fe35259,Cloud Collectives: Towards Cloud-aware Collectives forML Workloads with Rank Reordering,1,0.00277225,0.0347006,"ML workloads are becoming increasingly popular in the cloud. Good cloud
training performance is contingent on efficient parameter exchange among VMs.
We find that Collectives, the widely used distributed communication algorithms,
cannot perform optimally out of the box due to the hierarchical topology of
datacenter networks and multi-tenancy nature of the cloudenvironment.In this
paper, we present Cloud Collectives , a prototype that accelerates collectives
by reordering theranks of participating VMs such that the communication pattern
dictated by the selected collectives operation best exploits the locality in
the network.Collectives is non-intrusive, requires no code changes nor rebuild
of an existing application, and runs without support from cloud providers. Our
preliminary application of Cloud Collectives on allreduce operations in public
clouds results in a speedup of up to 3.7x in multiple microbenchmarks and 1.3x
in real-world workloads of distributed training of deep neural networks and
gradient boosted decision trees using state-of-the-art frameworks.",0,1,0,0,0,0,1.3496e-05,24.0,0.465727,48
ca8e7c90-ff5b-42db-be1f-e5b15f09d073,Improving Pretrained Models for Zero-shot Multi-label Text Classification through Reinforced Label Hierarchy Reasoning,18,0.14349,0.209979,"Exploiting label hierarchies has become a promising approach to tackling the
zero-shot multi-label text classification (ZS-MTC) problem. Conventional
methods aim to learn a matching model between text and labels, using a graph
encoder to incorporate label hierarchies to obtain effective label
representations \cite{rios2018few}. More recently, pretrained models like BERT
\cite{devlin2018bert} have been used to convert classification tasks into a
textual entailment task \cite{yin-etal-2019-benchmarking}. This approach is
naturally suitable for the ZS-MTC task. However, pretrained models are
underexplored in the existing work because they do not generate individual
vector representations for text or labels, making it unintuitive to combine
them with conventional graph encoding methods. In this paper, we explore to
improve pretrained models with label hierarchies on the ZS-MTC task. We propose
a Reinforced Label Hierarchy Reasoning (RLHR) approach to encourage
interdependence among labels in the hierarchies during training. Meanwhile, to
overcome the weakness of flat predictions, we design a rollback algorithm that
can remove logical errors from predictions during inference. Experimental
results on three real-life datasets show that our approach achieves better
performance and outperforms previous non-pretrained methods on the ZS-MTC task.",1,1,0,0,0,0,0.824682,4.0,0.736278,31
34d5bc3c-0906-4394-a781-bab2b7b70b4b,Word2Box: Capturing Set-Theoretic Semantics of Words using Box Embeddings,15,0.0730849,0.573927,"Learning representations of words in a continuous space is perhaps the most
fundamental task in NLP, however words interact in ways much richer than vector
dot product similarity can provide. Many relationships between words can be
expressed set-theoretically, for example, adjective-noun compounds (eg. ""red
cars""$\subseteq$""cars"") and homographs (eg. ""tongue""$\cap$""body"" should be
similar to ""mouth"", while ""tongue""$\cap$""language"" should be similar to
""dialect"") have natural set-theoretic interpretations. Box embeddings are a
novel region-based representation which provide the capability to perform these
set-theoretic operations. In this work, we provide a fuzzy-set interpretation
of box embeddings, and learn box representations of words using a set-theoretic
training objective. We demonstrate improved performance on various word
similarity tasks, particularly on less common words, and perform a quantitative
and qualitative analysis exploring the additional unique expressivity provided
by Word2Box.",1,0,0,0,0,0,0.165834,9.0,0.631454,54
b99be4a6-3f7a-4571-8f74-aafc4aac6c7f,"Causal Transformers Perform Below Chance on Recursive Nested Constructions, Unlike Humans",10,0.0431107,0.239898,"Recursive processing is considered a hallmark of human linguistic abilities.
A recent study evaluated recursive processing in recurrent neural language
models (RNN-LMs) and showed that such models perform below chance level on
embedded dependencies within nested constructions -- a prototypical example of
recursion in natural language. Here, we study if state-of-the-art Transformer
LMs do any better. We test four different Transformer LMs on two different
types of nested constructions, which differ in whether the embedded (inner)
dependency is short or long range. We find that Transformers achieve
near-perfect performance on short-range embedded dependencies, significantly
better than previous results reported for RNN-LMs and humans. However, on
long-range embedded dependencies, Transformers' performance sharply drops below
chance level. Remarkably, the addition of only three words to the embedded
dependency caused Transformers to fall from near-perfect to below-chance
performance. Taken together, our results reveal Transformers' shortcoming when
it comes to recursive, structure-based, processing.",0,0,0,0,0,0,0.219208,7.0,0.570572,36
871db8e8-a70d-4c03-86b0-1b4a747f9541,You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors,85,0.7739,0.925922,"In this paper, we propose a novel local descriptor-based framework, called
You Only Hypothesize Once (YOHO), for the registration of two unaligned point
clouds. In contrast to most existing local descriptors which rely on a fragile
local reference frame to gain rotation invariance, the proposed descriptor
achieves the rotation invariance by recent technologies of group equivariant
feature learning, which brings more robustness to point density and noise.
Meanwhile, the descriptor in YOHO also has a rotation equivariant part, which
enables us to estimate the registration from just one correspondence
hypothesis. Such property reduces the searching space for feasible
transformations, thus greatly improves both the accuracy and the efficiency of
YOHO. Extensive experiments show that YOHO achieves superior performances with
much fewer needed RANSAC iterations on four widely-used datasets, the
3DMatch/3DLoMatch datasets, the ETH dataset and the WHU-TLS dataset. More
details are shown in our project page: https://hpwang-whu.github.io/YOHO/.",1,0,0,0,0,0,0.785563,5.0,0.764435,99
e7e603fc-3c72-4a55-ab06-c40a7c1aa6cb,Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama,67,0.0858894,0.587794,"The concept of literary genre is a highly complex one: not only are different
genres frequently defined on several, but not necessarily the same levels of
description, but consideration of genres as cognitive, social, or scholarly
constructs with a rich history further complicate the matter. This contribution
focuses on thematic aspects of genre with a quantitative approach, namely Topic
Modeling. Topic Modeling has proven to be useful to discover thematic patterns
and trends in large collections of texts, with a view to class or browse them
on the basis of their dominant themes. It has rarely if ever, however, been
applied to collections of dramatic texts.
  In this contribution, Topic Modeling is used to analyze a collection of
French Drama of the Classical Age and the Enlightenment. The general aim of
this contribution is to discover what semantic types of topics are found in
this collection, whether different dramatic subgenres have distinctive dominant
topics and plot-related topic patterns, and inversely, to what extent
clustering methods based on topic scores per play produce groupings of texts
which agree with more conventional genre distinctions. This contribution shows
that interesting topic patterns can be detected which provide new insights into
the thematic, subgenre-related structure of French drama as well as into the
history of French drama of the Classical Age and the Enlightenment.",0,0,0,0,0,0,0.0372369,8.0,0.389877,44
38bc31c6-10e5-4972-945d-533850eac831,Matching with Transformers in MELT,9,0.123705,0.292145,"One of the strongest signals for automated matching of ontologies and
knowledge graphs are the textual descriptions of the concepts. The methods that
are typically applied (such as character- or token-based comparisons) are
relatively simple, and therefore do not capture the actual meaning of the
texts. With the rise of transformer-based language models, text comparison
based on meaning (rather than lexical features) is possible. In this paper, we
model the ontology matching task as classification problem and present
approaches based on transformer models. We further provide an easy to use
implementation in the MELT framework which is suited for ontology and knowledge
graph matching. We show that a transformer-based filter helps to choose the
correct correspondences given a high-recall alignment and already achieves a
good result with simple alignment post-processing methods.",0,1,0,0,0,0,0.733703,5.0,0.734115,20
f25c1eb4-fcb2-486d-be73-364e4e2b60ec,A Switched View of Retinex: Deep Self-Regularized Low-Light Image Enhancement,42,0.600456,0.714199,"Self-regularized low-light image enhancement does not require any
normal-light image in training, thereby freeing from the chains on paired or
unpaired low-/normal-images. However, existing methods suffer color deviation
and fail to generalize to various lighting conditions. This paper presents a
novel self-regularized method based on Retinex, which, inspired by HSV,
preserves all colors (Hue, Saturation) and only integrates Retinex theory into
brightness (Value). We build a reflectance estimation network by restricting
the consistency of reflectances embedded in both the original and a novel
random disturbed form of the brightness of the same scene. The generated
reflectance, which is assumed to be irrelevant of illumination by Retinex, is
treated as enhanced brightness. Our method is efficient as a low-light image is
decoupled into two subspaces, color and brightness, for better preservation and
enhancement. Extensive experiments demonstrate that our method outperforms
multiple state-of-the-art algorithms qualitatively and quantitatively and
adapts to more lighting conditions.",0,1,0,0,1,0,0.986566,12.0,0.987624,26
578c2507-96ab-4a7b-9dfb-c9b1ee5a2bf7,HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network that Achieves over 0.9 Mean Dice and 86 FPS,146,0.997067,0.780394,"We propose a new convolution neural network called HarDNet-MSEG for polyp
segmentation. It achieves SOTA in both accuracy and inference speed on five
popular datasets. For Kvasir-SEG, HarDNet-MSEG delivers 0.904 mean Dice running
at 86.7 FPS on a GeForce RTX 2080 Ti GPU. It consists of a backbone and a
decoder. The backbone is a low memory traffic CNN called HarDNet68, which has
been successfully applied to various CV tasks including image classification,
object detection, multi-object tracking and semantic segmentation, etc. The
decoder part is inspired by the Cascaded Partial Decoder, known for fast and
accurate salient object detection. We have evaluated HarDNet-MSEG using those
five popular datasets. The code and all experiment details are available at
Github. https://github.com/james128333/HarDNet-MSEG",1,1,0,0,1,0,0.959099,8.0,0.944081,36
6adad720-de27-481f-b0fe-f6a30a7f86ea,Cross-Modal Discrete Representation Learning,34,0.55657,0.576736,"Recent advances in representation learning have demonstrated an ability to
represent information from different modalities such as video, text, and audio
in a single high-level embedding vector. In this work we present a
self-supervised learning framework that is able to learn a representation that
captures finer levels of granularity across different modalities such as
concepts or events represented by visual objects or spoken words. Our framework
relies on a discretized embedding space created via vector quantization that is
shared across different modalities. Beyond the shared embedding space, we
propose a Cross-Modal Code Matching objective that forces the representations
from different views (modalities) to have a similar distribution over the
discrete embedding space such that cross-modal objects/actions localization can
be performed without direct supervision. In our experiments we show that the
proposed discretized multi-modal fine-grained representation (e.g.,
pixel/word/frame) can complement high-level summary representations (e.g.,
video/sentence/waveform) for improved performance on cross-modal retrieval
tasks. We also observe that the discretized representation uses individual
clusters to represent the same semantic concept across modalities.",0,0,0,0,0,0,0.935657,5.0,0.879961,47
c7e92b93-7aaf-426b-b9da-b2b5274e55cf,End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net,16,0.0445459,0.35022,"Information extraction from document images has received a lot of attention
recently, due to the need for digitizing a large volume of unstructured
documents such as invoices, receipts, bank transfers, etc. In this paper, we
propose a novel deep learning architecture for end-to-end information
extraction on the 2D character-grid embedding of the document, namely the
\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and
spatial relations between 2D elements, our model leverages a specialized
multi-stage encoder-decoders design, in conjunction with efficient uses of the
self-attention mechanism and the box convolution. Experimental results on
different datasets show that our model outperforms the baseline U-Net
architecture by a large margin while using 40\% fewer parameters. Moreover, it
also significantly improved the baseline in erroneous OCR and limited training
data scenario, thus becomes practical for real-world applications.",1,1,0,0,1,0,0.00401398,13.0,0.451892,33
5a448944-f47b-4d69-a518-37637518c542,Temporal-Relational CrossTransformers for Few-Shot Action Recognition,112,0.72797,0.799717,"We propose a novel approach to few-shot action recognition, finding
temporally-corresponding frame tuples between the query and videos in the
support set. Distinct from previous few-shot works, we construct class
prototypes using the CrossTransformer attention mechanism to observe relevant
sub-sequences of all support videos, rather than using class averages or single
best matches. Video representations are formed from ordered tuples of varying
numbers of frames, which allows sub-sequences of actions at different speeds
and temporal offsets to be compared.
  Our proposed Temporal-Relational CrossTransformers (TRX) achieve
state-of-the-art results on few-shot splits of Kinetics, Something-Something V2
(SSv2), HMDB51 and UCF101. Importantly, our method outperforms prior work on
SSv2 by a wide margin (12%) due to the its ability to model temporal relations.
A detailed ablation showcases the importance of matching to multiple support
set videos and learning higher-order relational CrossTransformers.",1,1,0,0,1,0,0.906846,6.0,0.875821,36
81ea272b-d1de-4776-b9c6-a94b94e0bf35,Vogtareuth Rehab Depth Datasets: Benchmark for Marker-less Posture Estimation in Rehabilitation,1,0.0445628,0.116204,"Posture estimation using a single depth camera has become a useful tool for
analyzing movements in rehabilitation. Recent advances in posture estimation in
computer vision research have been possible due to the availability of
large-scale pose datasets. However, the complex postures involved in
rehabilitation exercises are not represented in the existing benchmark depth
datasets. To address this limitation, we propose two rehabilitation-specific
pose datasets containing depth images and 2D pose information of patients, both
adult and children, performing rehab exercises. We use a state-of-the-art
marker-less posture estimation model which is trained on a non-rehab benchmark
dataset. We evaluate it on our rehab datasets, and observe that the performance
degrades significantly from non-rehab to rehab, highlighting the need for these
datasets. We show that our dataset can be used to train pose models to detect
rehab-specific complex postures. The datasets will be released for the benefit
of the research community.",0,1,1,1,0,0,0.512298,11.0,0.823577,18
d43e9f4c-c384-44df-84db-778065c6c982,Natural language understanding for logical games,1,0.0022741,0.0271744,"We developed a system able to automatically solve logical puzzles in natural
language. Our solution is composed by a parser and an inference module. The
parser translates the text into first order logic (FOL), while the MACE4 model
finder is used to compute the models of the given FOL theory. We also empower
our software agent with the capability to provide Yes/No answers to natural
language questions related to each puzzle. Moreover, in line with Explainalbe
Artificial Intelligence (XAI), the agent can back its answer, providing a
graphical representation of the proof. The advantage of using reasoning for
Natural Language Understanding (NLU) instead of Machine learning is that the
user can obtain an explanation of the reasoning chain. We illustrate how the
system performs on various types of natural language puzzles, including 382
knights and knaves puzzles. These features together with the overall
performance rate of 80.89\% makes the proposed solution an improvement upon
similar solvers for natural language understanding in the puzzles domain.",0,0,0,0,0,0,0.00275477,10.0,0.249752,18
adbecd19-9725-48f5-ad72-6701ae6f98b6,Learn to Resolve Conversational Dependency: A Consistency Training Framework for Conversational Question Answering,32,0.611826,0.563072,"One of the main challenges in conversational question answering (CQA) is to
resolve the conversational dependency, such as anaphora and ellipsis. However,
existing approaches do not explicitly train QA models on how to resolve the
dependency, and thus these models are limited in understanding human dialogues.
In this paper, we propose a novel framework, ExCorD (Explicit guidance on how
to resolve Conversational Dependency) to enhance the abilities of QA models in
comprehending conversational context. ExCorD first generates self-contained
questions that can be understood without the conversation history, then trains
a QA model with the pairs of original and self-contained questions using a
consistency-based regularizer. In our experiments, we demonstrate that ExCorD
significantly improves the QA models' performance by up to 1.2 F1 on QuAC, and
5.2 F1 on CANARD, while addressing the limitations of the existing approaches.",1,1,0,0,1,0,0.956566,5.0,0.906734,41
f05d328c-1a43-4be5-a0be-58ec7f884724,BlockCopy: High-Resolution Video Processing with Block-Sparse Feature Propagation and Online Policies,11,0.0332314,0.284982,"In this paper we propose BlockCopy, a scheme that accelerates pretrained
frame-based CNNs to process video more efficiently, compared to standard
frame-by-frame processing. To this end, a lightweight policy network determines
important regions in an image, and operations are applied on selected regions
only, using custom block-sparse convolutions. Features of non-selected regions
are simply copied from the preceding frame, reducing the number of computations
and latency. The execution policy is trained using reinforcement learning in an
online fashion without requiring ground truth annotations. Our universal
framework is demonstrated on dense prediction tasks such as pedestrian
detection, instance segmentation and semantic segmentation, using both state of
the art (Center and Scale Predictor, MGAN, SwiftNet) and standard baseline
networks (Mask-RCNN, DeepLabV3+). BlockCopy achieves significant FLOPS savings
and inference speedup with minimal impact on accuracy.",0,1,0,0,0,0,0.183677,8.0,0.599468,50
551577e5-ee41-4489-adc4-8d83c721e395,Improving Person Re-Identification with Temporal Constraints,4,0.0228946,0.254956,"In this paper we introduce an image-based person re-identification dataset
collected across five non-overlapping camera views in the large and busy
airport in Dublin, Ireland. Unlike all publicly available image-based datasets,
our dataset contains timestamp information in addition to frame number, and
camera and person IDs. Also our dataset has been fully anonymized to comply
with modern data privacy regulations. We apply state-of-the-art person
re-identification models to our dataset and show that by leveraging the
available timestamp information we are able to achieve a significant gain of
37.43% in mAP and a gain of 30.22% in Rank1 accuracy. We also propose a
Bayesian temporal re-ranking post-processing step, which further adds a 10.03%
gain in mAP and 9.95% gain in Rank1 accuracy metrics. This work on combining
visual and temporal information is not possible on other image-based person
re-identification datasets. We believe that the proposed new dataset will
enable further development of person re-identification research for challenging
real-world applications. DAA dataset can be downloaded from
https://bit.ly/3AtXTd6",1,1,1,1,1,0,0.272582,9.0,0.693962,33
e3884c6c-056b-42e9-b68e-585a20247531,Optimizing High-Dimensional Physics Simulations via Composite Bayesian Optimization,6,0.0789612,0.255858,"Physical simulation-based optimization is a common task in science and
engineering. Many such simulations produce image- or tensor-based outputs where
the desired objective is a function of those outputs, and optimization is
performed over a high-dimensional parameter space. We develop a Bayesian
optimization method leveraging tensor-based Gaussian process surrogates and
trust region Bayesian optimization to effectively model the image outputs and
to efficiently optimize these types of simulations, including a radio-frequency
tower configuration problem and an optical design problem.",0,1,0,0,0,0,0.741571,6.0,0.782164,21
14112390-d476-4ede-ba7a-025d9ca1ea98,Synthetic Data for Multi-Parameter Camera-Based Physiological Sensing,11,0.272115,0.671593,"Synthetic data is a powerful tool in training data hungry deep learning
algorithms. However, to date, camera-based physiological sensing has not taken
full advantage of these techniques. In this work, we leverage a high-fidelity
synthetics pipeline for generating videos of faces with faithful blood flow and
breathing patterns. We present systematic experiments showing how
physiologically-grounded synthetic data can be used in training camera-based
multi-parameter cardiopulmonary sensing. We provide empirical evidence that
heart and breathing rate measurement accuracy increases with the number of
synthetic avatars in the training set. Furthermore, training with avatars with
darker skin types leads to better overall performance than training with
avatars with lighter skin types. Finally, we discuss the opportunities that
synthetics present in the domain of camera-based physiological sensing and
limitations that need to be overcome.",0,1,0,1,0,0,0.498069,11.0,0.819861,42
528f9948-2136-4c18-a9fd-335902976e23,Evaluation of Unsupervised Entity and Event Salience Estimation,4,0.0254082,0.0572601,"Salience Estimation aims to predict term importance in documents. Due to few
existing human-annotated datasets and the subjective notion of salience,
previous studies typically generate pseudo-ground truth for evaluation.
However, our investigation reveals that the evaluation protocol proposed by
prior work is difficult to replicate, thus leading to few follow-up studies
existing. Moreover, the evaluation process is problematic: the entity linking
tool used for entity matching is very noisy, while the ignorance of event
argument for event evaluation leads to boosted performance. In this work, we
propose a light yet practical entity and event salience estimation evaluation
protocol, which incorporates the more reliable syntactic dependency parser.
Furthermore, we conduct a comprehensive analysis among popular entity and event
definition standards, and present our own definition for the Salience
Estimation task to reduce noise during the pseudo-ground truth generation
process. Furthermore, we construct dependency-based heterogeneous graphs to
capture the interactions of entities and events. The empirical results show
that both baseline methods and the novel GNN method utilizing the heterogeneous
graph consistently outperform the previous SOTA model in all proposed metrics.",0,1,0,0,1,0,0.0374095,12.0,0.593645,24
c8ff8879-8f79-4781-8d46-569fb0a12a92,Reducing Label Effort: Self-Supervised meets Active Learning,52,0.15183,0.494414,"Active learning is a paradigm aimed at reducing the annotation effort by
training the model on actively selected informative and/or representative
samples. Another paradigm to reduce the annotation effort is self-training that
learns from a large amount of unlabeled data in an unsupervised way and
fine-tunes on few labeled samples. Recent developments in self-training have
achieved very impressive results rivaling supervised learning on some datasets.
The current work focuses on whether the two paradigms can benefit from each
other. We studied object recognition datasets including CIFAR10, CIFAR100 and
Tiny ImageNet with several labeling budgets for the evaluations. Our
experiments reveal that self-training is remarkably more efficient than active
learning at reducing the labeling effort, that for a low labeling budget,
active learning offers no benefit to self-training, and finally that the
combination of active learning and self-training is fruitful when the labeling
budget is high. The performance gap between active learning trained either with
self-training or from scratch diminishes as we approach to the point where
almost half of the dataset is labeled.",0,1,0,0,0,1,0.380411,7.0,0.66484,56
cf259a0e-88cb-4c4b-98a4-e33fdbaf864d,Bridging the gap between streaming and non-streaming ASR systems bydistilling ensembles of CTC and RNN-T models,5,0.019895,0.219797,"Streaming end-to-end automatic speech recognition (ASR) systems are widely
used in everyday applications that require transcribing speech to text in
real-time. Their minimal latency makes them suitable for such tasks. Unlike
their non-streaming counterparts, streaming models are constrained to be causal
with no future context and suffer from higher word error rates (WER). To
improve streaming models, a recent study [1] proposed to distill a
non-streaming teacher model on unsupervised utterances, and then train a
streaming student using the teachers' predictions. However, the performance gap
between teacher and student WERs remains high. In this paper, we aim to close
this gap by using a diversified set of non-streaming teacher models and
combining them using Recognizer Output Voting Error Reduction (ROVER). In
particular, we show that, despite being weaker than RNN-T models, CTC models
are remarkable teachers. Further, by fusing RNN-T and CTC models together, we
build the strongest teachers. The resulting student models drastically improve
upon streaming models of previous work [1]: the WER decreases by 41% on
Spanish, 27% on Portuguese, and 13% on French.",0,1,0,0,0,0,0.567481,4.0,0.553495,29
dab51fc3-8b80-442c-a6da-ea8ce2326357,Integrating LSTMs and GNNs for COVID-19 Forecasting,14,0.32696,0.730644,"The spread of COVID-19 has coincided with the rise of Graph Neural Networks
(GNNs), leading to several studies proposing their use to better forecast the
evolution of the pandemic. Many such models also include Long Short Term Memory
(LSTM) networks, a common tool for time series forecasting. In this work, we
further investigate the integration of these two methods by implementing GNNs
within the gates of an LSTM and exploiting spatial information. In addition, we
introduce a skip connection which proves critical to jointly capture the
spatial and temporal patterns in the data. We validate our daily COVID-19 new
cases forecast model on data of 37 European nations for the last 472 days and
show superior performance compared to state-of-the-art graph time series models
based on mean absolute scaled error (MASE). This area of research has important
applications to policy-making and we analyze its potential for pandemic
resource control.",1,1,0,0,1,0,0.988642,3.0,0.963232,33
b2d3155f-c180-48f5-87b2-7656480f29f4,Predicting Rebar Endpoints using Sin Exponential Regression Model,2,0.0735761,0.100937,"Currently, unmanned automation studies are underway to minimize the loss rate
of rebar production and the time and accuracy of calibration when producing
defective products in the cutting process of processing rebar factories. In
this paper, we propose a method to detect and track rebar endpoint images
entering the machine vision camera based on YOLO (You Only Look Once)v3, and to
predict rebar endpoint in advance with sin exponential regression of acquired
coordinates. The proposed method solves the problem of large prediction error
rates for frame locations where rebar endpoints are far away in OPPDet (Object
Position Prediction Detect) models, which prepredict rebar endpoints with
improved results showing 0.23 to 0.52% less error rates at sin exponential
regression prediction points.",0,1,0,0,0,0,0.115662,8.0,0.536788,4
ebc5f658-9b7b-4392-892b-1e658265cd53,CPM-2: Large-scale Cost-effective Pre-trained Language Models,76,0.170771,0.557109,"In recent years, the size of pre-trained language models (PLMs) has grown by
leaps and bounds. However, efficiency issues of these large-scale PLMs limit
their utilization in real-world scenarios. We present a suite of cost-effective
techniques for the use of PLMs to deal with the efficiency issues of
pre-training, fine-tuning, and inference. (1) We introduce knowledge
inheritance to accelerate the pre-training process by exploiting existing PLMs
instead of training models from scratch. (2) We explore the best practice of
prompt tuning with large-scale PLMs. Compared with conventional fine-tuning,
prompt tuning significantly reduces the number of task-specific parameters. (3)
We implement a new inference toolkit, namely InfMoE, for using large-scale PLMs
with limited computational resources. Based on our cost-effective pipeline, we
pre-train two models: an encoder-decoder bilingual model with 11 billion
parameters (CPM-2) and its corresponding MoE version with 198 billion
parameters. In our experiments, we compare CPM-2 with mT5 on downstream tasks.
Experimental results show that CPM-2 has excellent general language
intelligence. Moreover, we validate the efficiency of InfMoE when conducting
inference of large-scale models having tens of billions of parameters on a
single GPU. All source code and model parameters are available at
https://github.com/TsinghuaAI/CPM.",1,1,0,0,0,0,0.821396,3.0,0.644796,44
23d1b212-5047-4d58-aef1-8035be6688b2,Tackling the Background Bias in Sparse Object Detection via Cropped Windows,7,0.0664786,0.0783247,"Object detection on Unmanned Aerial Vehicles (UAVs) is still a challenging
task. The recordings are mostly sparse and contain only small objects. In this
work, we propose a simple tiling method that improves the detection capability
in the remote sensing case without modifying the model itself. By reducing the
background bias and enabling the usage of higher image resolutions during
training, our method can improve the performance of models substantially. The
procedure was validated on three different data sets and outperformed similar
approaches in performance and speed.",1,1,0,0,1,0,0.832943,5.0,0.794491,33
be4d4064-b39b-47b0-97e0-3207c8146162,LED2-Net: Monocular 360 Layout Estimation via Differentiable Depth Rendering,40,0.532364,0.987307,"Although significant progress has been made in room layout estimation, most
methods aim to reduce the loss in the 2D pixel coordinate rather than
exploiting the room structure in the 3D space. Towards reconstructing the room
layout in 3D, we formulate the task of 360 layout estimation as a problem of
predicting depth on the horizon line of a panorama. Specifically, we propose
the Differentiable Depth Rendering procedure to make the conversion from layout
to depth prediction differentiable, thus making our proposed model end-to-end
trainable while leveraging the 3D geometric information, without the need of
providing the ground truth depth. Our method achieves state-of-the-art
performance on numerous 360 layout benchmark datasets. Moreover, our
formulation enables a pre-training step on the depth dataset, which further
improves the generalizability of our layout estimation model.",1,1,0,0,1,0,0.857285,7.0,0.865258,30
88218e58-9b35-4d6d-8beb-beb73237c9d5,Optimal personalised treatment computation through in silico clinical trials on patient digital twins,23,0.216207,0.554826,"In Silico Clinical Trials (ISTC), i.e., clinical experimental campaigns
carried out by means of computer simulations, hold the promise to decrease time
and cost for the safety and efficacy assessment of pharmacological treatments,
reduce the need for animal and human testing, and enable precision medicine. In
this paper we present methods and an algorithm that, by means of extensive
computer simulation--based experimental campaigns (ISTC) guided by intelligent
search, optimise a pharmacological treatment for an individual patient
(precision medicine). e show the effectiveness of our approach on a case study
involving a real pharmacological treatment, namely the downregulation phase of
a complex clinical protocol for assisted reproduction in humans.",0,0,0,0,0,0,0.00767146,13.0,0.501859,82
9a820b75-46f5-4449-a210-89544b4f6eec,Investigating Failures of Automatic Translation in the Case of Unambiguous Gender,27,0.0648457,0.732185,"Transformer based models are the modern work horses for neural machine
translation (NMT), reaching state of the art across several benchmarks. Despite
their impressive accuracy, we observe a systemic and rudimentary class of
errors made by transformer based models with regards to translating from a
language that doesn't mark gender on nouns into others that do. We find that
even when the surrounding context provides unambiguous evidence of the
appropriate grammatical gender marking, no transformer based model we tested
was able to accurately gender occupation nouns systematically. We release an
evaluation scheme and dataset for measuring the ability of transformer based
NMT models to translate gender morphology correctly in unambiguous contexts
across syntactically diverse sentences. Our dataset translates from an English
source into 20 languages from several different language families. With the
availability of this dataset, our hope is that the NMT community can iterate on
solutions for this class of especially egregious errors.",0,1,1,1,0,0,0.241435,5.0,0.420878,64
26383db2-2ab2-4466-a471-6ea267949248,Multimodal Knowledge Expansion,21,0.29268,0.820227,"The popularity of multimodal sensors and the accessibility of the Internet
have brought us a massive amount of unlabeled multimodal data. Since existing
datasets and well-trained models are primarily unimodal, the modality gap
between a unimodal network and unlabeled multimodal data poses an interesting
problem: how to transfer a pre-trained unimodal network to perform the same
task on unlabeled multimodal data? In this work, we propose multimodal
knowledge expansion (MKE), a knowledge distillation-based framework to
effectively utilize multimodal data without requiring labels. Opposite to
traditional knowledge distillation, where the student is designed to be
lightweight and inferior to the teacher, we observe that a multimodal student
model consistently denoises pseudo labels and generalizes better than its
teacher. Extensive experiments on four tasks and different modalities verify
this finding. Furthermore, we connect the mechanism of MKE to semi-supervised
learning and offer both empirical and theoretical explanations to understand
the denoising capability of a multimodal student.",1,0,0,0,0,0,0.975268,6.0,0.949801,53
e10bcd4b-c519-4cca-b334-20bb030bfce1,Artificial Intelligence based Autonomous Molecular Design for Medical Therapeutic: A Perspective,2,0.0200998,0.0595837,"Domain-aware machine learning (ML) models have been increasingly adopted for
accelerating small molecule therapeutic design in the recent years. These
models have been enabled by significant advancement in state-of-the-art
artificial intelligence (AI) and computing infrastructures. Several ML
architectures are pre-dominantly and independently used either for predicting
the properties of small molecules, or for generating lead therapeutic
candidates. Synergetically using these individual components along with robust
representation and data generation techniques autonomously in closed loops
holds enormous promise for accelerated drug design which is a time consuming
and expensive task otherwise. In this perspective, we present the most recent
breakthrough achieved by each of the components, and how such autonomous AI and
ML workflow can be realized to radically accelerate the hit identification and
lead optimization. Taken together, this could significantly shorten the
timeline for end-to-end antiviral discovery and optimization times to weeks
upon the arrival of a novel zoonotic transmission event. Our perspective serves
as a guide for researchers to practice autonomous molecular design in
therapeutic discovery.",0,0,0,0,0,0,0.48516,7.0,0.711563,112
5d455fc7-7b9a-4f58-91a9-23041760fc61,Detecting Inappropriate Messages on Sensitive Topics that Could Harm a Company's Reputation,9,0.074081,0.522717,"Not all topics are equally ""flammable"" in terms of toxicity: a calm
discussion of turtles or fishing less often fuels inappropriate toxic dialogues
than a discussion of politics or sexual minorities. We define a set of
sensitive topics that can yield inappropriate and toxic messages and describe
the methodology of collecting and labeling a dataset for appropriateness. While
toxicity in user-generated data is well-studied, we aim at defining a more
fine-grained notion of inappropriateness. The core of inappropriateness is that
it can harm the reputation of a speaker. This is different from toxicity in two
respects: (i) inappropriateness is topic-related, and (ii) inappropriate
message is not toxic but still unacceptable. We collect and release two
datasets for Russian: a topic-labeled dataset and an appropriateness-labeled
dataset. We also release pre-trained classification models trained on this
data.",0,1,0,1,0,0,0.794315,4.0,0.712219,23
6927fd09-d1e4-4e6b-bf5c-64b63257b182,X2Teeth: 3D Teeth Reconstruction from a Single Panoramic Radiograph,19,0.394469,0.412652,"3D teeth reconstruction from X-ray is important for dental diagnosis and many
clinical operations. However, no existing work has explored the reconstruction
of teeth for a whole cavity from a single panoramic radiograph. Different from
single object reconstruction from photos, this task has the unique challenge of
constructing multiple objects at high resolutions. To conquer this task, we
develop a novel ConvNet X2Teeth that decomposes the task into teeth
localization and single-shape estimation. We also introduce a patch-based
training strategy, such that X2Teeth can be end-to-end trained for optimal
performance. Extensive experiments show that our method can successfully
estimate the 3D structure of the cavity and reflect the details for each tooth.
Moreover, X2Teeth achieves a reconstruction IoU of 0.681, which significantly
outperforms the encoder-decoder method by $1.71X and the retrieval-based method
by $1.52X. Our method can also be promising for other multi-anatomy 3D
reconstruction tasks.",0,1,1,0,1,0,0.115383,15.0,0.752783,16
560e11f4-c235-44bd-9fc1-ee4a538f9f13,Scaling Ensemble Distribution Distillation to Many Classes with Proxy Targets,16,0.106723,0.648403,"Ensembles of machine learning models yield improved system performance as
well as robust and interpretable uncertainty estimates; however, their
inference costs may often be prohibitively high. \emph{Ensemble Distribution
Distillation} is an approach that allows a single model to efficiently capture
both the predictive performance and uncertainty estimates of an ensemble. For
classification, this is achieved by training a Dirichlet distribution over the
ensemble members' output distributions via the maximum likelihood criterion.
Although theoretically principled, this criterion exhibits poor convergence
when applied to large-scale tasks where the number of classes is very high. In
our work, we analyze this effect and show that the Dirichlet log-likelihood
criterion classes with low probability induce larger gradients than
high-probability classes. This forces the model to focus on the distribution of
the ensemble tail-class probabilities. We propose a new training objective that
minimizes the reverse KL-divergence to a \emph{Proxy-Dirichlet} target derived
from the ensemble. This loss resolves the gradient issues of Ensemble
Distribution Distillation, as we demonstrate both theoretically and empirically
on the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes,
respectively.",0,0,0,0,0,0,0.880067,6.0,0.857061,43
8353718d-6f90-469b-9d85-29ee64f5b819,A NIR-to-VIS face recognition via part adaptive and relation attention module,3,0.114447,0.192882,"In the face recognition application scenario, we need to process facial
images captured in various conditions, such as at night by near-infrared (NIR)
surveillance cameras. The illumination difference between NIR and visible-light
(VIS) causes a domain gap between facial images, and the variations in pose and
emotion also make facial matching more difficult. Heterogeneous face
recognition (HFR) has difficulties in domain discrepancy, and many studies have
focused on extracting domain-invariant features, such as facial part relational
information. However, when pose variation occurs, the facial component position
changes, and a different part relation is extracted. In this paper, we propose
a part relation attention module that crops facial parts obtained through a
semantic mask and performs relational modeling using each of these
representative features. Furthermore, we suggest component adaptive triplet
loss function using adaptive weights for each part to reduce the intra-class
identity regardless of the domain as well as pose. Finally, our method exhibits
a performance improvement in the CASIA NIR-VIS 2.0 and achieves superior result
in the BUAA-VisNir with large pose and emotion variations.",0,1,0,0,0,0,0.84799,9.0,0.89154,21
b0ba4c61-333f-46fc-80f0-3d6f5bf441fa,Blending Anti-Aliasing into Vision Transformer,18,0.384839,0.704723,"The transformer architectures, based on self-attention mechanism and
convolution-free design, recently found superior performance and booming
applications in computer vision. However, the discontinuous patch-wise
tokenization process implicitly introduces jagged artifacts into attention
maps, arising the traditional problem of aliasing for vision transformers.
Aliasing effect occurs when discrete patterns are used to produce high
frequency or continuous information, resulting in the indistinguishable
distortions. Recent researches have found that modern convolution networks
still suffer from this phenomenon. In this work, we analyze the uncharted
problem of aliasing in vision transformer and explore to incorporate
anti-aliasing properties. Specifically, we propose a plug-and-play
Aliasing-Reduction Module(ARM) to alleviate the aforementioned issue. We
investigate the effectiveness and generalization of the proposed method across
multiple tasks and various vision transformer families. This lightweight design
consistently attains a clear boost over several famous structures. Furthermore,
our module also improves data efficiency and robustness of vision transformers.",0,1,0,0,0,0,0.986819,3.0,0.951966,69
784bf71b-5486-4009-8c6c-1c7c2b70899b,"An open access NLP dataset for Arabic dialects : Data collection, labeling, and model construction",14,0.490535,0.663561,"Natural Language Processing (NLP) is today a very active field of research
and innovation. Many applications need however big sets of data for supervised
learning, suitably labelled for the training purpose. This includes
applications for the Arabic language and its national dialects. However, such
open access labeled data sets in Arabic and its dialects are lacking in the
Data Science ecosystem and this lack can be a burden to innovation and research
in this field. In this work, we present an open data set of social data content
in several Arabic dialects. This data was collected from the Twitter social
network and consists on +50K twits in five (5) national dialects. Furthermore,
this data was labeled for several applications, namely dialect detection, topic
detection and sentiment analysis. We publish this data as an open access data
to encourage innovation and encourage other works in the field of NLP for
Arabic dialects and social media. A selection of models were built using this
data set and are presented in this paper along with their performances.",0,1,1,1,0,0,0.427666,8.0,0.725903,20
de962e01-9b9a-4976-b7c9-f3657828f06f,A Gradient Estimator for Time-Varying Electrical Networks with Non-Linear Dissipation,6,0.0751775,0.700544,"We propose a method for extending the technique of equilibrium propagation
for estimating gradients in fixed-point neural networks to the more general
setting of directed, time-varying neural networks by modeling them as
electrical circuits. We use electrical circuit theory to construct a Lagrangian
capable of describing deep, directed neural networks modeled using nonlinear
capacitors and inductors, linear resistors and sources, and a special class of
nonlinear dissipative elements called fractional memristors. We then derive an
estimator for the gradient of the physical parameters of the network, such as
synapse conductances, with respect to an arbitrary loss function. This
estimator is entirely local, in that it only depends on information locally
available to each synapse. We conclude by suggesting methods for extending
these results to networks of biologically plausible neurons, e.g.
Hodgkin-Huxley neurons.",0,0,0,0,0,0,0.397643,18.0,0.872841,39
68117993-2341-4a1c-a847-d905c679b5ae,Analyzing the Effects of Reasoning Types on Cross-Lingual Transfer Performance,10,0.196598,0.422124,"Multilingual language models achieve impressive zero-shot accuracies in many
languages in complex tasks such as Natural Language Inference (NLI). Examples
in NLI (and equivalent complex tasks) often pertain to various types of
sub-tasks, requiring different kinds of reasoning. Certain types of reasoning
have proven to be more difficult to learn in a monolingual context, and in the
crosslingual context, similar observations may shed light on zero-shot transfer
efficiency and few-shot sample selection. Hence, to investigate the effects of
types of reasoning on transfer performance, we propose a category-annotated
multilingual NLI dataset and discuss the challenges to scale monolingual
annotations to multiple languages. We statistically observe interesting effects
that the confluence of reasoning types and language similarities have on
transfer performance.",0,0,0,0,0,0,0.969668,4.0,0.910513,22
5e5c0404-a2ce-4421-bbdb-0c53cb48923b,PatchNet -- Short-range Template Matching for Efficient Video Processing,3,0.00917478,0.0709163,"Object recognition is a fundamental problem in many video processing tasks,
accurately locating seen objects at low computation cost paves the way for
on-device video recognition. We propose PatchNet, an efficient convolutional
neural network to match objects in adjacent video frames. It learns the
patchwise correlation features instead of pixel features. PatchNet is very
compact, running at just 58MFLOPs, $5\times$ simpler than MobileNetV2. We
demonstrate its application on two tasks, video object detection and visual
object tracking. On ImageNet VID, PatchNet reduces the flops of R-FCN
ResNet-101 by 5x and EfficientDet-D0 by 3.4x with less than 1% mAP loss. On
OTB2015, PatchNet reduces SiamFC and SiamRPN by 2.5x with no accuracy loss.
Experiments on Jetson Nano further demonstrate 2.8x to 4.3x speed-ups
associated with flops reduction. Code is open sourced at
https://github.com/RalphMao/PatchNet.",1,1,1,0,0,0,0.597807,6.0,0.716193,35
de87946f-3e10-42e3-9857-413fbbdec6d8,Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?,66,0.380733,0.952001,"Five years after the first published proofs of concept, direct approaches to
speech translation (ST) are now competing with traditional cascade solutions.
In light of this steady progress, can we claim that the performance gap between
the two is closed? Starting from this question, we present a systematic
comparison between state-of-the-art systems representative of the two
paradigms. Focusing on three language directions
(English-German/Italian/Spanish), we conduct automatic and manual evaluations,
exploiting high-quality professional post-edits and annotations. Our
multi-faceted analysis on one of the few publicly available ST benchmarks
attests for the first time that: i) the gap between the two paradigms is now
closed, and ii) the subtle differences observed in their behavior are not
sufficient for humans neither to distinguish them nor to prefer one over the
other.",0,1,0,0,0,0,0.200025,7.0,0.555823,72
23ffe022-d3b0-4d53-882f-a80b4aa95b52,String Theories involving Regular Membership Predicates: From Practice to Theory and Back,5,0.0615677,0.102018,"Widespread use of string solvers in formal analysis of string-heavy programs
has led to a growing demand for more efficient and reliable techniques which
can be applied in this context, especially for real-world cases. Designing an
algorithm for the (generally undecidable) satisfiability problem for systems of
string constraints requires a thorough understanding of the structure of
constraints present in the targeted cases. In this paper, we investigate
benchmarks presented in the literature containing regular expression membership
predicates, extract different first order logic theories, and prove their
decidability, resp. undecidability. Notably, the most common theories in
real-world benchmarks are PSPACE-complete and directly lead to the
implementation of a more efficient algorithm to solving string constraints.",0,0,0,0,0,0,0.0827956,9.0,0.54912,35
e418c036-3807-47ba-941e-fb4ea0e9f699,Learning How to Ask: Querying LMs with Mixtures of Soft Prompts,433,0.842759,0.999104,"Natural-language prompts have recently been used to coax pretrained language
models into performing other AI tasks, using a fill-in-the-blank paradigm
(Petroni et al., 2019) or a few-shot extrapolation paradigm (Brown et al.,
2020). For example, language models retain factual knowledge from their
training corpora that can be extracted by asking them to ""fill in the blank"" in
a sentential prompt. However, where does this prompt come from? We explore the
idea of learning prompts by gradient descent -- either fine-tuning prompts
taken from previous work, or starting from random initialization. Our prompts
consist of ""soft words,"" i.e., continuous vectors that are not necessarily word
type embeddings from the language model. Furthermore, for each task, we
optimize a mixture of prompts, learning which prompts are most effective and
how to ensemble them. Across multiple English LMs and tasks, our approach
hugely outperforms previous methods, showing that the implicit factual
knowledge in language models was previously underestimated. Moreover, this
knowledge is cheap to elicit: random initialization is nearly as good as
informed initialization.",1,1,0,0,1,0,0.883845,4.0,0.789337,40
d89d56f0-398a-4db9-a127-104ec7b0c235,Taming Sparsely Activated Transformer with Stochastic Experts,82,0.892785,0.792749,"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can
easily scale to have outrageously large amounts of parameters without
significant increase in computational cost. However, SAMs are reported to be
parameter inefficient such that larger models do not always lead to better
performance. While most on-going research focuses on improving SAMs models by
exploring methods of routing inputs to experts, our analysis reveals that such
research might not lead to the solution we expect, i.e., the commonly-used
routing methods based on gating mechanisms do not work better than randomly
routing inputs to experts. In this paper, we propose a new expert-based model,
THOR (Transformer witH StOchastic ExpeRts). Unlike classic expert-based models,
such as the Switch Transformer, experts in THOR are randomly activated for each
input during training and inference. THOR models are trained using a
consistency regularized loss, where experts learn not only from training data
but also from other experts as teachers, such that all the experts make
consistent predictions. We validate the effectiveness of THOR on machine
translation tasks. Results show that THOR models are more parameter efficient
in that they significantly outperform the Transformer and MoE models across
various settings. For example, in multilingual translation, THOR outperforms
the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as
that of a state-of-the-art MoE model that is 18 times larger. Our code is
publicly available at:
https://github.com/microsoft/Stochastic-Mixture-of-Experts.",1,0,0,0,1,0,0.985523,5.0,0.966797,36
5da23f86-5e8a-44fd-83e1-1845cb35cfa9,Analyzing Online Political Advertisements,10,0.133013,0.411675,"Online political advertising is a central aspect of modern election
campaigning for influencing public opinion. Computational analysis of political
ads is of utmost importance in political science to understand the
characteristics of digital campaigning. It is also important in computational
linguistics to study features of political discourse and communication on a
large scale. In this work, we present the first computational study on online
political ads with the aim to (1) infer the political ideology of an ad
sponsor; and (2) identify whether the sponsor is an official political party or
a third-party organization. We develop two new large datasets for the two tasks
consisting of ads from the U.S.. Evaluation results show that our approach that
combines textual and visual information from pre-trained neural models
outperforms a state-of-the-art method for generic commercial ad classification.
Finally, we provide an in-depth analysis of the limitations of our
best-performing models and linguistic analysis to study the characteristics of
political ads discourse.",0,1,1,1,1,0,0.144657,8.0,0.566785,73
7a95d6b6-be22-4967-ac03-6cb6cae95316,"Discover, Hallucinate, and Adapt: Open Compound Domain Adaptation for Semantic Segmentation",31,0.0579737,0.341737,"Unsupervised domain adaptation (UDA) for semantic segmentation has been
attracting attention recently, as it could be beneficial for various
label-scarce real-world scenarios (e.g., robot control, autonomous driving,
medical imaging, etc.). Despite the significant progress in this field, current
works mainly focus on a single-source single-target setting, which cannot
handle more practical settings of multiple targets or even unseen targets. In
this paper, we investigate open compound domain adaptation (OCDA), which deals
with mixed and novel situations at the same time, for semantic segmentation. We
present a novel framework based on three main design principles: discover,
hallucinate, and adapt. The scheme first clusters compound target data based on
style, discovering multiple latent domains (discover). Then, it hallucinates
multiple latent target domains in source by using image-translation
(hallucinate). This step ensures the latent domains in the source and the
target to be paired. Finally, target-to-source alignment is learned separately
between domains (adapt). In high-level, our solution replaces a hard OCDA
problem with much easier multiple UDA problems. We evaluate our solution on
standard benchmark GTA to C-driving, and achieved new state-of-the-art results.",0,1,1,0,1,0,0.562206,7.0,0.742773,48
71bbebed-5710-4d3d-8059-cf35f17f10d7,Frequency learning for structured CNN filters with Gaussian fractional derivatives,6,0.0274802,0.162687,"Frequency information lies at the base of discriminating between textures,
and therefore between different objects. Classical CNN architectures limit the
frequency learning through fixed filter sizes, and lack a way of explicitly
controlling it. Here, we build on the structured receptive field filters with
Gaussian derivative basis. Yet, rather than using predetermined derivative
orders, which typically result in fixed frequency responses for the basis
functions, we learn these. We show that by learning the order of the basis we
can accurately learn the frequency of the filters, and hence adapt to the
optimal frequencies for the underlying learning task. We investigate the
well-founded mathematical formulation of fractional derivatives to adapt the
filter frequencies during training. Our formulation leads to parameter savings
and data efficiency when compared to the standard CNNs and the Gaussian
derivative CNN filter networks that we build upon.",0,0,0,0,0,0,0.373326,9.0,0.736649,48
04bf7692-49a1-45df-8389-c0b02f846779,Generated Knowledge Prompting for Commonsense Reasoning,222,0.941038,0.993366,"It remains an open question whether incorporating external knowledge benefits
commonsense reasoning while maintaining the flexibility of pretrained sequence
models. To investigate this question, we develop generated knowledge prompting,
which consists of generating knowledge from a language model, then providing
the knowledge as additional input when answering a question. Our method does
not require task-specific supervision for knowledge integration, or access to a
structured knowledge base, yet it improves performance of large-scale,
state-of-the-art models on four commonsense reasoning tasks, achieving
state-of-the-art results on numerical commonsense (NumerSense), general
commonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks.
Generated knowledge prompting highlights large-scale language models as
flexible sources of external knowledge for improving commonsense reasoning. Our
code is available at https://github.com/liujch1998/GKP",1,1,0,0,1,0,0.878533,5.0,0.827271,47
39887f47-a791-4484-9bee-26132dc9d184,Physical Reasoning Using Dynamics-Aware Models,3,0.0392711,0.0887804,"A common approach to solving physical reasoning tasks is to train a value
learner on example tasks. A limitation of such an approach is that it requires
learning about object dynamics solely from reward values assigned to the final
state of a rollout of the environment. This study aims to address this
limitation by augmenting the reward value with self-supervised signals about
object dynamics. Specifically, we train the model to characterize the
similarity of two environment rollouts, jointly with predicting the outcome of
the reasoning task. This similarity can be defined as a distance measure
between the trajectory of objects in the two rollouts, or learned directly from
pixels using a contrastive formulation. Empirically, we find that this approach
leads to substantial performance improvements on the PHYRE benchmark for
physical reasoning (Bakhtin et al., 2019), establishing a new state-of-the-art.",0,1,0,0,1,0,0.709087,6.0,0.766902,12
8e0f05fb-0dc5-436d-ad8a-a7c2a82689fd,Automatic tempered posterior distributions for Bayesian inversion problems,12,0.29287,0.224777,"We propose a novel adaptive importance sampling scheme for Bayesian inversion
problems where the inference of the variables of interest and the power of the
data noise is split. More specifically, we consider a Bayesian analysis for the
variables of interest (i.e., the parameters of the model to invert), whereas we
employ a maximum likelihood approach for the estimation of the noise power. The
whole technique is implemented by means of an iterative procedure, alternating
sampling and optimization steps. Moreover, the noise power is also used as a
tempered parameter for the posterior distribution of the the variables of
interest. Therefore, a sequence of tempered posterior densities is generated,
where the tempered parameter is automatically selected according to the actual
estimation of the noise power. A complete Bayesian study over the model
parameters and the scale parameter can be also performed. Numerical experiments
show the benefits of the proposed approach.",0,0,0,0,0,0,0.239182,19.0,0.847031,26
2172642c-0143-4300-bbd7-dcc5cfb476ab,Ensembling of Distilled Models from Multi-task Teachers for Constrained Resource Language Pairs,2,0.00336671,0.0814858,"This paper describes our submission to the constrained track of WMT21 shared
news translation task. We focus on the three relatively low resource language
pairs Bengali to and from Hindi, English to and from Hausa, and Xhosa to and
from Zulu. To overcome the limitation of relatively low parallel data we train
a multilingual model using a multitask objective employing both parallel and
monolingual data. In addition, we augment the data using back translation. We
also train a bilingual model incorporating back translation and knowledge
distillation then combine the two models using sequence-to-sequence mapping. We
see around 70% relative gain in BLEU point for English to and from Hausa, and
around 25% relative improvements for both Bengali to and from Hindi, and Xhosa
to and from Zulu compared to bilingual baselines.",0,1,0,0,0,0,0.0771072,10.0,0.586786,16
643b0c73-bce5-4cfa-a5bb-00a7040c7aa9,Encoder Fusion Network with Co-Attention Embedding for Referring Image Segmentation,127,0.927986,0.825604,"Recently, referring image segmentation has aroused widespread interest.
Previous methods perform the multi-modal fusion between language and vision at
the decoding side of the network. And, linguistic feature interacts with visual
feature of each scale separately, which ignores the continuous guidance of
language to multi-scale visual features. In this work, we propose an encoder
fusion network (EFN), which transforms the visual encoder into a multi-modal
feature learning network, and uses language to refine the multi-modal features
progressively. Moreover, a co-attention mechanism is embedded in the EFN to
realize the parallel update of multi-modal features, which can promote the
consistent of the cross-modal information representation in the semantic space.
Finally, we propose a boundary enhancement module (BEM) to make the network pay
more attention to the fine structure. The experiment results on four benchmark
datasets demonstrate that the proposed approach achieves the state-of-the-art
performance under different evaluation metrics without any post-processing.",0,1,0,0,1,0,0.974975,7.0,0.956516,45
37f732d0-933d-4093-8556-07aa97954514,More Identifiable yet Equally Performant Transformers for Text Classification,6,0.0106081,0.0938904,"Interpretability is an important aspect of the trustworthiness of a model's
predictions. Transformer's predictions are widely explained by the attention
weights, i.e., a probability distribution generated at its self-attention unit
(head). Current empirical studies provide shreds of evidence that attention
weights are not explanations by proving that they are not unique. A recent
study showed theoretical justifications to this observation by proving the
non-identifiability of attention weights. For a given input to a head and its
output, if the attention weights generated in it are unique, we call the
weights identifiable. In this work, we provide deeper theoretical analysis and
empirical observations on the identifiability of attention weights. Ignored in
the previous works, we find the attention weights are more identifiable than we
currently perceive by uncovering the hidden role of the key vector. However,
the weights are still prone to be non-unique attentions that make them unfit
for interpretation. To tackle this issue, we provide a variant of the encoder
layer that decouples the relationship between key and value vector and provides
identifiable weights up to the desired length of the input. We prove the
applicability of such variations by providing empirical justifications on
varied text classification tasks. The implementations are available at
https://github.com/declare-lab/identifiable-transformers.",1,0,0,0,0,0,0.502792,12.0,0.836008,15
8704daea-f3b6-4a0d-a821-c8c16856ae0f,Creating Unbiased Public Benchmark Datasets with Data Leakage Prevention for Predictive Process Monitoring,10,0.10858,0.571189,"Advances in AI, and especially machine learning, are increasingly drawing
research interest and efforts towards predictive process monitoring, the
subfield of process mining (PM) that concerns predicting next events, process
outcomes and remaining execution times. Unfortunately, researchers use a
variety of datasets and ways to split them into training and test sets. The
documentation of these preprocessing steps is not always complete.
Consequently, research results are hard or even impossible to reproduce and to
compare between papers. At times, the use of non-public domain knowledge
further hampers the fair competition of ideas. Often the training and test sets
are not completely separated, a data leakage problem particular to predictive
process monitoring. Moreover, test sets usually suffer from bias in terms of
both the mix of case durations and the number of running cases. These obstacles
pose a challenge to the field's progress. The contribution of this paper is to
identify and demonstrate the importance of these obstacles and to propose
preprocessing steps to arrive at unbiased benchmark datasets in a principled
way, thus creating representative test sets without data leakage with the aim
of levelling the playing field, promoting open science and contributing to more
rapid progress in predictive process monitoring.",0,1,0,0,0,0,0.579569,9.0,0.805249,8
2cd5510b-8f2d-44d8-84b7-1c99b6155c78,Learning Nigerian accent embeddings from speech: preliminary results based on SautiDB-Naija corpus,3,0.0872174,0.0267002,"This paper describes foundational efforts with SautiDB-Naija, a novel corpus
of non-native (L2) Nigerian English speech. We describe how the corpus was
created and curated as well as preliminary experiments with accent
classification and learning Nigerian accent embeddings. The initial version of
the corpus includes over 900 recordings from L2 English speakers of Nigerian
languages, such as Yoruba, Igbo, Edo, Efik-Ibibio, and Igala. We further
demonstrate how fine-tuning on a pre-trained model like wav2vec can yield
representations suitable for related speech tasks such as accent
classification. SautiDB-Naija has been published to Zenodo for general use
under a flexible Creative Commons License.",0,1,1,1,0,0,0.530383,8.0,0.763829,24
8d57faf4-40ac-4f13-82fa-c1d7e396b797,Weakly Supervised Named Entity Tagging with Learnable Logical Rules,33,0.601554,0.923938,"We study the problem of building entity tagging systems by using a few rules
as weak supervision. Previous methods mostly focus on disambiguation entity
types based on contexts and expert-provided rules, while assuming entity spans
are given. In this work, we propose a novel method TALLOR that bootstraps
high-quality logical rules to train a neural tagger in a fully automated
manner. Specifically, we introduce compound rules that are composed from simple
rules to increase the precision of boundary detection and generate more diverse
pseudo labels. We further design a dynamic label selection strategy to ensure
pseudo label quality and therefore avoid overfitting the neural tagger.
Experiments on three datasets demonstrate that our method outperforms other
weakly supervised methods and even rivals a state-of-the-art distantly
supervised tagger with a lexicon of over 2,000 terms when starting from only 20
simple rules. Our method can serve as a tool for rapidly building taggers in
emerging domains and tasks. Case studies show that learned rules can
potentially explain the predicted entities.",0,1,0,0,1,0,0.905527,9.0,0.916554,27
07c9a91e-6904-4582-8aad-3d220fdf1fa1,Combining Static Word Embeddings and Contextual Representations for Bilingual Lexicon Induction,15,0.358213,0.892101,"Bilingual Lexicon Induction (BLI) aims to map words in one language to their
translations in another, and is typically through learning linear projections
to align monolingual word representation spaces. Two classes of word
representations have been explored for BLI: static word embeddings and
contextual representations, but there is no studies to combine both. In this
paper, we propose a simple yet effective mechanism to combine the static word
embeddings and the contextual representations to utilize the advantages of both
paradigms. We test the combination mechanism on various language pairs under
the supervised and unsupervised BLI benchmark settings. Experiments show that
our mechanism consistently improves performances over robust BLI baselines on
all language pairs by averagely improving 3.2 points in the supervised setting,
and 3.1 points in the unsupervised setting.",1,1,0,0,0,0,0.949306,8.0,0.935392,43
067402cc-43c1-4b25-a9e7-87d17ce8ec29,A Psychologically Informed Part-of-Speech Analysis of Depression in Social Media,11,0.0,0.483572,"In this work, we provide an extensive part-of-speech analysis of the
discourse of social media users with depression. Research in psychology
revealed that depressed users tend to be self-focused, more preoccupied with
themselves and ruminate more about their lives and emotions. Our work aims to
make use of large-scale datasets and computational methods for a quantitative
exploration of discourse. We use the publicly available depression dataset from
the Early Risk Prediction on the Internet Workshop (eRisk) 2018 and extract
part-of-speech features and several indices based on them. Our results reveal
statistically significant differences between the depressed and non-depressed
individuals confirming findings from the existing psychology literature. Our
work provides insights regarding the way in which depressed individuals are
expressing themselves on social media platforms, allowing for better-informed
computational models to help monitor and prevent mental illnesses.",0,1,0,0,0,0,0.00230838,11.0,0.301864,61
ce705b38-9343-4ad4-bd0d-6855bc01f7b0,Co-Grounding Networks with Semantic Attention for Referring Expression Comprehension in Videos,15,0.210053,0.65283,"In this paper, we address the problem of referring expression comprehension
in videos, which is challenging due to complex expression and scene dynamics.
Unlike previous methods which solve the problem in multiple stages (i.e.,
tracking, proposal-based matching), we tackle the problem from a novel
perspective, \textbf{co-grounding}, with an elegant one-stage framework. We
enhance the single-frame grounding accuracy by semantic attention learning and
improve the cross-frame grounding consistency with co-grounding feature
learning. Semantic attention learning explicitly parses referring cues in
different attributes to reduce the ambiguity in the complex expression.
Co-grounding feature learning boosts visual feature representations by
integrating temporal correlation to reduce the ambiguity caused by scene
dynamics. Experiment results demonstrate the superiority of our framework on
the video grounding datasets VID and LiOTB in generating accurate and stable
results across frames. Our model is also applicable to referring expression
comprehension in images, illustrated by the improved performance on the RefCOCO
dataset. Our project is available at https://sijiesong.github.io/co-grounding.",1,1,0,0,1,0,0.948182,7.0,0.925108,43
6f5effed-8fdb-48cd-a473-f5ca0ef2414c,Efficient Strategy Synthesis for MDPs with Resource Constraints,4,0.0798949,0.135732,"We consider qualitative strategy synthesis for the formalism called
consumption Markov decision processes. This formalism can model dynamics of an
agents that operates under resource constraints in a stochastic environment.
The presented algorithms work in time polynomial with respect to the
representation of the model and they synthesize strategies ensuring that a
given set of goal states will be reached (once or infinitely many times) with
probability 1 without resource exhaustion. In particular, when the amount of
resource becomes too low to safely continue in the mission, the strategy
changes course of the agent towards one of a designated set of reload states
where the agent replenishes the resource to full capacity; with sufficient
amount of resource, the agent attempts to fulfill the mission again.
  We also present two heuristics that attempt to reduce expected time that the
agent needs to fulfill the given mission, a parameter important in practical
planning. The presented algorithms were implemented and numerical examples
demonstrate (i) the effectiveness (in terms of computation time) of the
planning approach based on consumption Markov decision processes and (ii) the
positive impact of the two heuristics on planning in a realistic example.",0,1,0,0,0,0,0.0033695,19.0,0.61575,37
a5b820b5-6265-4d7c-a7cf-7e8cf0a67211,Label quality in AffectNet: results of crowd-based re-annotation,3,0.0,0.290427,"AffectNet is one of the most popular resources for facial expression
recognition (FER) on relatively unconstrained in-the-wild images. Given that
images were annotated by only one annotator with limited consistency checks on
the data, however, label quality and consistency may be limited. Here, we take
a similar approach to a study that re-labeled another, smaller dataset
(FER2013) with crowd-based annotations, and report results from a re-labeling
and re-annotation of a subset of difficult AffectNet faces with 13 people on
both expression label, and valence and arousal ratings. Our results show that
human labels overall have medium to good consistency, whereas human ratings
especially for valence are in excellent agreement. Importantly, however,
crowd-based labels are significantly shifting towards neutral and happy
categories and crowd-based affective ratings form a consistent pattern
different from the original ratings. ResNets fully trained on the original
AffectNet dataset do not predict human voting patterns, but when weakly-trained
do so much better, particularly for valence. Our results have important
ramifications for label quality in affective computing.",0,1,0,0,0,0,0.325854,9.0,0.717771,22
e295739c-6e1f-42ef-b85a-102bd3744c70,Direct Servo Control from In-Sensor CNN Inference with A Pixel Processor Array,6,0.175503,0.330397,"This work demonstrates direct visual sensory-motor control using high-speed
CNN inference via a SCAMP-5 Pixel Processor Array (PPA). We demonstrate how
PPAs are able to efficiently bridge the gap between perception and action. A
binary Convolutional Neural Network (CNN) is used for a classic rock, paper,
scissors classification problem at over 8000 FPS. Control instructions are
directly sent to a servo motor from the PPA according to the CNN's
classification result without any other intermediate hardware.",0,1,0,0,0,0,0.820651,4.0,0.732992,6
1b36437b-d522-4f38-ae36-ec22e196004d,Act the Part: Learning Interaction Strategies for Articulated Object Part Discovery,38,0.61572,0.801336,"People often use physical intuition when manipulating articulated objects,
irrespective of object semantics. Motivated by this observation, we identify an
important embodied task where an agent must play with objects to recover their
parts. To this end, we introduce Act the Part (AtP) to learn how to interact
with articulated objects to discover and segment their pieces. By coupling
action selection and motion segmentation, AtP is able to isolate structures to
make perceptual part recovery possible without semantic labels. Our experiments
show AtP learns efficient strategies for part discovery, can generalize to
unseen categories, and is capable of conditional reasoning for the task.
Although trained in simulation, we show convincing transfer to real world data
with no fine-tuning.",1,1,1,0,0,0,0.536922,11.0,0.829911,56
3175a8f7-e54c-4906-8f43-4bec86db2937,Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition,7,0.14079,0.465035,"Key challenges in developing generalized automatic emotion recognition
systems include scarcity of labeled data and lack of gold-standard references.
Even for the cues that are labeled as the same emotion category, the
variability of associated expressions can be high depending on the elicitation
context e.g., emotion elicited during improvised conversations vs. acted
sessions with predefined scripts. In this work, we regard the emotion
elicitation approach as domain knowledge, and explore domain transfer learning
techniques on emotional utterances collected under different emotion
elicitation approaches, particularly with limited labeled target samples. Our
emotion recognition model combines the gradient reversal technique with an
entropy loss function as well as the softlabel loss, and the experiment results
show that domain transfer learning methods can be employed to alleviate the
domain mismatch between different elicitation approaches. Our work provides new
insights into emotion data collection, particularly the impact of its
elicitation strategies, and the importance of domain adaptation in emotion
recognition aiming for generalized systems.",0,1,0,0,0,0,0.59994,7.0,0.757568,33
a90111d7-24f3-491a-9815-8813a8cc551d,IntelliCAT: Intelligent Machine Translation Post-Editing with Quality Estimation and Translation Suggestion,17,0.0282583,0.45279,"We present IntelliCAT, an interactive translation interface with neural
models that streamline the post-editing process on machine translation output.
We leverage two quality estimation (QE) models at different granularities:
sentence-level QE, to predict the quality of each machine-translated sentence,
and word-level QE, to locate the parts of the machine-translated sentence that
need correction. Additionally, we introduce a novel translation suggestion
model conditioned on both the left and right contexts, providing alternatives
for specific words or phrases for correction. Finally, with word alignments,
IntelliCAT automatically preserves the original document's styles in the
translated document. The experimental results show that post-editing based on
the proposed QE and translation suggestions can significantly improve
translation quality. Furthermore, a user study reveals that three features
provided in IntelliCAT significantly accelerate the post-editing task,
achieving a 52.9\% speedup in translation time compared to translating from
scratch. The interface is publicly available at
https://intellicat.beringlab.com/.",1,1,0,0,0,0,0.0222502,9.0,0.399599,38
ea29ee79-59b3-43ce-9f2f-9d95c2c705a7,End2End Acoustic to Semantic Transduction,15,0.0249967,0.338455,"In this paper, we propose a novel end-to-end sequence-to-sequence spoken
language understanding model using an attention mechanism. It reliably selects
contextual acoustic features in order to hypothesize semantic contents. An
initial architecture capable of extracting all pronounced words and concepts
from acoustic spans is designed and tested. With a shallow fusion language
model, this system reaches a 13.6 concept error rate (CER) and an 18.5 concept
value error rate (CVER) on the French MEDIA corpus, achieving an absolute 2.8
points reduction compared to the state-of-the-art. Then, an original model is
proposed for hypothesizing concepts and their values. This transduction reaches
a 15.4 CER and a 21.6 CVER without any new type of context.",0,1,0,0,1,0,0.0366385,7.0,0.300359,30
29e9f14a-77ac-465d-b2af-8e92f9e0348e,Dense Unsupervised Learning for Video Segmentation,21,0.0947772,0.660809,"We present a novel approach to unsupervised learning for video object
segmentation (VOS). Unlike previous work, our formulation allows to learn dense
feature representations directly in a fully convolutional regime. We rely on
uniform grid sampling to extract a set of anchors and train our model to
disambiguate between them on both inter- and intra-video levels. However, a
naive scheme to train such a model results in a degenerate solution. We propose
to prevent this with a simple regularisation scheme, accommodating the
equivariance property of the segmentation task to similarity transformations.
Our training objective admits efficient implementation and exhibits fast
training convergence. On established VOS benchmarks, our approach exceeds the
segmentation accuracy of previous work despite using significantly less
training data and compute power.",1,0,0,0,1,0,0.80219,6.0,0.812211,50
ff313869-b48a-424d-a541-2894fb593cf5,Diverse Pretrained Context Encodings Improve Document Translation,12,0.0890483,0.298245,"We propose a new architecture for adapting a sentence-level
sequence-to-sequence transformer by incorporating multiple pretrained document
context signals and assess the impact on translation performance of (1)
different pretraining approaches for generating these signals, (2) the quantity
of parallel data for which document context is available, and (3) conditioning
on source, target, or source and target contexts. Experiments on the NIST
Chinese-English, and IWSLT and WMT English-German tasks support four general
conclusions: that using pretrained context representations markedly improves
sample efficiency, that adequate parallel data resources are crucial for
learning to use document context, that jointly conditioning on multiple context
representations outperforms any single representation, and that source context
is more valuable for translation performance than target side context. Our best
multi-context model consistently outperforms the best existing context-aware
transformers.",0,0,0,0,0,0,0.759122,5.0,0.748731,44
9b9431a3-76b8-4d25-9649-a3a875e2aa7c,StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose Estimation,38,0.539969,0.914673,"We present a large-scale stereo RGB image object pose estimation dataset
named the $\textbf{StereOBJ-1M}$ dataset. The dataset is designed to address
challenging cases such as object transparency, translucency, and specular
reflection, in addition to the common challenges of occlusion, symmetry, and
variations in illumination and environments. In order to collect data of
sufficient scale for modern deep learning models, we propose a novel method for
efficiently annotating pose data in a multi-view fashion that allows data
capturing in complex and flexible environments. Fully annotated with 6D object
poses, our dataset contains over 393K frames and over 1.5M annotations of 18
objects recorded in 182 scenes constructed in 11 different environments. The 18
objects include 8 symmetric objects, 7 transparent objects, and 8 reflective
objects. We benchmark two state-of-the-art pose estimation frameworks on
StereOBJ-1M as baselines for future work. We also propose a novel object-level
pose optimization method for computing 6D pose from keypoint predictions in
multiple images. Project website: https://sites.google.com/view/stereobj-1m.",0,1,0,1,0,0,0.896883,7.0,0.887311,43
2faaceb5-e934-4c14-a25c-2f260e16a7e8,Focus Attention: Promoting Faithfulness and Diversity in Summarization,40,0.0598429,0.393826,"Professional summaries are written with document-level information, such as
the theme of the document, in mind. This is in contrast with most seq2seq
decoders which simultaneously learn to focus on salient content, while deciding
what to generate, at each decoding step. With the motivation to narrow this
gap, we introduce Focus Attention Mechanism, a simple yet effective method to
encourage decoders to proactively generate tokens that are similar or topical
to the input document. Further, we propose a Focus Sampling method to enable
generation of diverse summaries, an area currently understudied in
summarization. When evaluated on the BBC extreme summarization task, two
state-of-the-art models augmented with Focus Attention generate summaries that
are closer to the target and more faithful to their input documents,
outperforming their vanilla counterparts on \rouge and multiple faithfulness
measures. We also empirically demonstrate that Focus Sampling is more effective
in generating diverse and faithful summaries than top-$k$ or nucleus
sampling-based decoding methods.",0,1,1,0,1,0,0.444947,5.0,0.572142,91
25ea43eb-fa5a-40a1-b601-720aceeb29e8,"Deepfake Detection by Human Crowds, Machines, and Machine-informed Crowds",101,0.980917,0.579951,"The recent emergence of machine-manipulated media raises an important
societal question: how can we know if a video that we watch is real or fake? In
two online studies with 15,016 participants, we present authentic videos and
deepfakes and ask participants to identify which is which. We compare the
performance of ordinary human observers against the leading computer vision
deepfake detection model and find them similarly accurate while making
different kinds of mistakes. Together, participants with access to the model's
prediction are more accurate than either alone, but inaccurate model
predictions often decrease participants' accuracy. To probe the relative
strengths and weaknesses of humans and machines as detectors of deepfakes, we
examine human and machine performance across video-level features, and we
evaluate the impact of pre-registered randomized interventions on deepfake
detection. We find that manipulations designed to disrupt visual processing of
faces hinder human participants' performance while mostly not affecting the
model's performance, suggesting a role for specialized cognitive capacities in
explaining human deepfake detection performance.",1,1,0,0,0,0,0.965363,5.0,0.920669,94
93c0d0c6-d752-4564-b2da-175cde3c0762,Clockwork Variational Autoencoders,42,0.228371,0.820291,"Deep learning has enabled algorithms to generate realistic images. However,
accurately predicting long video sequences requires understanding long-term
dependencies and remains an open challenge. While existing video prediction
models succeed at generating sharp images, they tend to fail at accurately
predicting far into the future. We introduce the Clockwork VAE (CW-VAE), a
video prediction model that leverages a hierarchy of latent sequences, where
higher levels tick at slower intervals. We demonstrate the benefits of both
hierarchical latents and temporal abstraction on 4 diverse video prediction
datasets with sequences of up to 1000 frames, where CW-VAE outperforms top
video prediction models. Additionally, we propose a Minecraft benchmark for
long-term video prediction. We conduct several experiments to gain insights
into CW-VAE and confirm that slower levels learn to represent objects that
change more slowly in the video, and faster levels learn to represent faster
objects.",0,1,0,0,1,0,0.682175,8.0,0.815883,61
13c09f90-d70e-42f5-b937-2c8f0a11419a,Connecting Deep-Reinforcement-Learning-based Obstacle Avoidance with Conventional Global Planners using Waypoint Generators,22,0.161462,0.847903,"Deep Reinforcement Learning has emerged as an efficient dynamic obstacle
avoidance method in highly dynamic environments. It has the potential to
replace overly conservative or inefficient navigation approaches. However, the
integration of Deep Reinforcement Learning into existing navigation systems is
still an open frontier due to the myopic nature of
Deep-Reinforcement-Learning-based navigation, which hinders its widespread
integration into current navigation systems. In this paper, we propose the
concept of an intermediate planner to interconnect novel
Deep-Reinforcement-Learning-based obstacle avoidance with conventional global
planning methods using waypoint generation. Therefore, we integrate different
waypoint generators into existing navigation systems and compare the joint
system against traditional ones. We found an increased performance in terms of
safety, efficiency and path smoothness especially in highly dynamic
environments.",1,1,0,0,0,0,0.611312,6.0,0.722328,26
8720fc73-db9a-40aa-8f6f-9b59afe8a62b,"FEWS: Large-Scale, Low-Shot Word Sense Disambiguation with the Dictionary",15,0.130471,0.817535,"Current models for Word Sense Disambiguation (WSD) struggle to disambiguate
rare senses, despite reaching human performance on global WSD metrics. This
stems from a lack of data for both modeling and evaluating rare senses in
existing WSD datasets. In this paper, we introduce FEWS (Few-shot Examples of
Word Senses), a new low-shot WSD dataset automatically extracted from example
sentences in Wiktionary. FEWS has high sense coverage across different natural
language domains and provides: (1) a large training set that covers many more
senses than previous datasets and (2) a comprehensive evaluation set containing
few- and zero-shot examples of a wide variety of senses. We establish baselines
on FEWS with knowledge-based and neural WSD approaches and present transfer
learning experiments demonstrating that models additionally trained with FEWS
better capture rare senses in existing WSD datasets. Finally, we find humans
outperform the best baseline models on FEWS, indicating that FEWS will support
significant future work on low-shot WSD.",1,1,1,1,0,0,0.0615025,16.0,0.727091,30
c01ae900-0f81-4d94-ae42-903cb8c4e03d,HerBERT: Efficiently Pretrained Transformer-based Language Model for Polish,65,0.269763,0.782381,"BERT-based models are currently used for solving nearly all Natural Language
Processing (NLP) tasks and most often achieve state-of-the-art results.
Therefore, the NLP community conducts extensive research on understanding these
models, but above all on designing effective and efficient training procedures.
Several ablation studies investigating how to train BERT-like models have been
carried out, but the vast majority of them concerned only the English language.
A training procedure designed for English does not have to be universal and
applicable to other especially typologically different languages. Therefore,
this paper presents the first ablation study focused on Polish, which, unlike
the isolating English language, is a fusional language. We design and
thoroughly evaluate a pretraining procedure of transferring knowledge from
multilingual to monolingual BERT-based models. In addition to multilingual
model initialization, other factors that possibly influence pretraining are
also explored, i.e. training objective, corpus size, BPE-Dropout, and
pretraining length. Based on the proposed procedure, a Polish BERT-based
language model -- HerBERT -- is trained. This model achieves state-of-the-art
results on multiple downstream tasks.",1,1,0,0,1,0,0.813317,4.0,0.727092,45
403dbcd6-debd-4d96-a300-e0bb4ee5692b,Machine learning and deep learning,685,0.28044,0.97804,"Today, intelligent systems that offer artificial intelligence capabilities
often rely on machine learning. Machine learning describes the capacity of
systems to learn from problem-specific training data to automate the process of
analytical model building and solve associated tasks. Deep learning is a
machine learning concept based on artificial neural networks. For many
applications, deep learning models outperform shallow machine learning models
and traditional data analysis approaches. In this article, we summarize the
fundamentals of machine learning and deep learning to generate a broader
understanding of the methodical underpinning of current intelligent systems. In
particular, we provide a conceptual distinction between relevant terms and
concepts, explain the process of automated analytical model building through
machine learning and deep learning, and discuss the challenges that arise when
implementing such intelligent systems in the field of electronic markets and
networked business. These naturally go beyond technological aspects and
highlight issues in human-machine interaction and artificial intelligence
servitization.",0,0,0,0,0,0,0.0419586,7.0,0.320121,64
95f65d62-055e-485d-8c5d-7f704143eebb,Sequential Attention Module for Natural Language Processing,1,0.00144058,0.0143219,"Recently, large pre-trained neural language models have attained remarkable
performance on many downstream natural language processing (NLP) applications
via fine-tuning. In this paper, we target at how to further improve the token
representations on the language models. We, therefore, propose a simple yet
effective plug-and-play module, Sequential Attention Module (SAM), on the token
embeddings learned from a pre-trained language model. Our proposed SAM consists
of two main attention modules deployed sequentially: Feature-wise Attention
Module (FAM) and Token-wise Attention Module (TAM). More specifically, FAM can
effectively identify the importance of features at each dimension and promote
the effect via dot-product on the original token embeddings for downstream NLP
applications. Meanwhile, TAM can further re-weight the features at the
token-wise level. Moreover, we propose an adaptive filter on FAM to prevent
noise impact and increase information absorption. Finally, we conduct extensive
experiments to demonstrate the advantages and properties of our proposed SAM.
We first show how SAM plays a primary role in the champion solution of two
subtasks of SemEval'21 Task 7. After that, we apply SAM on sentiment analysis
and three popular NLP tasks and demonstrate that SAM consistently outperforms
the state-of-the-art baselines.",1,1,0,0,1,1,0.111678,9.0,0.584117,45
50dbe688-14a0-41eb-90bf-afda97a94570,Mitigating Temporal-Drift: A Simple Approach to Keep NER Models Crisp,7,0.0426462,0.343362,"Performance of neural models for named entity recognition degrades over time,
becoming stale. This degradation is due to temporal drift, the change in our
target variables' statistical properties over time. This issue is especially
problematic for social media data, where topics change rapidly. In order to
mitigate the problem, data annotation and retraining of models is common.
Despite its usefulness, this process is expensive and time-consuming, which
motivates new research on efficient model updating. In this paper, we propose
an intuitive approach to measure the potential trendiness of tweets and use
this metric to select the most informative instances to use for training. We
conduct experiments on three state-of-the-art models on the Temporal Twitter
Dataset. Our approach shows larger increases in prediction accuracy with less
training data than the alternatives, making it an attractive, practical
solution.",1,1,0,0,0,0,0.20983,10.0,0.694455,18
bbe1beb8-baca-4479-b09f-7e66cde65456,Tea: Program Repair Using Neural Network Based on Program Information Attention Matrix,1,0.0125238,0.0225439,"The advance in machine learning (ML)-driven natural language process (NLP)
points a promising direction for automatic bug fixing for software programs, as
fixing a buggy program can be transformed to a translation task. While software
programs contain much richer information than one-dimensional natural language
documents, pioneering work on using ML-driven NLP techniques for automatic
program repair only considered a limited set of such information. We
hypothesize that more comprehensive information of software programs, if
appropriately utilized, can improve the effectiveness of ML-driven NLP
approaches in repairing software programs. As the first step towards proving
this hypothesis, we propose a unified representation to capture the syntax,
data flow, and control flow aspects of software programs, and devise a method
to use such a representation to guide the transformer model from NLP in better
understanding and fixing buggy programs. Our preliminary experiment confirms
that the more comprehensive information of software programs used, the better
ML-driven NLP techniques can perform in fixing bugs in these programs.",1,1,0,0,0,0,0.481169,9.0,0.77436,14
b56f7bf2-7816-4f54-b2e7-1fa414199074,Misinformation detection in Luganda-English code-mixed social media text,1,0.0425322,0.0107255,"The increasing occurrence, forms, and negative effects of misinformation on
social media platforms has necessitated more misinformation detection tools.
Currently, work is being done addressing COVID-19 misinformation however, there
are no misinformation detection tools for any of the 40 distinct indigenous
Ugandan languages. This paper addresses this gap by presenting basic language
resources and a misinformation detection data set based on code-mixed
Luganda-English messages sourced from the Facebook and Twitter social media
platforms. Several machine learning methods are applied on the misinformation
detection data set to develop classification models for detecting whether a
code-mixed Luganda-English message contains misinformation or not. A 10-fold
cross validation evaluation of the classification methods in an experimental
misinformation detection task shows that a Discriminative Multinomial Naive
Bayes (DMNB) method achieves the highest accuracy and F-measure of 78.19% and
77.90% respectively. Also, Support Vector Machine and Bagging ensemble
classification models achieve comparable results. These results are promising
since the machine learning models are based on n-gram features from only the
misinformation detection dataset.",1,1,1,1,1,0,0.638279,10.0,0.84073,41
590540db-6d68-4d85-8e2f-1dd5e7f4d8ae,How RL Agents Behave When Their Actions Are Modified,13,0.0179148,0.150044,"Reinforcement learning in complex environments may require supervision to
prevent the agent from attempting dangerous actions. As a result of supervisor
intervention, the executed action may differ from the action specified by the
policy. How does this affect learning? We present the Modified-Action Markov
Decision Process, an extension of the MDP model that allows actions to differ
from the policy. We analyze the asymptotic behaviours of common reinforcement
learning algorithms in this setting and show that they adapt in different ways:
some completely ignore modifications while others go to various lengths in
trying to avoid action modifications that decrease reward. By choosing the
right algorithm, developers can prevent their agents from learning to
circumvent interruptions or constraints, and better control agent responses to
other kinds of action modification, like self-damage.",1,0,0,0,0,0,0.0658302,10.0,0.570374,34
5f4d2c76-0e18-49ec-8653-bf6e8220f978,"Automated Cleanup of the ImageNet Dataset by Model Consensus, Explainability and Confident Learning",21,0.180724,0.565229,"The convolutional neural networks (CNNs) trained on ILSVRC12 ImageNet were
the backbone of various applications as a generic classifier, a feature
extractor or a base model for transfer learning. This paper describes automated
heuristics based on model consensus, explainability and confident learning to
correct labeling mistakes and remove ambiguous images from this dataset. After
making these changes on the training and validation sets, the ImageNet-Clean
improves the model performance by 2-2.4 % for SqueezeNet and EfficientNet-B0
models. The results support the importance of larger image corpora and
semi-supervised learning, but the original datasets must be fixed to avoid
transmitting their mistakes and biases to the student learner. Further
contributions describe the training impacts of widescreen input resolutions in
portrait and landscape orientations. The trained models and scripts are
published on Github (https://github.com/kecsap/imagenet-clean) to clean up
ImageNet and ImageNetV2 datasets for reproducible research.",1,1,0,0,1,1,0.806233,5.0,0.777185,33
eccda0a1-9b1b-420d-baa5-2356031eedc0,Learning to Infer Kinematic Hierarchies for Novel Object Instances,10,0.294945,0.198099,"Manipulating an articulated object requires perceiving itskinematic
hierarchy: its parts, how each can move, and howthose motions are coupled.
Previous work has explored per-ception for kinematics, but none infers a
complete kinematichierarchy on never-before-seen object instances, without
relyingon a schema or template. We present a novel perception systemthat
achieves this goal. Our system infers the moving parts ofan object and the
kinematic couplings that relate them. Toinfer parts, it uses a point cloud
instance segmentation neuralnetwork and to infer kinematic hierarchies, it uses
a graphneural network to predict the existence, direction, and typeof edges
(i.e. joints) that relate the inferred parts. We trainthese networks using
simulated scans of synthetic 3D models.We evaluate our system on simulated
scans of 3D objects, andwe demonstrate a proof-of-concept use of our system to
drivereal-world robotic manipulation.",0,1,1,0,0,0,0.637897,7.0,0.772323,37
0e5a1561-ed8a-4ba7-a653-4dedca080eab,Multilingual Offensive Language Identification for Low-resource Languages,57,0.758293,0.989234,"Offensive content is pervasive in social media and a reason for concern to
companies and government organizations. Several studies have been recently
published investigating methods to detect the various forms of such content
(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of
these studies deal with English partially because most annotated datasets
available contain English data. In this paper, we take advantage of available
English datasets by applying cross-lingual contextual word embeddings and
transfer learning to make predictions in low-resource languages. We project
predictions on comparable data in Arabic, Bengali, Danish, Greek, Hindi,
Spanish, and Turkish. We report results of 0.8415 F1 macro for Bengali in
TRAC-2 shared task, 0.8532 F1 macro for Danish and 0.8701 F1 macro for Greek in
OffensEval 2020, 0.8568 F1 macro for Hindi in HASOC 2019 shared task and 0.7513
F1 macro for Spanish in in SemEval-2019 Task 5 (HatEval) showing that our
approach compares favourably to the best systems submitted to recent shared
tasks on these three languages. Additionally, we report competitive performance
on Arabic, and Turkish using the training and development sets of OffensEval
2020 shared task. The results for all languages confirm the robustness of
cross-lingual contextual embeddings and transfer learning for this task.",0,1,0,0,1,0,0.876744,4.0,0.782349,61
524a7db4-f08c-4a2a-a238-dbd80ab55f73,Gaze Estimation using Transformer,54,0.737794,0.671259,"Recent work has proven the effectiveness of transformers in many computer
vision tasks. However, the performance of transformers in gaze estimation is
still unexplored. In this paper, we employ transformers and assess their
effectiveness for gaze estimation. We consider two forms of vision transformer
which are pure transformers and hybrid transformers. We first follow the
popular ViT and employ a pure transformer to estimate gaze from images. On the
other hand, we preserve the convolutional layers and integrate CNNs as well as
transformers. The transformer serves as a component to complement CNNs. We
compare the performance of the two transformers in gaze estimation. The Hybrid
transformer significantly outperforms the pure transformer in all evaluation
datasets with less parameters. We further conduct experiments to assess the
effectiveness of the hybrid transformer and explore the advantage of
self-attention mechanism. Experiments show the hybrid transformer can achieve
state-of-the-art performance in all benchmarks with pre-training.To facilitate
further research, we release codes and models in
https://github.com/yihuacheng/GazeTR.",1,0,0,0,1,0,0.975507,4.0,0.925355,46
3284cd68-d9e7-49ef-a778-0ba97549bc4e,Multilingual Language Models Predict Human Reading Behavior,37,0.0519424,0.296134,"We analyze if large language models are able to predict patterns of human
reading behavior. We compare the performance of language-specific and
multilingual pretrained transformer models to predict reading time measures
reflecting natural human sentence processing on Dutch, English, German, and
Russian texts. This results in accurate models of human reading behavior, which
indicates that transformer models implicitly encode relative importance in
language in a way that is comparable to human processing mechanisms. We find
that BERT and XLM models successfully predict a range of eye tracking features.
In a series of experiments, we analyze the cross-domain and cross-language
abilities of these models and show how they reflect human sentence processing.",0,0,0,0,0,0,0.155771,5.0,0.322933,67
4387016f-54bd-4ea8-ab21-1b373c58b380,IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural Language Generation,73,0.337703,0.745049,"Natural language generation (NLG) benchmarks provide an important avenue to
measure progress and develop better NLG systems. Unfortunately, the lack of
publicly available NLG benchmarks for low-resource languages poses a
challenging barrier for building NLG systems that work well for languages with
limited amounts of data. Here we introduce IndoNLG, the first benchmark to
measure natural language generation (NLG) progress in three low-resource -- yet
widely spoken -- languages of Indonesia: Indonesian, Javanese, and Sundanese.
Altogether, these languages are spoken by more than 100 million native
speakers, and hence constitute an important use case of NLG systems today.
Concretely, IndoNLG covers six tasks: summarization, question answering,
chit-chat, and three different pairs of machine translation (MT) tasks. We
collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese
datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and
IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on
all tasks -- despite using only one-fifth the parameters of a larger
multilingual model, mBART-LARGE (Liu et al., 2020). This finding emphasizes the
importance of pretraining on closely related, local languages to achieve more
efficient learning and faster inference for very low-resource languages like
Javanese and Sundanese.",1,1,0,1,0,0,0.842337,3.0,0.668095,73
3b70e29d-81b0-40a4-abe9-515739eaa490,Answering Open-Domain Multi-Answer Questions via a Recall-then-Verify Framework,8,0.0409346,0.277715,"Open-domain questions are likely to be open-ended and ambiguous, leading to
multiple valid answers. Existing approaches typically adopt the
rerank-then-read framework, where a reader reads top-ranking evidence to
predict answers. According to our empirical analysis, this framework faces
three problems: first, to leverage a large reader under a memory constraint,
the reranker should select only a few relevant passages to cover diverse
answers, while balancing relevance and diversity is non-trivial; second, the
small reading budget prevents the reader from accessing valuable retrieved
evidence filtered out by the reranker; third, when using a generative reader to
predict answers all at once based on all selected evidence, whether a valid
answer will be predicted also pathologically depends on the evidence of some
other valid answer(s). To address these issues, we propose to answer
open-domain multi-answer questions with a recall-then-verify framework, which
separates the reasoning process of each answer so that we can make better use
of retrieved evidence while also leveraging large models under the same memory
constraint. Our framework achieves state-of-the-art results on two multi-answer
datasets, and predicts significantly more gold answers than a rerank-then-read
system that uses an oracle reranker.",0,1,0,0,1,0,0.716093,4.0,0.655242,38
b883349d-3c4f-4533-90fe-c560c6e5076f,Dynamically Switching Human Prediction Models for Efficient Planning,5,0.0284782,0.177705,"As environments involving both robots and humans become increasingly common,
so does the need to account for people during planning. To plan effectively,
robots must be able to respond to and sometimes influence what humans do. This
requires a human model which predicts future human actions. A simple model may
assume the human will continue what they did previously; a more complex one
might predict that the human will act optimally, disregarding the robot;
whereas an even more complex one might capture the robot's ability to influence
the human. These models make different trade-offs between computational time
and performance of the resulting robot plan. Using only one model of the human
either wastes computational resources or is unable to handle critical
situations. In this work, we give the robot access to a suite of human models
and enable it to assess the performance-computation trade-off online. By
estimating how an alternate model could improve human prediction and how that
may translate to performance gain, the robot can dynamically switch human
models whenever the additional computation is justified. Our experiments in a
driving simulator showcase how the robot can achieve performance comparable to
always using the best human model, but with greatly reduced computation.",0,1,0,0,0,0,0.140638,10.0,0.650382,30
c13faa8b-6a1d-49e4-9a05-45612f106568,SpartQA: : A Textual Question Answering Benchmark for Spatial Reasoning,53,0.394284,0.574947,"This paper proposes a question-answering (QA) benchmark for spatial reasoning
on natural language text which contains more realistic spatial phenomena not
covered by prior work and is challenging for state-of-the-art language models
(LM). We propose a distant supervision method to improve on this task.
Specifically, we design grammar and reasoning rules to automatically generate a
spatial description of visual scenes and corresponding QA pairs. Experiments
show that further pretraining LMs on these automatically generated data
significantly improves LMs' capability on spatial understanding, which in turn
helps to better solve two external datasets, bAbI, and boolQ. We hope that this
work can foster investigations into more sophisticated models for spatial
reasoning over text.",1,1,1,1,0,0,0.7351,5.0,0.734908,56
29124be2-0b45-4f78-81d9-893eada357c7,BART based semantic correction for Mandarin automatic speech recognition system,21,0.0846241,0.724687,"Although automatic speech recognition (ASR) systems achieved significantly
improvements in recent years, spoken language recognition error occurs which
can be easily spotted by human beings. Various language modeling techniques
have been developed on post recognition tasks like semantic correction. In this
paper, we propose a Transformer based semantic correction method with
pretrained BART initialization, Experiments on 10000 hours Mandarin speech
dataset show that character error rate (CER) can be effectively reduced by
21.7% relatively compared to our baseline ASR system. Expert evaluation
demonstrates that actual improvement of our model surpasses what CER indicates.",0,1,0,0,1,0,0.653028,4.0,0.611856,23
3ccd2c03-a4e3-4ef6-a870-474ec07ad2dd,"Human-Level Reinforcement Learning through Theory-Based Modeling, Exploration, and Planning",35,0.0475041,0.40863,"Reinforcement learning (RL) studies how an agent comes to achieve reward in
an environment through interactions over time. Recent advances in machine RL
have surpassed human expertise at the world's oldest board games and many
classic video games, but they require vast quantities of experience to learn
successfully -- none of today's algorithms account for the human ability to
learn so many different tasks, so quickly. Here we propose a new approach to
this challenge based on a particularly strong form of model-based RL which we
call Theory-Based Reinforcement Learning, because it uses human-like intuitive
theories -- rich, abstract, causal models of physical objects, intentional
agents, and their interactions -- to explore and model an environment, and plan
effectively to achieve task goals. We instantiate the approach in a video game
playing agent called EMPA (the Exploring, Modeling, and Planning Agent), which
performs Bayesian inference to learn probabilistic generative models expressed
as programs for a game-engine simulator, and runs internal simulations over
these models to support efficient object-based, relational exploration and
heuristic planning. EMPA closely matches human learning efficiency on a suite
of 90 challenging Atari-style video games, learning new games in just minutes
of game play and generalizing robustly to new game situations and new levels.
The model also captures fine-grained structure in people's exploration
trajectories and learning dynamics. Its design and behavior suggest a way
forward for building more general human-like AI systems.",0,0,0,0,0,0,0.011434,11.0,0.44774,88
e89e071f-29d3-41b8-b2e0-66db5c27b880,A Fourier-based Framework for Domain Generalization,308,0.745048,0.999784,"Modern deep neural networks suffer from performance degradation when
evaluated on testing data under different distributions from training data.
Domain generalization aims at tackling this problem by learning transferable
knowledge from multiple source domains in order to generalize to unseen target
domains. This paper introduces a novel Fourier-based perspective for domain
generalization. The main assumption is that the Fourier phase information
contains high-level semantics and is not easily affected by domain shifts. To
force the model to capture phase information, we develop a novel Fourier-based
data augmentation strategy called amplitude mix which linearly interpolates
between the amplitude spectrums of two images. A dual-formed consistency loss
called co-teacher regularization is further introduced between the predictions
induced from original and augmented images. Extensive experiments on three
benchmarks have demonstrated that the proposed method is able to achieve
state-of-the-arts performance for domain generalization.",1,1,0,0,1,0,0.743871,7.0,0.814225,55
532e88c2-0756-42c1-a6a2-e59ed08c37c3,Plug-Tagger: A Pluggable Sequence Labeling Framework Using Language Models,5,0.0156719,0.255873,"Plug-and-play functionality allows deep learning models to adapt well to
different tasks without requiring any parameters modified. Recently,
prefix-tuning was shown to be a plug-and-play method on various text generation
tasks by simply inserting corresponding continuous vectors into the inputs.
However, sequence labeling tasks invalidate existing plug-and-play methods
since different label sets demand changes to the architecture of the model
classifier. In this work, we propose the use of label word prediction instead
of classification to totally reuse the architecture of pre-trained models for
sequence labeling tasks. Specifically, for each task, a label word set is first
constructed by selecting a high-frequency word for each class respectively, and
then, task-specific vectors are inserted into the inputs and optimized to
manipulate the model predictions towards the corresponding label words. As a
result, by simply switching the plugin vectors on the input, a frozen
pre-trained language model is allowed to perform different tasks. Experimental
results on three sequence labeling tasks show that the performance of the
proposed method can achieve comparable performance with standard fine-tuning
with only 0.1\% task-specific parameters. In addition, our method is up to 70
times faster than non-plug-and-play methods while switching different tasks
under the resource-constrained scenario.",0,1,0,0,0,0,0.757463,5.0,0.747765,44
10cb9bf6-84ba-4181-8976-d4d53cf709c3,Putting RDF2vec in Order,11,0.0984631,0.486044,"The RDF2vec method for creating node embeddings on knowledge graphs is based
on word2vec, which, in turn, is agnostic towards the position of context words.
In this paper, we argue that this might be a shortcoming when training RDF2vec,
and show that using a word2vec variant which respects order yields considerable
performance gains especially on tasks where entities of different classes are
involved.",0,0,0,0,0,0,0.276545,8.0,0.657835,15
a59c4b52-8b1e-48a8-a902-a1ec54e99725,Challenges in Detoxifying Language Models,140,0.110065,0.53595,"Large language models (LM) generate remarkably fluent text and can be
efficiently adapted across NLP tasks. Measuring and guaranteeing the quality of
generated text in terms of safety is imperative for deploying LMs in the real
world; to this end, prior work often relies on automatic evaluation of LM
toxicity. We critically discuss this approach, evaluate several toxicity
mitigation strategies with respect to both automatic and human evaluation, and
analyze consequences of toxicity mitigation in terms of model bias and LM
quality. We demonstrate that while basic intervention strategies can
effectively optimize previously established automatic metrics on the
RealToxicityPrompts dataset, this comes at the cost of reduced LM coverage for
both texts about, and dialects of, marginalized groups. Additionally, we find
that human raters often disagree with high automatic toxicity scores after
strong toxicity reduction interventions -- highlighting further the nuances
involved in careful evaluation of LM toxicity.",0,1,0,0,0,0,0.24999,5.0,0.428924,62
9da30265-a44a-4917-a345-8c4dafd49436,How to Split: the Effect of Word Segmentation on Gender Bias in Speech Translation,13,0.0900737,0.426533,"Having recognized gender bias as a major issue affecting current translation
technologies, researchers have primarily attempted to mitigate it by working on
the data front. However, whether algorithmic aspects concur to exacerbate
unwanted outputs remains so far under-investigated. In this work, we bring the
analysis on gender bias in automatic translation onto a seemingly neutral yet
critical component: word segmentation. Can segmenting methods influence the
ability to translate gender? Do certain segmentation approaches penalize the
representation of feminine linguistic markings? We address these questions by
comparing 5 existing segmentation strategies on the target side of speech
translation systems. Our results on two language pairs (English-Italian/French)
show that state-of-the-art sub-word splitting (BPE) comes at the cost of higher
gender bias. In light of this finding, we propose a combined approach that
preserves BPE overall translation quality, while leveraging the higher ability
of character-based segmentation to properly translate gender.",1,0,0,0,0,0,0.399738,5.0,0.543596,99
b4aa5783-94a0-43f7-9f7e-a0059386e466,Predicting Lexical Complexity in English Texts: The Complex 2.0 Dataset,33,0.565597,0.685904,"Identifying words which may cause difficulty for a reader is an essential
step in most lexical text simplification systems prior to lexical substitution
and can also be used for assessing the readability of a text. This task is
commonly referred to as Complex Word Identification (CWI) and is often modelled
as a supervised classification problem. For training such systems, annotated
datasets in which words and sometimes multi-word expressions are labelled
regarding complexity are required. In this paper we analyze previous work
carried out in this task and investigate the properties of CWI datasets for
English. We develop a protocol for the annotation of lexical complexity and use
this to annotate a new dataset, CompLex 2.0. We present experiments using both
new and old datasets to investigate the nature of lexical complexity. We found
that a Likert-scale annotation protocol provides an objective setting that is
superior for identifying the complexity of words compared to a binary
annotation protocol. We release a new dataset using our new protocol to promote
the task of Lexical Complexity Prediction.",0,1,0,1,0,0,0.166065,10.0,0.668461,95
0463fafe-3b98-42a3-9a8c-bfa691e0f812,A model for full local image interpretation,8,0.0242729,0.346948,"We describe a computational model of humans' ability to provide a detailed
interpretation of components in a scene. Humans can identify in an image
meaningful components almost everywhere, and identifying these components is an
essential part of the visual process, and of understanding the surrounding
scene and its potential meaning to the viewer. Detailed interpretation is
beyond the scope of current models of visual recognition. Our model suggests
that this is a fundamental limitation, related to the fact that existing models
rely on feed-forward but limited top-down processing. In our model, a first
recognition stage leads to the initial activation of class candidates, which is
incomplete and with limited accuracy. This stage then triggers the application
of class-specific interpretation and validation processes, which recover richer
and more accurate interpretation of the visible scene. We discuss implications
of the model for visual interpretation by humans and by computer vision models.",0,0,0,0,0,0,0.0669387,21.0,0.796239,23
ef3d0327-c0d1-4812-a431-57f253526778,Technical Language Supervision for Intelligent Fault Diagnosis in Process Industry,4,0.0607876,0.229335,"In the process industry, condition monitoring systems with automated fault
diagnosis methods assist human experts and thereby improve maintenance
efficiency, process sustainability, and workplace safety. Improving the
automated fault diagnosis methods using data and machine learning-based models
is a central aspect of intelligent fault diagnosis (IFD). A major challenge in
IFD is to develop realistic datasets with accurate labels needed to train and
validate models, and to transfer models trained with labeled lab data to
heterogeneous process industry environments. However, fault descriptions and
work-orders written by domain experts are increasingly digitised in modern
condition monitoring systems, for example in the context of rotating equipment
monitoring. Thus, domain-specific knowledge about fault characteristics and
severities exists as technical language annotations in industrial datasets.
Furthermore, recent advances in natural language processing enable weakly
supervised model optimisation using natural language annotations, most notably
in the form of natural language supervision (NLS). This creates a timely
opportunity to develop technical language supervision (TLS) solutions for IFD
systems grounded in industrial data, for example as a complement to
pre-training with lab data to address problems like overfitting and inaccurate
out-of-sample generalisation. We surveyed the literature and identify a
considerable improvement in the maturity of NLS over the last two years,
facilitating applications beyond natural language; a rapid development of weak
supervision methods; and transfer learning as a current trend in IFD which can
benefit from these developments. Finally we describe a general framework for
TLS and implement a TLS case study based on SentenceBERT and contrastive
learning based zero-shot inference on annotated industry data.",0,0,0,0,0,0,0.887984,6.0,0.862343,173
b09ed03d-cbb7-4978-9c0b-5acd66e79f9b,Learning Crisp Boundaries Using Deep Refinement Network and Adaptive Weighting Loss,33,0.149046,0.863451,"Significant progress has been made in boundary detection with the help of
convolutional neural networks. Recent boundary detection models not only focus
on real object boundary detection but also ""crisp"" boundaries (precisely
localized along the object's contour). There are two methods to evaluate crisp
boundary performance. One uses more strict tolerance to measure the distance
between the ground truth and the detected contour. The other focuses on
evaluating the contour map without any postprocessing. In this study, we
analyze both methods and conclude that both methods are two aspects of crisp
contour evaluation. Accordingly, we propose a novel network named deep
refinement network (DRNet) that stacks multiple refinement modules to achieve
richer feature representation and a novel loss function, which combines
cross-entropy and dice loss through effective adaptive fusion. Experimental
results demonstrated that we achieve state-of-the-art performance for several
available datasets.",0,1,0,0,1,0,0.140204,12.0,0.708374,48
34560bbb-ba8f-4ba4-ad27-3f1f82cfa8a9,Mixup Without Hesitation,15,0.0423774,0.190909,"Mixup linearly interpolates pairs of examples to form new samples, which is
easy to implement and has been shown to be effective in image classification
tasks. However, there are two drawbacks in mixup: one is that more training
epochs are needed to obtain a well-trained model; the other is that mixup
requires tuning a hyper-parameter to gain appropriate capacity but that is a
difficult task. In this paper, we find that mixup constantly explores the
representation space, and inspired by the exploration-exploitation dilemma in
reinforcement learning, we propose mixup Without hesitation (mWh), a concise,
effective, and easy-to-use training algorithm. We show that mWh strikes a good
balance between exploration and exploitation by gradually replacing mixup with
basic data augmentation. It can achieve a strong baseline with less training
time than original mixup and without searching for optimal hyper-parameter,
i.e., mWh acts as mixup without hesitation. mWh can also transfer to CutMix,
and gain consistent improvement on other machine learning and computer vision
tasks such as object detection. Our code is open-source and available at
https://github.com/yuhao318/mwh",1,1,0,0,0,1,0.900753,5.0,0.845574,26
13088cfb-347b-4589-a42e-25dcf3824f9d,Misinfo Reaction Frames: Reasoning about Readers' Reactions to News Headlines,30,0.505541,0.947915,"Even to a simple and short news headline, readers react in a multitude of
ways: cognitively (e.g. inferring the writer's intent), emotionally (e.g.
feeling distrust), and behaviorally (e.g. sharing the news with their friends).
Such reactions are instantaneous and yet complex, as they rely on factors that
go beyond interpreting factual content of news. We propose Misinfo Reaction
Frames (MRF), a pragmatic formalism for modeling how readers might react to a
news headline. In contrast to categorical schema, our free-text dimensions
provide a more nuanced way of understanding intent beyond being benign or
malicious. We also introduce a Misinfo Reaction Frames corpus, a crowdsourced
dataset of reactions to over 25k news headlines focusing on global crises: the
Covid-19 pandemic, climate change, and cancer. Empirical results confirm that
it is indeed possible for neural models to predict the prominent patterns of
readers' reactions to previously unseen news headlines. Additionally, our user
study shows that displaying machine-generated MRF implications alongside news
headlines to readers can increase their trust in real news while decreasing
their trust in misinformation. Our work demonstrates the feasibility and
importance of pragmatic inferences on news headlines to help enhance AI-guided
misinformation detection and mitigation.",1,0,1,1,0,0,0.93941,5.0,0.884295,87
94b55f08-1b3e-4afb-b063-aa5b2710771c,Machine Translation Verbosity Control for Automatic Dubbing,20,0.0331615,0.517966,"Automatic dubbing aims at seamlessly replacing the speech in a video document
with synthetic speech in a different language. The task implies many
challenges, one of which is generating translations that not only convey the
original content, but also match the duration of the corresponding utterances.
In this paper, we focus on the problem of controlling the verbosity of machine
translation output, so that subsequent steps of our automatic dubbing pipeline
can generate dubs of better quality. We propose new methods to control the
verbosity of MT output and compare them against the state of the art with both
intrinsic and extrinsic evaluations. For our experiments we use a public data
set to dub English speeches into French, Italian, German and Spanish. Finally,
we report extensive subjective tests that measure the impact of MT verbosity
control on the final quality of dubbed video clips.",0,1,0,0,0,0,0.0975155,6.0,0.35228,32
f56c9f3a-2f54-4174-8c66-cbf0fe0be64e,The Catalan Language CLUB,2,0.00454302,0.0558837,"The Catalan Language Understanding Benchmark (CLUB) encompasses various
datasets representative of different NLU tasks that enable accurate evaluations
of language models, following the General Language Understanding Evaluation
(GLUE) example. It is part of AINA and PlanTL, two public funding initiatives
to empower the Catalan language in the Artificial Intelligence era.",0,1,0,1,0,0,0.760691,7.0,0.821177,7
c7d4cee5-3b0e-438c-b98b-77512cc3e369,Image-Based CLIP-Guided Essence Transfer,42,0.0386072,0.399538,"We make the distinction between (i) style transfer, in which a source image
is manipulated to match the textures and colors of a target image, and (ii)
essence transfer, in which one edits the source image to include high-level
semantic attributes from the target. Crucially, the semantic attributes that
constitute the essence of an image may differ from image to image. Our blending
operator combines the powerful StyleGAN generator and the semantic encoder of
CLIP in a novel way that is simultaneously additive in both latent spaces,
resulting in a mechanism that guarantees both identity preservation and
high-level feature transfer without relying on a facial recognition network. We
present two variants of our method. The first is based on optimization, while
the second fine-tunes an existing inversion encoder to perform essence
extraction. Through extensive experiments, we demonstrate the superiority of
our methods for essence transfer over existing methods for style transfer,
domain adaptation, and text-based semantic editing. Our code is available at
https://github.com/hila-chefer/TargetCLIP.",1,0,1,0,0,0,0.431042,4.0,0.454443,55
b7c00ce8-7e65-41f4-8c55-d419fe8af0e2,Clinical Outcome Prediction from Admission Notes using Self-Supervised Knowledge Integration,55,0.452932,0.976738,"Outcome prediction from clinical text can prevent doctors from overlooking
possible risks and help hospitals to plan capacities. We simulate patients at
admission time, when decision support can be especially valuable, and
contribute a novel admission to discharge task with four common outcome
prediction targets: Diagnoses at discharge, procedures performed, in-hospital
mortality and length-of-stay prediction. The ideal system should infer outcomes
based on symptoms, pre-conditions and risk factors of a patient. We evaluate
the effectiveness of language models to handle this scenario and propose
clinical outcome pre-training to integrate knowledge about patient outcomes
from multiple public sources. We further present a simple method to incorporate
ICD code hierarchy into the models. We show that our approach improves
performance on the outcome tasks against several baselines. A detailed analysis
reveals further strengths of the model, including transferability, but also
weaknesses such as handling of vital values and inconsistencies in the
underlying data.",1,1,1,0,0,0,0.701697,4.0,0.645222,48
488cbce2-d7c8-4f90-a4a8-8596a926a816,Towards Personalized Federated Learning,517,0.995964,0.999844,"In parallel with the rapid adoption of Artificial Intelligence (AI) empowered
by advances in AI research, there have been growing awareness and concerns of
data privacy. Recent significant developments in the data regulation landscape
have prompted a seismic shift in interest towards privacy-preserving AI. This
has contributed to the popularity of Federated Learning (FL), the leading
paradigm for the training of machine learning models on data silos in a
privacy-preserving manner. In this survey, we explore the domain of
Personalized FL (PFL) to address the fundamental challenges of FL on
heterogeneous data, a universal characteristic inherent in all real-world
datasets. We analyze the key motivations for PFL and present a unique taxonomy
of PFL techniques categorized according to the key challenges and
personalization strategies in PFL. We highlight their key ideas, challenges and
opportunities and envision promising future trajectories of research towards
new PFL architectural design, realistic PFL benchmarking, and trustworthy PFL
approaches.",0,0,1,0,0,0,0.952764,3.0,0.835519,138
1f7b665a-20d3-4f38-8e6c-f7b8c41fe46c,WSDesc: Weakly Supervised 3D Local Descriptor Learning for Point Cloud Registration,10,0.153846,0.271623,"In this work, we present a novel method called WSDesc to learn 3D local
descriptors in a weakly supervised manner for robust point cloud registration.
Our work builds upon recent 3D CNN-based descriptor extractors, which leverage
a voxel-based representation to parameterize local geometry of 3D points.
Instead of using a predefined fixed-size local support in voxelization, we
propose to learn the optimal support in a data-driven manner. To this end, we
design a novel differentiable voxelization layer that can back-propagate the
gradient to the support size optimization. To train the extracted descriptors,
we propose a novel registration loss based on the deviation from rigidity of 3D
transformations, and the loss is weakly supervised by the prior knowledge that
the input point clouds have partial overlap, without requiring ground-truth
alignment information. Through extensive experiments, we show that our learned
descriptors yield superior performance on existing geometric registration
benchmarks.",1,1,0,0,1,0,0.930602,7.0,0.910264,79
b22b5fce-f2c2-4836-b454-490ef8105fe1,Improving Entity Linking through Semantic Reinforced Entity Embeddings,36,0.229403,0.578892,"Entity embeddings, which represent different aspects of each entity with a
single vector like word embeddings, are a key component of neural entity
linking models. Existing entity embeddings are learned from canonical Wikipedia
articles and local contexts surrounding target entities. Such entity embeddings
are effective, but too distinctive for linking models to learn contextual
commonality. We propose a simple yet effective method, FGS2EE, to inject
fine-grained semantic information into entity embeddings to reduce the
distinctiveness and facilitate the learning of contextual commonality. FGS2EE
first uses the embeddings of semantic type words to generate semantic
embeddings, and then combines them with existing entity embeddings through
linear aggregation. Extensive experiments show the effectiveness of such
embeddings. Based on our entity embeddings, we achieved new sate-of-the-art
performance on entity linking.",1,1,0,0,1,0,0.219939,8.0,0.624722,25
210cce7f-ec85-4526-b823-1d8b908ba099,Diff-TTS: A Denoising Diffusion Model for Text-to-Speech,148,0.408197,0.997963,"Although neural text-to-speech (TTS) models have attracted a lot of attention
and succeeded in generating human-like speech, there is still room for
improvements to its naturalness and architectural efficiency. In this work, we
propose a novel non-autoregressive TTS model, namely Diff-TTS, which achieves
highly natural and efficient speech synthesis. Given the text, Diff-TTS
exploits a denoising diffusion framework to transform the noise signal into a
mel-spectrogram via diffusion time steps. In order to learn the mel-spectrogram
distribution conditioned on the text, we present a likelihood-based
optimization method for TTS. Furthermore, to boost up the inference speed, we
leverage the accelerated sampling method that allows Diff-TTS to generate raw
waveforms much faster without significantly degrading perceptual quality.
Through experiments, we verified that Diff-TTS generates 28 times faster than
the real-time with a single NVIDIA 2080Ti GPU.",0,0,1,0,0,0,0.946829,2.0,0.733505,31
540c65ac-c641-4856-892d-6ff12a721e7a,Deep Algorithm Unrolling for Biomedical Imaging,8,0.0258408,0.328185,"In this chapter, we review biomedical applications and breakthroughs via
leveraging algorithm unrolling, an important technique that bridges between
traditional iterative algorithms and modern deep learning techniques. To
provide context, we start by tracing the origin of algorithm unrolling and
providing a comprehensive tutorial on how to unroll iterative algorithms into
deep networks. We then extensively cover algorithm unrolling in a wide variety
of biomedical imaging modalities and delve into several representative recent
works in detail. Indeed, there is a rich history of iterative algorithms for
biomedical image synthesis, which makes the field ripe for unrolling
techniques. In addition, we put algorithm unrolling into a broad perspective,
in order to understand why it is particularly effective and discuss recent
trends. Finally, we conclude the chapter by discussing open challenges, and
suggesting future research directions.",0,0,0,0,0,0,0.063226,9.0,0.518,46
a46e3245-7355-4530-bd3f-293963b78d75,Disentangled Representation with Dual-stage Feature Learning for Face Anti-spoofing,14,0.318062,0.80734,"As face recognition is widely used in diverse security-critical applications,
the study of face anti-spoofing (FAS) has attracted more and more attention.
Several FAS methods have achieved promising performances if the attack types in
the testing data are the same as training data, while the performance
significantly degrades for unseen attack types. It is essential to learn more
generalized and discriminative features to prevent overfitting to pre-defined
spoof attack types. This paper proposes a novel dual-stage disentangled
representation learning method that can efficiently untangle spoof-related
features from irrelevant ones. Unlike previous FAS disentanglement works with
one-stage architecture, we found that the dual-stage training design can
improve the training stability and effectively encode the features to detect
unseen attack types. Our experiments show that the proposed method provides
superior accuracy than the state-of-the-art methods on several cross-type FAS
benchmarks.",0,1,0,0,1,0,0.965384,8.0,0.950441,37
1c0f68be-b29f-4260-8b88-dd01a31eb912,Challenges in Generalization in Open Domain Question Answering,33,0.395121,0.822075,"Recent work on Open Domain Question Answering has shown that there is a large
discrepancy in model performance between novel test questions and those that
largely overlap with training questions. However, it is unclear which aspects
of novel questions make them challenging. Drawing upon studies on systematic
generalization, we introduce and annotate questions according to three
categories that measure different levels and kinds of generalization: training
set overlap, compositional generalization (comp-gen), and novel-entity
generalization (novel-entity). When evaluating six popular parametric and
non-parametric models, we find that for the established Natural Questions and
TriviaQA datasets, even the strongest model performance for
comp-gen/novel-entity is 13.1/5.4% and 9.6/1.5% lower compared to that for the
full test set -- indicating the challenge posed by these types of questions.
Furthermore, we show that whilst non-parametric models can handle questions
containing novel entities relatively well, they struggle with those requiring
compositional generalization. Lastly, we find that key question difficulty
factors are: cascading errors from the retrieval component, frequency of
question pattern, and frequency of the entity.",0,0,0,0,0,0,0.962085,4.0,0.894021,75
cf7f6135-8933-42db-be06-7c09e0ce7aa4,Contextualized Knowledge-aware Attentive Neural Network: Enhancing Answer Selection with Knowledge,18,0.127224,0.309064,"Answer selection, which is involved in many natural language processing
applications such as dialog systems and question answering (QA), is an
important yet challenging task in practice, since conventional methods
typically suffer from the issues of ignoring diverse real-world background
knowledge. In this paper, we extensively investigate approaches to enhancing
the answer selection model with external knowledge from knowledge graph (KG).
First, we present a context-knowledge interaction learning framework,
Knowledge-aware Neural Network (KNN), which learns the QA sentence
representations by considering a tight interaction with the external knowledge
from KG and the textual information. Then, we develop two kinds of
knowledge-aware attention mechanism to summarize both the context-based and
knowledge-based interactions between questions and answers. To handle the
diversity and complexity of KG information, we further propose a Contextualized
Knowledge-aware Attentive Neural Network (CKANN), which improves the knowledge
representation learning with structure information via a customized Graph
Convolutional Network (GCN) and comprehensively learns context-based and
knowledge-based sentence representation via the multi-view knowledge-aware
attention mechanism. We evaluate our method on four widely-used benchmark QA
datasets, including WikiQA, TREC QA, InsuranceQA and Yahoo QA. Results verify
the benefits of incorporating external knowledge from KG, and show the robust
superiority and extensive applicability of our method.",1,1,0,0,0,1,0.269035,8.0,0.653782,71
0044e6b5-e63e-495e-9e0c-3db812b71af2,Explaining Time Series Predictions with Dynamic Masks,52,0.248776,0.872865,"How can we explain the predictions of a machine learning model? When the data
is structured as a multivariate time series, this question induces additional
difficulties such as the necessity for the explanation to embody the time
dependency and the large number of inputs. To address these challenges, we
propose dynamic masks (Dynamask). This method produces instance-wise importance
scores for each feature at each time step by fitting a perturbation mask to the
input sequence. In order to incorporate the time dependency of the data,
Dynamask studies the effects of dynamic perturbation operators. In order to
tackle the large number of inputs, we propose a scheme to make the feature
selection parsimonious (to select no more feature than necessary) and legible
(a notion that we detail by making a parallel with information theory). With
synthetic and real-world data, we demonstrate that the dynamic underpinning of
Dynamask, together with its parsimony, offer a neat improvement in the
identification of feature importance over time. The modularity of Dynamask
makes it ideal as a plug-in to increase the transparency of a wide range of
machine learning models in areas such as medicine and finance, where time
series are abundant.",1,1,0,0,0,0,0.642157,7.0,0.773978,49
1243ba7d-f88b-4408-9071-771e566592e6,"""Will You Find These Shortcuts?"" A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification",56,0.0963523,0.778857,"Feature attribution a.k.a. input salience methods which assign an importance
score to a feature are abundant but may produce surprisingly different results
for the same model on the same input. While differences are expected if
disparate definitions of importance are assumed, most methods claim to provide
faithful attributions and point at the features most relevant for a model's
prediction. Existing work on faithfulness evaluation is not conclusive and does
not provide a clear answer as to how different methods are to be compared.
Focusing on text classification and the model debugging scenario, our main
contribution is a protocol for faithfulness evaluation that makes use of
partially synthetic data to obtain ground truth for feature importance ranking.
Following the protocol, we do an in-depth analysis of four standard salience
method classes on a range of datasets and shortcuts for BERT and LSTM models
and demonstrate that some of the most popular method configurations provide
poor results even for simplest shortcuts. We recommend following the protocol
for each new task and model combination to find the best method for identifying
shortcuts.",1,1,0,0,0,0,0.236487,5.0,0.416116,65
3f63c4e7-3726-459a-ab63-3996d3a43232,Network of Tensor Time Series,29,0.429117,0.594217,"Co-evolving time series appears in a multitude of applications such as
environmental monitoring, financial analysis, and smart transportation. This
paper aims to address the following challenges, including (C1) how to
incorporate explicit relationship networks of the time series; (C2) how to
model the implicit relationship of the temporal dynamics. We propose a novel
model called Network of Tensor Time Series, which is comprised of two modules,
including Tensor Graph Convolutional Network (TGCN) and Tensor Recurrent Neural
Network (TRNN). TGCN tackles the first challenge by generalizing Graph
Convolutional Network (GCN) for flat graphs to tensor graphs, which captures
the synergy between multiple graphs associated with the tensors. TRNN leverages
tensor decomposition to model the implicit relationships among co-evolving time
series. The experimental results on five real-world datasets demonstrate the
efficacy of the proposed method.",0,0,0,0,0,0,0.729399,9.0,0.850931,46
8fdceb75-c918-41fa-980b-7e213b6fd290,Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder,5,0.0847454,0.293505,"In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an
Artificial Intelligence (AI) Health Outcomes Challenge seeking solutions to
predict risk in value-based care for incorporation into CMS Innovation Center
payment and service delivery models. Recently, modern language models have
played key roles in a number of health related tasks. This paper presents, to
the best of our knowledge, the first application of these models to patient
readmission prediction. To facilitate this, we create a dataset of 1.2 million
medical history samples derived from the Limited Dataset (LDS) issued by CMS.
Moreover, we propose a comprehensive modeling solution centered on a deep
learning framework for this data. To demonstrate the framework, we train an
attention-based Transformer to learn Medicare semantics in support of
performing downstream prediction tasks thereby achieving 0.91 AUC and 0.91
recall on readmission classification. We also introduce a novel data
pre-processing pipeline and discuss pertinent deployment considerations
surrounding model explainability and bias.",0,1,0,1,0,0,0.648734,8.0,0.804467,55
a76532f9-c315-49d3-8d77-4b3cf5103501,Impact of Aliasing on Generalization in Deep Convolutional Networks,30,0.0208298,0.345426,"We investigate the impact of aliasing on generalization in Deep Convolutional
Networks and show that data augmentation schemes alone are unable to prevent it
due to structural limitations in widely used architectures. Drawing insights
from frequency analysis theory, we take a closer look at ResNet and
EfficientNet architectures and review the trade-off between aliasing and
information loss in each of their major components. We show how to mitigate
aliasing by inserting non-trainable low-pass filters at key locations,
particularly where networks lack the capacity to learn them. These simple
architectural changes lead to substantial improvements in generalization on
i.i.d. and even more on out-of-distribution conditions, such as image
classification under natural corruptions on ImageNet-C [11] and few-shot
learning on Meta-Dataset [26]. State-of-the art results are achieved on both
datasets without introducing additional trainable parameters and using the
default hyper-parameters of open source codebases.",0,0,0,0,1,0,0.316114,5.0,0.484577,32
437d1a0c-5858-4797-862c-fee7b82657a2,Multilingual AMR Parsing with Noisy Knowledge Distillation,14,0.344511,0.533867,"We study multilingual AMR parsing from the perspective of knowledge
distillation, where the aim is to learn and improve a multilingual AMR parser
by using an existing English parser as its teacher. We constrain our
exploration in a strict multilingual setting: there is but one model to parse
all different languages including English. We identify that noisy input and
precise output are the key to successful distillation. Together with extensive
pre-training, we obtain an AMR parser whose performances surpass all previously
published results on four different foreign languages, including German,
Spanish, Italian, and Chinese, by large margins (up to 18.8 \textsc{Smatch}
points on Chinese and on average 11.3 \textsc{Smatch} points). Our parser also
achieves comparable performance on English to the latest state-of-the-art
English-only parser.",1,1,0,0,1,0,0.907503,6.0,0.876318,58
c50243d1-0770-44e9-8746-d30fa44c5da7,Extracting and Inferring Personal Attributes from Dialogue,12,0.707781,0.691635,"Personal attributes represent structured information about a person, such as
their hobbies, pets, family, likes and dislikes. We introduce the tasks of
extracting and inferring personal attributes from human-human dialogue, and
analyze the linguistic demands of these tasks. To meet these challenges, we
introduce a simple and extensible model that combines an autoregressive
language model utilizing constrained attribute generation with a discriminative
reranker. Our model outperforms strong baselines on extracting personal
attributes as well as inferring personal attributes that are not contained
verbatim in utterances and instead requires commonsense reasoning and lexical
inferences, which occur frequently in everyday conversation. Finally, we
demonstrate the benefit of incorporating personal attributes in social
chit-chat and task-oriented dialogue settings.",0,0,0,0,0,0,0.987781,5.0,0.974648,50
005ef079-17a8-405a-abd1-db7f06c436b0,Combining Textual Features for the Detection of Hateful and Offensive Language,4,0.156351,0.463869,"The detection of offensive, hateful and profane language has become a
critical challenge since many users in social networks are exposed to
cyberbullying activities on a daily basis. In this paper, we present an
analysis of combining different textual features for the detection of hateful
or offensive posts on Twitter. We provide a detailed experimental evaluation to
understand the impact of each building block in a neural network architecture.
The proposed architecture is evaluated on the English Subtask 1A: Identifying
Hate, offensive and profane content from the post datasets of HASOC-2021
dataset under the team name TIB-VA. We compared different variants of the
contextual word embeddings combined with the character level embeddings and the
encoding of collected hate terms.",0,1,0,0,0,0,0.989734,5.0,0.982405,16
0d900376-01e4-4508-9784-9587efe9f74f,Value alignment: a formal approach,28,0.133303,0.333147,"principles that should govern autonomous AI systems. It essentially states
that a system's goals and behaviour should be aligned with human values. But
how to ensure value alignment? In this paper we first provide a formal model to
represent values through preferences and ways to compute value aggregations;
i.e. preferences with respect to a group of agents and/or preferences with
respect to sets of values. Value alignment is then defined, and computed, for a
given norm with respect to a given value through the increase/decrease that it
results in the preferences of future states of the world. We focus on norms as
it is norms that govern behaviour, and as such, the alignment of a given system
with a given value will be dictated by the norms the system follows.",0,0,0,0,0,0,0.00958951,11.0,0.431663,26
19fac8e1-84ac-4379-8830-b28da1469cfa,Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition,6,0.0540848,0.379932,"End-to-end speech recognition generally uses hand-engineered acoustic
features as input and excludes the feature extraction module from its joint
optimization. To extract learnable and adaptive features and mitigate
information loss, we propose a new encoder that adopts globally attentive
locally recurrent (GALR) networks and directly takes raw waveform as input. We
observe improved ASR performance and robustness by applying GALR on different
window lengths to aggregate fine-grain temporal information into multi-scale
acoustic features. Experiments are conducted on a benchmark dataset AISHELL-2
and two large-scale Mandarin speech corpus of 5,000 hours and 21,000 hours.
With faster speed and comparable model size, our proposed multi-scale GALR
waveform encoder achieved consistent character error rate reductions (CERRs)
from 7.9% to 28.1% relative over strong baselines, including Conformer and
TDNN-Conformer. In particular, our approach demonstrated notable robustness
than the traditional handcrafted features and outperformed the baseline
MFCC-based TDNN-Conformer model by a 15.2% CERR on a music-mixed real-world
speech test set.",0,1,0,0,1,0,0.469201,6.0,0.655644,37
7e68c453-1388-4d5e-9f77-a763361b7b96,Let-Mi: An Arabic Levantine Twitter Dataset for Misogynistic Language,35,0.413139,0.208831,"Online misogyny has become an increasing worry for Arab women who experience
gender-based online abuse on a daily basis. Misogyny automatic detection
systems can assist in the prohibition of anti-women Arabic toxic content.
Developing such systems is hindered by the lack of the Arabic misogyny
benchmark datasets. In this paper, we introduce an Arabic Levantine Twitter
dataset for Misogynistic language (LeT-Mi) to be the first benchmark dataset
for Arabic misogyny. We further provide a detailed review of the dataset
creation and annotation phases. The consistency of the annotations for the
proposed dataset was emphasized through inter-rater agreement evaluation
measures. Moreover, Let-Mi was used as an evaluation dataset through
binary/multi-/target classification tasks conducted by several state-of-the-art
machine learning systems along with Multi-Task Learning (MTL) configuration.
The obtained results indicated that the performances achieved by the used
systems are consistent with state-of-the-art results for languages other than
Arabic, while employing MTL improved the performance of the misogyny/target
classification tasks.",0,1,1,1,1,0,0.750257,6.0,0.786323,30
46a3278a-8319-4c42-834d-177576460f22,Itihasa: A large-scale corpus for Sanskrit to English translation,6,0.763959,0.657481,"This work introduces Itihasa, a large-scale translation dataset containing
93,000 pairs of Sanskrit shlokas and their English translations. The shlokas
are extracted from two Indian epics viz., The Ramayana and The Mahabharata. We
first describe the motivation behind the curation of such a dataset and follow
up with empirical analysis to bring out its nuances. We then benchmark the
performance of standard translation models on this corpus and show that even
state-of-the-art transformer architectures perform poorly, emphasizing the
complexity of the dataset.",0,1,0,1,0,0,0.971571,7.0,0.951488,32
ac03271a-4a5d-4d41-9cb6-ef32f14f42ca,Multi-view Inference for Relation Extraction with Uncertain Knowledge,16,0.114858,0.437226,"Knowledge graphs (KGs) are widely used to facilitate relation extraction (RE)
tasks. While most previous RE methods focus on leveraging deterministic KGs,
uncertain KGs, which assign a confidence score for each relation instance, can
provide prior probability distributions of relational facts as valuable
external knowledge for RE models. This paper proposes to exploit uncertain
knowledge to improve relation extraction. Specifically, we introduce ProBase,
an uncertain KG that indicates to what extent a target entity belongs to a
concept, into our RE architecture. We then design a novel multi-view inference
framework to systematically integrate local context and global knowledge across
three views: mention-, entity- and concept-view. The experimental results show
that our model achieves competitive performances on both sentence- and
document-level relation extraction, which verifies the effectiveness of
introducing uncertain knowledge and the multi-view inference framework that we
design.",0,1,0,0,0,0,0.387839,6.0,0.613127,38
d8d18b97-91a5-4ad3-866c-25b291978f32,Transferable Dialogue Systems and User Simulators,46,0.28083,0.795008,"One of the difficulties in training dialogue systems is the lack of training
data. We explore the possibility of creating dialogue data through the
interaction between a dialogue system and a user simulator. Our goal is to
develop a modelling framework that can incorporate new dialogue scenarios
through self-play between the two agents. In this framework, we first pre-train
the two agents on a collection of source domain dialogues, which equips the
agents to converse with each other via natural language. With further
fine-tuning on a small amount of target domain data, the agents continue to
interact with the aim of improving their behaviors using reinforcement learning
with structured reward functions. In experiments on the MultiWOZ dataset, two
practical transfer learning problems are investigated: 1) domain adaptation and
2) single-to-multiple domain transfer. We demonstrate that the proposed
framework is highly effective in bootstrapping the performance of the two
agents in transfer learning. We also show that our method leads to improvements
in dialogue system performance on complete datasets.",1,1,0,0,0,0,0.221236,8.0,0.625557,40
08a249f8-2f14-4e7c-bd36-79ab45616393,A Classification of Artificial Intelligence Systems for Mathematics Education,5,0.0423847,0.409714,"This chapter provides an overview of the different Artificial Intelligence
(AI) systems that are being used in contemporary digital tools for Mathematics
Education (ME). It is aimed at researchers in AI and Machine Learning (ML), for
whom we shed some light on the specific technologies that are being used in
educational applications; and at researchers in ME, for whom we clarify: i)
what the possibilities of the current AI technologies are, ii) what is still
out of reach and iii) what is to be expected in the near future. We start our
analysis by establishing a high-level taxonomy of AI tools that are found as
components in digital ME applications. Then, we describe in detail how these AI
tools, and in particular ML, are being used in two key applications,
specifically AI-based calculators and intelligent tutoring systems. We finish
the chapter with a discussion about student modeling systems and their
relationship to artificial general intelligence.",0,0,0,0,0,0,0.12217,9.0,0.59474,63
7917bb66-5065-412d-8226-571dd9ada0bd,Weakly Supervised Few-Shot Segmentation Via Meta-Learning,14,0.137743,0.304054,"Semantic segmentation is a classic computer vision task with multiple
applications, which includes medical and remote sensing image analysis. Despite
recent advances with deep-based approaches, labeling samples (pixels) for
training models is laborious and, in some cases, unfeasible. In this paper, we
present two novel meta learning methods, named WeaSeL and ProtoSeg, for the
few-shot semantic segmentation task with sparse annotations. We conducted
extensive evaluation of the proposed methods in different applications (12
datasets) in medical imaging and agricultural remote sensing, which are very
distinct fields of knowledge and usually subject to data scarcity. The results
demonstrated the potential of our method, achieving suitable results for
segmenting both coffee/orange crops and anatomical parts of the human body in
comparison with full dense annotation.",0,0,0,0,0,0,0.398066,8.0,0.714064,49
a0805d97-fb72-4880-abfe-ba60f1a7b10c,Explainable Tsetlin Machine framework for fake news detection with credibility score assessment,26,0.379891,0.733563,"The proliferation of fake news, i.e., news intentionally spread for
misinformation, poses a threat to individuals and society. Despite various
fact-checking websites such as PolitiFact, robust detection techniques are
required to deal with the increase in fake news. Several deep learning models
show promising results for fake news classification, however, their black-box
nature makes it difficult to explain their classification decisions and
quality-assure the models. We here address this problem by proposing a novel
interpretable fake news detection framework based on the recently introduced
Tsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to
capture lexical and semantic properties of both true and fake news text.
Further, we use the clause ensembles to calculate the credibility of fake news.
For evaluation, we conduct experiments on two publicly available datasets,
PolitiFact and GossipCop, and demonstrate that the TM framework significantly
outperforms previously published baselines by at least $5\%$ in terms of
accuracy, with the added benefit of an interpretable logic-based
representation. Further, our approach provides higher F1-score than BERT and
XLNet, however, we obtain slightly lower accuracy. We finally present a case
study on our model's explainability, demonstrating how it decomposes into
meaningful words and their negations.",0,1,0,0,1,0,0.844763,8.0,0.876581,43
c766ca2a-d6d2-4b23-a295-27c556ddf477,Monocular Depth Estimation Primed by Salient Point Detection and Normalized Hessian Loss,4,0.0562388,0.163283,"Deep neural networks have recently thrived on single image depth estimation.
That being said, current developments on this topic highlight an apparent
compromise between accuracy and network size. This work proposes an accurate
and lightweight framework for monocular depth estimation based on a
self-attention mechanism stemming from salient point detection. Specifically,
we utilize a sparse set of keypoints to train a FuSaNet model that consists of
two major components: Fusion-Net and Saliency-Net. In addition, we introduce a
normalized Hessian loss term invariant to scaling and shear along the depth
direction, which is shown to substantially improve the accuracy. The proposed
method achieves state-of-the-art results on NYU-Depth-v2 and KITTI while using
3.1-38.4 times smaller model in terms of the number of parameters than baseline
approaches. Experiments on the SUN-RGBD further demonstrate the
generalizability of the proposed method.",0,1,0,0,1,0,0.816798,7.0,0.845646,71
1c92f44e-7314-4de5-ad8a-2b6135956ee2,Probabilistic two-stage detection,190,0.155096,0.858083,"We develop a probabilistic interpretation of two-stage object detection. We
show that this probabilistic interpretation motivates a number of common
empirical training practices. It also suggests changes to two-stage detection
pipelines. Specifically, the first stage should infer proper
object-vs-background likelihoods, which should then inform the overall score of
the detector. A standard region proposal network (RPN) cannot infer this
likelihood sufficiently well, but many one-stage detectors can. We show how to
build a probabilistic two-stage detector from any state-of-the-art one-stage
detector. The resulting detectors are faster and more accurate than both their
one- and two-stage precursors. Our detector achieves 56.4 mAP on COCO test-dev
with single-scale testing, outperforming all published results. Using a
lightweight backbone, our detector achieves 49.2 mAP on COCO at 33 fps on a
Titan Xp, outperforming the popular YOLOv4 model.",1,1,0,0,1,0,0.634613,4.0,0.599334,66
0db6821c-5453-46f1-bf47-7b8cbdeb9053,UnitedQA: A Hybrid Approach for Open Domain Question Answering,46,0.503797,0.811296,"To date, most of recent work under the retrieval-reader framework for
open-domain QA focuses on either extractive or generative reader exclusively.
In this paper, we study a hybrid approach for leveraging the strengths of both
models. We apply novel techniques to enhance both extractive and generative
readers built upon recent pretrained neural language models, and find that
proper training methods can provide large improvement over previous
state-of-the-art models. We demonstrate that a simple hybrid approach by
combining answers from both readers can efficiently take advantages of
extractive and generative answer inference strategies and outperforms single
models as well as homogeneous ensembles. Our approach outperforms previous
state-of-the-art models by 3.3 and 2.7 points in exact match on
NaturalQuestions and TriviaQA respectively.",0,1,0,0,1,1,0.973507,3.0,0.893344,35
4a5eeda0-0675-4345-b645-9503a1fb2031,IsoScore: Measuring the Uniformity of Embedding Space Utilization,20,0.295946,0.665718,"The recent success of distributed word representations has led to an
increased interest in analyzing the properties of their spatial distribution.
Several studies have suggested that contextualized word embedding models do not
isotropically project tokens into vector space. However, current methods
designed to measure isotropy, such as average random cosine similarity and the
partition score, have not been thoroughly analyzed and are not appropriate for
measuring isotropy. We propose IsoScore: a novel tool that quantifies the
degree to which a point cloud uniformly utilizes the ambient vector space.
Using rigorously designed tests, we demonstrate that IsoScore is the only tool
available in the literature that accurately measures how uniformly distributed
variance is across dimensions in vector space. Additionally, we use IsoScore to
challenge a number of recent conclusions in the NLP literature that have been
derived using brittle metrics of isotropy. We caution future studies from using
existing tools to measure isotropy in contextualized embedding space as
resulting conclusions will be misleading or altogether inaccurate.",1,0,0,0,0,0,0.741451,5.0,0.738529,30
89e6c612-8b4f-4784-8956-cc96f2c76ee4,Combining Context-Free and Contextualized Representations for Arabic Sarcasm Detection and Sentiment Identification,11,0.311969,0.616705,"Since their inception, transformer-based language models have led to
impressive performance gains across multiple natural language processing tasks.
For Arabic, the current state-of-the-art results on most datasets are achieved
by the AraBERT language model. Notwithstanding these recent advancements,
sarcasm and sentiment detection persist to be challenging tasks in Arabic,
given the language's rich morphology, linguistic disparity and dialectal
variations. This paper proffers team SPPU-AASM's submission for the WANLP
ArSarcasm shared-task 2021, which centers around the sarcasm and sentiment
polarity detection of Arabic tweets. The study proposes a hybrid model,
combining sentence representations from AraBERT with static word vectors
trained on Arabic social media corpora. The proposed system achieves a
F1-sarcastic score of 0.62 and a F-PN score of 0.715 for the sarcasm and
sentiment detection tasks, respectively. Simulation results show that the
proposed system outperforms multiple existing approaches for both the tasks,
suggesting that the amalgamation of context-free and context-dependent text
representations can help capture complementary facets of word meaning in
Arabic. The system ranked second and tenth in the respective sub-tasks of
sarcasm detection and sentiment identification.",1,1,0,0,0,0,0.953585,6.0,0.918713,31
bb1a25c6-7d84-4fbc-bba1-3b3c17eb3e2a,Adaptive Warm-Start MCTS in AlphaZero-like Deep Reinforcement Learning,7,0.0166489,0.131903,"AlphaZero has achieved impressive performance in deep reinforcement learning
by utilizing an architecture that combines search and training of a neural
network in self-play. Many researchers are looking for ways to reproduce and
improve results for other games/tasks. However, the architecture is designed to
learn from scratch, tabula rasa, accepting a cold-start problem in self-play.
Recently, a warm-start enhancement method for Monte Carlo Tree Search was
proposed to improve the self-play starting phase. It employs a fixed parameter
$I^\prime$ to control the warm-start length. Improved performance was reported
in small board games. In this paper we present results with an adaptive switch
method. Experiments show that our approach works better than the fixed
$I^\prime$, especially for ""deep,"" tactical, games (Othello and Connect Four).
We conjecture that the adaptive value for $I^\prime$ is also influenced by the
size of the game, and that on average $I^\prime$ will increase with game size.
We conclude that AlphaZero-like deep reinforcement learning benefits from
adaptive rollout based warm-start, as Rapid Action Value Estimate did for
rollout-based reinforcement learning 15 years ago.",0,1,0,0,0,0,0.0321029,11.0,0.542548,34
62ddf280-7ef5-4be8-af03-dc526788e010,On Generating Identifiable Virtual Faces,10,0.0950785,0.260693,"Face anonymization with generative models have become increasingly prevalent
since they sanitize private information by generating virtual face images,
ensuring both privacy and image utility. Such virtual face images are usually
not identifiable after the removal or protection of the original identity. In
this paper, we formalize and tackle the problem of generating identifiable
virtual face images. Our virtual face images are visually different from the
original ones for privacy protection. In addition, they are bound with new
virtual identities, which can be directly used for face recognition. We propose
an Identifiable Virtual Face Generator (IVFG) to generate the virtual face
images. The IVFG projects the latent vectors of the original face images into
virtual ones according to a user specific key, based on which the virtual face
images are generated. To make the virtual face images identifiable, we propose
a multi-task learning objective as well as a triplet styled training strategy
to learn the IVFG. We evaluate the performance of our virtual face images using
different face recognizers on diffident face image datasets, all of which
demonstrate the effectiveness of the IVFG for generate identifiable virtual
face images.",0,1,0,0,0,0,0.618966,9.0,0.8172,35
4799a177-9f1a-4f07-80c2-56e9c49392b6,A User-Centred Framework for Explainable Artificial Intelligence in Human-Robot Interaction,10,0.058985,0.328579,"State of the art Artificial Intelligence (AI) techniques have reached an
impressive complexity. Consequently, researchers are discovering more and more
methods to use them in real-world applications. However, the complexity of such
systems requires the introduction of methods that make those transparent to the
human user. The AI community is trying to overcome the problem by introducing
the Explainable AI (XAI) field, which is tentative to make AI algorithms less
opaque. However, in recent years, it became clearer that XAI is much more than
a computer science problem: since it is about communication, XAI is also a
Human-Agent Interaction problem. Moreover, AI came out of the laboratories to
be used in real life. This implies the need for XAI solutions tailored to
non-expert users. Hence, we propose a user-centred framework for XAI that
focuses on its social-interactive aspect taking inspiration from cognitive and
social sciences' theories and findings. The framework aims to provide a
structure for interactive XAI solutions thought for non-expert users.",0,0,0,0,0,0,0.235408,10.0,0.707533,37
acbd22b1-8873-41de-987b-bb1b7aa7fe2b,Fast and Accurate Road Crack Detection Based on Adaptive Cost-Sensitive Loss Function,31,0.610898,0.840711,"Numerous detection problems in computer vision, including road crack
detection, suffer from exceedingly foreground-background imbalance.
Fortunately, modification of loss function appears to solve this puzzle once
and for all. In this paper, we propose a pixel-based adaptive weighted
cross-entropy loss in conjunction with Jaccard distance to facilitate
high-quality pixel-level road crack detection. Our work profoundly demonstrates
the influence of loss functions on detection outcomes, and sheds light on the
sophisticated consecutive improvements in the realm of crack detection.
Specifically, to verify the effectiveness of the proposed loss, we conduct
extensive experiments on four public databases, i.e., CrackForest, AigleRN,
Crack360, and BJN260. Compared with the vanilla weighted cross-entropy, the
proposed loss significantly speeds up the training process while retaining the
test accuracy.",1,1,0,1,0,0,0.863328,9.0,0.897642,70
cfb3e133-3ed7-47ee-a60a-17f112272a66,NOPE: A Corpus of Naturally-Occurring Presuppositions in English,18,0.266517,0.13758,"Understanding language requires grasping not only the overtly stated content,
but also making inferences about things that were left unsaid. These inferences
include presuppositions, a phenomenon by which a listener learns about new
information through reasoning about what a speaker takes as given.
Presuppositions require complex understanding of the lexical and syntactic
properties that trigger them as well as the broader conversational context. In
this work, we introduce the Naturally-Occurring Presuppositions in English
(NOPE) Corpus to investigate the context-sensitivity of 10 different types of
presupposition triggers and to evaluate machine learning models' ability to
predict human inferences. We find that most of the triggers we investigate
exhibit moderate variability. We further find that transformer-based models
draw correct inferences in simple cases involving presuppositions, but they
fail to capture the minority of exceptional cases in which human judgments
reveal complex interactions between context and triggers.",1,0,0,1,0,0,0.690554,7.0,0.792872,71
f6f10c91-941a-43d8-ad92-0d960afd2e08,GooAQ: Open Question Answering with Diverse Answer Types,38,0.0635626,0.484032,"While day-to-day questions come with a variety of answer types, the current
question-answering (QA) literature has failed to adequately address the answer
diversity of questions. To this end, we present GooAQ, a large-scale dataset
with a variety of answer types. This dataset contains over 5 million questions
and 3 million answers collected from Google. GooAQ questions are collected
semi-automatically from the Google search engine using its autocomplete
feature. This results in naturalistic questions of practical interest that are
nonetheless short and expressed using simple language. GooAQ answers are mined
from Google's responses to our collected questions, specifically from the
answer boxes in the search results. This yields a rich space of answer types,
containing both textual answers (short and long) as well as more structured
ones such as collections. We benchmarkT5 models on GooAQ and observe that: (a)
in line with recent work, LM's strong performance on GooAQ's short-answer
questions heavily benefit from annotated data; however, (b) their quality in
generating coherent and accurate responses for questions requiring long
responses (such as 'how' and 'why' questions) is less reliant on observing
annotated data and mainly supported by their pre-training. We release GooAQ to
facilitate further research on improving QA with diverse response types.",0,1,1,1,0,0,0.570457,4.0,0.555546,24
7b0f6af7-fcaa-4ff2-bde4-e98845ee0124,Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images,17,0.409637,0.722077,"In multi-modal dialogue systems, it is important to allow the use of images
as part of a multi-turn conversation. Training such dialogue systems generally
requires a large-scale dataset consisting of multi-turn dialogues that involve
images, but such datasets rarely exist. In response, this paper proposes a 45k
multi-modal dialogue dataset created with minimal human intervention. Our
method to create such a dataset consists of (1) preparing and pre-processing
text dialogue datasets, (2) creating image-mixed dialogues by using a
text-to-image replacement technique, and (3) employing a
contextual-similarity-based filtering step to ensure the contextual coherence
of the dataset. To evaluate the validity of our dataset, we devise a simple
retrieval model for dialogue sentence prediction tasks. Automatic metrics and
human evaluation results on such tasks show that our dataset can be effectively
used as training data for multi-modal dialogue systems which require an
understanding of images and text in a context-aware manner. Our dataset and
generation code is available at
https://github.com/shh1574/multi-modal-dialogue-dataset.",0,1,0,1,0,0,0.987615,6.0,0.978362,18
3d93e8ca-dea2-4fc4-bdef-023708713f02,Robust Optimal Classification Trees Against Adversarial Examples,18,0.07215,0.62594,"Decision trees are a popular choice of explainable model, but just like
neural networks, they suffer from adversarial examples. Existing algorithms for
fitting decision trees robust against adversarial examples are greedy
heuristics and lack approximation guarantees. In this paper we propose ROCT, a
collection of methods to train decision trees that are optimally robust against
user-specified attack models. We show that the min-max optimization problem
that arises in adversarial learning can be solved using a single minimization
formulation for decision trees with 0-1 loss. We propose such formulations in
Mixed-Integer Linear Programming and Maximum Satisfiability, which widely
available solvers can optimize. We also present a method that determines the
upper bound on adversarial accuracy for any model using bipartite matching. Our
experimental results demonstrate that the existing heuristics achieve close to
optimal scores while ROCT achieves state-of-the-art scores.",0,0,0,0,1,0,0.114815,7.0,0.469498,32
40c3c553-9608-4f7a-b417-5bee98a01b10,Revisiting State Augmentation methods for Reinforcement Learning with Stochastic Delays,15,0.0220032,0.209586,"Several real-world scenarios, such as remote control and sensing, are
comprised of action and observation delays. The presence of delays degrades the
performance of reinforcement learning (RL) algorithms, often to such an extent
that algorithms fail to learn anything substantial. This paper formally
describes the notion of Markov Decision Processes (MDPs) with stochastic delays
and shows that delayed MDPs can be transformed into equivalent standard MDPs
(without delays) with significantly simplified cost structure. We employ this
equivalence to derive a model-free Delay-Resolved RL framework and show that
even a simple RL algorithm built upon this framework achieves near-optimal
rewards in environments with stochastic delays in actions and observations. The
delay-resolved deep Q-network (DRDQN) algorithm is bench-marked on a variety of
environments comprising of multi-step and stochastic delays and results in
better performance, both in terms of achieving near-optimal rewards and
minimizing the computational overhead thereof, with respect to the currently
established algorithms.",0,1,0,0,0,0,3.60908e-07,22.0,0.252542,37
4cf7adaa-2adb-46bf-8d12-0f7efdb11863,Incorporating Connections Beyond Knowledge Embeddings: A Plug-and-Play Module to Enhance Commonsense Reasoning in Machine Reading Comprehension,2,0.0249588,0.0520306,"Conventional Machine Reading Comprehension (MRC) has been well-addressed by
pattern matching, but the ability of commonsense reasoning remains a gap
between humans and machines. Previous methods tackle this problem by enriching
word representations via pre-trained Knowledge Graph Embeddings (KGE). However,
they make limited use of a large number of connections between nodes in
Knowledge Graphs (KG), which could be pivotal cues to build the commonsense
reasoning chains. In this paper, we propose a Plug-and-play module to
IncorporatE Connection information for commonsEnse Reasoning (PIECER). Beyond
enriching word representations with knowledge embeddings, PIECER constructs a
joint query-passage graph to explicitly guide commonsense reasoning by the
knowledge-oriented connections between words. Further, PIECER has high
generalizability since it can be plugged into suitable positions in any MRC
model. Experimental results on ReCoRD, a large-scale public MRC dataset
requiring commonsense reasoning, show that PIECER introduces stable performance
improvements for four representative base MRC models, especially in
low-resource settings.",0,1,0,0,0,0,0.940277,7.0,0.918087,45
af3a8f54-c129-4b55-aa9f-10e1913dd493,Case-based Reasoning for Better Generalization in Textual Reinforcement Learning,8,0.210199,0.11679,"Text-based games (TBG) have emerged as promising environments for driving
research in grounded language understanding and studying problems like
generalization and sample efficiency. Several deep reinforcement learning (RL)
methods with varying architectures and learning schemes have been proposed for
TBGs. However, these methods fail to generalize efficiently, especially under
distributional shifts. In a departure from deep RL approaches, in this paper,
we propose a general method inspired by case-based reasoning to train agents
and generalize out of the training distribution. The case-based reasoner
collects instances of positive experiences from the agent's interaction with
the world in the past and later reuses the collected experiences to act
efficiently. The method can be applied in conjunction with any existing
on-policy neural agent in the literature for TBGs. Our experiments show that
the proposed approach consistently improves existing methods, obtains good
out-of-distribution generalization, and achieves new state-of-the-art results
on widely used environments.",0,1,0,0,1,0,0.720894,6.0,0.772404,45
873356c0-118c-4aae-ad70-8ecc03339b4e,Revisiting the Uniform Information Density Hypothesis,52,0.142231,0.892424,"The uniform information density (UID) hypothesis posits a preference among
language users for utterances structured such that information is distributed
uniformly across a signal. While its implications on language production have
been well explored, the hypothesis potentially makes predictions about language
comprehension and linguistic acceptability as well. Further, it is unclear how
uniformity in a linguistic signal -- or lack thereof -- should be measured, and
over which linguistic unit, e.g., the sentence or language level, this
uniformity should hold. Here we investigate these facets of the UID hypothesis
using reading time and acceptability data. While our reading time results are
generally consistent with previous work, they are also consistent with a weakly
super-linear effect of surprisal, which would be compatible with UID's
predictions. For acceptability judgments, we find clearer evidence that
non-uniformity in information density is predictive of lower acceptability. We
then explore multiple operationalizations of UID, motivated by different
interpretations of the original hypothesis, and analyze the scope over which
the pressure towards uniformity is exerted. The explanatory power of a subset
of the proposed operationalizations suggests that the strongest trend may be a
regression towards a mean surprisal across the language, rather than the
phrase, sentence, or document -- a finding that supports a typical
interpretation of UID, namely that it is the byproduct of language users
maximizing the use of a (hypothetical) communication channel.",0,0,0,0,0,0,0.00250882,14.0,0.45742,60
5aef8ecf-adec-4811-b6ac-39efe1db920b,DuctTake: Spatiotemporal Video Compositing,25,0.437819,0.18854,"DuctTake is a system designed to enable practical compositing of multiple
takes of a scene into a single video. Current industry solutions are based
around object segmentation, a hard problem that requires extensive manual input
and cleanup, making compositing an expensive part of the film-making process.
Our method instead composites shots together by finding optimal spatiotemporal
seams using motion-compensated 3D graph cuts through the video volume. We
describe in detail the required components, decisions, and new techniques that
together make a usable, interactive tool for compositing HD video, paying
special attention to running time and performance of each section. We validate
our approach by presenting a wide variety of examples and by comparing result
quality and creation time to composites made by professional artists using
current state-of-the-art tools.",0,1,0,0,1,0,0.270032,16.0,0.827163,32
3f48a40c-8600-4c22-a380-27869bac62b9,Distantly-Supervised Named Entity Recognition with Noise-Robust Learning and Language Model Augmented Self-Training,56,0.298745,0.98594,"We study the problem of training named entity recognition (NER) models using
only distantly-labeled data, which can be automatically obtained by matching
entity mentions in the raw text with entity types in a knowledge base. The
biggest challenge of distantly-supervised NER is that the distant supervision
may induce incomplete and noisy labels, rendering the straightforward
application of supervised learning ineffective. In this paper, we propose (1) a
noise-robust learning scheme comprised of a new loss function and a noisy label
removal step, for training NER models on distantly-labeled data, and (2) a
self-training method that uses contextualized augmentations created by
pre-trained language models to improve the generalization ability of the NER
model. On three benchmark datasets, our method achieves superior performance,
outperforming existing distantly-supervised NER models by significant margins.",1,1,0,0,1,1,0.551274,7.0,0.738442,51
42066724-5005-45bf-a8aa-92fd9fefaf7b,Passive Inter-Photon Imaging,26,0.204451,0.754378,"Digital camera pixels measure image intensities by converting incident light
energy into an analog electrical current, and then digitizing it into a
fixed-width binary representation. This direct measurement method, while
conceptually simple, suffers from limited dynamic range and poor performance
under extreme illumination -- electronic noise dominates under low
illumination, and pixel full-well capacity results in saturation under bright
illumination. We propose a novel intensity cue based on measuring inter-photon
timing, defined as the time delay between detection of successive photons.
Based on the statistics of inter-photon times measured by a time-resolved
single-photon sensor, we develop theory and algorithms for a scene brightness
estimator which works over extreme dynamic range; we experimentally demonstrate
imaging scenes with a dynamic range of over ten million to one. The proposed
techniques, aided by the emergence of single-photon sensors such as
single-photon avalanche diodes (SPADs) with picosecond timing resolution, will
have implications for a wide range of imaging applications: robotics, consumer
photography, astronomy, microscopy and biomedical imaging.",0,0,1,0,0,0,0.292682,7.0,0.618577,58
9f0f0389-9de8-4bf3-adcf-c5e9f97e59c5,Structured Graph Learning for Scalable Subspace Clustering: From Single-view to Multi-view,150,0.714005,0.994702,"Graph-based subspace clustering methods have exhibited promising performance.
However, they still suffer some of these drawbacks: encounter the expensive
time overhead, fail in exploring the explicit clusters, and cannot generalize
to unseen data points. In this work, we propose a scalable graph learning
framework, seeking to address the above three challenges simultaneously.
Specifically, it is based on the ideas of anchor points and bipartite graph.
Rather than building a $n\times n$ graph, where $n$ is the number of samples,
we construct a bipartite graph to depict the relationship between samples and
anchor points. Meanwhile, a connectivity constraint is employed to ensure that
the connected components indicate clusters directly. We further establish the
connection between our method and the K-means clustering. Moreover, a model to
process multi-view data is also proposed, which is linear scaled with respect
to $n$. Extensive experiments demonstrate the efficiency and effectiveness of
our approach with respect to many state-of-the-art clustering methods.",0,1,0,0,1,0,0.432532,6.0,0.637068,73
5c3f2d05-17e2-4682-b005-8b9914d6592b,Learning Description Logic Ontologies. Five Approaches. Where Do They Stand?,29,0.308652,0.169208,"The quest for acquiring a formal representation of the knowledge of a domain
of interest has attracted researchers with various backgrounds into a diverse
field called ontology learning. We highlight classical machine learning and
data mining approaches that have been proposed for (semi-)automating the
creation of description logic (DL) ontologies. These are based on association
rule mining, formal concept analysis, inductive logic programming,
computational learning theory, and neural networks. We provide an overview of
each approach and how it has been adapted for dealing with DL ontologies.
Finally, we discuss the benefits and limitations of each of them for learning
DL ontologies.",0,0,0,0,0,0,0.00619601,16.0,0.581864,54
35bd2a0c-e296-4116-9874-2837e1435d66,Incentivizing Efficient Equilibria in Traffic Networks with Mixed Autonomy,14,0.0265035,0.320791,"Traffic congestion has large economic and social costs. The introduction of
autonomous vehicles can potentially reduce this congestion by increasing road
capacity via vehicle platooning and by creating an avenue for influencing
people's choice of routes. We consider a network of parallel roads with two
modes of transportation: (i) human drivers, who will choose the quickest route
available to them, and (ii) a ride hailing service, which provides an array of
autonomous vehicle route options, each with different prices, to users. We
formalize a model of vehicle flow in mixed autonomy and a model of how
autonomous service users make choices between routes with different prices and
latencies. Developing an algorithm to learn the preferences of the users, we
formulate a planning optimization that chooses prices to maximize a social
objective. We demonstrate the benefit of the proposed scheme by comparing the
results to theoretical benchmarks which we show can be efficiently calculated.",0,0,0,0,0,0,0.000128073,18.0,0.412651,47
4fd6607e-661d-40dd-bd65-06273d1e2f26,Addressing Inquiries about History: An Efficient and Practical Framework for Evaluating Open-domain Chatbot Consistency,13,0.406658,0.472708,"A good open-domain chatbot should avoid presenting contradictory responses
about facts or opinions in a conversational session, known as its consistency
capacity. However, evaluating the consistency capacity of a chatbot is still
challenging. Employing human judges to interact with chatbots on purpose to
check their capacities is costly and low-efficient, and difficult to get rid of
subjective bias. In this paper, we propose the Addressing Inquiries about
History (AIH), an efficient and practical framework for the consistency
evaluation. At the conversation stage, AIH attempts to address appropriate
inquiries about the dialogue history to induce the chatbot to redeclare the
historical facts or opinions. We carry out the conversation between chatbots,
which is more efficient than the human-bot interaction and can also alleviate
the subjective bias. In this way, we manage to rapidly obtain a dialog session
that contains responses with high contradiction possibilities. At the
contradiction recognition stage, we can either employ human judges or a natural
language inference (NLI) model to recognize whether the answers to the
inquiries are contradictory with history. Finally, we are able to rank chatbots
according to the contradiction statistics. Experiments on open-domain chatbots
show that our approach can efficiently and reliably assess the consistency
capacity of chatbots and achieve a high ranking correlation with the human
evaluation. We release the framework and hope to help improve the consistency
capacity of chatbots. \footnote{\url{https://github.com/ictnlp/AIH}}",0,1,0,0,0,1,0.976444,4.0,0.927971,31
6bc3edef-70c0-42a1-97a5-ed69f55ff14e,Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation,21,0.480606,0.650246,"For a computer to naturally interact with a human, it needs to be human-like.
In this paper, we propose a neural response generation model with multi-task
learning of generation and classification, focusing on emotion. Our model based
on BART (Lewis et al., 2020), a pre-trained transformer encoder-decoder model,
is trained to generate responses and recognize emotions simultaneously.
Furthermore, we weight the losses for the tasks to control the update of
parameters. Automatic evaluations and crowdsourced manual evaluations show that
the proposed model makes generated responses more emotionally aware.",0,1,0,0,0,0,0.941943,6.0,0.906099,23
081b54fa-c6db-4f44-981b-56522d2bc67a,Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features,61,0.848266,0.843601,"We report two essential improvements in readability assessment: 1. three
novel features in advanced semantics and 2. the timely evidence that
traditional ML models (e.g. Random Forest, using handcrafted features) can
combine with transformers (e.g. RoBERTa) to augment model performance. First,
we explore suitable transformers and traditional ML models. Then, we extract
255 handcrafted linguistic features using self-developed extraction software.
Finally, we assemble those to create several hybrid models, achieving
state-of-the-art (SOTA) accuracy on popular datasets in readability assessment.
The use of handcrafted features help model performance on smaller datasets.
Notably, our RoBERTA-RF-T1 hybrid achieves the near-perfect classification
accuracy of 99%, a 20.3% increase from the previous SOTA.",1,1,0,0,1,0,0.185357,17.0,0.812109,107
15ba7c96-a7de-4029-8f37-310f0dfcadf9,Data-to-text Generation with Macro Planning,65,0.333476,0.904312,"Recent approaches to data-to-text generation have adopted the very successful
encoder-decoder architecture or variants thereof. These models generate text
which is fluent (but often imprecise) and perform quite poorly at selecting
appropriate content and ordering it coherently. To overcome some of these
issues, we propose a neural model with a macro planning stage followed by a
generation stage reminiscent of traditional methods which embrace separate
modules for planning and surface realization. Macro plans represent high level
organization of important content such as entities, events and their
interactions; they are learnt from data and given as input to the generator.
Extensive experiments on two data-to-text benchmarks (RotoWire and MLB) show
that our approach outperforms competitive baselines in terms of automatic and
human evaluation.",1,1,0,0,1,0,0.215881,10.0,0.697667,73
3ffe429e-891d-4dc9-bf08-99805932b067,Towards a fully RL-based Market Simulator,14,0.37294,0.68154,"We present a new financial framework where two families of RL-based agents
representing the Liquidity Providers and Liquidity Takers learn simultaneously
to satisfy their objective. Thanks to a parametrized reward formulation and the
use of Deep RL, each group learns a shared policy able to generalize and
interpolate over a wide range of behaviors. This is a step towards a fully
RL-based market simulator replicating complex market conditions particularly
suited to study the dynamics of the financial market under various scenarios.",0,0,0,0,0,0,0.0936611,14.0,0.719376,21
43e2c0b5-2135-4f4b-b6c7-e0a4504f5c33,Visualization Techniques to Enhance Automated Event Extraction,2,0.0204312,0.0947975,"Robust visualization of complex data is critical for the effective use of NLP
for event classification, as the volume of data is large and the
high-dimensional structure of text makes data challenging to summarize
succinctly. In event extraction tasks in particular, visualization can aid in
understanding and illustrating the textual relationships from which machine
learning tools produce insights. Through our case study which seeks to identify
potential triggers of state-led mass killings from news articles using NLP, we
demonstrate how visualizations can aid in each stage, from exploratory analysis
of raw data, to machine learning training analysis, and finally post-inference
validation.",1,1,0,0,0,0,0.0841414,10.0,0.595893,20
8be6c628-a18f-460f-bcb7-6b45f7e71e0c,Know Your Surroundings: Panoramic Multi-Object Tracking by Multimodality Collaboration,9,0.0721905,0.187915,"In this paper, we focus on the multi-object tracking (MOT) problem of
automatic driving and robot navigation. Most existing MOT methods track
multiple objects using a singular RGB camera, which are prone to camera
field-of-view and suffer tracking failures in complex scenarios due to
background clutters and poor light conditions. To meet these challenges, we
propose a MultiModality PAnoramic multi-object Tracking framework (MMPAT),
which takes both 2D panorama images and 3D point clouds as input and then
infers target trajectories using the multimodality data. The proposed method
contains four major modules, a panorama image detection module, a multimodality
data fusion module, a data association module and a trajectory inference model.
We evaluate the proposed method on the JRDB dataset, where the MMPAT achieves
the top performance in both the detection and tracking tasks and significantly
outperforms state-of-the-art methods by a large margin (15.7 and 8.5
improvement in terms of AP and MOTA, respectively).",0,1,0,0,1,0,0.801238,7.0,0.838614,93
86986bc4-ac76-470e-93d2-1cb52c0dc509,ViTA: Visual-Linguistic Translation by Aligning Object Tags,12,0.0944249,0.347626,"Multimodal Machine Translation (MMT) enriches the source text with visual
information for translation. It has gained popularity in recent years, and
several pipelines have been proposed in the same direction. Yet, the task lacks
quality datasets to illustrate the contribution of visual modality in the
translation systems. In this paper, we propose our system under the team name
Volta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We
also participate in the textual-only subtask of the same language pair for
which we use mBART, a pretrained multilingual sequence-to-sequence model. For
multimodal translation, we propose to enhance the textual input by bringing the
visual information to a textual domain by extracting object tags from the
image. We also explore the robustness of our system by systematically degrading
the source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test
set and challenge set of the multimodal task.",1,1,0,0,0,0,0.415957,9.0,0.752251,31
4a1b20c9-1e7c-4857-8d6d-3af80f4ed838,Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm,25,0.224977,0.452915,"Conventional wisdom in pruning Transformer-based language models is that
pruning reduces the model expressiveness and thus is more likely to underfit
rather than overfit. However, under the trending pretrain-and-finetune
paradigm, we postulate a counter-traditional hypothesis, that is: pruning
increases the risk of overfitting when performed at the fine-tuning phase. In
this paper, we aim to address the overfitting problem and improve pruning
performance via progressive knowledge distillation with error-bound properties.
We show for the first time that reducing the risk of overfitting can help the
effectiveness of pruning under the pretrain-and-finetune paradigm. Ablation
studies and experiments on the GLUE benchmark show that our method outperforms
the leading competitors across different tasks.",0,1,0,0,1,0,0.788372,4.0,0.707676,47
9081472c-b89d-4978-b9bf-99ae7c8ce8f1,A Reinforcement Learning Benchmark for Autonomous Driving in Intersection Scenarios,8,0.038833,0.187528,"In recent years, control under urban intersection scenarios becomes an
emerging research topic. In such scenarios, the autonomous vehicle confronts
complicated situations since it must deal with the interaction with social
vehicles timely while obeying the traffic rules. Generally, the autonomous
vehicle is supposed to avoid collisions while pursuing better efficiency. The
existing work fails to provide a framework that emphasizes the integrity of the
scenarios while being able to deploy and test reinforcement learning(RL)
methods. Specifically, we propose a benchmark for training and testing RL-based
autonomous driving agents in complex intersection scenarios, which is called
RL-CIS. Then, a set of baselines are deployed consists of various algorithms.
The test benchmark and baselines are to provide a fair and comprehensive
training and testing platform for the study of RL for autonomous driving in the
intersection scenario, advancing the progress of RL-based methods for
intersection autonomous driving control. The code of our proposed framework can
be found at https://github.com/liuyuqi123/ComplexUrbanScenarios.",1,1,0,0,0,0,0.205124,6.0,0.486502,23
e4bfe314-243e-49c1-910e-7507abfead38,Oriented Feature Alignment for Fine-grained Object Recognition in High-Resolution Satellite Imagery,7,0.0472551,0.323998,"Oriented object detection in remote sensing images has made great progress in
recent years. However, most of the current methods only focus on detecting
targets, and cannot distinguish fine-grained objects well in complex scenes. In
this technical report, we analyzed the key issues of fine-grained object
recognition, and use an oriented feature alignment network (OFA-Net) to achieve
high-performance fine-grained oriented object recognition in optical remote
sensing images. OFA-Net achieves accurate object localization through a rotated
bounding boxes refinement module. On this basis, the boundary-constrained
rotation feature alignment module is applied to achieve local feature
extraction, which is beneficial to fine-grained object classification. The
single model of our method achieved mAP of 46.51\% in the GaoFen competition
and won 3rd place in the ISPRS benchmark with the mAP of 43.73\%.",1,1,0,0,0,0,0.951915,3.0,0.833567,15
3136eaf1-e3b8-45b3-9302-a1a85f06ded3,Extracting Adverse Drug Events from Clinical Notes,21,0.279425,0.259112,"Adverse drug events (ADEs) are unexpected incidents caused by the
administration of a drug or medication. To identify and extract these events,
we require information about not just the drug itself but attributes describing
the drug (e.g., strength, dosage), the reason why the drug was initially
prescribed, and any adverse reaction to the drug. This paper explores the
relationship between a drug and its associated attributes using relation
extraction techniques. We explore three approaches: a rule-based approach, a
deep learning-based approach, and a contextualized language model-based
approach. We evaluate our system on the n2c2-2018 ADE extraction dataset. Our
experimental results demonstrate that the contextualized language model-based
approach outperformed other models overall and obtain the state-of-the-art
performance in ADE extraction with a Precision of 0.93, Recall of 0.96, and an
$F_1$ score of 0.94; however, for certain relation types, the rule-based
approach obtained a higher Precision and Recall than either learning approach.",0,1,0,0,1,0,0.480108,8.0,0.745765,24
e9fd98fc-1ff8-4373-975f-aaa6d01236af,ABCNet: Attentive Bilateral Contextual Network for Efficient Semantic Segmentation of Fine-Resolution Remote Sensing Images,116,0.203342,0.742538,"Semantic segmentation of remotely sensed images plays a crucial role in
precision agriculture, environmental protection, and economic assessment. In
recent years, substantial fine-resolution remote sensing images are available
for semantic segmentation. However, due to the complicated information caused
by the increased spatial resolution, state-of-the-art deep learning algorithms
normally utilize complex network architectures for segmentation, which usually
incurs high computational complexity. Specifically, the high-caliber
performance of the convolutional neural network (CNN) heavily relies on
fine-grained spatial details (fine resolution) and sufficient contextual
information (large receptive fields), both of which trigger high computational
costs. This crucially impedes their practicability and availability in
real-world scenarios that require real-time processing. In this paper, we
propose an Attentive Bilateral Contextual Network (ABCNet), a convolutional
neural network (CNN) with double branches, with prominently lower computational
consumptions compared to the cutting-edge algorithms, while maintaining a
competitive accuracy. Code is available at https://github.com/lironui/ABCNet.",1,1,0,0,0,0,0.509079,5.0,0.610029,85
5a54ab3b-120f-477d-9d5d-1bd633667676,Neural Photofit: Gaze-based Mental Image Reconstruction,8,0.127971,0.62977,"We propose a novel method that leverages human fixations to visually decode
the image a person has in mind into a photofit (facial composite). Our method
combines three neural networks: An encoder, a scoring network, and a decoder.
The encoder extracts image features and predicts a neural activation map for
each face looked at by a human observer. A neural scoring network compares the
human and neural attention and predicts a relevance score for each extracted
image feature. Finally, image features are aggregated into a single feature
vector as a linear combination of all features weighted by relevance which a
decoder decodes into the final photofit. We train the neural scoring network on
a novel dataset containing gaze data of 19 participants looking at collages of
synthetic faces. We show that our method significantly outperforms a mean
baseline predictor and report on a human study that shows that we can decode
photofits that are visually plausible and close to the observer's mental image.",1,0,0,1,0,0,0.0950538,11.0,0.644252,42
7aea363c-4c6e-441d-b939-6624fffcaa36,Large-scale Taxonomy Induction Using Entity and Word Embeddings,23,0.0521372,0.235691,"Taxonomies are an important ingredient of knowledge organization, and serve
as a backbone for more sophisticated knowledge representations in intelligent
systems, such as formal ontologies. However, building taxonomies manually is a
costly endeavor, and hence, automatic methods for taxonomy induction are a good
alternative to build large-scale taxonomies. In this paper, we propose TIEmb,
an approach for automatic unsupervised class subsumption axiom extraction from
knowledge bases using entity and text embeddings. We apply the approach on the
WebIsA database, a database of subsumption relations extracted from the large
portion of the World Wide Web, to extract class hierarchies in the Person and
Place domain.",0,0,0,0,0,0,0.283662,7.0,0.613251,33
144a2306-3f39-43d0-a554-6cc0a3a46658,Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task,41,0.505071,0.852894,"This report describes Microsoft's machine translation systems for the WMT21
shared task on large-scale multilingual machine translation. We participated in
all three evaluation tracks including Large Track and two Small Tracks where
the former one is unconstrained and the latter two are fully constrained. Our
model submissions to the shared task were initialized with
DeltaLM\footnote{\url{https://aka.ms/deltalm}}, a generic pre-trained
multilingual encoder-decoder model, and fine-tuned correspondingly with the
vast collected parallel data and allowed data sources according to track
settings, together with applying progressive learning and iterative
back-translation approaches to further improve the performance. Our final
submissions ranked first on three tracks in terms of the automatic evaluation
metric.",0,1,0,0,0,1,0.890922,5.0,0.837225,31
40b43a57-1cbe-432f-923d-2b2d7a3f8357,Space-Time Memory Network for Sounding Object Localization in Videos,5,0.0207047,0.319366,"Leveraging temporal synchronization and association within sight and sound is
an essential step towards robust localization of sounding objects. To this end,
we propose a space-time memory network for sounding object localization in
videos. It can simultaneously learn spatio-temporal attention over both
uni-modal and cross-modal representations from audio and visual modalities. We
show and analyze both quantitatively and qualitatively the effectiveness of
incorporating spatio-temporal learning in localizing audio-visual objects. We
demonstrate that our approach generalizes over various complex audio-visual
scenes and outperforms recent state-of-the-art methods.",1,0,0,0,1,0,0.284496,6.0,0.549374,35
c5a8aaff-82e3-4fdf-ba60-07d5fe0df51a,Efficient Visual Pretraining with Contrastive Detection,137,0.679135,0.93382,"Self-supervised pretraining has been shown to yield powerful representations
for transfer learning. These performance gains come at a large computational
cost however, with state-of-the-art methods requiring an order of magnitude
more computation than supervised pretraining. We tackle this computational
bottleneck by introducing a new self-supervised objective, contrastive
detection, which tasks representations with identifying object-level features
across augmentations. This objective extracts a rich learning signal per image,
leading to state-of-the-art transfer accuracy on a variety of downstream tasks,
while requiring up to 10x less pretraining. In particular, our strongest
ImageNet-pretrained model performs on par with SEER, one of the largest
self-supervised systems to date, which uses 1000x more pretraining data.
Finally, our objective seamlessly handles pretraining on more complex images
such as those in COCO, closing the gap with supervised transfer learning from
COCO to PASCAL.",0,1,0,0,1,0,0.93697,8.0,0.925911,70
a5284248-cbfe-4557-84e2-17293962a7b0,Human-Machine Interaction Speech Corpus from the ROBIN project,4,0.0308916,0.217407,"This paper introduces a new Romanian speech corpus from the ROBIN project,
called ROBIN Technical Acquisition Speech Corpus (ROBINTASC). Its main purpose
was to improve the behaviour of a conversational agent, allowing human-machine
interaction in the context of purchasing technical equipment. The paper
contains a detailed description of the acquisition process, corpus statistics
as well as an evaluation of the corpus influence on a low-latency ASR system as
well as a dialogue component.",0,1,1,1,0,0,0.197066,5.0,0.374816,28
6a5ec616-2e0c-4ed8-b471-9094bb40802a,Texture Generation with Neural Cellular Automata,6,0.0928359,0.106024,"Neural Cellular Automata (NCA) have shown a remarkable ability to learn the
required rules to ""grow"" images, classify morphologies, segment images, as well
as to do general computation such as path-finding. We believe the inductive
prior they introduce lends itself to the generation of textures. Textures in
the natural world are often generated by variants of locally interacting
reaction-diffusion systems. Human-made textures are likewise often generated in
a local manner (textile weaving, for instance) or using rules with local
dependencies (regular grids or geometric patterns). We demonstrate learning a
texture generator from a single template image, with the generation method
being embarrassingly parallel, exhibiting quick convergence and high fidelity
of output, and requiring only some minimal assumptions around the underlying
state manifold. Furthermore, we investigate properties of the learned models
that are both useful and interesting, such as non-stationary dynamics and an
inherent robustness to damage. Finally, we make qualitative claims that the
behaviour exhibited by the NCA model is a learned, distributed, local algorithm
to generate a texture, setting our method apart from existing work on texture
generation. We discuss the advantages of such a paradigm.",0,0,0,0,0,0,0.325494,12.0,0.788216,42
1eb8048b-cabf-4a09-b0ab-6c4c8b0ca954,Inferring the Class Conditional Response Map for Weakly Supervised Semantic Segmentation,11,0.228403,0.278192,"Image-level weakly supervised semantic segmentation (WSSS) relies on class
activation maps (CAMs) for pseudo labels generation. As CAMs only highlight the
most discriminative regions of objects, the generated pseudo labels are usually
unsatisfactory to serve directly as supervision. To solve this, most existing
approaches follow a multi-training pipeline to refine CAMs for better
pseudo-labels, which includes: 1) re-training the classification model to
generate CAMs; 2) post-processing CAMs to obtain pseudo labels; and 3) training
a semantic segmentation model with the obtained pseudo labels. However, this
multi-training pipeline requires complicated adjustment and additional time. To
address this, we propose a class-conditional inference strategy and an
activation aware mask refinement loss function to generate better pseudo labels
without re-training the classifier. The class conditional inference-time
approach is presented to separately and iteratively reveal the classification
network's hidden object activation to generate more complete response maps.
Further, our activation aware mask refinement loss function introduces a novel
way to exploit saliency maps during segmentation training and refine the
foreground object masks without suppressing background objects. Our method
achieves superior WSSS results without requiring re-training of the classifier.",1,1,0,0,0,0,0.978278,7.0,0.961896,54
5a8d9f60-0550-45ca-85ff-14719c816e12,Learning Not to Reconstruct Anomalies,31,0.499832,0.632465,"Video anomaly detection is often seen as one-class classification (OCC)
problem due to the limited availability of anomaly examples. Typically, to
tackle this problem, an autoencoder (AE) is trained to reconstruct the input
with training set consisting only of normal data. At test time, the AE is then
expected to well reconstruct the normal data while poorly reconstructing the
anomalous data. However, several studies have shown that, even with only normal
data training, AEs can often start reconstructing anomalies as well which
depletes the anomaly detection performance. To mitigate this problem, we
propose a novel methodology to train AEs with the objective of reconstructing
only normal data, regardless of the input (i.e., normal or abnormal). Since no
real anomalies are available in the OCC settings, the training is assisted by
pseudo anomalies that are generated by manipulating normal data to simulate the
out-of-normal-data distribution. We additionally propose two ways to generate
pseudo anomalies: patch and skip frame based. Extensive experiments on three
challenging video anomaly datasets demonstrate the effectiveness of our method
in improving conventional AEs, achieving state-of-the-art performance.",1,1,0,0,1,0,0.902595,8.0,0.904494,61
5d4aa12f-cfdc-4a00-8a71-57e490a0e116,The Emergence of the Shape Bias Results from Communicative Efficiency,15,0.0514709,0.349713,"By the age of two, children tend to assume that new word categories are based
on objects' shape, rather than their color or texture; this assumption is
called the shape bias. They are thought to learn this bias by observing that
their caregiver's language is biased towards shape based categories. This
presents a chicken and egg problem: if the shape bias must be present in the
language in order for children to learn it, how did it arise in language in the
first place? In this paper, we propose that communicative efficiency explains
both how the shape bias emerged and why it persists across generations. We
model this process with neural emergent language agents that learn to
communicate about raw pixelated images. First, we show that the shape bias
emerges as a result of efficient communication strategies employed by agents.
Second, we show that pressure brought on by communicative need is also
necessary for it to persist across generations; simply having a shape bias in
an agent's input language is insufficient. These results suggest that, over and
above the operation of other learning strategies, the shape bias in human
learners may emerge and be sustained by communicative pressures.",1,0,0,0,0,0,0.0377434,10.0,0.513279,62
8eeb695c-d84b-4c6c-afd3-71faa06aa64f,hSMAL: Detailed Horse Shape and Pose Reconstruction for Motion Pattern Recognition,15,0.128141,0.368207,"In this paper we present our preliminary work on model-based behavioral
analysis of horse motion. Our approach is based on the SMAL model, a 3D
articulated statistical model of animal shape. We define a novel SMAL model for
horses based on a new template, skeleton and shape space learned from $37$
horse toys. We test the accuracy of our hSMAL model in reconstructing a horse
from 3D mocap data and images. We apply the hSMAL model to the problem of
lameness detection from video, where we fit the model to images to recover 3D
pose and train an ST-GCN network on pose data. A comparison with the same
network trained on mocap points illustrates the benefit of our approach.",0,1,0,0,0,0,0.349178,6.0,0.590912,21
8d0f8061-ebdd-4e04-9e16-e5a243035927,EnergyVis: Interactively Tracking and Exploring Energy Consumption for ML Models,12,0.210938,0.483577,"The advent of larger machine learning (ML) models have improved
state-of-the-art (SOTA) performance in various modeling tasks, ranging from
computer vision to natural language. As ML models continue increasing in size,
so does their respective energy consumption and computational requirements.
However, the methods for tracking, reporting, and comparing energy consumption
remain limited. We presentEnergyVis, an interactive energy consumption tracker
for ML models. Consisting of multiple coordinated views, EnergyVis enables
researchers to interactively track, visualize and compare model energy
consumption across key energy consumption and carbon footprint metrics (kWh and
CO2), helping users explore alternative deployment locations and hardware that
may reduce carbon footprints. EnergyVis aims to raise awareness concerning
computational sustainability by interactively highlighting excessive energy
usage during model training; and by providing alternative training options to
reduce energy usage.",0,1,0,0,0,0,0.969409,4.0,0.909906,24
013339b3-7c9e-4398-8eae-dd8fa8330fb0,A learning gap between neuroscience and reinforcement learning,3,0.0,0.172619,"Historically, artificial intelligence has drawn much inspiration from
neuroscience to fuel advances in the field. However, current progress in
reinforcement learning is largely focused on benchmark problems that fail to
capture many of the aspects that are of interest in neuroscience today. We
illustrate this point by extending a T-maze task from neuroscience for use with
reinforcement learning algorithms, and show that state-of-the-art algorithms
are not capable of solving this problem. Finally, we point out where insights
from neuroscience could help explain some of the issues encountered.",0,0,0,0,0,0,0.743893,8.0,0.837454,38
4ee5fd32-f4ce-427b-97dd-d240180830be,A 3D 2D convolutional Neural Network Model for Hyperspectral Image Classification,1,0.00648325,0.065498,"In the proposed SEHybridSN model, a dense block was used to reuse shallow
feature and aimed at better exploiting hierarchical spatial spectral feature.
Subsequent depth separable convolutional layers were used to discriminate the
spatial information. Further refinement of spatial spectral features was
realized by the channel attention method, which were performed behind every 3D
convolutional layer and every 2D convolutional layer. Experiment results
indicate that our proposed model learn more discriminative spatial spectral
features using very few training data. SEHybridSN using only 0.05 and 0.01
labeled data for training, a very satisfactory performance is obtained.",0,1,0,0,0,0,0.374938,8.0,0.704417,32
6fe2143e-cde2-4c37-aade-70c2d6e92480,On the Copying Behaviors of Pre-Training for Neural Machine Translation,21,0.0508089,0.768002,"Previous studies have shown that initializing neural machine translation
(NMT) models with the pre-trained language models (LM) can speed up the model
training and boost the model performance. In this work, we identify a critical
side-effect of pre-training for NMT, which is due to the discrepancy between
the training objectives of LM-based pre-training and NMT. Since the LM
objective learns to reconstruct a few source tokens and copy most of them, the
pre-training initialization would affect the copying behaviors of NMT models.
We provide a quantitative analysis of copying behaviors by introducing a metric
called copying ratio, which empirically shows that pre-training based NMT
models have a larger copying ratio than the standard one. In response to this
problem, we propose a simple and effective method named copying penalty to
control the copying behaviors in decoding. Extensive experiments on both
in-domain and out-of-domain benchmarks show that the copying penalty method
consistently improves translation performance by controlling copying behaviors
for pre-training based NMT models. Source code is freely available at
https://github.com/SunbowLiu/CopyingPenalty.",1,0,0,0,0,0,0.580109,5.0,0.649744,43
2e463074-f3c1-434a-9405-81fe5f0f18fc,Actively Learning Concepts and Conjunctive Queries under ELr-Ontologies,6,0.0142295,0.15337,"We consider the problem to learn a concept or a query in the presence of an
ontology formulated in the description logic ELr, in Angluin's framework of
active learning that allows the learning algorithm to interactively query an
oracle (such as a domain expert). We show that the following can be learned in
polynomial time: (1) EL-concepts, (2) symmetry-free ELI-concepts, and (3)
conjunctive queries (CQs) that are chordal, symmetry-free, and of bounded
arity. In all cases, the learner can pose to the oracle membership queries
based on ABoxes and equivalence queries that ask whether a given concept/query
from the considered class is equivalent to the target. The restriction to
bounded arity in (3) can be removed when we admit unrestricted CQs in
equivalence queries. We also show that EL-concepts are not polynomial query
learnable in the presence of ELI-ontologies.",0,0,0,0,0,0,8.27567e-06,19.0,0.299388,45
b87a08c5-c90e-46b9-aa79-c261c8fb8ec6,CFR-MIX: Solving Imperfect Information Extensive-Form Games with Combinatorial Action Space,7,0.157256,0.554479,"In many real-world scenarios, a team of agents coordinate with each other to
compete against an opponent. The challenge of solving this type of game is that
the team's joint action space grows exponentially with the number of agents,
which results in the inefficiency of the existing algorithms, e.g.,
Counterfactual Regret Minimization (CFR). To address this problem, we propose a
new framework of CFR: CFR-MIX. Firstly, we propose a new strategy
representation that represents a joint action strategy using individual
strategies of all agents and a consistency relationship to maintain the
cooperation between agents. To compute the equilibrium with individual
strategies under the CFR framework, we transform the consistency relationship
between strategies to the consistency relationship between the cumulative
regret values. Furthermore, we propose a novel decomposition method over
cumulative regret values to guarantee the consistency relationship between the
cumulative regret values. Finally, we introduce our new algorithm CFR-MIX which
employs a mixing layer to estimate cumulative regret values of joint actions as
a non-linear combination of cumulative regret values of individual actions.
Experimental results show that CFR-MIX outperforms existing algorithms on
various games significantly.",0,0,0,0,1,0,0.369171,11.0,0.783236,35
717464af-37ce-4259-9a35-5f7e95aca99a,Document-level Entity-based Extraction as Template Generation,48,0.633803,0.996677,"Document-level entity-based extraction (EE), aiming at extracting
entity-centric information such as entity roles and entity relations, is key to
automatic knowledge acquisition from text corpora for various domains. Most
document-level EE systems build extractive models, which struggle to model
long-term dependencies among entities at the document level. To address this
issue, we propose a generative framework for two document-level EE tasks:
role-filler entity extraction (REE) and relation extraction (RE). We first
formulate them as a template generation problem, allowing models to efficiently
capture cross-entity dependencies, exploit label semantics, and avoid the
exponential computation complexity of identifying N-ary relations. A novel
cross-attention guided copy mechanism, TopK Copy, is incorporated into a
pre-trained sequence-to-sequence model to enhance the capabilities of
identifying key information in the input document. Experiments done on the
MUC-4 and SciREX dataset show new state-of-the-art results on REE (+3.26%),
binary RE (+4.8%), and 4-ary RE (+2.7%) in F1 score.",1,1,0,0,1,0,0.918304,5.0,0.86175,29
9cc75cb2-cf9a-498c-aba3-e9a88b1581a2,Regularization via deep generative models: an analysis point of view,7,0.00624419,0.0497047,"This paper proposes a new way of regularizing an inverse problem in imaging
(e.g., deblurring or inpainting) by means of a deep generative neural network.
Compared to end-to-end models, such approaches seem particularly interesting
since the same network can be used for many different problems and experimental
conditions, as soon as the generative model is suited to the data. Previous
works proposed to use a synthesis framework, where the estimation is performed
on the latent vector, the solution being obtained afterwards via the decoder.
Instead, we propose an analysis formulation where we directly optimize the
image itself and penalize the latent vector. We illustrate the interest of such
a formulation by running experiments of inpainting, deblurring and
super-resolution. In many cases our technique achieves a clear improvement of
the performance and seems to be more robust, in particular with respect to
initialization.",0,0,0,0,0,0,0.153172,8.0,0.574543,29
2408df59-ae3c-428e-9f20-073be4d79af1,Using Knowledge-Embedded Attention to Augment Pre-trained Language Models for Fine-Grained Emotion Recognition,14,0.0767842,0.440693,"Modern emotion recognition systems are trained to recognize only a small set
of emotions, and hence fail to capture the broad spectrum of emotions people
experience and express in daily life. In order to engage in more empathetic
interactions, future AI has to perform \textit{fine-grained} emotion
recognition, distinguishing between many more varied emotions. Here, we focus
on improving fine-grained emotion recognition by introducing external knowledge
into a pre-trained self-attention model. We propose Knowledge-Embedded
Attention (KEA) to use knowledge from emotion lexicons to augment the
contextual representations from pre-trained ELECTRA and BERT models. Our
results and error analyses outperform previous models on several datasets, and
is better able to differentiate closely-confusable emotions, such as afraid and
terrified.",0,1,0,0,0,0,0.553426,5.0,0.635016,49
c46671ab-9b61-49bd-a4ef-c7fe15fceed5,Sentence Concatenation Approach to Data Augmentation for Neural Machine Translation,15,0.0365614,0.518381,"Neural machine translation (NMT) has recently gained widespread attention
because of its high translation accuracy. However, it shows poor performance in
the translation of long sentences, which is a major issue in low-resource
languages. It is assumed that this issue is caused by insufficient number of
long sentences in the training data. Therefore, this study proposes a simple
data augmentation method to handle long sentences. In this method, we use only
the given parallel corpora as the training data and generate long sentences by
concatenating two sentences. Based on the experimental results, we confirm
improvements in long sentence translation by the proposed data augmentation
method, despite its simplicity. Moreover, the translation quality is further
improved by the proposed method, when combined with back-translation.",0,1,0,0,0,0,0.325943,6.0,0.576712,15
4713dfd1-fd4b-427b-b58b-7f811c706b5f,Supervised Video Summarization via Multiple Feature Sets with Parallel Attention,34,0.239078,0.391578,"The assignment of importance scores to particular frames or (short) segments
in a video is crucial for summarization, but also a difficult task. Previous
work utilizes only one source of visual features. In this paper, we suggest a
novel model architecture that combines three feature sets for visual content
and motion to predict importance scores. The proposed architecture utilizes an
attention mechanism before fusing motion features and features representing the
(static) visual content, i.e., derived from an image classification model.
Comprehensive experimental evaluations are reported for two well-known
datasets, SumMe and TVSum. In this context, we identify methodological issues
on how previous work used these benchmark datasets, and present a fair
evaluation scheme with appropriate data splits that can be used in future work.
When using static and motion features with parallel attention mechanism, we
improve state-of-the-art results for SumMe, while being on par with the state
of the art for the other dataset.",1,1,0,0,1,0,0.514351,8.0,0.758151,17
22583cce-e5ee-4cd5-a463-0ead06ac99e4,Question-Driven Design Process for Explainable AI User Experiences,39,0.642683,0.749047,"A pervasive design issue of AI systems is their explainability--how to
provide appropriate information to help users understand the AI. The technical
field of explainable AI (XAI) has produced a rich toolbox of techniques.
Designers are now tasked with the challenges of how to select the most suitable
XAI techniques and translate them into UX solutions. Informed by our previous
work studying design challenges around XAI UX, this work proposes a design
process to tackle these challenges. We review our and related prior work to
identify requirements that the process should fulfill, and accordingly, propose
a Question-Driven Design Process that grounds the user needs, choices of XAI
techniques, design, and evaluation of XAI UX all in the user questions. We
provide a mapping guide between prototypical user questions and exemplars of
XAI techniques to reframe the technical space of XAI, also serving as boundary
objects to support collaboration between designers and AI engineers. We
demonstrate it with a use case of designing XAI for healthcare adverse events
prediction, and discuss lessons learned for tackling design challenges of AI
systems.",0,0,0,0,0,0,0.945686,5.0,0.891948,56
3957f27d-e2a8-43dd-a46a-99c221c54cf9,Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as a Target for NLP,13,0.31173,0.832245,"Cryptic crosswords, the dominant crossword variety in the UK, are a promising
target for advancing NLP systems that seek to process semantically complex,
highly compositional language. Cryptic clues read like fluent natural language
but are adversarially composed of two parts: a definition and a wordplay cipher
requiring character-level manipulations. Expert humans use creative
intelligence to solve cryptics, flexibly combining linguistic, world, and
domain knowledge. In this paper, we make two main contributions. First, we
present a dataset of cryptic clues as a challenging new benchmark for NLP
systems that seek to process compositional language in more creative,
human-like ways. After showing that three non-neural approaches and T5, a
state-of-the-art neural language model, do not achieve good performance, we
make our second main contribution: a novel curriculum approach, in which the
model is first fine-tuned on related tasks such as unscrambling words.We also
introduce a challenging data split, examine the meta-linguistic capabilities of
subword-tokenized models, and investigate model systematicity by perturbing the
wordplay part of clues, showing that T5 exhibits behavior partially consistent
with human solving strategies. Although our curricular approach considerably
improves on the T5 baseline, our best-performing model still fails to
generalize to the extent that humans can. Thus, cryptic crosswords remain an
unsolved challenge for NLP systems and a potential source of future innovation.",1,0,1,1,0,0,0.8693,4.0,0.775246,43
08fbaf6b-63e7-451e-849d-c62ddb8564c3,Patch-Based Deep Autoencoder for Point Cloud Geometry Compression,20,0.224624,0.726227,"The ever-increasing 3D application makes the point cloud compression
unprecedentedly important and needed. In this paper, we propose a patch-based
compression process using deep learning, focusing on the lossy point cloud
geometry compression. Unlike existing point cloud compression networks, which
apply feature extraction and reconstruction on the entire point cloud, we
divide the point cloud into patches and compress each patch independently. In
the decoding process, we finally assemble the decompressed patches into a
complete point cloud. In addition, we train our network by a patch-to-patch
criterion, i.e., use the local reconstruction loss for optimization, to
approximate the global reconstruction optimality. Our method outperforms the
state-of-the-art in terms of rate-distortion performance, especially at low
bitrates. Moreover, the compression process we proposed can guarantee to
generate the same number of points as the input. The network model of this
method can be easily applied to other point cloud reconstruction problems, such
as upsampling.",1,1,0,0,1,0,0.763709,8.0,0.844634,23
54ea8976-7061-4b83-b34f-2cd4baf0d863,Verb Sense Clustering using Contextualized Word Representations for Semantic Frame Induction,6,0.0577652,0.41438,"Contextualized word representations have proven useful for various natural
language processing tasks. However, it remains unclear to what extent these
representations can cover hand-coded semantic information such as semantic
frames, which specify the semantic role of the arguments associated with a
predicate. In this paper, we focus on verbs that evoke different frames
depending on the context, and we investigate how well contextualized word
representations can recognize the difference of frames that the same verb
evokes. We also explore which types of representation are suitable for semantic
frame induction. In our experiments, we compare seven different contextualized
word representations for two English frame-semantic resources, FrameNet and
PropBank. We demonstrate that several contextualized word representations,
especially BERT and its variants, are considerably informative for semantic
frame induction. Furthermore, we examine the extent to which the contextualized
representation of a verb can estimate the number of frames that the verb can
evoke.",0,0,0,0,0,0,0.431579,7.0,0.688492,32
bb6d0ebd-fab8-47af-b071-03de44d78c8a,An Educational System for Personalized Teacher Recommendation in K-12 Online Classrooms,5,0.0238428,0.177084,"In this paper, we propose a simple yet effective solution to build practical
teacher recommender systems for online one-on-one classes. Our system consists
of (1) a pseudo matching score module that provides reliable training labels;
(2) a ranking model that scores every candidate teacher; (3) a novelty boosting
module that gives additional opportunities to new teachers; and (4) a diversity
metric that guardrails the recommended results to reduce the chance of
collision. Offline experimental results show that our approach outperforms a
wide range of baselines. Furthermore, we show that our approach is able to
reduce the number of student-teacher matching attempts from 7.22 to 3.09 in a
five-month observation on a third-party online education platform.",0,1,0,0,1,0,0.00215626,22.0,0.64783,13
3f88493c-fe69-4fcb-978e-8bf765e1fcef,Automatic Visual Inspection of Rare Defects: A Framework based on GP-WGAN and Enhanced Faster R-CNN,7,0.151461,0.258814,"A current trend in industries such as semiconductors and foundry is to shift
their visual inspection processes to Automatic Visual Inspection (AVI) systems,
to reduce their costs, mistakes, and dependency on human experts. This paper
proposes a two-staged fault diagnosis framework for AVI systems. In the first
stage, a generation model is designed to synthesize new samples based on real
samples. The proposed augmentation algorithm extracts objects from the real
samples and blends them randomly, to generate new samples and enhance the
performance of the image processor. In the second stage, an improved deep
learning architecture based on Faster R-CNN, Feature Pyramid Network (FPN), and
a Residual Network is proposed to perform object detection on the enhanced
dataset. The performance of the algorithm is validated and evaluated on two
multi-class datasets. The experimental results performed over a range of
imbalance severities demonstrate the superiority of the proposed framework
compared to other solutions.",0,1,0,0,0,0,0.653367,7.0,0.778335,31
06a0825b-1fdf-4b45-b9f6-c0997bbad867,ToxCCIn: Toxic Content Classification with Interpretability,12,0.0505698,0.411609,"Despite the recent successes of transformer-based models in terms of
effectiveness on a variety of tasks, their decisions often remain opaque to
humans. Explanations are particularly important for tasks like offensive
language or toxicity detection on social media because a manual appeal process
is often in place to dispute automatically flagged content. In this work, we
propose a technique to improve the interpretability of these models, based on a
simple and powerful assumption: a post is at least as toxic as its most toxic
span. We incorporate this assumption into transformer models by scoring a post
based on the maximum toxicity of its spans and augmenting the training process
to identify correct spans. We find this approach effective and can produce
explanations that exceed the quality of those provided by Logistic Regression
analysis (often regarded as a highly-interpretable model), according to a human
study.",0,1,0,0,0,0,0.823894,5.0,0.788506,48
4f8a4048-1ba2-4812-a101-481eea47df18,EditVAE: Unsupervised Part-Aware Controllable 3D Point Cloud Shape Generation,17,0.201468,0.63985,"This paper tackles the problem of parts-aware point cloud generation. Unlike
existing works which require the point cloud to be segmented into parts a
priori, our parts-aware editing and generation are performed in an unsupervised
manner. We achieve this with a simple modification of the Variational
Auto-Encoder which yields a joint model of the point cloud itself along with a
schematic representation of it as a combination of shape primitives. In
particular, we introduce a latent representation of the point cloud which can
be decomposed into a disentangled representation for each part of the shape.
These parts are in turn disentangled into both a shape primitive and a point
cloud representation, along with a standardising transformation to a canonical
coordinate system. The dependencies between our standardising transformations
preserve the spatial dependencies between the parts in a manner that allows
meaningful parts-aware point cloud generation and shape editing. In addition to
the flexibility afforded by our disentangled representation, the inductive bias
introduced by our joint modeling approach yields state-of-the-art experimental
results on the ShapeNet dataset.",0,0,0,0,1,0,0.731267,6.0,0.777278,44
3cf7d445-92b5-4ee7-90a1-87661aeab819,Algorithmic Recourse in Partially and Fully Confounded Settings Through Bounding Counterfactual Effects,2,0.0513785,0.0122902,"Algorithmic recourse aims to provide actionable recommendations to
individuals to obtain a more favourable outcome from an automated
decision-making system. As it involves reasoning about interventions performed
in the physical world, recourse is fundamentally a causal problem. Existing
methods compute the effect of recourse actions using a causal model learnt from
data under the assumption of no hidden confounding and modelling assumptions
such as additive noise. Building on the seminal work of Balke and Pearl (1994),
we propose an alternative approach for discrete random variables which relaxes
these assumptions and allows for unobserved confounding and arbitrary
structural equations. The proposed approach only requires specification of the
causal graph and confounding structure and bounds the expected counterfactual
effect of recourse actions. If the lower bound is above a certain threshold,
i.e., on the other side of the decision boundary, recourse is guaranteed in
expectation.",0,0,0,0,0,0,0.926041,4.0,0.836927,25
73c3028f-dc57-43ce-b631-85c7c5829e2f,Domain-Class Correlation Decomposition for Generalizable Person Re-Identification,9,0.0562574,0.404423,"Domain generalization in person re-identification is a highly important
meaningful and practical task in which a model trained with data from several
source domains is expected to generalize well to unseen target domains. Domain
adversarial learning is a promising domain generalization method that aims to
remove domain information in the latent representation through adversarial
training. However, in person re-identification, the domain and class are
correlated, and we theoretically show that domain adversarial learning will
lose certain information about class due to this domain-class correlation.
Inspired by casual inference, we propose to perform interventions to the domain
factor $d$, aiming to decompose the domain-class correlation. To achieve this
goal, we proposed estimating the resulting representation $z^{*}$ caused by the
intervention through first- and second-order statistical characteristic
matching. Specifically, we build a memory bank to restore the statistical
characteristics of each domain. Then, we use the newly generated samples
$\{z^{*},y,d^{*}\}$ to compute the loss function. These samples are
domain-class correlation decomposed; thus, we can learn a domain-invariant
representation that can capture more class-related features. Extensive
experiments show that our model outperforms the state-of-the-art methods on the
large-scale domain generalization Re-ID benchmark.",0,0,0,0,1,0,0.59228,7.0,0.75458,82
0479321c-4728-464d-a270-725b7e5f8664,TöRF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis,80,0.88306,0.889951,"Neural networks can represent and accurately reconstruct radiance fields for
static 3D scenes (e.g., NeRF). Several works extend these to dynamic scenes
captured with monocular video, with promising performance. However, the
monocular setting is known to be an under-constrained problem, and so methods
rely on data-driven priors for reconstructing dynamic content. We replace these
priors with measurements from a time-of-flight (ToF) camera, and introduce a
neural representation based on an image formation model for continuous-wave ToF
cameras. Instead of working with processed depth maps, we model the raw ToF
sensor measurements to improve reconstruction quality and avoid issues with low
reflectance regions, multi-path interference, and a sensor's limited
unambiguous depth range. We show that this approach improves robustness of
dynamic scene reconstruction to erroneous calibration and large motions, and
discuss the benefits and limitations of integrating RGB+ToF sensors that are
now available on modern smartphones.",0,0,0,0,0,0,0.969536,5.0,0.928162,57
005b0dba-9a47-40d6-b70a-22e34d940b8e,Scene-aware Generative Network for Human Motion Synthesis,57,0.756315,0.837708,"We revisit human motion synthesis, a task useful in various real world
applications, in this paper. Whereas a number of methods have been developed
previously for this task, they are often limited in two aspects: focusing on
the poses while leaving the location movement behind, and ignoring the impact
of the environment on the human motion. In this paper, we propose a new
framework, with the interaction between the scene and the human motion taken
into account. Considering the uncertainty of human motion, we formulate this
task as a generative task, whose objective is to generate plausible human
motion conditioned on both the scene and the human initial position. This
framework factorizes the distribution of human motions into a distribution of
movement trajectories conditioned on scenes and that of body pose dynamics
conditioned on both scenes and trajectories. We further derive a GAN based
learning approach, with discriminators to enforce the compatibility between the
human motion and the contextual scene as well as the 3D to 2D projection
constraints. We assess the effectiveness of the proposed method on two
challenging datasets, which cover both synthetic and real world environments.",0,0,0,0,0,0,0.930465,6.0,0.895186,37
d1b66a9c-6313-4402-a830-69b135290b55,Simulated Annealing for Emotional Dialogue Systems,5,0.109523,0.284075,"Explicitly modeling emotions in dialogue generation has important
applications, such as building empathetic personal companions. In this study,
we consider the task of expressing a specific emotion for dialogue generation.
Previous approaches take the emotion as an input signal, which may be ignored
during inference. We instead propose a search-based emotional dialogue system
by simulated annealing (SA). Specifically, we first define a scoring function
that combines contextual coherence and emotional correctness. Then, SA
iteratively edits a general response and searches for a sentence with a higher
score, enforcing the presence of the desired emotion. We evaluate our system on
the NLPCC2017 dataset. Our proposed method shows 12% improvements in emotion
accuracy compared with the previous state-of-the-art method, without hurting
the generation quality (measured by BLEU).",1,1,0,0,1,0,0.903318,8.0,0.904893,28
93bab54f-2373-453c-9488-adee1a721984,Desiderata for Explainable AI in statistical production systems of the European Central Bank,9,0.0532466,0.277951,"Explainable AI constitutes a fundamental step towards establishing fairness
and addressing bias in algorithmic decision-making. Despite the large body of
work on the topic, the benefit of solutions is mostly evaluated from a
conceptual or theoretical point of view and the usefulness for real-world use
cases remains uncertain. In this work, we aim to state clear user-centric
desiderata for explainable AI reflecting common explainability needs
experienced in statistical production systems of the European Central Bank. We
link the desiderata to archetypical user roles and give examples of techniques
and methods which can be used to address the user's needs. To this end, we
provide two concrete use cases from the domain of statistical data production
in central banks: the detection of outliers in the Centralised Securities
Database and the data-driven identification of data quality checks for the
Supervisory Banking data system.",0,1,0,0,0,0,0.517678,7.0,0.724954,51
ae1da5d2-9d4f-4f99-90b6-0321868a3382,NeRF in detail: Learning to sample for view synthesis,33,0.180671,0.305378,"Neural radiance fields (NeRF) methods have demonstrated impressive novel view
synthesis performance. The core approach is to render individual rays by
querying a neural network at points sampled along the ray to obtain the density
and colour of the sampled points, and integrating this information using the
rendering equation. Since dense sampling is computationally prohibitive, a
common solution is to perform coarse-to-fine sampling.
  In this work we address a clear limitation of the vanilla coarse-to-fine
approach -- that it is based on a heuristic and not trained end-to-end for the
task at hand. We introduce a differentiable module that learns to propose
samples and their importance for the fine network, and consider and compare
multiple alternatives for its neural architecture. Training the proposal module
from scratch can be unstable due to lack of supervision, so an effective
pre-training strategy is also put forward. The approach, named `NeRF in detail'
(NeRF-ID), achieves superior view synthesis quality over NeRF and the
state-of-the-art on the synthetic Blender benchmark and on par or better
performance on the real LLFF-NeRF scenes. Furthermore, by leveraging the
predicted sample importance, a 25% saving in computation can be achieved
without significantly sacrificing the rendering quality.",0,0,0,0,1,0,0.939581,5.0,0.884497,70
18f67c76-5ba1-4b7d-9a1f-906ada67db66,Detecting Speaker Personas from Conversational Texts,15,0.2182,0.770481,"Personas are useful for dialogue response prediction. However, the personas
used in current studies are pre-defined and hard to obtain before a
conversation. To tackle this issue, we study a new task, named Speaker Persona
Detection (SPD), which aims to detect speaker personas based on the plain
conversational text. In this task, a best-matched persona is searched out from
candidates given the conversational text. This is a many-to-many semantic
matching task because both contexts and personas in SPD are composed of
multiple sentences. The long-term dependency and the dynamic redundancy among
these sentences increase the difficulty of this task. We build a dataset for
SPD, dubbed as Persona Match on Persona-Chat (PMPC). Furthermore, we evaluate
several baseline models and propose utterance-to-profile (U2P) matching
networks for this task. The U2P models operate at a fine granularity which
treat both contexts and personas as sets of multiple sequences. Then, each
sequence pair is scored and an interpretable overall score is obtained for a
context-persona pair through aggregation. Evaluation results show that the U2P
models outperform their baseline counterparts significantly.",1,0,1,1,0,0,0.781152,9.0,0.867651,32
b5debf36-483f-401a-aea8-50c32bf2c0eb,Towards Benchmarking the Utility of Explanations for Model Debugging,15,0.0382742,0.435799,"Post-hoc explanation methods are an important class of approaches that help
understand the rationale underlying a trained model's decision. But how useful
are they for an end-user towards accomplishing a given task? In this vision
paper, we argue the need for a benchmark to facilitate evaluations of the
utility of post-hoc explanation methods. As a first step to this end, we
enumerate desirable properties that such a benchmark should possess for the
task of debugging text classifiers. Additionally, we highlight that such a
benchmark facilitates not only assessing the effectiveness of explanations but
also their efficiency.",0,0,0,0,0,0,0.779033,4.0,0.700625,18
b701e345-e9b0-4bb6-9d5b-ca0b27478b1c,In the light of feature distributions: moment matching for Neural Style Transfer,38,0.48097,0.543619,"Style transfer aims to render the content of a given image in the
graphical/artistic style of another image. The fundamental concept underlying
NeuralStyle Transfer (NST) is to interpret style as a distribution in the
feature space of a Convolutional Neural Network, such that a desired style can
be achieved by matching its feature distribution. We show that most current
implementations of that concept have important theoretical and practical
limitations, as they only partially align the feature distributions. We propose
a novel approach that matches the distributions more precisely, thus
reproducing the desired style more faithfully, while still being
computationally efficient. Specifically, we adapt the dual form of Central
Moment Discrepancy (CMD), as recently proposed for domain adaptation, to
minimize the difference between the target style and the feature distribution
of the output image. The dual interpretation of this metric explicitly matches
all higher-order centralized moments and is therefore a natural extension of
existing NST methods that only take into account the first and second moments.
Our experiments confirm that the strong theoretical properties also translate
to visually better style transfer, and better disentangle style from semantic
image content.",0,0,0,0,0,0,0.975264,9.0,0.966529,41
8adc139f-675f-4b43-a7b8-22ef1a2fcd3f,ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language Generation,30,0.0929213,0.450869,"Despite the recent advancement in NLP research, cross-lingual transfer for
natural language generation is relatively understudied. In this work, we
transfer supervision from high resource language (HRL) to multiple low-resource
languages (LRLs) for natural language generation (NLG). We consider four NLG
tasks (text summarization, question generation, news headline generation, and
distractor generation) and three syntactically diverse languages, i.e.,
English, Hindi, and Japanese. We propose an unsupervised cross-lingual language
generation framework (called ZmBART) that does not use any parallel or
pseudo-parallel/back-translated data. In this framework, we further pre-train
mBART sequence-to-sequence denoising auto-encoder model with an auxiliary task
using monolingual data of three languages. The objective function of the
auxiliary task is close to the target tasks which enriches the multi-lingual
latent representation of mBART and provides good initialization for target
tasks. Then, this model is fine-tuned with task-specific supervised English
data and directly evaluated with low-resource languages in the Zero-shot
setting. To overcome catastrophic forgetting and spurious correlation issues,
we applied freezing model component and data argumentation approaches
respectively. This simple modeling approach gave us promising results.We
experimented with few-shot training (with 1000 supervised data points) which
boosted the model performance further. We performed several ablations and
cross-lingual transferability analyses to demonstrate the robustness of ZmBART.",1,1,0,1,0,0,0.621971,4.0,0.590742,26
a0de1011-374a-4aab-bc89-6e6d01ecbfc1,"Confucius, Cyberpunk and Mr. Science: Comparing AI ethics between China and the EU",1,0.0193811,0.0687525,"The exponential development and application of artificial intelligence
triggered an unprecedented global concern for potential social and ethical
issues. Stakeholders from different industries, international foundations,
governmental organisations and standards institutions quickly improvised and
created various codes of ethics attempting to regulate AI. A major concern is
the large homogeneity and presumed consensualism around these principles. While
it is true that some ethical doctrines, such as the famous Kantian deontology,
aspire to universalism, they are however not universal in practice. In fact,
ethical pluralism is more about differences in which relevant questions to ask
rather than different answers to a common question. When people abide by
different moral doctrines, they tend to disagree on the very approach to an
issue. Even when people from different cultures happen to agree on a set of
common principles, it does not necessarily mean that they share the same
understanding of these concepts and what they entail. In order to better
understand the philosophical roots and cultural context underlying ethical
principles in AI, we propose to analyse and compare the ethical principles
endorsed by the Chinese National New Generation Artificial Intelligence
Governance Professional Committee (CNNGAIGPC) and those elaborated by the
European High-level Expert Group on AI (HLEGAI). China and the EU have very
different political systems and diverge in their cultural heritages. In our
analysis, we wish to highlight that principles that seem similar a priori may
actually have different meanings, derived from different approaches and reflect
distinct goals.",0,0,0,0,0,0,0.332145,7.0,0.640491,26
63b01718-f21f-4348-a351-c86d5f977965,Versatile modular neural locomotion control with fast learning,18,0.297134,0.702483,"Legged robots have significant potential to operate in highly unstructured
environments. The design of locomotion control is, however, still challenging.
Currently, controllers must be either manually designed for specific robots and
tasks, or automatically designed via machine learning methods that require long
training times and yield large opaque controllers. Drawing inspiration from
animal locomotion, we propose a simple yet versatile modular neural control
structure with fast learning. The key advantages of our approach are that
behavior-specific control modules can be added incrementally to obtain
increasingly complex emergent locomotion behaviors, and that neural connections
interfacing with existing modules can be quickly and automatically learned. In
a series of experiments, we show how eight modules can be quickly learned and
added to a base control module to obtain emergent adaptive behaviors allowing a
hexapod robot to navigate in complex environments. We also show that modules
can be added and removed during operation without affecting the functionality
of the remaining controller. Finally, the control approach was successfully
demonstrated on a physical hexapod robot. Taken together, our study reveals a
significant step towards fast automatic design of versatile neural locomotion
control for complex robotic systems.",1,0,0,0,0,0,0.0872214,12.0,0.666378,61
6c06c8c7-c5a5-43bb-a1c7-42206e23fc4e,Neural Relational Inference with Efficient Message Passing Mechanisms,11,0.0772506,0.191028,"Many complex processes can be viewed as dynamical systems of interacting
agents. In many cases, only the state sequences of individual agents are
observed, while the interacting relations and the dynamical rules are unknown.
The neural relational inference (NRI) model adopts graph neural networks that
pass messages over a latent graph to jointly learn the relations and the
dynamics based on the observed data. However, NRI infers the relations
independently and suffers from error accumulation in multi-step prediction at
dynamics learning procedure. Besides, relation reconstruction without prior
knowledge becomes more difficult in more complex systems. This paper introduces
efficient message passing mechanisms to the graph neural networks with
structural prior knowledge to address these problems. A relation interaction
mechanism is proposed to capture the coexistence of all relations, and a
spatio-temporal message passing mechanism is proposed to use historical
information to alleviate error accumulation. Additionally, the structural prior
knowledge, symmetry as a special case, is introduced for better relation
prediction in more complex systems. The experimental results on simulated
physics systems show that the proposed method outperforms existing
state-of-the-art methods.",0,0,0,0,1,0,0.71085,5.0,0.721265,36
c2d45b12-6d7e-4c70-beed-331bbcb6ad5e,Auction-based and Distributed Optimization Approaches for Scheduling Observations in Satellite Constellations with Exclusive Orbit Portions,8,0.427045,0.498695,"We investigate the use of multi-agent allocation techniques on problems
related to Earth observation scenarios with multiple users and satellites. We
focus on the problem of coordinating users having reserved exclusive orbit
portions and one central planner having several requests that may use some
intervals of these exclusives. We define this problem as Earth Observation
Satellite Constellation Scheduling Problem (EOSCSP) and map it to a Mixed
Integer Linear Program. As to solve EOSCSP, we propose market-based techniques
and a distributed problem solving technique based on Distributed Constraint
Optimization (DCOP), where agents cooperate to allocate requests without
sharing their own schedules. These contributions are experimentally evaluated
on randomly generated EOSCSP instances based on real large-scale or highly
conflicting observation order books.",0,1,0,0,0,0,0.602928,25.0,0.932445,18
832c94a4-f855-4d1b-8380-b5f13b5e3ee4,M3DSSD: Monocular 3D Single Stage Object Detector,64,0.41163,0.93178,"In this paper, we propose a Monocular 3D Single Stage object Detector
(M3DSSD) with feature alignment and asymmetric non-local attention. Current
anchor-based monocular 3D object detection methods suffer from feature
mismatching. To overcome this, we propose a two-step feature alignment
approach. In the first step, the shape alignment is performed to enable the
receptive field of the feature map to focus on the pre-defined anchors with
high confidence scores. In the second step, the center alignment is used to
align the features at 2D/3D centers. Further, it is often difficult to learn
global information and capture long-range relationships, which are important
for the depth prediction of objects. Therefore, we propose a novel asymmetric
non-local attention block with multi-scale sampling to extract depth-wise
features. The proposed M3DSSD achieves significantly better performance than
the monocular 3D object detection methods on the KITTI dataset, in both 3D
object detection and bird's eye view tasks.",1,1,0,0,1,0,0.880896,5.0,0.829126,47
94bc1717-a739-4a8e-9166-ed9234c69ae7,KITTI-CARLA: a KITTI-like dataset generated by CARLA Simulator,36,0.126142,0.567125,"KITTI-CARLA is a dataset built from the CARLA v0.9.10 simulator using a
vehicle with sensors identical to the KITTI dataset. The vehicle thus has a
Velodyne HDL64 LiDAR positioned in the middle of the roof and two color cameras
similar to Point Grey Flea 2. The positions of the LiDAR and cameras are the
same as the setup used in KITTI. The objective of this dataset is to test
approaches of semantic segmentation LiDAR and/or images, odometry LiDAR and/or
image in synthetic data and to compare with the results obtained on real data
like KITTI. This dataset thus makes it possible to improve transfer learning
methods from a synthetic dataset to a real dataset. We created 7 sequences with
5000 frames in each sequence in the 7 maps of CARLA providing different
environments (city, suburban area, mountain, rural area, highway...). The
dataset is available at: http://npm3d.fr",0,1,0,1,0,0,0.993262,19.0,1.0,2
7aa28794-f2eb-4b0b-ba5d-da37027e7bf3,An Optical physics inspired CNN approach for intrinsic image decomposition,1,0.0573611,0.0280298,"Intrinsic Image Decomposition is an open problem of generating the
constituents of an image. Generating reflectance and shading from a single
image is a challenging task specifically when there is no ground truth. There
is a lack of unsupervised learning approaches for decomposing an image into
reflectance and shading using a single image. We propose a neural network
architecture capable of this decomposition using physics-based parameters
derived from the image. Through experimental results, we show that (a) the
proposed methodology outperforms the existing deep learning-based IID
techniques and (b) the derived parameters improve the efficacy significantly.
We conclude with a closer analysis of the results (numerical and example
images) showing several avenues for improvement.",0,1,0,0,1,0,0.890318,8.0,0.897954,19
733654c4-1309-4bf3-a054-515e29733350,Boosting Transformers for Job Expression Extraction and Classification in a Low-Resource Setting,4,0.0113275,0.119331,"In this paper, we explore possible improvements of transformer models in a
low-resource setting. In particular, we present our approaches to tackle the
first two of three subtasks of the MEDDOPROF competition, i.e., the extraction
and classification of job expressions in Spanish clinical texts. As neither
language nor domain experts, we experiment with the multilingual XLM-R
transformer model and tackle these low-resource information extraction tasks as
sequence-labeling problems. We explore domain- and language-adaptive
pretraining, transfer learning and strategic datasplits to boost the
transformer model. Our results show strong improvements using these methods by
up to 5.3 F1 points compared to a fine-tuned XLM-R model. Our best models
achieve 83.2 and 79.3 F1 for the first two tasks, respectively.",0,1,0,0,0,0,0.498153,3.0,0.339571,18
52ef92fd-09c0-47f9-9e3a-cbe295dab6c3,Adding Visibility to Visibility Graphs: Weighting Visibility Analysis with Attenuation Coefficients,1,0.0125332,0.0667122,"Evaluating the built environment based on visibility has been long used as a
tool for human-centric design. The origins of isovists and visibility graphs
are within interior spaces, while more recently, these evaluation techniques
have been applied in the urban context. One of the key differentiators of an
outside environment is the weather, which has largely been ignored in the
design computation and space-syntax research areas. While a visibility graph is
a straightforward metric for determining connectivity between regions of space
through a line of sight calculation, this approach largely ignores the actual
visibility of one point to another. This paper introduces a new method for
weighting a visibility graph based on weather conditions (i.e. rain, fog,
snow). These new factors are integrated into visibility graphs and applied to
sample environments to demonstrate the variance between assuming a straight
line of sight and reduced visibility.",0,0,1,0,0,0,0.0012902,17.0,0.514015,42
fccabc71-6692-426c-8ec0-b3ee585a002d,A Template-guided Hybrid Pointer Network for Knowledge-basedTask-oriented Dialogue Systems,11,0.331267,0.604856,"Most existing neural network based task-oriented dialogue systems follow
encoder-decoder paradigm, where the decoder purely depends on the source texts
to generate a sequence of words, usually suffering from instability and poor
readability. Inspired by the traditional template-based generation approaches,
we propose a template-guided hybrid pointer network for the knowledge-based
task-oriented dialogue system, which retrieves several potentially relevant
answers from a pre-constructed domain-specific conversational repository as
guidance answers, and incorporates the guidance answers into both the encoding
and decoding processes. Specifically, we design a memory pointer network model
with a gating mechanism to fully exploit the semantic correlation between the
retrieved answers and the ground-truth response. We evaluate our model on four
widely used task-oriented datasets, including one simulated and three manually
created datasets. The experimental results demonstrate that the proposed model
achieves significantly better performance than the state-of-the-art methods
over different automatic evaluation metrics.",1,1,0,0,1,0,0.952526,11.0,0.954991,39
8b469dd3-578a-4ada-9878-35bcd223a45e,IoTDevID: A Behavior-Based Device Identification Method for the IoT,22,0.46979,0.470557,"Device identification is one way to secure a network of IoT devices, whereby
devices identified as suspicious can subsequently be isolated from a network.
In this study, we present a machine learning-based method, IoTDevID, that
recognizes devices through characteristics of their network packets. As a
result of using a rigorous feature analysis and selection process, our study
offers a generalizable and realistic approach to modelling device behavior,
achieving high predictive accuracy across two public datasets. The model's
underlying feature set is shown to be more predictive than existing feature
sets used for device identification, and is shown to generalize to data unseen
during the feature selection process. Unlike most existing approaches to IoT
device identification, IoTDevID is able to detect devices using non-IP and
low-energy protocols.",1,1,0,0,0,0,0.986739,6.0,0.975749,19
541457b8-915b-4a47-b0d9-c877198a9495,SMIL: Multimodal Learning with Severely Missing Modality,169,0.635722,0.996147,"A common assumption in multimodal learning is the completeness of training
data, i.e., full modalities are available in all training examples. Although
there exists research endeavor in developing novel methods to tackle the
incompleteness of testing data, e.g., modalities are partially missing in
testing examples, few of them can handle incomplete training modalities. The
problem becomes even more challenging if considering the case of severely
missing, e.g., 90% training examples may have incomplete modalities. For the
first time in the literature, this paper formally studies multimodal learning
with missing modality in terms of flexibility (missing modalities in training,
testing, or both) and efficiency (most training data have incomplete modality).
Technically, we propose a new method named SMIL that leverages Bayesian
meta-learning in uniformly achieving both objectives. To validate our idea, we
conduct a series of experiments on three popular benchmarks: MM-IMDb, CMU-MOSI,
and avMNIST. The results prove the state-of-the-art performance of SMIL over
existing methods and generative baselines including autoencoders and generative
adversarial networks. Our code is available at
https://github.com/mengmenm/SMIL.",1,0,1,0,1,0,0.642414,8.0,0.802318,53
12b76889-bd0c-43a6-b671-53e2ec4748c1,Proposal-free One-stage Referring Expression via Grid-Word Cross-Attention,13,0.184824,0.597972,"Referring Expression Comprehension (REC) has become one of the most important
tasks in visual reasoning, since it is an essential step for many
vision-and-language tasks such as visual question answering. However, it has
not been widely used in many downstream tasks because it suffers 1) two-stage
methods exist heavy computation cost and inevitable error accumulation, and 2)
one-stage methods have to depend on lots of hyper-parameters (such as anchors)
to generate bounding box. In this paper, we present a proposal-free one-stage
(PFOS) model that is able to regress the region-of-interest from the image,
based on a textual query, in an end-to-end manner. Instead of using the
dominant anchor proposal fashion, we directly take the dense-grid of an image
as input for a cross-attention transformer that learns grid-word
correspondences. The final bounding box is predicted directly from the image
without the time-consuming anchor selection process that previous methods
suffer. Our model achieves the state-of-the-art performance on four referring
expression datasets with higher efficiency, comparing to previous best
one-stage and two-stage methods.",0,1,0,0,1,0,0.95374,8.0,0.939171,27
e7fe75f9-96fe-4806-a24c-fe2f28b1e081,Text Counterfactuals via Latent Optimization and Shapley-Guided Search,15,0.0558922,0.235287,"We study the problem of generating counterfactual text for a classifier as a
means for understanding and debugging classification. Given a textual input and
a classification model, we aim to minimally alter the text to change the
model's prediction. White-box approaches have been successfully applied to
similar problems in vision where one can directly optimize the continuous
input. Optimization-based approaches become difficult in the language domain
due to the discrete nature of text. We bypass this issue by directly optimizing
in the latent space and leveraging a language model to generate candidate
modifications from optimized latent representations. We additionally use
Shapley values to estimate the combinatoric effect of multiple changes. We then
use these estimates to guide a beam search for the final counterfactual text.
We achieve favorable performance compared to recent white-box and black-box
baselines using human and automatic evaluations. Ablation studies show that
both latent optimization and the use of Shapley values improve success rate and
the quality of the generated counterfactuals.",0,1,0,0,0,0,0.766519,5.0,0.753066,34
2fef4bf2-a0e6-4ead-ac85-03323005fd7a,Point Cloud Learning with Transformer,26,0.162494,0.61741,"Remarkable performance from Transformer networks in Natural Language
Processing promote the development of these models in dealing with computer
vision tasks such as image recognition and segmentation. In this paper, we
introduce a novel framework, called Multi-level Multi-scale Point Transformer
(MLMSPT) that works directly on the irregular point clouds for representation
learning. Specifically, a point pyramid transformer is investigated to model
features with diverse resolutions or scales we defined, followed by a
multi-level transformer module to aggregate contextual information from
different levels of each scale and enhance their interactions. While a
multi-scale transformer module is designed to capture the dependencies among
representations across different scales. Extensive evaluation on public
benchmark datasets demonstrate the effectiveness and the competitive
performance of our methods on 3D shape classification, segmentation tasks.",0,0,1,0,0,0,0.833085,5.0,0.794586,62
72df8294-4535-4836-be89-8d2e75334a62,End-to-end Neural Information Status Classification,6,0.145088,0.398122,"Most previous studies on information status (IS) classification and bridging
anaphora recognition assume that the gold mention or syntactic tree information
is given (Hou et al., 2013; Roesiger et al., 2018; Hou, 2020; Yu and Poesio,
2020). In this paper, we propose an end-to-end neural approach for information
status classification. Our approach consists of a mention extraction component
and an information status assignment component. During the inference time, our
system takes a raw text as the input and generates mentions together with their
information status. On the ISNotes corpus (Markert et al., 2012), we show that
our information status assignment component achieves new state-of-the-art
results on fine-grained IS classification based on gold mentions. Furthermore,
our system performs significantly better than other baselines for both mention
extraction and fine-grained IS classification in the end-to-end setting.
Finally, we apply our system on BASHI (Roesiger, 2018) and SciCorp (Roesiger,
2016) to recognize referential bridging anaphora. We find that our end-to-end
system trained on ISNotes achieves competitive results on bridging anaphora
recognition compared to the previous state-of-the-art system that relies on
syntactic information and is trained on the in-domain datasets (Yu and Poesio,
2020).",1,1,0,0,1,0,0.242105,11.0,0.737053,41
f36c9ef1-42b3-4de3-a2a7-75ed89d9c66e,Integration of Pre-trained Networks with Continuous Token Interface for End-to-End Spoken Language Understanding,28,0.344152,0.493078,"Most End-to-End (E2E) SLU networks leverage the pre-trained ASR networks but
still lack the capability to understand the semantics of utterances, crucial
for the SLU task. To solve this, recently proposed studies use pre-trained NLU
networks. However, it is not trivial to fully utilize both pre-trained
networks; many solutions were proposed, such as Knowledge Distillation,
cross-modal shared embedding, and network integration with Interface. We
propose a simple and robust integration method for the E2E SLU network with
novel Interface, Continuous Token Interface (CTI), the junctional
representation of the ASR and NLU networks when both networks are pre-trained
with the same vocabulary. Because the only difference is the noise level, we
directly feed the ASR network's output to the NLU network. Thus, we can train
our SLU network in an E2E manner without additional modules, such as
Gumbel-Softmax. We evaluate our model using SLURP, a challenging SLU dataset
and achieve state-of-the-art scores on both intent classification and slot
filling tasks. We also verify the NLU network, pre-trained with Masked Language
Model, can utilize a noisy textual representation of CTI. Moreover, we show our
model can be trained with multi-task learning from heterogeneous data even
after integration with CTI.",0,1,0,0,1,0,0.78415,4.0,0.704475,35
4218b0c5-17b9-47fe-931c-a46df5796119,Efficient Combinatorial Optimization for Word-level Adversarial Textual Attack,23,0.109638,0.592395,"Over the past few years, various word-level textual attack approaches have
been proposed to reveal the vulnerability of deep neural networks used in
natural language processing. Typically, these approaches involve an important
optimization step to determine which substitute to be used for each word in the
original input. However, current research on this step is still rather limited,
from the perspectives of both problem-understanding and problem-solving. In
this paper, we address these issues by uncovering the theoretical properties of
the problem and proposing an efficient local search algorithm (LS) to solve it.
We establish the first provable approximation guarantee on solving the problem
in general cases.Extensive experiments involving 5 NLP tasks, 8 datasets and 26
NLP models show that LS can largely reduce the number of queries usually by an
order of magnitude to achieve high attack success rates. Further experiments
show that the adversarial examples crafted by LS usually have higher quality,
exhibit better transferability, and can bring more robustness improvement to
victim models by adversarial training.",1,0,0,0,0,0,0.512577,7.0,0.722878,51
f2364dc5-2e25-4206-92fd-735d31e363c8,Learning Riemannian Manifolds for Geodesic Motion Skills,24,0.315117,0.953861,"For robots to work alongside humans and perform in unstructured environments,
they must learn new motion skills and adapt them to unseen situations on the
fly. This demands learning models that capture relevant motion patterns, while
offering enough flexibility to adapt the encoded skills to new requirements,
such as dynamic obstacle avoidance. We introduce a Riemannian manifold
perspective on this problem, and propose to learn a Riemannian manifold from
human demonstrations on which geodesics are natural motion skills. We realize
this with a variational autoencoder (VAE) over the space of position and
orientations of the robot end-effector. Geodesic motion skills let a robot plan
movements from and to arbitrary points on the data manifold. They also provide
a straightforward method to avoid obstacles by redefining the ambient metric in
an online fashion. Moreover, geodesics naturally exploit the manifold resulting
from multiple--mode tasks to design motions that were not explicitly
demonstrated previously. We test our learning framework using a 7-DoF robotic
manipulator, where the robot satisfactorily learns and reproduces realistic
skills featuring elaborated motion patterns, avoids previously unseen
obstacles, and generates novel movements in multiple-mode settings.",0,1,0,0,0,0,0.299445,8.0,0.669676,41
09f817d5-820a-4c41-b9a8-d1e80bebd381,Improved Learning of Robot Manipulation Tasks via Tactile Intrinsic Motivation,16,0.0870131,0.513299,"In this paper we address the challenge of exploration in deep reinforcement
learning for robotic manipulation tasks. In sparse goal settings, an agent does
not receive any positive feedback until randomly achieving the goal, which
becomes infeasible for longer control sequences. Inspired by touch-based
exploration observed in children, we formulate an intrinsic reward based on the
sum of forces between a robot's force sensors and manipulation objects that
encourages physical interaction. Furthermore, we introduce contact-prioritized
experience replay, a sampling scheme that prioritizes contact rich episodes and
transitions. We show that our solution accelerates the exploration and
outperforms state-of-the-art methods on three fundamental robot manipulation
benchmarks.",0,1,0,0,1,0,0.485909,7.0,0.711875,32
092bb998-2fb3-4e2a-9023-6d9cfdb73be7,Deep Discourse Analysis for Generating Personalized Feedback in Intelligent Tutor Systems,16,0.172252,0.583252,"We explore creating automated, personalized feedback in an intelligent
tutoring system (ITS). Our goal is to pinpoint correct and incorrect concepts
in student answers in order to achieve better student learning gains. Although
automatic methods for providing personalized feedback exist, they do not
explicitly inform students about which concepts in their answers are correct or
incorrect. Our approach involves decomposing students answers using neural
discourse segmentation and classification techniques. This decomposition yields
a relational graph over all discourse units covered by the reference solutions
and student answers. We use this inferred relational graph structure and a
neural classifier to match student answers with reference solutions and
generate personalized feedback. Although the process is completely automated
and data-driven, the personalized feedback generated is highly contextual,
domain-aware and effectively targets each student's misconceptions and
knowledge gaps. We test our method in a dialogue-based ITS and demonstrate that
our approach results in high-quality feedback and significantly improved
student learning gains.",0,1,0,0,0,0,0.19772,9.0,0.653088,52
42fd193e-e494-4522-af8b-216420b0903e,Guaranteeing Maximin Shares: Some Agents Left Behind,14,0.252398,0.373928,"The maximin share (MMS) guarantee is a desirable fairness notion for
allocating indivisible goods. While MMS allocations do not always exist,
several approximation techniques have been developed to ensure that all agents
receive a fraction of their maximin share. We focus on an alternative
approximation notion, based on the population of agents, that seeks to
guarantee MMS for a fraction of agents. We show that no optimal approximation
algorithm can satisfy more than a constant number of agents, and discuss the
existence and computation of MMS for all but one agent and its relation to
approximate MMS guarantees. We then prove the existence of allocations that
guarantee MMS for $\frac{2}{3}$ of agents, and devise a polynomial time
algorithm that achieves this bound for up to nine agents. A key implication of
our result is the existence of allocations that guarantee
$\text{MMS}^{\lceil{3n/2}\rceil}$, i.e., the value that agents receive by
partitioning the goods into $\lceil{\frac{3}{2}n}\rceil$ bundles, improving the
best known guarantee of $\text{MMS}^{2n-2}$. Finally, we provide empirical
experiments using synthetic data.",0,0,0,0,0,0,0.209992,10.0,0.694542,52
dff1075a-4127-4499-a823-3dc9488d4390,SkillNER: Mining and Mapping Soft Skills from any Text,34,0.0925157,0.789621,"In today's digital world, there is an increasing focus on soft skills. On the
one hand, they facilitate innovation at companies, but on the other, they are
unlikely to be automated soon. Researchers struggle with accurately approaching
quantitatively the study of soft skills due to the lack of data-driven methods
to retrieve them. This limits the possibility for psychologists and HR managers
to understand the relation between humans and digitalisation. This paper
presents SkillNER, a novel data-driven method for automatically extracting soft
skills from text. It is a named entity recognition (NER) system trained with a
support vector machine (SVM) on a corpus of more than 5000 scientific papers.
We developed this system by measuring the performance of our approach against
different training models and validating the results together with a team of
psychologists. Finally, SkillNER was tested in a real-world case study using
the job descriptions of ESCO (European Skill/Competence Qualification and
Occupation) as textual source. The system enabled the detection of communities
of job profiles based on their shared soft skills and communities of soft
skills based on their shared job profiles. This case study demonstrates that
the tool can automatically retrieve soft skills from a large corpus in an
efficient way, proving useful for firms, institutions, and workers. The tool is
open and available online to foster quantitative methods for the study of soft
skills.",0,1,0,0,0,0,0.044993,8.0,0.414031,60
670d1191-602b-4075-b45b-58c7c2fc2e8a,RGB Stream Is Enough for Temporal Action Detection,21,0.285781,0.397105,"State-of-the-art temporal action detectors to date are based on two-stream
input including RGB frames and optical flow. Although combining RGB frames and
optical flow boosts performance significantly, optical flow is a hand-designed
representation which not only requires heavy computation, but also makes it
methodologically unsatisfactory that two-stream methods are often not learned
end-to-end jointly with the flow. In this paper, we argue that optical flow is
dispensable in high-accuracy temporal action detection and image level data
augmentation (ILDA) is the key solution to avoid performance degradation when
optical flow is removed. To evaluate the effectiveness of ILDA, we design a
simple yet efficient one-stage temporal action detector based on single RGB
stream named DaoTAD. Our results show that when trained with ILDA, DaoTAD has
comparable accuracy with all existing state-of-the-art two-stream detectors
while surpassing the inference speed of previous methods by a large margin and
the inference speed is astounding 6668 fps on GeForce GTX 1080 Ti. Code is
available at \url{https://github.com/Media-Smart/vedatad}.",1,1,0,0,1,0,0.946799,7.0,0.923831,61
5479d0ac-c5d3-4bde-ba87-7f286a396561,All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality,78,0.170307,0.668195,"Similarity measures are a vital tool for understanding how language models
represent and process language. Standard representational similarity measures
such as cosine similarity and Euclidean distance have been successfully used in
static word embedding models to understand how words cluster in semantic space.
Recently, these measures have been applied to embeddings from contextualized
models such as BERT and GPT-2. In this work, we call into question the
informativity of such measures for contextualized language models. We find that
a small number of rogue dimensions, often just 1-3, dominate these measures.
Moreover, we find a striking mismatch between the dimensions that dominate
similarity measures and those which are important to the behavior of the model.
We show that simple postprocessing techniques such as standardization are able
to correct for rogue dimensions and reveal underlying representational quality.
We argue that accounting for rogue dimensions is essential for any
similarity-based analysis of contextual language models.",1,0,0,0,0,0,0.350559,5.0,0.510081,47
3509d938-dbcc-4d55-b7cc-2d9255099b29,"Summaformers @ LaySumm 20, LongSumm 20",13,0.0501242,0.466806,"Automatic text summarization has been widely studied as an important task in
natural language processing. Traditionally, various feature engineering and
machine learning based systems have been proposed for extractive as well as
abstractive text summarization. Recently, deep learning based, specifically
Transformer-based systems have been immensely popular. Summarization is a
cognitively challenging task - extracting summary worthy sentences is
laborious, and expressing semantics in brief when doing abstractive
summarization is complicated. In this paper, we specifically look at the
problem of summarizing scientific research papers from multiple domains. We
differentiate between two types of summaries, namely, (a) LaySumm: A very short
summary that captures the essence of the research paper in layman terms
restricting overtly specific technical jargon and (b) LongSumm: A much longer
detailed summary aimed at providing specific insights into various ideas
touched upon in the paper. While leveraging latest Transformer-based models,
our systems are simple, intuitive and based on how specific paper sections
contribute to human summaries of the two types described above. Evaluations
against gold standard summaries using ROUGE metrics prove the effectiveness of
our approach. On blind test corpora, our system ranks first and third for the
LongSumm and LaySumm tasks respectively.",0,1,0,0,0,0,0.499311,6.0,0.670344,28
e78c2f12-f576-46e7-b80a-a341d2675a8a,SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction,32,0.440918,0.963388,"Stepping from sentence-level to document-level, the research on relation
extraction (RE) confronts increasing text length and more complicated entity
interactions. Consequently, it is more challenging to encode the key
information sources--relevant contexts and entity types. However, existing
methods only implicitly learn to model these critical information sources while
being trained for RE. As a result, they suffer the problems of ineffective
supervision and uninterpretable model predictions. In contrast, we propose to
explicitly teach the model to capture relevant contexts and entity types by
supervising and augmenting intermediate steps (SAIS) for RE. Based on a broad
spectrum of carefully designed tasks, our proposed SAIS method not only
extracts relations of better quality due to more effective supervision, but
also retrieves the corresponding supporting evidence more accurately so as to
enhance interpretability. By assessing model uncertainty, SAIS further boosts
the performance via evidence-based data augmentation and ensemble inference
while reducing the computational cost. Eventually, SAIS delivers
state-of-the-art RE results on three benchmarks (DocRED, CDR, and GDA) and
outperforms the runner-up by 5.04% relatively in F1 score in evidence retrieval
on DocRED.",0,1,0,0,1,0,0.923615,5.0,0.867047,54
50acd641-25cc-4550-993c-2236ccd853fc,High-Resolution Image Harmonization via Collaborative Dual Transformations,59,0.145924,0.886059,"Given a composite image, image harmonization aims to adjust the foreground to
make it compatible with the background. High-resolution image harmonization is
in high demand, but still remains unexplored. Conventional image harmonization
methods learn global RGB-to-RGB transformation which could effortlessly scale
to high resolution, but ignore diverse local context. Recent deep learning
methods learn the dense pixel-to-pixel transformation which could generate
harmonious outputs, but are highly constrained in low resolution. In this work,
we propose a high-resolution image harmonization network with Collaborative
Dual Transformation (CDTNet) to combine pixel-to-pixel transformation and
RGB-to-RGB transformation coherently in an end-to-end network. Our CDTNet
consists of a low-resolution generator for pixel-to-pixel transformation, a
color mapping module for RGB-to-RGB transformation, and a refinement module to
take advantage of both. Extensive experiments on high-resolution benchmark
dataset and our created high-resolution real composite images demonstrate that
our CDTNet strikes a good balance between efficiency and effectiveness. Our
used datasets can be found in
https://github.com/bcmi/CDTNet-High-Resolution-Image-Harmonization.",1,0,0,0,0,0,0.0522432,8.0,0.433178,46
d354b491-53cd-4f8f-89bd-6e529073ec97,AfroMT: Pretraining Strategies and Reproducible Benchmarks for Translation of 8 African Languages,25,0.0412787,0.613815,"Reproducible benchmarks are crucial in driving progress of machine
translation research. However, existing machine translation benchmarks have
been mostly limited to high-resource or well-represented languages. Despite an
increasing interest in low-resource machine translation, there are no
standardized reproducible benchmarks for many African languages, many of which
are used by millions of speakers but have less digitized textual data. To
tackle these challenges, we propose AfroMT, a standardized, clean, and
reproducible machine translation benchmark for eight widely spoken African
languages. We also develop a suite of analysis tools for system diagnosis
taking into account the unique properties of these languages. Furthermore, we
explore the newly considered case of low-resource focused pretraining and
develop two novel data augmentation-based strategies, leveraging word-level
alignment information and pseudo-monolingual data for pretraining multilingual
sequence-to-sequence models. We demonstrate significant improvements when
pretraining on 11 languages, with gains of up to 2 BLEU points over strong
baselines. We also show gains of up to 12 BLEU points over cross-lingual
transfer baselines in data-constrained scenarios. All code and pretrained
models will be released as further steps towards larger reproducible benchmarks
for African languages.",1,1,1,1,0,0,0.334124,6.0,0.581794,52
24e67616-8a52-4f99-b1f3-0bd2df7810d1,Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals,19,0.20153,0.647573,"The ability to sequence unordered events is an essential skill to comprehend
and reason about real world task procedures, which often requires thorough
understanding of temporal common sense and multimodal information, as these
procedures are often communicated through a combination of texts and images.
Such capability is essential for applications such as sequential task planning
and multi-source instruction summarization. While humans are capable of
reasoning about and sequencing unordered multimodal procedural instructions,
whether current machine learning models have such essential capability is still
an open question. In this work, we benchmark models' capability of reasoning
over and sequencing unordered multimodal instructions by curating datasets from
popular online instructional manuals and collecting comprehensive human
annotations. We find models not only perform significantly worse than humans
but also seem incapable of efficiently utilizing the multimodal information. To
improve machines' performance on multimodal event sequencing, we propose
sequentiality-aware pretraining techniques that exploit the sequential
alignment properties of both texts and images, resulting in > 5% significant
improvements.",0,0,0,1,0,0,0.700233,5.0,0.715367,56
54317ddd-f289-42b5-bb02-47ef58db9adb,Capturing Stance Dynamics in Social Media: Open Challenges and Research Directions,14,0.0794051,0.479146,"Social media platforms provide a goldmine for mining public opinion on issues
of wide societal interest and impact. Opinion mining is a problem that can be
operationalised by capturing and aggregating the stance of individual social
media posts as supporting, opposing or being neutral towards the issue at hand.
While most prior work in stance detection has investigated datasets that cover
short periods of time, interest in investigating longitudinal datasets has
recently increased. Evolving dynamics in linguistic and behavioural patterns
observed in new data require adapting stance detection systems to deal with the
changes. In this survey paper, we investigate the intersection between
computational linguistics and the temporal evolution of human communication in
digital media. We perform a critical review of emerging research considering
dynamics, exploring different semantic and pragmatic factors that impact
linguistic data in general, and stance in particular. We further discuss
current directions in capturing stance dynamics in social media. We discuss the
challenges encountered when dealing with stance dynamics, identify open
challenges and discuss future directions in three key dimensions: utterance,
context and influence.",0,0,0,0,0,0,0.0289301,9.0,0.429148,114
5b4704de-7a94-4af6-9eae-a447fa0bd9e6,Exploring Genetic-histologic Relationships in Breast Cancer,5,0.132041,0.19175,"The advent of digital pathology presents opportunities for computer vision
for fast, accurate, and objective solutions for histopathological images and
aid in knowledge discovery. This work uses deep learning to predict genomic
biomarkers - TP53 mutation, PIK3CA mutation, ER status, PR status, HER2 status,
and intrinsic subtypes, from breast cancer histopathology images. Furthermore,
we attempt to understand the underlying morphology as to how these genomic
biomarkers manifest in images. Since gene sequencing is expensive, not always
available, or even feasible, predicting these biomarkers from images would help
in diagnosis, prognosis, and effective treatment planning. We outperform the
existing works with a minimum improvement of 0.02 and a maximum of 0.13 AUROC
scores across all tasks. We also gain insights that can serve as hypotheses for
further experimentations, including the presence of lymphocytes and
karyorrhexis. Moreover, our fully automated workflow can be extended to other
tasks across other cancer subtypes.",1,1,0,0,1,0,0.934877,6.0,0.899234,21
00c69dfb-7b75-480e-bd84-fe82120e10da,Comparing Representations in Tracking for Event Camera-based SLAM,24,0.548605,0.726099,"This paper investigates two typical image-type representations for event
camera-based tracking: time surface (TS) and event map (EM). Based on the
original TS-based tracker, we make use of these two representations'
complementary strengths to develop an enhanced version. The proposed tracker
consists of a general strategy to evaluate the optimization problem's
degeneracy online and then switch proper representations. Both TS and EM are
motion- and scene-dependent, and thus it is important to figure out their
limitations in tracking. We develop six tracker variations and conduct a
thorough comparison of them on sequences covering various scenarios and motion
complexities. We release our implementations and detailed results to benefit
the research community on event cameras: https:
//github.com/gogojjh/ESVO_extension.",1,1,0,0,0,0,0.90155,8.0,0.903919,34
cddfad80-796d-4efc-bce4-54640a1cf1de,Assessing the Sufficiency of Arguments through Conclusion Generation,21,0.361144,0.935684,"The premises of an argument give evidence or other reasons to support a
conclusion. However, the amount of support required depends on the generality
of a conclusion, the nature of the individual premises, and similar. An
argument whose premises make its conclusion rationally worthy to be drawn is
called sufficient in argument quality research. Previous work tackled
sufficiency assessment as a standard text classification problem, not modeling
the inherent relation of premises and conclusion. In this paper, we hypothesize
that the conclusion of a sufficient argument can be generated from its
premises. To study this hypothesis, we explore the potential of assessing
sufficiency based on the output of large-scale pre-trained language models. Our
best model variant achieves an F1-score of .885, outperforming the previous
state-of-the-art and being on par with human experts. While manual evaluation
reveals the quality of the generated conclusions, their impact remains low
ultimately.",1,0,0,0,1,0,0.788563,5.0,0.766257,23
6ee28611-332c-4e3f-a12e-ef0ab7fa7151,GTM: A Generative Triple-Wise Model for Conversational Question Generation,12,0.153192,0.425687,"Generating some appealing questions in open-domain conversations is an
effective way to improve human-machine interactions and lead the topic to a
broader or deeper direction. To avoid dull or deviated questions, some
researchers tried to utilize answer, the ""future"" information, to guide
question generation. However, they separate a post-question-answer (PQA) triple
into two parts: post-question (PQ) and question-answer (QA) pairs, which may
hurt the overall coherence. Besides, the QA relationship is modeled as a
one-to-one mapping that is not reasonable in open-domain conversations. To
tackle these problems, we propose a generative triple-wise model with
hierarchical variations for open-domain conversational question generation
(CQG). Latent variables in three hierarchies are used to represent the shared
background of a triple and one-to-many semantic mappings in both PQ and QA
pairs. Experimental results on a large-scale CQG dataset show that our method
significantly improves the quality of questions in terms of fluency, coherence
and diversity over competitive baselines.",0,0,0,0,0,0,0.343821,9.0,0.725134,49
3c541a96-a240-4d9b-bab1-ec669cdcf452,On Explaining Your Explanations of BERT: An Empirical Study with Sequence Classification,17,0.0289878,0.200943,"BERT, as one of the pretrianed language models, attracts the most attention
in recent years for creating new benchmarks across GLUE tasks via fine-tuning.
One pressing issue is to open up the blackbox and explain the decision makings
of BERT. A number of attribution techniques have been proposed to explain BERT
models, but are often limited to sequence to sequence tasks. In this paper, we
adapt existing attribution methods on explaining decision makings of BERT in
sequence classification tasks. We conduct extensive analyses of four existing
attribution methods by applying them to four different datasets in sentiment
analysis. We compare the reliability and robustness of each method via various
ablation studies. Furthermore, we test whether attribution methods explain
generalized semantics across semantically similar tasks. Our work provides
solid guidance for using attribution methods to explain decision makings of
BERT for downstream classification tasks.",1,0,0,0,0,0,0.853486,4.0,0.760804,32
5a2632ff-6088-4ae8-ac34-d15cfbf2c077,A Novel Adaptive Minority Oversampling Technique for Improved Classification in Data Imbalanced Scenarios,3,0.0155222,0.159698,"Imbalance in the proportion of training samples belonging to different
classes often poses performance degradation of conventional classifiers. This
is primarily due to the tendency of the classifier to be biased towards the
majority classes in the imbalanced dataset. In this paper, we propose a novel
three step technique to address imbalanced data. As a first step we
significantly oversample the minority class distribution by employing the
traditional Synthetic Minority OverSampling Technique (SMOTE) algorithm using
the neighborhood of the minority class samples and in the next step we
partition the generated samples using a Gaussian-Mixture Model based clustering
algorithm. In the final step synthetic data samples are chosen based on the
weight associated with the cluster, the weight itself being determined by the
distribution of the majority class samples. Extensive experiments on several
standard datasets from diverse domains shows the usefulness of the proposed
technique in comparison with the original SMOTE and its state-of-the-art
variants algorithms.",0,1,0,0,1,0,0.0157605,17.0,0.661661,46
059e858d-64f9-42c3-b8ce-0e5b9181585c,Transformer-Based Attention Networks for Continuous Pixel-Wise Prediction,134,0.905592,0.995632,"While convolutional neural networks have shown a tremendous impact on various
computer vision tasks, they generally demonstrate limitations in explicitly
modeling long-range dependencies due to the intrinsic locality of the
convolution operation. Initially designed for natural language processing
tasks, Transformers have emerged as alternative architectures with innate
global self-attention mechanisms to capture long-range dependencies. In this
paper, we propose TransDepth, an architecture that benefits from both
convolutional neural networks and transformers. To avoid the network losing its
ability to capture local-level details due to the adoption of transformers, we
propose a novel decoder that employs attention mechanisms based on gates.
Notably, this is the first paper that applies transformers to pixel-wise
prediction problems involving continuous labels (i.e., monocular depth
prediction and surface normal estimation). Extensive experiments demonstrate
that the proposed TransDepth achieves state-of-the-art performance on three
challenging datasets. Our code is available at:
https://github.com/ygjwd12345/TransDepth.",1,1,1,0,1,0,0.918818,5.0,0.862253,73
26de4c49-446b-4df3-aaab-e4e81ed470cd,"QuALITY: Question Answering with Long Input Texts, Yes!",86,0.600643,0.999908,"To enable building and testing models on long-document comprehension, we
introduce QuALITY, a multiple-choice QA dataset with context passages in
English that have an average length of about 5,000 tokens, much longer than
typical current models can process. Unlike in prior work with passages, our
questions are written and validated by contributors who have read the entire
passage, rather than relying on summaries or excerpts. In addition, only half
of the questions are answerable by annotators working under tight time
constraints, indicating that skimming and simple search are not enough to
consistently perform well. Our baseline models perform poorly on this task
(55.4%) and significantly lag behind human performance (93.5%).",1,1,1,1,0,0,0.90565,5.0,0.849908,44
43304ffd-cb35-444d-979e-4a115b1aa86a,TeCoMiner: Topic Discovery Through Term Community Detection,3,0.00401299,0.0590467,"This note is a short description of TeCoMiner, an interactive tool for
exploring the topic content of text collections. Unlike other topic modeling
tools, TeCoMiner is not based on some generative probabilistic model but on
topological considerations about co-occurrence networks of terms. We outline
the methods used for identifying topics, describe the features of the tool, and
sketch an application, using a corpus of policy related scientific news on
environmental issues published by the European Commission over the last decade.",0,0,0,0,0,0,0.0551638,10.0,0.552135,22
394e743f-38d8-4a9e-af9f-227cc5e927bc,"Document AI: Benchmarks, Models and Applications",47,0.738931,0.979438,"Document AI, or Document Intelligence, is a relatively new research topic
that refers to the techniques for automatically reading, understanding, and
analyzing business documents. It is an important research direction for natural
language processing and computer vision. In recent years, the popularity of
deep learning technology has greatly advanced the development of Document AI,
such as document layout analysis, visual information extraction, document
visual question answering, document image classification, etc. This paper
briefly reviews some of the representative models, tasks, and benchmark
datasets. Furthermore, we also introduce early-stage heuristic rule-based
document analysis, statistical machine learning algorithms, and deep learning
approaches especially pre-training methods. Finally, we look into future
directions for Document AI research.",0,1,0,0,0,0,0.815041,6.0,0.81898,117
e10d892f-96ce-4935-acbb-5510001addd7,Fine-grained Anomaly Detection via Multi-task Self-Supervision,6,0.0221638,0.140117,"Detecting anomalies using deep learning has become a major challenge over the
last years, and is becoming increasingly promising in several fields. The
introduction of self-supervised learning has greatly helped many methods
including anomaly detection where simple geometric transformation recognition
tasks are used. However these methods do not perform well on fine-grained
problems since they lack finer features. By combining in a multi-task framework
high-scale shape features oriented task with low-scale fine features oriented
task, our method greatly improves fine-grained anomaly detection. It
outperforms state-of-the-art with up to 31% relative error reduction measured
with AUROC on various anomaly detection problems.",0,1,0,0,1,0,0.683769,7.0,0.790205,43
ce1db0c4-d26b-4cf6-b8c0-bd1ac5904fb7,ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining,49,0.476779,0.776508,"While online conversations can cover a vast amount of information in many
different formats, abstractive text summarization has primarily focused on
modeling solely news articles. This research gap is due, in part, to the lack
of standardized datasets for summarizing online discussions. To address this
gap, we design annotation protocols motivated by an
issues--viewpoints--assertions framework to crowdsource four new datasets on
diverse online conversation forms of news comments, discussion forums,
community question answering forums, and email threads. We benchmark
state-of-the-art models on our datasets and analyze characteristics associated
with the data. To create a comprehensive benchmark, we also evaluate these
models on widely-used conversation summarization datasets to establish strong
baselines in this domain. Furthermore, we incorporate argument mining through
graph construction to directly model the issues, viewpoints, and assertions
present in a conversation and filter noisy input, showing comparable or
improved results according to automatic and human evaluations.",1,1,1,1,1,0,0.574229,6.0,0.705428,79
ada7a582-845c-4804-be22-43572642dcde,A Systematic Investigation of Commonsense Knowledge in Large Language Models,39,0.452306,0.918191,"Language models (LMs) trained on large amounts of data have shown impressive
performance on many NLP tasks under the zero-shot and few-shot setup. Here we
aim to better understand the extent to which such models learn commonsense
knowledge -- a critical component of many NLP applications. We conduct a
systematic and rigorous zero-shot and few-shot commonsense evaluation of large
pre-trained LMs, where we: (i) carefully control for the LMs' ability to
exploit potential surface cues and annotation artefacts, and (ii) account for
variations in performance that arise from factors that are not related to
commonsense knowledge. Our findings highlight the limitations of pre-trained
LMs in acquiring commonsense knowledge without task-specific supervision;
furthermore, using larger models or few-shot evaluation are insufficient to
achieve human-level commonsense performance.",0,0,0,0,0,1,0.946496,5.0,0.892976,66
bbb3e6b5-5fc0-4be5-84ed-c486bcf1cce2,Magic dust for cross-lingual adaptation of monolingual wav2vec-2.0,18,0.214967,0.584443,"We propose a simple and effective cross-lingual transfer learning method to
adapt monolingual wav2vec-2.0 models for Automatic Speech Recognition (ASR) in
resource-scarce languages. We show that a monolingual wav2vec-2.0 is a good
few-shot ASR learner in several languages. We improve its performance further
via several iterations of Dropout Uncertainty-Driven Self-Training (DUST) by
using a moderate-sized unlabeled speech dataset in the target language. A key
finding of this work is that the adapted monolingual wav2vec-2.0 achieves
similar performance as the topline multilingual XLSR model, which is trained on
fifty-three languages, on the target language ASR task.",0,1,0,0,0,0,0.882978,5.0,0.830777,27
bf90b351-09b1-47ac-87ba-4f7dfac2b91d,Intelligent Railway Foreign Object Detection: A Semi-supervised Convolutional Autoencoder Based Method,10,0.632157,0.76792,"Automated inspection and detection of foreign objects on railways is
important for rail transportation safety as it helps prevent potential
accidents and trains derailment. Most existing vision-based approaches focus on
the detection of frontal intrusion objects with prior labels, such as
categories and locations of the objects. In reality, foreign objects with
unknown categories can appear anytime on railway tracks. In this paper, we
develop a semi-supervised convolutional autoencoder based framework that only
requires railway track images without prior knowledge on the foreign objects in
the training process. It consists of three different modules, a bottleneck
feature generator as encoder, a photographic image generator as decoder, and a
reconstruction discriminator developed via adversarial learning. In the
proposed framework, the problem of detecting the presence, location, and shape
of foreign objects is addressed by comparing the input and reconstructed images
as well as setting thresholds based on reconstruction errors. The proposed
method is evaluated through comprehensive studies under different performance
criteria. The results show that the proposed method outperforms some well-known
benchmarking methods. The proposed framework is useful for data analytics via
the train Internet-of-Things (IoT) systems",0,1,0,0,1,0,0.971735,9.0,0.96245,26
732b3406-64a6-4584-a424-826e0a6010ed,KECRS: Towards Knowledge-Enriched Conversational Recommendation System,22,0.331794,0.678903,"The chit-chat-based conversational recommendation systems (CRS) provide item
recommendations to users through natural language interactions. To better
understand user's intentions, external knowledge graphs (KG) have been
introduced into chit-chat-based CRS. However, existing chit-chat-based CRS
usually generate repetitive item recommendations, and they cannot properly
infuse knowledge from KG into CRS to generate informative responses. To remedy
these issues, we first reformulate the conversational recommendation task to
highlight that the recommended items should be new and possibly interested by
users. Then, we propose the Knowledge-Enriched Conversational Recommendation
System (KECRS). Specifically, we develop the Bag-of-Entity (BOE) loss and the
infusion loss to better integrate KG with CRS for generating more diverse and
informative responses. BOE loss provides an additional supervision signal to
guide CRS to learn from both human-written utterances and KG. Infusion loss
bridges the gap between the word embeddings and entity embeddings by minimizing
distances of the same words in these two embeddings. Moreover, we facilitate
our study by constructing a high-quality KG, \ie The Movie Domain Knowledge
Graph (TMDKG). Experimental results on a large-scale dataset demonstrate that
KECRS outperforms state-of-the-art chit-chat-based CRS, in terms of both
recommendation accuracy and response generation quality.",0,0,0,1,1,0,0.93716,6.0,0.901398,40
783cbc13-9cda-4869-8c08-4a1c5ca6848f,CRSLab: An Open-Source Toolkit for Building Conversational Recommender System,51,0.443416,0.788763,"In recent years, conversational recommender system (CRS) has received much
attention in the research community. However, existing studies on CRS vary in
scenarios, goals and techniques, lacking unified, standardized implementation
or comparison. To tackle this challenge, we propose an open-source CRS toolkit
CRSLab, which provides a unified and extensible framework with highly-decoupled
modules to develop CRSs. Based on this framework, we collect 6 commonly-used
human-annotated CRS datasets and implement 18 models that include recent
techniques such as graph neural network and pre-training models. Besides, our
toolkit provides a series of automatic evaluation protocols and a human-machine
interaction interface to test and compare different CRS methods. The project
and documents are released at https://github.com/RUCAIBox/CRSLab.",1,1,0,1,0,0,0.94188,5.0,0.887242,34
16c1b3ac-8f30-4206-8932-39248ba80108,NEAT: Neural Attention Fields for End-to-End Autonomous Driving,158,0.553803,0.982677,"Efficient reasoning about the semantic, spatial, and temporal structure of a
scene is a crucial prerequisite for autonomous driving. We present NEural
ATtention fields (NEAT), a novel representation that enables such reasoning for
end-to-end imitation learning models. NEAT is a continuous function which maps
locations in Bird's Eye View (BEV) scene coordinates to waypoints and
semantics, using intermediate attention maps to iteratively compress
high-dimensional 2D image features into a compact representation. This allows
our model to selectively attend to relevant regions in the input while ignoring
information irrelevant to the driving task, effectively associating the images
with the BEV representation. In a new evaluation setting involving adverse
environmental conditions and challenging scenarios, NEAT outperforms several
strong baselines and achieves driving scores on par with the privileged CARLA
expert used to generate its training data. Furthermore, visualizing the
attention maps for models with NEAT intermediate representations provides
improved interpretability.",1,1,0,0,0,0,0.710351,4.0,0.651234,81
f17f5c8b-99c4-47fd-bf46-1c2f71cb9333,Macro-Average: Rare Types Are Important Too,20,0.0331615,0.465189,"While traditional corpus-level evaluation metrics for machine translation
(MT) correlate well with fluency, they struggle to reflect adequacy.
Model-based MT metrics trained on segment-level human judgments have emerged as
an attractive replacement due to strong correlation results. These models,
however, require potentially expensive re-training for new domains and
languages. Furthermore, their decisions are inherently non-transparent and
appear to reflect unwelcome biases. We explore the simple type-based classifier
metric, MacroF1, and study its applicability to MT evaluation. We find that
MacroF1 is competitive on direct assessment, and outperforms others in
indicating downstream cross-lingual information retrieval task performance.
Further, we show that MacroF1 can be used to effectively compare supervised and
unsupervised neural machine translation, and reveal significant qualitative
differences in the methods' outputs.",1,1,0,0,0,0,0.114442,8.0,0.535378,52
cf79d17d-098c-4775-94fa-202c0f0a0083,"MMOCR: A Comprehensive Toolbox for Text Detection, Recognition and Understanding",51,0.182101,0.866766,"We present MMOCR-an open-source toolbox which provides a comprehensive
pipeline for text detection and recognition, as well as their downstream tasks
such as named entity recognition and key information extraction. MMOCR
implements 14 state-of-the-art algorithms, which is significantly more than all
the existing open-source OCR projects we are aware of to date. To facilitate
future research and industrial applications of text recognition-related
problems, we also provide a large number of trained models and detailed
benchmarks to give insights into the performance of text detection, recognition
and understanding. MMOCR is publicly released at
https://github.com/open-mmlab/mmocr.",1,1,0,0,0,0,0.360179,7.0,0.654913,47
23aed1b5-03a4-44b1-a8a2-afcfcd0f9029,Class-Balanced Distillation for Long-Tailed Visual Recognition,26,0.287082,0.552271,"Real-world imagery is often characterized by a significant imbalance of the
number of images per class, leading to long-tailed distributions. An effective
and simple approach to long-tailed visual recognition is to learn feature
representations and a classifier separately, with instance and class-balanced
sampling, respectively. In this work, we introduce a new framework, by making
the key observation that a feature representation learned with instance
sampling is far from optimal in a long-tailed setting. Our main contribution is
a new training method, referred to as Class-Balanced Distillation (CBD), that
leverages knowledge distillation to enhance feature representations. CBD allows
the feature representation to evolve in the second training stage, guided by
the teacher learned in the first stage. The second stage uses class-balanced
sampling, in order to focus on under-represented classes. This framework can
naturally accommodate the usage of multiple teachers, unlocking the information
from an ensemble of models to enhance recognition capabilities. Our experiments
show that the proposed technique consistently outperforms the state of the art
on long-tailed recognition benchmarks such as ImageNet-LT, iNaturalist17 and
iNaturalist18.",1,1,0,0,1,0,0.947932,5.0,0.894826,67
2bf4dcab-2063-46a5-8634-0b8aed65dd47,OmniLayout: Room Layout Reconstruction from Indoor Spherical Panoramas,8,0.188315,0.503143,"Given a single RGB panorama, the goal of 3D layout reconstruction is to
estimate the room layout by predicting the corners, floor boundary, and ceiling
boundary. A common approach has been to use standard convolutional networks to
predict the corners and boundaries, followed by post-processing to generate the
3D layout. However, the space-varying distortions in panoramic images are not
compatible with the translational equivariance property of standard
convolutions, thus degrading performance. Instead, we propose to use spherical
convolutions. The resulting network, which we call OmniLayout performs
convolutions directly on the sphere surface, sampling according to inverse
equirectangular projection and hence invariant to equirectangular distortions.
Using a new evaluation metric, we show that our network reduces the error in
the heavily distorted regions (near the poles) by approx 25 % when compared to
standard convolutional networks. Experimental results show that OmniLayout
outperforms the state-of-the-art by approx 4% on two different benchmark
datasets (PanoContext and Stanford 2D-3D). Code is available at
https://github.com/rshivansh/OmniLayout.",1,1,0,0,1,0,0.7419,10.0,0.869393,32
76fde558-d7f9-48ed-8817-ec1f33cbdebd,Spatial-Temporal Transformer for Dynamic Scene Graph Generation,90,0.774247,0.991502,"Dynamic scene graph generation aims at generating a scene graph of the given
video. Compared to the task of scene graph generation from images, it is more
challenging because of the dynamic relationships between objects and the
temporal dependencies between frames allowing for a richer semantic
interpretation. In this paper, we propose Spatial-temporal Transformer
(STTran), a neural network that consists of two core modules: (1) a spatial
encoder that takes an input frame to extract spatial context and reason about
the visual relationships within a frame, and (2) a temporal decoder which takes
the output of the spatial encoder as input in order to capture the temporal
dependencies between frames and infer the dynamic relationships. Furthermore,
STTran is flexible to take varying lengths of videos as input without clipping,
which is especially important for long videos. Our method is validated on the
benchmark dataset Action Genome (AG). The experimental results demonstrate the
superior performance of our method in terms of dynamic scene graphs. Moreover,
a set of ablative studies is conducted and the effect of each proposed module
is justified. Code available at: https://github.com/yrcong/STTran.",1,1,0,0,1,0,0.903526,8.0,0.905008,66
fcf5cc01-ade3-4804-a56d-86234e262bc1,Detecting Textual Adversarial Examples through Randomized Substitution and Vote,8,0.13781,0.455997,"A line of work has shown that natural text processing models are vulnerable
to adversarial examples. Correspondingly, various defense methods are proposed
to mitigate the threat of textual adversarial examples, eg, adversarial
training, input transformations, detection, etc. In this work, we treat the
optimization process for synonym substitution based textual adversarial attacks
as a specific sequence of word replacement, in which each word mutually
influences other words. We identify that we could destroy such mutual
interaction and eliminate the adversarial perturbation by randomly substituting
a word with its synonyms. Based on this observation, we propose a novel textual
adversarial example detection method, termed Randomized Substitution and Vote
(RS&V), which votes the prediction label by accumulating the logits of k
samples generated by randomly substituting the words in the input text with
synonyms. The proposed RS&V is generally applicable to any existing neural
networks without modification on the architecture or extra training, and it is
orthogonal to prior work on making the classification network itself more
robust. Empirical evaluations on three benchmark datasets demonstrate that our
RS&V could detect the textual adversarial examples more successfully than the
existing detection methods while maintaining the high classification accuracy
on benign samples.",1,1,0,0,0,0,0.934381,5.0,0.878525,44
13f5dc45-5c14-4d1f-8b75-48b26cb43e57,Does referent predictability affect the choice of referential form? A computational approach using masked coreference resolution,2,0.0432354,0.0228742,"It is often posited that more predictable parts of a speaker's meaning tend
to be made less explicit, for instance using shorter, less informative words.
Studying these dynamics in the domain of referring expressions has proven
difficult, with existing studies, both psycholinguistic and corpus-based,
providing contradictory results. We test the hypothesis that speakers produce
less informative referring expressions (e.g., pronouns vs. full noun phrases)
when the context is more informative about the referent, using novel
computational estimates of referent predictability. We obtain these estimates
training an existing coreference resolution system for English on a new task,
masked coreference resolution, giving us a probability distribution over
referents that is conditioned on the context but not the referring expression.
The resulting system retains standard coreference resolution performance while
yielding a better estimate of human-derived referent predictability than
previous attempts. A statistical analysis of the relationship between model
output and mention form supports the hypothesis that predictability affects the
form of a mention, both its morphosyntactic type and its length.",1,0,0,0,0,0,0.141316,15.0,0.767268,40
3fcda4e3-eaea-489f-b3f9-9bc067a35eef,SELM: Software Engineering of Machine Learning Models,1,0.00192083,0.0487682,"One of the pillars of any machine learning model is its concepts. Using
software engineering, we can engineer these concepts and then develop and
expand them. In this article, we present a SELM framework for Software
Engineering of machine Learning Models. We then evaluate this framework through
a case study. Using the SELM framework, we can improve a machine learning
process efficiency and provide more accuracy in learning with less processing
hardware resources and a smaller training dataset. This issue highlights the
importance of an interdisciplinary approach to machine learning. Therefore, in
this article, we have provided interdisciplinary teams' proposals for machine
learning.",0,0,0,0,0,0,0.000329396,17.0,0.433675,22
38bce746-22ce-443f-86e5-779e3d8f803d,On tuning consistent annealed sampling for denoising score matching,4,0.0290626,0.219597,"Score-based generative models provide state-of-the-art quality for image and
audio synthesis. Sampling from these models is performed iteratively, typically
employing a discretized series of noise levels and a predefined scheme. In this
note, we first overview three common sampling schemes for models trained with
denoising score matching. Next, we focus on one of them, consistent annealed
sampling, and study its hyper-parameter boundaries. We then highlight a
possible formulation of such hyper-parameter that explicitly considers those
boundaries and facilitates tuning when using few or a variable number of steps.
Finally, we highlight some connections of the formulation with other sampling
schemes.",0,0,0,0,0,0,0.977962,2.0,0.86475,11
db1dbaaf-abcb-4786-8d61-ad784efaefb7,HandTailor: Towards High-Precision Monocular 3D Hand Recovery,23,0.542904,0.540658,"3D hand pose estimation and shape recovery are challenging tasks in computer
vision. We introduce a novel framework HandTailor, which combines a
learning-based hand module and an optimization-based tailor module to achieve
high-precision hand mesh recovery from a monocular RGB image. The proposed hand
module unifies perspective projection and weak perspective projection in a
single network towards accuracy-oriented and in-the-wild scenarios. The
proposed tailor module then utilizes the coarsely reconstructed mesh model
provided by the hand module as initialization, and iteratively optimizes an
energy function to obtain better results. The tailor module is time-efficient,
costs only 8ms per frame on a modern CPU. We demonstrate that HandTailor can
get state-of-the-art performance on several public benchmarks, with impressive
qualitative results on in-the-wild experiments. Code and video are available on
our project webpage https://sites.google.com/view/handtailor.",1,1,0,0,1,0,0.967952,5.0,0.925238,46
61897e2c-13e8-401f-bea1-71f236f0499f,Attention Can Reflect Syntactic Structure (If You Let It),29,0.51536,0.714292,"Since the popularization of the Transformer as a general-purpose feature
encoder for NLP, many studies have attempted to decode linguistic structure
from its novel multi-head attention mechanism. However, much of such work
focused almost exclusively on English -- a language with rigid word order and a
lack of inflectional morphology. In this study, we present decoding experiments
for multilingual BERT across 18 languages in order to test the generalizability
of the claim that dependency syntax is reflected in attention patterns. We show
that full trees can be decoded above baseline accuracy from single attention
heads, and that individual relations are often tracked by the same heads across
languages. Furthermore, in an attempt to address recent debates about the
status of attention as an explanatory mechanism, we experiment with fine-tuning
mBERT on a supervised parsing objective while freezing different series of
parameters. Interestingly, in steering the objective to learn explicit
linguistic structure, we find much of the same structure represented in the
resulting attention patterns, with interesting differences with respect to
which parameters are frozen.",0,0,0,0,0,0,0.975624,4.0,0.925678,39
ae084368-c944-4c64-a08a-97bd4650191f,E2ETag: An End-to-End Trainable Method for Generating and Detecting Fiducial Markers,10,0.222807,0.543455,"Existing fiducial markers solutions are designed for efficient detection and
decoding, however, their ability to stand out in natural environments is
difficult to infer from relatively limited analysis. Furthermore, worsening
performance in challenging image capture scenarios - such as poor exposure,
motion blur, and off-axis viewing - sheds light on their limitations. E2ETag
introduces an end-to-end trainable method for designing fiducial markers and a
complimentary detector. By introducing back-propagatable marker augmentation
and superimposition into training, the method learns to generate markers that
can be detected and classified in challenging real-world environments using a
fully convolutional detector network. Results demonstrate that E2ETag
outperforms existing methods in ideal conditions and performs much better in
the presence of motion blur, contrast fluctuations, noise, and off-axis viewing
angles. Source code and trained models are available at
https://github.com/jbpeace/E2ETag.",1,1,0,0,1,0,0.688962,21.0,0.930749,20
6376a83d-28a7-4cac-a628-27871213e387,Image Inpainting with External-internal Learning and Monochromic Bottleneck,47,0.289418,0.735805,"Although recent inpainting approaches have demonstrated significant
improvements with deep neural networks, they still suffer from artifacts such
as blunt structures and abrupt colors when filling in the missing regions. To
address these issues, we propose an external-internal inpainting scheme with a
monochromic bottleneck that helps image inpainting models remove these
artifacts. In the external learning stage, we reconstruct missing structures
and details in the monochromic space to reduce the learning dimension. In the
internal learning stage, we propose a novel internal color propagation method
with progressive learning strategies for consistent color restoration.
Extensive experiments demonstrate that our proposed scheme helps image
inpainting models produce more structure-preserved and visually compelling
results.",1,0,0,0,0,0,0.843333,9.0,0.889745,44
cfb7da78-e90f-4e75-9145-a5889e5d9f97,NeRP: Neural Rearrangement Planning for Unknown Objects,53,0.389397,0.832171,"Robots will be expected to manipulate a wide variety of objects in complex
and arbitrary ways as they become more widely used in human environments. As
such, the rearrangement of objects has been noted to be an important benchmark
for AI capabilities in recent years. We propose NeRP (Neural Rearrangement
Planning), a deep learning based approach for multi-step neural object
rearrangement planning which works with never-before-seen objects, that is
trained on simulation data, and generalizes to the real world. We compare NeRP
to several naive and model-based baselines, demonstrating that our approach is
measurably better and can efficiently arrange unseen objects in fewer steps and
with less planning time. Finally, we demonstrate it on several challenging
rearrangement problems in the real world.",0,1,0,0,0,0,0.773973,4.0,0.696848,38
44a4b01a-227e-4c3a-9270-da2b5edaa92a,Segmentation in Style: Unsupervised Semantic Image Segmentation with Stylegan and CLIP,27,0.0596866,0.28232,"We introduce a method that allows to automatically segment images into
semantically meaningful regions without human supervision. Derived regions are
consistent across different images and coincide with human-defined semantic
classes on some datasets. In cases where semantic regions might be hard for
human to define and consistently label, our method is still able to find
meaningful and consistent semantic classes. In our work, we use pretrained
StyleGAN2 generative model: clustering in the feature space of the generative
model allows to discover semantic classes. Once classes are discovered, a
synthetic dataset with generated images and corresponding segmentation masks
can be created. After that a segmentation model is trained on the synthetic
dataset and is able to generalize to real images. Additionally, by using CLIP
we are able to use prompts defined in a natural language to discover some
desired semantic classes. We test our method on publicly available datasets and
show state-of-the-art results.",0,1,0,1,1,0,0.726432,8.0,0.83125,26
90406f3b-facb-4eeb-8df9-8d1f322dfad1,"DAC: Deep Autoencoder-based Clustering, a General Deep Learning Framework of Representation Learning",6,0.00687417,0.0494819,"Clustering performs an essential role in many real world applications, such
as market research, pattern recognition, data analysis, and image processing.
However, due to the high dimensionality of the input feature values, the data
being fed to clustering algorithms usually contains noise and thus could lead
to in-accurate clustering results. While traditional dimension reduction and
feature selection algorithms could be used to address this problem, the simple
heuristic rules used in those algorithms are based on some particular
assumptions. When those assumptions does not hold, these algorithms then might
not work. In this paper, we propose DAC, Deep Autoencoder-based Clustering, a
generalized data-driven framework to learn clustering representations using
deep neuron networks. Experiment results show that our approach could
effectively boost performance of the K-Means clustering algorithm on a variety
types of datasets.",0,1,0,0,0,1,0.00591555,17.0,0.603727,16
4b458ca6-1607-4cb0-b3d3-07eb758cad76,Emergent Unfairness in Algorithmic Fairness-Accuracy Trade-Off Research,43,0.159267,0.812382,"Across machine learning (ML) sub-disciplines, researchers make explicit
mathematical assumptions in order to facilitate proof-writing. We note that,
specifically in the area of fairness-accuracy trade-off optimization
scholarship, similar attention is not paid to the normative assumptions that
ground this approach. Such assumptions presume that 1) accuracy and fairness
are in inherent opposition to one another, 2) strict notions of mathematical
equality can adequately model fairness, 3) it is possible to measure the
accuracy and fairness of decisions independent from historical context, and 4)
collecting more data on marginalized individuals is a reasonable solution to
mitigate the effects of the trade-off. We argue that such assumptions, which
are often left implicit and unexamined, lead to inconsistent conclusions: While
the intended goal of this work may be to improve the fairness of machine
learning models, these unexamined, implicit assumptions can in fact result in
emergent unfairness. We conclude by suggesting a concrete path forward toward a
potential resolution.",0,0,0,0,0,0,0.195303,9.0,0.65156,77
a0c3cd8e-cf84-4852-893f-a799aa55b962,Weak-shot Semantic Segmentation by Transferring Semantic Affinity and Boundary,8,0.126804,0.174162,"Weakly-supervised semantic segmentation (WSSS) with image-level labels has
been widely studied to relieve the annotation burden of the traditional
segmentation task. In this paper, we show that existing fully-annotated base
categories can help segment objects of novel categories with only image-level
labels, even if base categories and novel categories have no overlap. We refer
to this task as weak-shot semantic segmentation, which could also be treated as
WSSS with auxiliary fully-annotated categories. Recent advanced WSSS methods
usually obtain class activation maps (CAMs) and refine them by affinity
propagation. Based on the observation that semantic affinity and boundary are
class-agnostic, we propose a method under the WSSS framework to transfer
semantic affinity and boundary from base to novel categories. As a result, we
find that pixel-level annotation of base categories can facilitate affinity
learning and propagation, leading to higher-quality CAMs of novel categories.
Extensive experiments on PASCAL VOC 2012 dataset prove that our method
significantly outperforms WSSS baselines on novel categories.",0,0,0,0,0,0,0.830687,7.0,0.852133,63
b01a461e-fb5b-4609-b30e-ae21cc833366,Probabilistic Verification of Neural Networks Against Group Fairness,18,0.326458,0.311151,"Fairness is crucial for neural networks which are used in applications with
important societal implication. Recently, there have been multiple attempts on
improving fairness of neural networks, with a focus on fairness testing (e.g.,
generating individual discriminatory instances) and fairness training (e.g.,
enhancing fairness through augmented training). In this work, we propose an
approach to formally verify neural networks against fairness, with a focus on
independence-based fairness such as group fairness. Our method is built upon an
approach for learning Markov Chains from a user-provided neural network (i.e.,
a feed-forward neural network or a recurrent neural network) which is
guaranteed to facilitate sound analysis. The learned Markov Chain not only
allows us to verify (with Probably Approximate Correctness guarantee) whether
the neural network is fair or not, but also facilities sensitivity analysis
which helps to understand why fairness is violated. We demonstrate that with
our analysis results, the neural weights can be optimized to improve fairness.
Our approach has been evaluated with multiple models trained on benchmark
datasets and the experiment results show that our approach is effective and
efficient.",0,0,0,0,0,0,0.73609,8.0,0.834669,58
8fde0884-4605-4273-8ece-d913c3976841,Quantum adaptive agents with efficient long-term memories,16,0.115798,0.448126,"Central to the success of adaptive systems is their ability to interpret
signals from their environment and respond accordingly -- they act as agents
interacting with their surroundings. Such agents typically perform better when
able to execute increasingly complex strategies. This comes with a cost: the
more information the agent must recall from its past experiences, the more
memory it will need. Here we investigate the power of agents capable of quantum
information processing. We uncover the most general form a quantum agent need
adopt to maximise memory compression advantages, and provide a systematic means
of encoding their memory states. We show these encodings can exhibit extremely
favourable scaling advantages relative to memory-minimal classical agents,
particularly when information must be retained about events increasingly far
into the past.",0,0,0,0,0,0,0.00984049,14.0,0.555304,74
eb1e00a4-fda9-4bb7-92c2-cb604edf2f5a,Connect-the-Dots: Bridging Semantics between Words and Definitions via Aligning Word Sense Inventories,6,0.0546891,0.63229,"Word Sense Disambiguation (WSD) aims to automatically identify the exact
meaning of one word according to its context. Existing supervised models
struggle to make correct predictions on rare word senses due to limited
training data and can only select the best definition sentence from one
predefined word sense inventory (e.g., WordNet). To address the data sparsity
problem and generalize the model to be independent of one predefined inventory,
we propose a gloss alignment algorithm that can align definition sentences
(glosses) with the same meaning from different sense inventories to collect
rich lexical knowledge. We then train a model to identify semantic equivalence
between a target word in context and one of its glosses using these aligned
inventories, which exhibits strong transfer capability to many WSD tasks.
Experiments on benchmark datasets show that the proposed method improves
predictions on both frequent and rare word senses, outperforming prior work by
1.2% on the All-Words WSD Task and 4.3% on the Low-Shot WSD Task. Evaluation on
WiC Task also indicates that our method can better capture word meanings in
context.",1,1,0,0,1,0,0.700542,7.0,0.796813,43
2bb7c343-a7cb-466c-8874-26d755a55d24,Continual Speaker Adaptation for Text-to-Speech Synthesis,8,0.104207,0.458014,"Training a multi-speaker Text-to-Speech (TTS) model from scratch is
computationally expensive and adding new speakers to the dataset requires the
model to be re-trained. The naive solution of sequential fine-tuning of a model
for new speakers can lead to poor performance of older speakers. This
phenomenon is known as catastrophic forgetting. In this paper, we look at TTS
modeling from a continual learning perspective, where the goal is to add new
speakers without forgetting previous speakers. Therefore, we first propose an
experimental setup and show that serial fine-tuning for new speakers can cause
the forgetting of the earlier speakers. Then we exploit two well-known
techniques for continual learning, namely experience replay and weight
regularization. We reveal how one can mitigate the effect of degradation in
speech synthesis diversity in sequential training of new speakers using these
methods. Finally, we present a simple extension to experience replay to improve
the results in extreme setups where we have access to very small buffers.",1,1,0,0,0,0,0.891798,6.0,0.86496,20
64945619-b12b-4652-b15c-1f1f269362eb,Self-supervised Incremental Deep Graph Learning for Ethereum Phishing Scam Detection,18,0.754846,0.699811,"In recent years, phishing scams have become the crime type with the largest
money involved on Ethereum, the second-largest blockchain platform. Meanwhile,
graph neural network (GNN) has shown promising performance in various node
classification tasks. However, for Ethereum transaction data, which could be
naturally abstracted to a real-world complex graph, the scarcity of labels and
the huge volume of transaction data make it difficult to take advantage of GNN
methods. Here in this paper, to address the two challenges, we propose a
Self-supervised Incremental deep Graph learning model (SIEGE), for the phishing
scam detection problem on Ethereum. In our model, two pretext tasks designed
from spatial and temporal perspectives help us effectively learn useful node
embedding from the huge amount of unlabelled transaction data. And the
incremental paradigm allows us to efficiently handle large-scale transaction
data and help the model maintain good performance when the data distribution is
drastically changing. We collect transaction records about half a year from
Ethereum and our extensive experiments show that our model consistently
outperforms strong baselines in both transductive and inductive settings.",0,1,0,0,0,0,0.99065,5.0,0.986448,42
d0f3551a-129c-4ef5-86db-ba805ae939e5,Extending Challenge Sets to Uncover Gender Bias in Machine Translation: Impact of Stereotypical Verbs and Adjectives,11,0.0183772,0.333416,"Human gender bias is reflected in language and text production. Because
state-of-the-art machine translation (MT) systems are trained on large corpora
of text, mostly generated by humans, gender bias can also be found in MT. For
instance when occupations are translated from a language like English, which
mostly uses gender neutral words, to a language like German, which mostly uses
a feminine and a masculine version for an occupation, a decision must be made
by the MT System. Recent research showed that MT systems are biased towards
stereotypical translation of occupations. In 2019 the first, and so far only,
challenge set, explicitly designed to measure the extent of gender bias in MT
systems has been published. In this set measurement of gender bias is solely
based on the translation of occupations. In this paper we present an extension
of this challenge set, called WiBeMT, with gender-biased adjectives and adds
sentences with gender-biased verbs. The resulting challenge set consists of
over 70, 000 sentences and has been translated with three commercial MT
systems: DeepL Translator, Microsoft Translator, and Google Translate. Results
show a gender bias for all three MT systems. This gender bias is to a great
extent significantly influenced by adjectives and to a lesser extent by verbs.",0,1,0,1,0,0,0.239003,7.0,0.584677,14
7acfbce7-45c6-4609-a438-80d4304813e3,Gaussian Kernel Mixture Network for Single Image Defocus Deblurring,25,0.194763,0.603198,"Defocus blur is one kind of blur effects often seen in images, which is
challenging to remove due to its spatially variant amount. This paper presents
an end-to-end deep learning approach for removing defocus blur from a single
image, so as to have an all-in-focus image for consequent vision tasks. First,
a pixel-wise Gaussian kernel mixture (GKM) model is proposed for representing
spatially variant defocus blur kernels in an efficient linear parametric form,
with higher accuracy than existing models. Then, a deep neural network called
GKMNet is developed by unrolling a fixed-point iteration of the GKM-based
deblurring. The GKMNet is built on a lightweight scale-recurrent architecture,
with a scale-recurrent attention module for estimating the mixing coefficients
in GKM for defocus deblurring. Extensive experiments show that the GKMNet not
only noticeably outperforms existing defocus deblurring methods, but also has
its advantages in terms of model complexity and computational efficiency.",1,1,0,0,1,0,0.332485,8.0,0.685587,49
0fea6a63-1a15-4a62-b319-a4d6854d6af1,Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers,11,0.152714,0.234255,"This paper introduces Timers and Such, a new open source dataset of spoken
English commands for common voice control use cases involving numbers. We
describe the gap in existing spoken language understanding datasets that Timers
and Such fills, the design and creation of the dataset, and experiments with a
number of ASR-based and end-to-end baseline models, the code for which has been
made available as part of the SpeechBrain toolkit.",1,1,1,1,0,0,0.78256,5.0,0.76262,43
3fe096c2-45c9-4b1c-a496-2cf14a356f7d,Continuous Learning in Neural Machine Translation using Bilingual Dictionaries,12,0.0293577,0.417085,"While recent advances in deep learning led to significant improvements in
machine translation, neural machine translation is often still not able to
continuously adapt to the environment. For humans, as well as for machine
translation, bilingual dictionaries are a promising knowledge source to
continuously integrate new knowledge. However, their exploitation poses several
challenges: The system needs to be able to perform one-shot learning as well as
model the morphology of source and target language.
  In this work, we proposed an evaluation framework to assess the ability of
neural machine translation to continuously learn new phrases. We integrate
one-shot learning methods for neural machine translation with different word
representations and show that it is important to address both in order to
successfully make use of bilingual dictionaries. By addressing both challenges
we are able to improve the ability to translate new, rare words and phrases
from 30% to up to 70%. The correct lemma is even generated by more than 90%.",0,1,0,0,0,0,0.0693423,8.0,0.469697,30
563b6046-93d0-40e6-87f1-cc048305630b,Coreference-Aware Dialogue Summarization,52,0.718158,0.811225,"Summarizing conversations via neural approaches has been gaining research
traction lately, yet it is still challenging to obtain practical solutions.
Examples of such challenges include unstructured information exchange in
dialogues, informal interactions between speakers, and dynamic role changes of
speakers as the dialogue evolves. Many of such challenges result in complex
coreference links. Therefore, in this work, we investigate different approaches
to explicitly incorporate coreference information in neural abstractive
dialogue summarization models to tackle the aforementioned challenges.
Experimental results show that the proposed approaches achieve state-of-the-art
performance, implying it is useful to utilize coreference information in
dialogue summarization. Evaluation results on factual correctness suggest such
coreference-aware models are better at tracing the information flow among
interlocutors and associating accurate status/actions with the corresponding
interlocutors and person mentions.",0,1,0,0,1,0,0.979974,5.0,0.950858,43
0690fccb-f0f6-49b2-b51a-540cc95adb04,Constrained Language Models Yield Few-Shot Semantic Parsers,164,0.594305,0.976628,"We explore the use of large pretrained language models as few-shot semantic
parsers. The goal in semantic parsing is to generate a structured meaning
representation given a natural language input. However, language models are
trained to generate natural language. To bridge the gap, we use language models
to paraphrase inputs into a controlled sublanguage resembling English that can
be automatically mapped to a target meaning representation. Our results
demonstrate that with only a small amount of data and very little code to
convert into English-like representations, our blueprint for rapidly
bootstrapping semantic parsers leads to surprisingly effective performance on
multiple community tasks, greatly exceeding baseline methods also trained on
the same limited data.",1,1,0,0,0,0,0.600645,5.0,0.66098,64
3b8289e7-2914-4543-a708-0d5b2b96fc44,Successive Subspace Learning: An Overview,13,0.0437492,0.396099,"Successive Subspace Learning (SSL) offers a light-weight unsupervised feature
learning method based on inherent statistical properties of data units (e.g.
image pixels and points in point cloud sets). It has shown promising results,
especially on small datasets. In this paper, we intuitively explain this
method, provide an overview of its development, and point out some open
questions and challenges for future research.",0,0,0,0,0,0,0.381197,3.0,0.218842,11
fda9e861-8271-4c1b-b10d-0be584689387,NICE: An Algorithm for Nearest Instance Counterfactual Explanations,41,0.809552,0.698644,"In this paper we suggest NICE: a new algorithm to generate counterfactual
explanations for heterogeneous tabular data. The design of our algorithm
specifically takes into account algorithmic requirements that often emerge in
real-life deployments: (1) the ability to provide an explanation for all
predictions, (2) being able to handle any classification model (also
non-differentiable ones), and (3) being efficient in run time. More
specifically, our approach exploits information from a nearest unlike neighbour
to speed up the search process, by iteratively introducing feature values from
this neighbour in the instance to be explained. We propose four versions of
NICE, one without optimization and, three which optimize the explanations for
one of the following properties: sparsity, proximity or plausibility. An
extensive empirical comparison on 40 datasets shows that our algorithm
outperforms the current state-of-the-art in terms of these criteria. Our
analyses show a trade-off between on the one hand plausibility and on the other
hand proximity or sparsity, with our different optimization methods offering
users the choice to select the types of counterfactuals that they prefer. An
open-source implementation of NICE can be found at
https://github.com/ADMAntwerp/NICE.",1,1,0,0,1,0,0.960135,6.0,0.926774,74
3ecc49b6-803d-478a-9f5f-451fe77e881a,AnaXNet: Anatomy Aware Multi-label Finding Classification in Chest X-ray,24,0.0493934,0.311935,"Radiologists usually observe anatomical regions of chest X-ray images as well
as the overall image before making a decision. However, most existing deep
learning models only look at the entire X-ray image for classification, failing
to utilize important anatomical information. In this paper, we propose a novel
multi-label chest X-ray classification model that accurately classifies the
image finding and also localizes the findings to their correct anatomical
regions. Specifically, our model consists of two modules, the detection module
and the anatomical dependency module. The latter utilizes graph convolutional
networks, which enable our model to learn not only the label dependency but
also the relationship between the anatomical regions in the chest X-ray. We
further utilize a method to efficiently create an adjacency matrix for the
anatomical regions using the correlation of the label across the different
regions. Detailed experiments and analysis of our results show the
effectiveness of our method when compared to the current state-of-the-art
multi-label chest X-ray image classification methods while also providing
accurate location information.",0,1,0,0,1,0,0.232023,7.0,0.57982,36
079d849a-983a-4e5c-8f03-23c9a4883cd4,Shifting Transformation Learning for Out-of-Distribution Detection,6,0.0819787,0.321186,"Detecting out-of-distribution (OOD) samples plays a key role in open-world
and safety-critical applications such as autonomous systems and healthcare.
Recently, self-supervised representation learning techniques (via contrastive
learning and pretext learning) have shown effective in improving OOD detection.
However, one major issue with such approaches is the choice of shifting
transformations and pretext tasks which depends on the in-domain distribution.
In this paper, we propose a simple framework that leverages a shifting
transformation learning setting for learning multiple shifted representations
of the training set for improved OOD detection. To address the problem of
selecting optimal shifting transformation and pretext tasks, we propose a
simple mechanism for automatically selecting the transformations and modulating
their effect on representation learning without requiring any OOD training
samples. In extensive experiments, we show that our simple framework
outperforms state-of-the-art OOD detection models on several image datasets. We
also characterize the criteria for a desirable OOD detector for real-world
applications and demonstrate the efficacy of our proposed technique against
state-of-the-art OOD detection techniques.",0,1,0,0,1,0,0.953534,6.0,0.918654,52
31edf009-f47c-4f62-82b1-49eb2662a87a,Software Engineering for Responsible AI: An Empirical Study and Operationalised Patterns,25,0.486679,0.619837,"Although artificial intelligence (AI) is solving real-world challenges and
transforming industries, there are serious concerns about its ability to behave
and make decisions in a responsible way. Many AI ethics principles and
guidelines for responsible AI have been recently issued by governments,
organisations, and enterprises. However, these AI ethics principles and
guidelines are typically high-level and do not provide concrete guidance on how
to design and develop responsible AI systems. To address this shortcoming, we
first present an empirical study where we interviewed 21 scientists and
engineers to understand the practitioners' perceptions on AI ethics principles
and their implementation. We then propose a template that enables AI ethics
principles to be operationalised in the form of concrete patterns and suggest a
list of patterns using the newly created template. These patterns provide
concrete, operationalised guidance that facilitate the development of
responsible AI systems.",0,1,0,0,0,0,0.812411,5.0,0.781096,71
97cc9659-68a8-44bc-bd62-954d31db8021,CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows,264,0.636628,0.999064,"Unsupervised anomaly detection with localization has many practical
applications when labeling is infeasible and, moreover, when anomaly examples
are completely missing in the train data. While recently proposed models for
such data setup achieve high accuracy metrics, their complexity is a limiting
factor for real-time processing. In this paper, we propose a real-time model
and analytically derive its relationship to prior methods. Our CFLOW-AD model
is based on a conditional normalizing flow framework adopted for anomaly
detection with localization. In particular, CFLOW-AD consists of a
discriminatively pretrained encoder followed by a multi-scale generative
decoders where the latter explicitly estimate likelihood of the encoded
features. Our approach results in a computationally and memory-efficient model:
CFLOW-AD is faster and smaller by a factor of 10x than prior state-of-the-art
with the same input setting. Our experiments on the MVTec dataset show that
CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by
1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source
our code with fully reproducible experiments.",1,1,0,0,1,0,0.715088,6.0,0.769693,44
4177a618-217b-40a8-a7ab-c84e208adcce,Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for Automated Driving using Distributional Reinforcement Learning,24,0.252397,0.648412,"For highly automated driving above SAE level~3, behavior generation
algorithms must reliably consider the inherent uncertainties of the traffic
environment, e.g. arising from the variety of human driving styles. Such
uncertainties can generate ambiguous decisions, requiring the algorithm to
appropriately balance low-probability hazardous events, e.g. collisions, and
high-probability beneficial events, e.g. quickly crossing the intersection.
State-of-the-art behavior generation algorithms lack a distributional treatment
of decision outcome. This impedes a proper risk evaluation in ambiguous
situations, often encouraging either unsafe or conservative behavior. Thus, we
propose a two-step approach for risk-sensitive behavior generation combining
offline distribution learning with online risk assessment. Specifically, we
first learn an optimal policy in an uncertain environment with Deep
Distributional Reinforcement Learning. During execution, the optimal
risk-sensitive action is selected by applying established risk criteria, such
as the Conditional Value at Risk, to the learned state-action return
distributions. In intersection crossing scenarios, we evaluate different risk
criteria and demonstrate that our approach increases safety, while maintaining
an active driving style. Our approach shall encourage further studies about the
benefits of risk-sensitive approaches for self-driving vehicles.",0,1,0,0,0,0,0.761154,4.0,0.687397,30
cdf0d84c-b3db-472c-9c4d-77fd653c52fd,DataCLUE: A Benchmark Suite for Data-centric NLP,14,0.251691,0.374429,"Data-centric AI has recently proven to be more effective and
high-performance, while traditional model-centric AI delivers fewer and fewer
benefits. It emphasizes improving the quality of datasets to achieve better
model performance. This field has significant potential because of its great
practicability and getting more and more attention. However, we have not seen
significant research progress in this field, especially in NLP. We propose
DataCLUE, which is the first Data-Centric benchmark applied in NLP field. We
also provide three simple but effective baselines to foster research in this
field (improve Macro-F1 up to 5.7% point). In addition, we conduct
comprehensive experiments with human annotators and show the hardness of
DataCLUE. We also try an advanced method: the forgetting informed bootstrapping
label correction method. All the resources related to DataCLUE, including
datasets, toolkit, leaderboard, and baselines, is available online at
https://github.com/CLUEbenchmark/DataCLUE",1,0,1,1,0,0,0.952598,6.0,0.917568,18
f17c0cb2-d032-433c-8f1f-7094409d7aaf,Circular-Symmetric Correlation Layer based on FFT,1,0.00136191,0.0247573,"Despite the vast success of standard planar convolutional neural networks,
they are not the most efficient choice for analyzing signals that lie on an
arbitrarily curved manifold, such as a cylinder. The problem arises when one
performs a planar projection of these signals and inevitably causes them to be
distorted or broken where there is valuable information. We propose a
Circular-symmetric Correlation Layer (CCL) based on the formalism of
roto-translation equivariant correlation on the continuous group $S^1 \times
\mathbb{R}$, and implement it efficiently using the well-known Fast Fourier
Transform (FFT) algorithm. We showcase the performance analysis of a general
network equipped with CCL on various recognition and classification tasks and
datasets. The PyTorch package implementation of CCL is provided online.",0,0,0,0,0,0,0.00694579,12.0,0.452035,35
6261e148-33ab-45b8-9627-9bb9379bed8d,MV-TON: Memory-based Video Virtual Try-on network,15,0.705735,0.903713,"With the development of Generative Adversarial Network, image-based virtual
try-on methods have made great progress. However, limited work has explored the
task of video-based virtual try-on while it is important in real-world
applications. Most existing video-based virtual try-on methods usually require
clothing templates and they can only generate blurred and low-resolution
results. To address these challenges, we propose a Memory-based Video virtual
Try-On Network (MV-TON), which seamlessly transfers desired clothes to a target
person without using any clothing templates and generates high-resolution
realistic videos. Specifically, MV-TON consists of two modules: 1) a try-on
module that transfers the desired clothes from model images to frame images by
pose alignment and region-wise replacing of pixels; 2) a memory refinement
module that learns to embed the existing generated frames into the latent space
as external memory for the following frame generation. Experimental results
show the effectiveness of our method in the video virtual try-on task and its
superiority over other existing methods.",0,1,1,0,1,0,0.981344,8.0,0.97153,47
77fe5280-bfec-44e0-a2d8-fc450e2e4b1e,ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders,37,0.11615,0.656106,"Pre-trained text encoders have drawn sustaining attention in natural language
processing (NLP) and shown their capability in obtaining promising results in
different tasks. Recent studies illustrated that external self-supervised
signals (or knowledge extracted by unsupervised learning, such as n-grams) are
beneficial to provide useful semantic evidence for understanding languages such
as Chinese, so as to improve the performance on various downstream tasks
accordingly. To further enhance the encoders, in this paper, we propose to
pre-train n-gram-enhanced encoders with a large volume of data and advanced
techniques for training. Moreover, we try to extend the encoder to different
languages as well as different domains, where it is confirmed that the same
architecture is applicable to these varying circumstances and new
state-of-the-art performance is observed from a long list of NLP tasks across
languages and domains.",1,1,0,0,1,0,0.507831,4.0,0.511642,42
32f2cb48-b3dd-42fc-9869-67d4b98615d1,Prototypical Representation Learning for Relation Extraction,49,0.31178,0.816605,"Recognizing relations between entities is a pivotal task of relational
learning. Learning relation representations from distantly-labeled datasets is
difficult because of the abundant label noise and complicated expressions in
human language. This paper aims to learn predictive, interpretable, and robust
relation representations from distantly-labeled data that are effective in
different settings, including supervised, distantly supervised, and few-shot
learning. Instead of solely relying on the supervision from noisy labels, we
propose to learn prototypes for each relation from contextual information to
best explore the intrinsic semantics of relations. Prototypes are
representations in the feature space abstracting the essential semantics of
relations between entities in sentences. We learn prototypes based on
objectives with clear geometric interpretation, where the prototypes are unit
vectors uniformly dispersed in a unit ball, and statement embeddings are
centered at the end of their corresponding prototype vectors on the surface of
the ball. This approach allows us to learn meaningful, interpretable prototypes
for the final classification. Results on several relation learning tasks show
that our model significantly outperforms the previous state-of-the-art models.
We further demonstrate the robustness of the encoder and the interpretability
of prototypes with extensive experiments.",1,1,0,0,1,0,0.500746,11.0,0.820564,74
a3b6139c-2b91-465f-9982-56d135d896dc,Parallel Refinements for Lexically Constrained Text Generation with BART,31,0.629714,0.756505,"Lexically constrained text generation aims to control the generated text by
incorporating some pre-specified keywords into the output. Previous work
injects lexical constraints into the output by controlling the decoding process
or refining the candidate output iteratively, which tends to generate generic
or ungrammatical sentences, and has high computational complexity. To address
these challenges, we propose Constrained BART (CBART) for lexically constrained
text generation. CBART leverages the pre-trained model BART and transfers part
of the generation burden from the decoder to the encoder by decomposing this
task into two sub-tasks, thereby improving the sentence quality. Concretely, we
extend BART by adding a token-level classifier over the encoder, aiming at
instructing the decoder where to replace and insert. Guided by the encoder, the
decoder refines multiple tokens of the input in one step by inserting tokens
before specific positions and re-predicting tokens with low confidence. To
further reduce the inference latency, the decoder predicts all tokens in
parallel. Experiment results on One-Billion-Word and Yelp show that CBART can
generate plausible text with high quality and diversity while significantly
accelerating inference.",1,1,0,0,0,0,0.954648,7.0,0.9314,47
f1a99961-0675-420d-81c6-346203da0733,Rethinking Self-Supervised Learning: Small is Beautiful,21,0.0643397,0.233212,"Self-supervised learning (SSL), in particular contrastive learning, has made
great progress in recent years. However, a common theme in these methods is
that they inherit the learning paradigm from the supervised deep learning
scenario. Current SSL methods are often pretrained for many epochs on
large-scale datasets using high resolution images, which brings heavy
computational cost and lacks flexibility. In this paper, we demonstrate that
the learning paradigm for SSL should be different from supervised learning and
the information encoded by the contrastive loss is expected to be much less
than that encoded in the labels in supervised learning via the cross entropy
loss. Hence, we propose scaled-down self-supervised learning (S3L), which
include 3 parts: small resolution, small architecture and small data. On a
diverse set of datasets, SSL methods and backbone architectures, S3L achieves
higher accuracy consistently with much less training cost when compared to
previous SSL learning paradigm. Furthermore, we show that even without a large
pretraining dataset, S3L can achieve impressive results on small data alone.
Our code has been made publically available at
https://github.com/CupidJay/Scaled-down-self-supervised-learning.",1,1,0,0,0,0,0.956841,9.0,0.948411,41
08e194cb-148e-408b-8b51-473dd259f76f,Video Sentiment Analysis with Bimodal Information-augmented Multi-Head Attention,44,0.156737,0.736051,"Humans express feelings or emotions via different channels. Take language as
an example, it entails different sentiments under different visual-acoustic
contexts. To precisely understand human intentions as well as reduce the
misunderstandings caused by ambiguity and sarcasm, we should consider
multimodal signals including textual, visual and acoustic signals. The crucial
challenge is to fuse different modalities of features for sentiment analysis.
To effectively fuse the information carried by different modalities and better
predict the sentiments, we design a novel multi-head attention based fusion
network, which is inspired by the observations that the interactions between
any two pair-wise modalities are different and they do not equally contribute
to the final sentiment prediction. By assigning the acoustic-visual,
acoustic-textual and visual-textual features with reasonable attention and
exploiting a residual structure, we attend to attain the significant features.
We conduct extensive experiments on four public multimodal datasets including
one in Chinese and three in English. The results show that our approach
outperforms the existing methods and can explain the contributions of bimodal
interaction in multiple modalities.",1,1,0,0,1,0,0.471031,4.0,0.484826,73
00b3d0f9-257a-4119-a6a7-76a2d59913a9,Differentiable Subset Pruning of Transformer Heads,41,0.554932,0.625351,"Multi-head attention, a collection of several attention mechanisms that
independently attend to different parts of the input, is the key ingredient in
the Transformer. Recent work has shown, however, that a large proportion of the
heads in a Transformer's multi-head attention mechanism can be safely pruned
away without significantly harming the performance of the model; such pruning
leads to models that are noticeably smaller and faster in practice. Our work
introduces a new head pruning technique that we term differentiable subset
pruning. Intuitively, our method learns per-head importance variables and then
enforces a user-specified hard constraint on the number of unpruned heads. The
importance variables are learned via stochastic gradient descent. We conduct
experiments on natural language inference and machine translation; we show that
differentiable subset pruning performs comparably or better than previous works
while offering precise control of the sparsity level.",0,1,0,0,0,0,0.953745,9.0,0.945934,65
45c8fb29-6ed9-4c4e-9f79-ef027c719dce,Do as we do: Multiple Person Video-To-Video Transfer,1,0.00687061,0.0339814,"Our goal is to transfer the motion of real people from a source video to a
target video with realistic results. While recent advances significantly
improved image-to-image translations, only few works account for body motions
and temporal consistency. However, those focus only on video re-targeting for a
single actor/ for single actors. In this work, we propose a marker-less
approach for multiple-person video-to-video transfer using pose as an
intermediate representation. Given a source video with multiple persons dancing
or working out, our method transfers the body motion of all actors to a new set
of actors in a different video. Differently from recent ""do as I do"" methods,
we focus specifically on transferring multiple person at the same time and
tackle the related identity switch problem. Our method is able to convincingly
transfer body motion to the target video, while preserving specific features of
the target video, such as feet touching the floor and relative position of the
actors. The evaluation is performed with visual quality and appearance metrics
using publicly available videos with the permission of their owners.",0,1,0,0,0,0,0.472915,6.0,0.657482,37
e4fd7b76-c8b8-4d37-8fda-7e3bcca7c07c,Stratified Data Integration,16,0.167456,0.355455,"We propose a novel approach to the problem of semantic heterogeneity where
data are organized into a set of stratified and independent representation
layers, namely: conceptual(where a set of unique alinguistic identifiers are
connected inside a graph codifying their meaning), language(where sets of
synonyms, possibly from multiple languages, annotate concepts), knowledge(in
the form of a graph where nodes are entity types and links are properties), and
data(in the form of a graph of entities populating the previous knowledge
graph). This allows us to state the problem of semantic heterogeneity as a
problem of Representation Diversity where the different types of heterogeneity,
viz. Conceptual, Language, Knowledge, and Data, are uniformly dealt within each
single layer, independently from the others. In this paper we describe the
proposed stratified representation of data and the process by which data are
first transformed into the target representation, then suitably integrated and
then, finally, presented to the user in her preferred format. The proposed
framework has been evaluated in various pilot case studies and in a number of
industrial data integration problems.",0,0,0,0,0,0,0.0220305,13.0,0.583566,44
46d41f18-0256-42c3-8924-8380c1a2090c,Towards unconstrained joint hand-object reconstruction from RGB videos,47,0.81045,0.765092,"Our work aims to obtain 3D reconstruction of hands and manipulated objects
from monocular videos. Reconstructing hand-object manipulations holds a great
potential for robotics and learning from human demonstrations. The supervised
learning approach to this problem, however, requires 3D supervision and remains
limited to constrained laboratory settings and simulators for which 3D ground
truth is available. In this paper we first propose a learning-free fitting
approach for hand-object reconstruction which can seamlessly handle two-hand
object interactions. Our method relies on cues obtained with common methods for
object detection, hand pose estimation and instance segmentation. We
quantitatively evaluate our approach and show that it can be applied to
datasets with varying levels of difficulty for which training data is
unavailable.",1,1,0,0,0,0,0.987401,6.0,0.977711,73
3fd62801-2a95-4c14-ae4d-aba6c495e6ba,Fully Hyperbolic Neural Networks,59,0.339004,0.700328,"Hyperbolic neural networks have shown great potential for modeling complex
data. However, existing hyperbolic networks are not completely hyperbolic, as
they encode features in a hyperbolic space yet formalize most of their
operations in the tangent space (a Euclidean subspace) at the origin of the
hyperbolic space. This hybrid method greatly limits the modeling ability of
networks. In this paper, we propose a fully hyperbolic framework to build
hyperbolic networks based on the Lorentz model by adapting the Lorentz
transformations (including boost and rotation) to formalize essential
operations of neural networks. Moreover, we also prove that linear
transformation in tangent spaces used by existing hyperbolic networks is a
relaxation of the Lorentz rotation and does not include the boost, implicitly
limiting the capabilities of existing hyperbolic networks. The experimental
results on four NLP tasks show that our method has better performance for
building both shallow and deep networks. Our code will be released to
facilitate follow-up research.",1,0,0,0,0,0,0.349828,7.0,0.649685,71
0c9d8525-bb24-4e10-a14a-acf4cc9fc5a8,Using Recursive KMeans and Dijkstra Algorithm to Solve CVRP,2,0.038316,0.131566,"Capacitated vehicle routing problem (CVRP) is being one of the most common
optimization problems in our days, considering the wide usage of routing
algorithms in multiple fields such as transportation domain, food delivery,
network routing, ... Capacitated vehicle routing problem is classified as an
NP-Hard problem, hence normal optimization algorithm can't solve it. In our
paper, we discuss a new way to solve the mentioned problem, using a recursive
approach of the most known clustering algorithm ""K-Means"", one of the known
shortest path algorithm ""Dijkstra"", and some mathematical operations. In this
paper, we will show how to implement those methods together in order to get the
nearest solution of the optimal route, since research and development are still
on go, this research paper may be extended with another one, that will involve
the implementational results of this thoric side.",0,1,0,0,0,0,0.992731,18.0,0.999151,3
ffa205d0-b013-4278-8ea8-4f9739df1b88,LaneRCNN: Distributed Representations for Graph-Centric Motion Forecasting,140,0.998929,0.893133,"Forecasting the future behaviors of dynamic actors is an important task in
many robotics applications such as self-driving. It is extremely challenging as
actors have latent intentions and their trajectories are governed by complex
interactions between the other actors, themselves, and the maps. In this paper,
we propose LaneRCNN, a graph-centric motion forecasting model. Importantly,
relying on a specially designed graph encoder, we learn a local lane graph
representation per actor (LaneRoI) to encode its past motions and the local map
topology. We further develop an interaction module which permits efficient
message passing among local graph representations within a shared global lane
graph. Moreover, we parameterize the output trajectories based on lane graphs,
a more amenable prediction parameterization. Our LaneRCNN captures the
actor-to-actor and the actor-to-map relations in a distributed and map-aware
manner. We demonstrate the effectiveness of our approach on the large-scale
Argoverse Motion Forecasting Benchmark. We achieve the 1st place on the
leaderboard and significantly outperform previous best results.",0,1,0,0,1,0,0.991652,6.0,0.992699,66
6ac65ff0-b946-432e-b0e6-6bddf69b194e,Region-aware Adaptive Instance Normalization for Image Harmonization,101,0.231838,0.959116,"Image composition plays a common but important role in photo editing. To
acquire photo-realistic composite images, one must adjust the appearance and
visual style of the foreground to be compatible with the background. Existing
deep learning methods for harmonizing composite images directly learn an image
mapping network from the composite to the real one, without explicit
exploration on visual style consistency between the background and the
foreground images. To ensure the visual style consistency between the
foreground and the background, in this paper, we treat image harmonization as a
style transfer problem. In particular, we propose a simple yet effective
Region-aware Adaptive Instance Normalization (RAIN) module, which explicitly
formulates the visual style from the background and adaptively applies them to
the foreground. With our settings, our RAIN module can be used as a drop-in
module for existing image harmonization networks and is able to bring
significant improvements. Extensive experiments on the existing image
harmonization benchmark datasets show the superior capability of the proposed
method. Code is available at {https://github.com/junleen/RainNet}.",1,1,1,0,1,0,0.256778,10.0,0.717573,45
5a9dd9bb-bc76-4137-a674-327a81f5a608,Conformer-based Hybrid ASR System for Switchboard Dataset,17,0.0660431,0.720872,"The recently proposed conformer architecture has been successfully used for
end-to-end automatic speech recognition (ASR) architectures achieving
state-of-the-art performance on different datasets. To our best knowledge, the
impact of using conformer acoustic model for hybrid ASR is not investigated. In
this paper, we present and evaluate a competitive conformer-based hybrid model
training recipe. We study different training aspects and methods to improve
word-error-rate as well as to increase training speed. We apply time
downsampling methods for efficient training and use transposed convolutions to
upsample the output sequence again. We conduct experiments on Switchboard 300h
dataset and our conformer-based hybrid model achieves competitive results
compared to other architectures. It generalizes very well on Hub5'01 test set
and outperforms the BLSTM-based hybrid model significantly.",1,1,0,0,0,0,0.178051,9.0,0.640146,40
d55ad200-6b79-4af8-a9a0-6f71cfd6e47e,Deep Learning for Two-Sided Matching,10,0.217843,0.30903,"We initiate the study of deep learning for the automated design of two-sided
matching mechanisms. What is of most interest is to use machine learning to
understand the possibility of new tradeoffs between strategy-proofness and
stability. These properties cannot be achieved simultaneously, but the
efficient frontier is not understood. We introduce novel differentiable
surrogates for quantifying ordinal strategy-proofness and stability and use
them to train differentiable matching mechanisms that map discrete preferences
to valid randomized matchings. We demonstrate that the efficient frontier
characterized by these learned mechanisms is substantially better than that
achievable through a convex combination of baselines of deferred acceptance
(stable and strategy-proof for only one side of the market), top trading cycles
(strategy-proof for one side, but not stable), and randomized serial
dictatorship (strategy-proof for both sides, but not stable). This gives a new
target for economic theory and opens up new possibilities for machine learning
pipelines in matching market design.",0,0,1,0,0,0,0.0541423,17.0,0.735419,59
e977844b-f9ba-43af-a017-a4172e67b0d6,Neural Bi-Lexicalized PCFG Induction,17,0.38693,0.713206,"Neural lexicalized PCFGs (L-PCFGs) have been shown effective in grammar
induction. However, to reduce computational complexity, they make a strong
independence assumption on the generation of the child word and thus bilexical
dependencies are ignored. In this paper, we propose an approach to parameterize
L-PCFGs without making implausible independence assumptions. Our approach
directly models bilexical dependencies and meanwhile reduces both learning and
representation complexities of L-PCFGs. Experimental results on the English WSJ
dataset confirm the effectiveness of our approach in improving both running
speed and unsupervised parsing performance.",1,0,0,0,0,0,0.541892,6.0,0.690489,57
3080d1ec-c2bc-44cc-a1f8-e97b4038ec3e,Benchmarking Scientific Image Forgery Detectors,6,0.0754516,0.188961,"The scientific image integrity area presents a challenging research
bottleneck, the lack of available datasets to design and evaluate forensic
techniques. Its data sensitivity creates a legal hurdle that prevents one to
rely on real tampered cases to build any sort of accessible forensic benchmark.
To mitigate this bottleneck, we present an extendable open-source library that
reproduces the most common image forgery operations reported by the research
integrity community: duplication, retouching, and cleaning. Using this library
and realistic scientific images, we create a large scientific forgery image
benchmark (39,423 images) with an enriched ground-truth. In addition, concerned
about the high number of retracted papers due to image duplication, this work
evaluates the state-of-the-art copy-move detection methods in the proposed
dataset, using a new metric that asserts consistent match detection between the
source and the copied region. The dataset and source-code will be freely
available upon acceptance of the paper.",0,1,0,1,0,0,0.0209952,11.0,0.503426,38
2200c92f-a5c4-4e0a-a7c9-e1a92b7b6ada,Hierarchical Clustering using Auto-encoded Compact Representation for Time-series Analysis,5,0.0402677,0.447399,"Getting a robust time-series clustering with best choice of distance measure
and appropriate representation is always a challenge. We propose a novel
mechanism to identify the clusters combining learned compact representation of
time-series, Auto Encoded Compact Sequence (AECS) and hierarchical clustering
approach. Proposed algorithm aims to address the large computing time issue of
hierarchical clustering as learned latent representation AECS has a length much
less than the original length of time-series and at the same time want to
enhance its performance.Our algorithm exploits Recurrent Neural Network (RNN)
based under complete Sequence to Sequence(seq2seq) autoencoder and
agglomerative hierarchical clustering with a choice of best distance measure to
recommend the best clustering. Our scheme selects the best distance measure and
corresponding clustering for both univariate and multivariate time-series. We
have experimented with real-world time-series from UCR and UCI archive taken
from diverse application domains like health, smart-city, manufacturing etc.
Experimental results show that proposed method not only produce close to
benchmark results but also in some cases outperform the benchmark.",0,1,0,0,1,0,0.819305,13.0,0.917508,33
2f288587-c65f-46d1-8d0d-dff944a32801,Self-Guided Contrastive Learning for BERT Sentence Representations,173,0.309613,0.901427,"Although BERT and its variants have reshaped the NLP landscape, it still
remains unclear how best to derive sentence embeddings from such pre-trained
Transformers. In this work, we propose a contrastive learning method that
utilizes self-guidance for improving the quality of BERT sentence
representations. Our method fine-tunes BERT in a self-supervised fashion, does
not rely on data augmentation, and enables the usual [CLS] token embeddings to
function as sentence vectors. Moreover, we redesign the contrastive learning
objective (NT-Xent) and apply it to sentence representation learning. We
demonstrate with extensive experiments that our approach is more effective than
competitive baselines on diverse sentence-related tasks. We also show it is
efficient at inference and robust to domain shifts.",0,1,0,0,0,0,0.862613,4.0,0.769039,48
7e53fe5a-ac1a-4058-b987-ddc76460f6d4,Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective,7,0.0704221,0.16478,"Deep ensemble learning has been shown to improve accuracy by training
multiple neural networks and averaging their outputs. Ensemble learning has
also been suggested to defend against membership inference attacks that
undermine privacy. In this paper, we empirically demonstrate a trade-off
between these two goals, namely accuracy and privacy (in terms of membership
inference attacks), in deep ensembles. Using a wide range of datasets and model
architectures, we show that the effectiveness of membership inference attacks
increases when ensembling improves accuracy. We analyze the impact of various
factors in deep ensembles and demonstrate the root cause of the trade-off.
Then, we evaluate common defenses against membership inference attacks based on
regularization and differential privacy. We show that while these defenses can
mitigate the effectiveness of membership inference attacks, they simultaneously
degrade ensemble accuracy. We illustrate similar trade-off in more advanced and
state-of-the-art ensembling techniques, such as snapshot ensembles and
diversified ensemble networks. Finally, we propose a simple yet effective
defense for deep ensembles to break the trade-off and, consequently, improve
the accuracy and privacy, simultaneously.",1,1,0,0,0,0,0.900853,4.0,0.807077,71
2b89173f-94cc-4c8f-8793-26e913f6b19b,Neural Unsupervised Semantic Role Labeling,2,0.0246828,0.0403162,"The task of semantic role labeling (SRL) is dedicated to finding the
predicate-argument structure. Previous works on SRL are mostly supervised and
do not consider the difficulty in labeling each example which can be very
expensive and time-consuming. In this paper, we present the first neural
unsupervised model for SRL. To decompose the task as two argument related
subtasks, identification and clustering, we propose a pipeline that
correspondingly consists of two neural modules. First, we train a neural model
on two syntax-aware statistically developed rules. The neural model gets the
relevance signal for each token in a sentence, to feed into a BiLSTM, and then
an adversarial layer for noise-adding and classifying simultaneously, thus
enabling the model to learn the semantic structure of a sentence. Then we
propose another neural model for argument role clustering, which is done
through clustering the learned argument embeddings biased towards their
dependency relations. Experiments on CoNLL-2009 English dataset demonstrate
that our model outperforms previous state-of-the-art baseline in terms of
non-neural models for argument identification and classification.",1,0,0,0,1,0,0.00409706,20.0,0.644756,45
c174d66a-6785-4a59-985e-9e8cf9bbae38,ProtAugment: Unsupervised diverse short-texts paraphrasing for intent detection meta-learning,23,0.43619,0.748299,"Recent research considers few-shot intent detection as a meta-learning
problem: the model is learning to learn from a consecutive set of small tasks
named episodes. In this work, we propose ProtAugment, a meta-learning algorithm
for short texts classification (the intent detection task). ProtAugment is a
novel extension of Prototypical Networks, that limits overfitting on the bias
introduced by the few-shots classification objective at each episode. It relies
on diverse paraphrasing: a conditional language model is first fine-tuned for
paraphrasing, and diversity is later introduced at the decoding stage at each
meta-learning episode. The diverse paraphrasing is unsupervised as it is
applied to unlabelled data, and then fueled to the Prototypical Network
training objective as a consistency loss. ProtAugment is the state-of-the-art
method for intent detection meta-learning, at no extra labeling efforts and
without the need to fine-tune a conditional language model on a given
application domain.",1,1,0,0,1,0,0.898555,4.0,0.804586,43
4ad8b7b3-7670-422d-8a71-0ef56d1a5b7a,"A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose",195,0.969255,0.556881,"While deep learning reshaped the classical motion capture pipeline with
feed-forward networks, generative models are required to recover fine alignment
via iterative refinement. Unfortunately, the existing models are usually
hand-crafted or learned in controlled conditions, only applicable to limited
domains. We propose a method to learn a generative neural body model from
unlabelled monocular videos by extending Neural Radiance Fields (NeRFs). We
equip them with a skeleton to apply to time-varying and articulated motion. A
key insight is that implicit models require the inverse of the forward
kinematics used in explicit surface models. Our reparameterization defines
spatial latent variables relative to the pose of body parts and thereby
overcomes ill-posed inverse operations with an overparameterization. This
enables learning volumetric body shape and appearance from scratch while
jointly refining the articulated pose; all without ground truth labels for
appearance, pose, or 3D shape on the input videos. When used for
novel-view-synthesis and motion capture, our neural model improves accuracy on
diverse datasets. Project website: https://lemonatsu.github.io/anerf/ .",0,0,0,0,0,0,0.981336,5.0,0.954427,80
76a09754-e628-4fde-89e3-fc4e04c1c2b5,Addressing the Vulnerability of NMT in Input Perturbations,10,0.105408,0.454524,"Neural Machine Translation (NMT) has achieved significant breakthrough in
performance but is known to suffer vulnerability to input perturbations. As
real input noise is difficult to predict during training, robustness is a big
issue for system deployment. In this paper, we improve the robustness of NMT
models by reducing the effect of noisy words through a Context-Enhanced
Reconstruction (CER) approach. CER trains the model to resist noise in two
steps: (1) perturbation step that breaks the naturalness of input sequence with
made-up words; (2) reconstruction step that defends the noise propagation by
generating better and more robust contextual representation. Experimental
results on Chinese-English (ZH-EN) and French-English (FR-EN) translation tasks
demonstrate robustness improvement on both news and social media text. Further
fine-tuning experiments on social media text show our approach can converge at
a higher position and provide a better adaptation.",0,1,0,0,0,0,0.637373,7.0,0.77212,42
213c0951-28c6-4917-9d54-b2d10d889aad,Meta-Aggregator: Learning to Aggregate for 1-bit Graph Neural Networks,28,0.055755,0.402964,"In this paper, we study a novel meta aggregation scheme towards binarizing
graph neural networks (GNNs). We begin by developing a vanilla 1-bit GNN
framework that binarizes both the GNN parameters and the graph features.
Despite the lightweight architecture, we observed that this vanilla framework
suffered from insufficient discriminative power in distinguishing graph
topologies, leading to a dramatic drop in performance. This discovery motivates
us to devise meta aggregators to improve the expressive power of vanilla
binarized GNNs, of which the aggregation schemes can be adaptively changed in a
learnable manner based on the binarized features. Towards this end, we propose
two dedicated forms of meta neighborhood aggregators, an exclusive meta
aggregator termed as Greedy Gumbel Neighborhood Aggregator (GNA), and a
diffused meta aggregator termed as Adaptable Hybrid Neighborhood Aggregator
(ANA). GNA learns to exclusively pick one single optimal aggregator from a pool
of candidates, while ANA learns a hybrid aggregation behavior to simultaneously
retain the benefits of several individual aggregators. Furthermore, the
proposed meta aggregators may readily serve as a generic plugin module into
existing full-precision GNNs. Experiments across various domains demonstrate
that the proposed method yields results superior to the state of the art.",0,1,0,0,1,0,0.246059,8.0,0.640785,68
43af7170-c745-4a04-b72c-879a5f6c264f,Predicting Patient Readmission Risk from Medical Text via Knowledge Graph Enhanced Multiview Graph Convolution,14,0.189689,0.666993,"Unplanned intensive care unit (ICU) readmission rate is an important metric
for evaluating the quality of hospital care. Efficient and accurate prediction
of ICU readmission risk can not only help prevent patients from inappropriate
discharge and potential dangers, but also reduce associated costs of
healthcare. In this paper, we propose a new method that uses medical text of
Electronic Health Records (EHRs) for prediction, which provides an alternative
perspective to previous studies that heavily depend on numerical and
time-series features of patients. More specifically, we extract discharge
summaries of patients from their EHRs, and represent them with multiview graphs
enhanced by an external knowledge graph. Graph convolutional networks are then
used for representation learning. Experimental results prove the effectiveness
of our method, yielding state-of-the-art performance for this task.",0,1,0,0,1,0,0.876738,5.0,0.825874,23
ad0c7655-afc0-4da4-954f-815e32f233ae,Large Scale Autonomous Driving Scenarios Clustering with Self-supervised Feature Extraction,13,0.148066,0.589939,"The clustering of autonomous driving scenario data can substantially benefit
the autonomous driving validation and simulation systems by improving the
simulation tests' completeness and fidelity. This article proposes a
comprehensive data clustering framework for a large set of vehicle driving
data. Existing algorithms utilize handcrafted features whose quality relies on
the judgments of human experts. Additionally, the related feature compression
methods are not scalable for a large data-set. Our approach thoroughly
considers the traffic elements, including both in-traffic agent objects and map
information. Meanwhile, we proposed a self-supervised deep learning approach
for spatial and temporal feature extraction to avoid biased data
representation. With the newly designed driving data clustering evaluation
metrics based on data-augmentation, the accuracy assessment does not require a
human-labeled data-set, which is subject to human bias. Via such unprejudiced
evaluation metrics, we have shown our approach surpasses the existing methods
that rely on handcrafted feature extractions.",0,1,0,0,0,0,0.762404,6.0,0.792208,28
da325a92-d1e1-4f2f-a71c-c7403380311a,An Extensive Study of User Identification via Eye Movements across Multiple Datasets,7,0.0482327,0.605294,"Several studies have reported that biometric identification based on eye
movement characteristics can be used for authentication. This paper provides an
extensive study of user identification via eye movements across multiple
datasets based on an improved version of method originally proposed by George
and Routray. We analyzed our method with respect to several factors that affect
the identification accuracy, such as the type of stimulus, the IVT parameters
(used for segmenting the trajectories into fixation and saccades), adding new
features such as higher-order derivatives of eye movements, the inclusion of
blink information, template aging, age and gender.We find that three methods
namely selecting optimal IVT parameters, adding higher-order derivatives
features and including an additional blink classifier have a positive impact on
the identification accuracy. The improvements range from a few percentage
points, up to an impressive 9 % increase on one of the datasets.",0,1,0,0,0,0,0.0141742,11.0,0.467396,58
bf968fb5-c76b-4a21-8d21-253aed4e3e3f,Boosting Adversarial Transferability through Enhanced Momentum,57,0.205324,0.82171,"Deep learning models are known to be vulnerable to adversarial examples
crafted by adding human-imperceptible perturbations on benign images. Many
existing adversarial attack methods have achieved great white-box attack
performance, but exhibit low transferability when attacking other models.
Various momentum iterative gradient-based methods are shown to be effective to
improve the adversarial transferability. In what follows, we propose an
enhanced momentum iterative gradient-based method to further enhance the
adversarial transferability. Specifically, instead of only accumulating the
gradient during the iterative process, we additionally accumulate the average
gradient of the data points sampled in the gradient direction of the previous
iteration so as to stabilize the update direction and escape from poor local
maxima. Extensive experiments on the standard ImageNet dataset demonstrate that
our method could improve the adversarial transferability of momentum-based
methods by a large margin of 11.1% on average. Moreover, by incorporating with
various input transformation methods, the adversarial transferability could be
further improved significantly. We also attack several extra advanced defense
models under the ensemble-model setting, and the enhancements are remarkable
with at least 7.8% on average.",0,1,0,0,0,0,0.825774,7.0,0.849813,47
6988da81-bfef-49f9-8960-43ae70bc3fb8,Cross-Task Instance Representation Interactions and Label Dependencies for Joint Information Extraction with Graph Convolutional Networks,58,0.152264,0.788564,"Existing works on information extraction (IE) have mainly solved the four
main tasks separately (entity mention recognition, relation extraction, event
trigger detection, and argument extraction), thus failing to benefit from
inter-dependencies between tasks. This paper presents a novel deep learning
model to simultaneously solve the four tasks of IE in a single model (called
FourIE). Compared to few prior work on jointly performing four IE tasks, FourIE
features two novel contributions to capture inter-dependencies between tasks.
First, at the representation level, we introduce an interaction graph between
instances of the four tasks that is used to enrich the prediction
representation for one instance with those from related instances of other
tasks. Second, at the label level, we propose a dependency graph for the
information types in the four IE tasks that captures the connections between
the types expressed in an input sentence. A new regularization mechanism is
introduced to enforce the consistency between the golden and predicted type
dependency graphs to improve representation learning. We show that the proposed
model achieves the state-of-the-art performance for joint IE on both
monolingual and multilingual learning settings with three different languages.",0,0,0,0,1,0,0.0653052,9.0,0.521717,39
6771ac3c-3ffd-4ed4-a1b3-9a2ee80b2b5a,ViTGAN: Training GANs with Vision Transformers,145,0.251754,0.885497,"Recently, Vision Transformers (ViTs) have shown competitive performance on
image recognition while requiring less vision-specific inductive biases. In
this paper, we investigate if such performance can be extended to image
generation. To this end, we integrate the ViT architecture into generative
adversarial networks (GANs). For ViT discriminators, we observe that existing
regularization methods for GANs interact poorly with self-attention, causing
serious instability during training. To resolve this issue, we introduce
several novel regularization techniques for training GANs with ViTs. For ViT
generators, we examine architectural choices for latent and pixel mapping
layers to facilitate convergence. Empirically, our approach, named ViTGAN,
achieves comparable performance to the leading CNN-based GAN models on three
datasets: CIFAR-10, CelebA, and LSUN bedroom.",1,1,0,0,0,0,0.893646,3.0,0.732492,70
fc691df4-43fc-41b4-bcaf-fde2aae19642,"An Automatic Approach for Generating Rich, Linked Geo-Metadata from Historical Map Images",12,0.199877,0.259532,"Historical maps contain detailed geographic information difficult to find
elsewhere covering long-periods of time (e.g., 125 years for the historical
topographic maps in the US). However, these maps typically exist as scanned
images without searchable metadata. Existing approaches making historical maps
searchable rely on tedious manual work (including crowd-sourcing) to generate
the metadata (e.g., geolocations and keywords). Optical character recognition
(OCR) software could alleviate the required manual work, but the recognition
results are individual words instead of location phrases (e.g., ""Black"" and
""Mountain"" vs. ""Black Mountain""). This paper presents an end-to-end approach to
address the real-world problem of finding and indexing historical map images.
This approach automatically processes historical map images to extract their
text content and generates a set of metadata that is linked to large external
geospatial knowledge bases. The linked metadata in the RDF (Resource
Description Framework) format support complex queries for finding and indexing
historical maps, such as retrieving all historical maps covering mountain peaks
higher than 1,000 meters in California. We have implemented the approach in a
system called mapKurator. We have evaluated mapKurator using historical maps
from several sources with various map styles, scales, and coverage. Our results
show significant improvement over the state-of-the-art methods. The code has
been made publicly available as modules of the Kartta Labs project at
https://github.com/kartta-labs/Project.",1,1,0,0,1,0,0.175875,10.0,0.674774,26
783fd2c1-b51e-4d75-a693-05f6778366a8,Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-box Approach,81,0.684911,0.986164,"We propose a black-box reduction that turns a certain reinforcement learning
algorithm with optimal regret in a (near-)stationary environment into another
algorithm with optimal dynamic regret in a non-stationary environment,
importantly without any prior knowledge on the degree of non-stationarity. By
plugging different algorithms into our black-box, we provide a list of examples
showing that our approach not only recovers recent results for (contextual)
multi-armed bandits achieved by very specialized algorithms, but also
significantly improves the state of the art for (generalized) linear bandits,
episodic MDPs, and infinite-horizon MDPs in various ways. Specifically, in most
cases our algorithm achieves the optimal dynamic regret
$\widetilde{\mathcal{O}}(\min\{\sqrt{LT}, \Delta^{1/3}T^{2/3}\})$ where $T$ is
the number of rounds and $L$ and $\Delta$ are the number and amount of changes
of the world respectively, while previous works only obtain suboptimal bounds
and/or require the knowledge of $L$ and $\Delta$.",0,0,0,0,1,0,0.683693,4.0,0.632808,64
36e4e0a5-1c8f-4fb5-9b3a-5151c973021f,Deep Geospatial Interpolation Networks,2,0.0165266,0.0836241,"Interpolation in Spatio-temporal data has applications in various domains
such as climate, transportation, and mining. Spatio-Temporal interpolation is
highly challenging due to the complex spatial and temporal relationships.
However, traditional techniques such as Kriging suffer from high running time
and poor performance on data that exhibit high variance across space and time
dimensions. To this end, we propose a novel deep neural network called as Deep
Geospatial Interpolation Network(DGIN), which incorporates both spatial and
temporal relationships and has significantly lower training time. DGIN consists
of three major components: Spatial Encoder to capture the spatial dependencies,
Sequential module to incorporate the temporal dynamics, and an Attention block
to learn the importance of the temporal neighborhood around the gap. We
evaluate DGIN on the MODIS reflectance dataset from two different regions. Our
experimental results indicate that DGIN has two advantages: (a) it outperforms
alternative approaches (has lower MSE with p-value < 0.01) and, (b) it has
significantly low execution time than Kriging.",0,1,0,0,1,0,0.0487109,11.0,0.581234,11
209874b6-5ae8-4429-8b8d-34089edf6468,"Think you have Solved Direct-Answer Question Answering? Try ARC-DA, the Direct-Answer AI2 Reasoning Challenge",36,0.0635626,0.459257,"We present the ARC-DA dataset, a direct-answer (""open response"", ""freeform"")
version of the ARC (AI2 Reasoning Challenge) multiple-choice dataset. While ARC
has been influential in the community, its multiple-choice format is
unrepresentative of real-world questions, and multiple choice formats can be
particularly susceptible to artifacts. The ARC-DA dataset addresses these
concerns by converting questions to direct-answer format using a combination of
crowdsourcing and expert review. The resulting dataset contains 2985 questions
with a total of 8436 valid answers (questions typically have more than one
valid answer). ARC-DA is one of the first DA datasets of natural questions that
often require reasoning, and where appropriate question decompositions are not
evident from the questions themselves. We describe the conversion approach
taken, appropriate evaluation metrics, and several strong models. Although
high, the best scores (81% GENIE, 61.4% F1, 63.2% ROUGE-L) still leave
considerable room for improvement. In addition, the dataset provides a natural
setting for new research on explanation, as many questions require reasoning to
construct answers. We hope the dataset spurs further advances in complex
question-answering by the community. ARC-DA is available at
https://allenai.org/data/arc-da",0,0,1,1,0,0,0.332857,5.0,0.497216,27
f3fa428b-5b7c-479f-82d7-5dda8b372408,Distilling Holistic Knowledge with Graph Neural Networks,43,0.360613,0.879718,"Knowledge Distillation (KD) aims at transferring knowledge from a larger
well-optimized teacher network to a smaller learnable student network.Existing
KD methods have mainly considered two types of knowledge, namely the individual
knowledge and the relational knowledge. However, these two types of knowledge
are usually modeled independently while the inherent correlations between them
are largely ignored. It is critical for sufficient student network learning to
integrate both individual knowledge and relational knowledge while reserving
their inherent correlation. In this paper, we propose to distill the novel
holistic knowledge based on an attributed graph constructed among instances.
The holistic knowledge is represented as a unified graph-based embedding by
aggregating individual knowledge from relational neighborhood samples with
graph neural networks, the student network is learned by distilling the
holistic knowledge in a contrastive manner. Extensive experiments and ablation
studies are conducted on benchmark datasets, the results demonstrate the
effectiveness of the proposed method. The code has been published in
https://github.com/wyc-ruiker/HKD",1,0,0,0,0,0,0.762933,7.0,0.822114,42
38ce159f-6854-4ad0-8dcb-5e1800c48037,GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds,110,0.656063,0.758569,"We present GANcraft, an unsupervised neural rendering framework for
generating photorealistic images of large 3D block worlds such as those created
in Minecraft. Our method takes a semantic block world as input, where each
block is assigned a semantic label such as dirt, grass, or water. We represent
the world as a continuous volumetric function and train our model to render
view-consistent photorealistic images for a user-controlled camera. In the
absence of paired ground truth real images for the block world, we devise a
training technique based on pseudo-ground truth and adversarial training. This
stands in contrast to prior work on neural rendering for view synthesis, which
requires ground truth images to estimate scene geometry and view-dependent
appearance. In addition to camera trajectory, GANcraft allows user control over
both scene semantics and output style. Experimental results with comparison to
strong baselines show the effectiveness of GANcraft on this novel task of
photorealistic 3D block world synthesis. The project website is available at
https://nvlabs.github.io/GANcraft/ .",1,0,0,0,0,0,0.974076,4.0,0.9215,71
b73783e7-39a4-4353-8890-49c08d3f4e68,Is Automated Topic Model Evaluation Broken?: The Incoherence of Coherence,91,0.323884,0.995013,"Topic model evaluation, like evaluation of other unsupervised methods, can be
contentious. However, the field has coalesced around automated estimates of
topic coherence, which rely on the frequency of word co-occurrences in a
reference corpus. Contemporary neural topic models surpass classical ones
according to these metrics. At the same time, topic model evaluation suffers
from a validation gap: automated coherence, developed for classical models, has
not been validated using human experimentation for neural models. In addition,
a meta-analysis of topic modeling literature reveals a substantial
standardization gap in automated topic modeling benchmarks. To address the
validation gap, we compare automated coherence with the two most widely
accepted human judgment tasks: topic rating and word intrusion. To address the
standardization gap, we systematically evaluate a dominant classical model and
two state-of-the-art neural models on two commonly used datasets. Automated
evaluations declare a winning model when corresponding human evaluations do
not, calling into question the validity of fully automatic evaluations
independent of human judgments.",1,0,0,0,0,1,0.116261,7.0,0.471401,107
7b2eb584-aed6-44df-8a1c-b04d4fd3e5bf,Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation,38,0.643374,0.908928,"Knowledge-grounded dialogue systems are challenging to build due to the lack
of training data and heterogeneous knowledge sources. Existing systems perform
poorly on unseen topics due to limited topics covered in the training data. In
addition, heterogeneous knowledge sources make it challenging for systems to
generalize to other tasks because knowledge sources in different knowledge
representations require different knowledge encoders. To address these
challenges, we present PLUG, a language model that homogenizes different
knowledge sources to a unified knowledge representation for knowledge-grounded
dialogue generation tasks. PLUG is pre-trained on a dialogue generation task
conditioned on a unified essential knowledge representation. It can generalize
to different downstream knowledge-grounded dialogue generation tasks with a few
training examples. The empirical evaluation on two benchmarks shows that our
model generalizes well across different knowledge-grounded tasks. It can
achieve comparable performance with state-of-the-art methods under a
fully-supervised setting and significantly outperforms other methods in
zero-shot and few-shot settings.",0,1,0,0,1,0,0.944701,5.0,0.89071,55
0030ea90-de10-44d7-b670-0e599a2ff86a,Vampire With a Brain Is a Good ITP Hammer,9,0.136298,0.833076,"Vampire has been for a long time the strongest first-order automatic theorem
prover, widely used for hammer-style proof automation in ITPs such as Mizar,
Isabelle, HOL, and Coq. In this work, we considerably improve the performance
of Vampire in hammering over the full Mizar library by enhancing its saturation
procedure with efficient neural guidance. In particular, we employ a recently
proposed recursive neural network classifying the generated clauses based only
on their derivation history. Compared to previous neural methods based on
considering the logical content of the clauses, our architecture makes
evaluating a single clause much less time consuming. The resulting system shows
good learning capability and improves on the state-of-the-art performance on
the Mizar library, while proving many theorems that the related ENIGMA system
could not prove in a similar hammering evaluation.",0,1,0,0,0,0,0.208262,10.0,0.69361,47
cecd2a69-9163-40a0-bf92-633aa593f383,DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances,10,0.201514,0.0769026,"Toxic speech, also known as hate speech, is regarded as one of the crucial
issues plaguing online social media today. Most recent work on toxic speech
detection is constrained to the modality of text and written conversations with
very limited work on toxicity detection from spoken utterances or using the
modality of speech. In this paper, we introduce a new dataset DeToxy, the first
publicly available toxicity annotated dataset for the English language. DeToxy
is sourced from various openly available speech databases and consists of over
2 million utterances. We believe that our dataset would act as a benchmark for
the relatively new and un-explored Spoken Language Processing task of detecting
toxicity from spoken utterances and boost further research in this space.
Finally, we also provide strong unimodal baselines for our dataset and compare
traditional two-step and E2E approaches. Our experiments show that in the case
of spoken utterances, text-based approaches are largely dependent on gold
human-annotated transcripts for their performance and also suffer from the
problem of keyword bias. However, the presence of speech files in DeToxy helps
facilitates the development of E2E speech models which alleviate both the
above-stated problems by better capturing speech clues.",0,1,1,1,0,0,0.865812,5.0,0.817592,45
c090aadc-8b46-439e-9606-f15bb0aa1859,Equivariant Filters for Efficient Tracking in 3D Imaging,11,0.082721,0.205444,"We demonstrate an object tracking method for 3D images with fixed
computational cost and state-of-the-art performance. Previous methods predicted
transformation parameters from convolutional layers. We instead propose an
architecture that does not include either flattening of convolutional features
or fully connected layers, but instead relies on equivariant filters to
preserve transformations between inputs and outputs (e.g. rot./trans. of inputs
rotate/translate outputs). The transformation is then derived in closed form
from the outputs of the filters. This method is useful for applications
requiring low latency, such as real-time tracking. We demonstrate our model on
synthetically augmented adult brain MRI, as well as fetal brain MRI, which is
the intended use-case.",0,1,0,0,1,0,0.360284,13.0,0.814213,22
384558e0-5d93-43d9-a7f5-19ad732a556c,Improved Loss Function-Based Prediction Method of Extreme Temperatures in Greenhouses,1,0.0153576,0.0838624,"The prediction of extreme greenhouse temperatures to which crops are
susceptible is essential in the field of greenhouse planting. It can help avoid
heat or freezing damage and economic losses. Therefore, it's important to
develop models that can predict them accurately. Due to the lack of extreme
temperature data in datasets, it is challenging for models to accurately
predict it. In this paper, we propose an improved loss function, which is
suitable for a variety of machine learning models. By increasing the weight of
extreme temperature samples and reducing the possibility of misjudging extreme
temperature as normal, the proposed loss function can enhance the prediction
results in extreme situations. To verify the effectiveness of the proposed
method, we implement the improved loss function in LightGBM, long short-term
memory, and artificial neural network and conduct experiments on a real-world
greenhouse dataset. The results show that the performance of models with the
improved loss function is enhanced compared to the original models in extreme
cases. The improved models can be used to guarantee the timely judgment of
extreme temperatures in agricultural greenhouses, thereby preventing
unnecessary losses caused by incorrect predictions.",0,1,0,0,0,0,0.120504,21.0,0.825619,29
06a23c7c-e857-4a5d-9d25-aa8ea0ed540f,PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World,60,0.7779,0.992775,"We propose PIGLeT: a model that learns physical commonsense knowledge through
interaction, and then uses this knowledge to ground language. We factorize
PIGLeT into a physical dynamics model, and a separate language model. Our
dynamics model learns not just what objects are but also what they do: glass
cups break when thrown, plastic ones don't. We then use it as the interface to
our language model, giving us a unified model of linguistic form and grounded
meaning. PIGLeT can read a sentence, simulate neurally what might happen next,
and then communicate that result through a literal symbolic representation, or
natural language.
  Experimental results show that our model effectively learns world dynamics,
along with how to communicate them. It is able to correctly forecast ""what
happens next"" given an English sentence over 80% of the time, outperforming a
100x larger, text-to-text approach by over 10%. Likewise, its natural language
summaries of physical interactions are also judged by humans as more accurate
than LM alternatives. We present comprehensive analysis showing room for future
work.",0,0,1,0,0,0,0.914326,7.0,0.898513,44
19992dcc-d135-4570-8e1a-538e34dac216,A Conditional Generative Matching Model for Multi-lingual Reply Suggestion,1,0.0744232,0.202127,"We study the problem of multilingual automated reply suggestions (RS) model
serving many languages simultaneously. Multilingual models are often challenged
by model capacity and severe data distribution skew across languages. While
prior works largely focus on monolingual models, we propose Conditional
Generative Matching models (CGM), optimized within a Variational Autoencoder
framework to address challenges arising from multi-lingual RS. CGM does so with
expressive message conditional priors, mixture densities to enhance
multi-lingual data representation, latent alignment for language
discrimination, and effective variational optimization techniques for training
multi-lingual RS. The enhancements result in performance that exceed
competitive baselines in relevance (ROUGE score) by more than 10\% on average,
and 16\% for low resource languages. CGM also shows remarkable improvements in
diversity (80\%) illustrating its expressiveness in representation of
multi-lingual data.",0,1,0,0,1,0,0.960785,6.0,0.927622,59
7183b07f-373b-4249-a653-61b90a58e045,DocOIE: A Document-level Context-Aware Dataset for OpenIE,12,0.1178,0.660276,"Open Information Extraction (OpenIE) aims to extract structured relational
tuples (subject, relation, object) from sentences and plays critical roles for
many downstream NLP applications. Existing solutions perform extraction at
sentence level, without referring to any additional contextual information. In
reality, however, a sentence typically exists as part of a document rather than
standalone; we often need to access relevant contextual information around the
sentence before we can accurately interpret it. As there is no document-level
context-aware OpenIE dataset available, we manually annotate 800 sentences from
80 documents in two domains (Healthcare and Transportation) to form a DocOIE
dataset for evaluation. In addition, we propose DocIE, a novel document-level
context-aware OpenIE model. Our experimental results based on DocIE demonstrate
that incorporating document-level context is helpful in improving OpenIE
performance. Both DocOIE dataset and DocIE model are released for public.",0,1,1,1,0,0,0.376865,8.0,0.705236,31
29ec0760-7a49-4b87-be9b-a5989931e2b5,IQDet: Instance-wise Quality Distribution Sampling for Object Detection,42,0.0370407,0.335587,"We propose a dense object detector with an instance-wise sampling strategy,
named IQDet. Instead of using human prior sampling strategies, we first extract
the regional feature of each ground-truth to estimate the instance-wise quality
distribution. According to a mixture model in spatial dimensions, the
distribution is more noise-robust and adapted to the semantic pattern of each
instance. Based on the distribution, we propose a quality sampling strategy,
which automatically selects training samples in a probabilistic manner and
trains with more high-quality samples. Extensive experiments on MS COCO show
that our method steadily improves baseline by nearly 2.4 AP without bells and
whistles. Moreover, our best model achieves 51.6 AP, outperforming all existing
state-of-the-art one-stage detectors and it is completely cost-free in
inference time.",0,1,0,0,1,0,0.406325,5.0,0.547874,23
7af2e4e6-4073-4b9a-afcd-a1314342a88c,Stereo Matching Based on Visual Sensitive Information,4,0.024462,0.146414,"The area of computer vision is one of the most discussed topics amongst many
scholars, and stereo matching is its most important sub fields. After the
parallax map is transformed into a depth map, it can be applied to many
intelligent fields. In this paper, a stereo matching algorithm based on visual
sensitive information is proposed by using standard images from Middlebury
dataset. Aiming at the limitation of traditional stereo matching algorithms
regarding the cost window, a cost aggregation algorithm based on the dynamic
window is proposed, and the disparity image is optimized by using left and
right consistency detection to further reduce the error matching rate. The
experimental results show that the proposed algorithm can effectively enhance
the stereo matching effect of the image providing significant improvement in
accuracy as compared with the classical census algorithm. The proposed model
code, dataset, and experimental results are available at
https://github.com/WangHewei16/Stereo-Matching.",1,1,0,0,0,0,0.00140819,10.0,0.182582,25
de4a1751-74a9-4f87-8953-6dbade535a61,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,25,0.414344,0.555471,"While argument mining has achieved significant success in classifying
argumentative relations between statements (support, attack, and neutral), we
have a limited computational understanding of logical mechanisms that
constitute those relations. Most recent studies rely on black-box models, which
are not as linguistically insightful as desired. On the other hand, earlier
studies use rather simple lexical features, missing logical relations between
statements. To overcome these limitations, our work classifies argumentative
relations based on four logical and theory-informed mechanisms between two
statements, namely (i) factual consistency, (ii) sentiment coherence, (iii)
causal relation, and (iv) normative relation. We demonstrate that our
operationalization of these logical mechanisms classifies argumentative
relations without directly training on data labeled with the relations,
significantly better than several unsupervised baselines. We further
demonstrate that these mechanisms also improve supervised classifiers through
representation learning.",0,0,0,0,0,0,0.591566,7.0,0.754301,57
5e827d3a-0dfb-49b1-93ad-f3bd7fcc8b03,"Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs",65,0.353259,0.783423,"Disaggregated evaluations of AI systems, in which system performance is
assessed and reported separately for different groups of people, are
conceptually simple. However, their design involves a variety of choices. Some
of these choices influence the results that will be obtained, and thus the
conclusions that can be drawn; others influence the impacts -- both beneficial
and harmful -- that a disaggregated evaluation will have on people, including
the people whose data is used to conduct the evaluation. We argue that a deeper
understanding of these choices will enable researchers and practitioners to
design careful and conclusive disaggregated evaluations. We also argue that
better documentation of these choices, along with the underlying considerations
and tradeoffs that have been made, will help others when interpreting an
evaluation's results and conclusions.",0,0,0,0,0,1,0.617641,5.0,0.670239,75
4c1a32b0-531b-4152-bd36-2dd30659844f,Joint Optimization of Multi-Objective Reinforcement Learning with Policy Gradient Based Algorithm,6,0.158636,0.172199,"Many engineering problems have multiple objectives, and the overall aim is to
optimize a non-linear function of these objectives. In this paper, we formulate
the problem of maximizing a non-linear concave function of multiple long-term
objectives. A policy-gradient based model-free algorithm is proposed for the
problem. To compute an estimate of the gradient, a biased estimator is
proposed. The proposed algorithm is shown to achieve convergence to within an
$\epsilon$ of the global optima after sampling
$\mathcal{O}(\frac{M^4\sigma^2}{(1-\gamma)^8\epsilon^4})$ trajectories where
$\gamma$ is the discount factor and $M$ is the number of the agents, thus
achieving the same dependence on $\epsilon$ as the policy gradient algorithm
for the standard reinforcement learning.",0,0,0,0,0,0,0.878887,6.0,0.85629,40
557caff8-5c81-4bde-994e-a00aecd4352b,Demonstration Informed Specification Search,2,0.073218,0.0545742,"This paper considers the problem of learning temporal task specifications,
e.g. automata and temporal logic, from expert demonstrations. Task
specifications are a class of sparse memory augmented rewards with explicit
support for temporal and Boolean composition. Three features make learning
temporal task specifications difficult: (1) the (countably) infinite number of
tasks under consideration; (2) an a-priori ignorance of what memory is needed
to encode the task; and (3) the discrete solution space - typically addressed
by (brute force) enumeration. To overcome these hurdles, we propose
Demonstration Informed Specification Search (DISS): a family of algorithms
requiring only black box access to a maximum entropy planner and a task sampler
from labeled examples. DISS then works by alternating between conjecturing
labeled examples to make the provided demonstrations less surprising and
sampling tasks consistent with the conjectured labeled examples. We provide a
concrete implementation of DISS in the context of tasks described by
Deterministic Finite Automata, and show that DISS is able to efficiently
identify tasks from only one or two expert demonstrations.",0,0,0,0,0,0,0.0896937,24.0,0.834409,24
fd157955-b83d-449e-8f0c-a6ca9ab66265,LiST: Lite Prompted Self-training Makes Parameter-Efficient Few-shot Learners,10,0.0449896,0.159554,"We present a new method LiST is short for Lite Prompted Self-Training for
parameter-efficient fine-tuning of large pre-trained language models (PLMs) for
few-shot learning. LiST improves over recent methods that adopt prompt-based
fine-tuning (FN) using two key techniques. The first is the use of
self-training to leverage large amounts of unlabeled data for prompt-based FN
in few-shot settings. We use self-training in conjunction with meta-learning
for re-weighting noisy pseudo-prompt labels. Self-training is expensive as it
requires updating all the model parameters repetitively. Therefore, we use a
second technique for light-weight fine-tuning where we introduce a small number
of task-specific parameters that are fine-tuned during self-training while
keeping the PLM encoder frozen. Our experiments show that LiST can effectively
leverage unlabeled data to improve the model performance for few-shot learning.
Additionally, the fine-tuning is efficient as it only updates a small
percentage of parameters and the overall model footprint is reduced since
several tasks can share a common PLM encoder as backbone. A comprehensive study
on six NLU tasks demonstrate LiST to improve by 35% over classic fine-tuning
and 6% over prompt-based FN with 96% reduction in number of trainable
parameters when fine-tuned with no more than 30 labeled examples from each
task. With only 14M tunable parameters, LiST outperforms GPT-3 in-context
learning by 33% on few-shot NLU tasks.",1,1,0,0,0,0,0.94336,3.0,0.815079,49
f92e7cd0-6d70-4b8c-9e7f-f2dd44939c95,Metaknowledge Extraction Based on Multi-Modal Documents,3,0.0101487,0.146544,"The triple-based knowledge in large-scale knowledge bases is most likely
lacking in structural logic and problematic of conducting knowledge hierarchy.
In this paper, we introduce the concept of metaknowledge to knowledge
engineering research for the purpose of structural knowledge construction.
Therefore, the Metaknowledge Extraction Framework and Document Structure Tree
model are presented to extract and organize metaknowledge elements (titles,
authors, abstracts, sections, paragraphs, etc.), so that it is feasible to
extract the structural knowledge from multi-modal documents. Experiment results
have proved the effectiveness of metaknowledge elements extraction by our
framework. Meanwhile, detailed examples are given to demonstrate what exactly
metaknowledge is and how to generate it. At the end of this paper, we propose
and analyze the task flow of metaknowledge applications and the associations
between knowledge and metaknowledge.",0,0,0,0,0,0,0.658631,4.0,0.615672,50
d76b0764-3a38-4b7a-a04a-3982150d2ef9,Graph Ensemble Learning over Multiple Dependency Trees for Aspect-level Sentiment Classification,49,0.30791,0.974425,"Recent work on aspect-level sentiment classification has demonstrated the
efficacy of incorporating syntactic structures such as dependency trees with
graph neural networks(GNN), but these approaches are usually vulnerable to
parsing errors. To better leverage syntactic information in the face of
unavoidable errors, we propose a simple yet effective graph ensemble technique,
GraphMerge, to make use of the predictions from differ-ent parsers. Instead of
assigning one set of model parameters to each dependency tree, we first combine
the dependency relations from different parses before applying GNNs over the
resulting graph. This allows GNN mod-els to be robust to parse errors at no
additional computational cost, and helps avoid overparameterization and
overfitting from GNN layer stacking by introducing more connectivity into the
ensemble graph. Our experiments on the SemEval 2014 Task 4 and ACL 14 Twitter
datasets show that our GraphMerge model not only outperforms models with single
dependency tree, but also beats other ensemble mod-els without adding model
parameters.",0,1,0,0,1,0,0.83444,5.0,0.795494,39
48481461-8977-488f-8bc7-5e7ad3468394,GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation,30,0.193453,0.545483,"Practical dialogue systems require robust methods of detecting out-of-scope
(OOS) utterances to avoid conversational breakdowns and related failure modes.
Directly training a model with labeled OOS examples yields reasonable
performance, but obtaining such data is a resource-intensive process. To tackle
this limited-data problem, previous methods focus on better modeling the
distribution of in-scope (INS) examples. We introduce GOLD as an orthogonal
technique that augments existing data to train better OOS detectors operating
in low-data regimes. GOLD generates pseudo-labeled candidates using samples
from an auxiliary dataset and keeps only the most beneficial candidates for
training through a novel filtering mechanism. In experiments across three
target benchmarks, the top GOLD model outperforms all existing methods on all
key metrics, achieving relative gains of 52.4%, 48.9% and 50.3% against median
baseline performance. We also analyze the unique properties of OOS data to
identify key factors for optimally applying our proposed method.",1,1,0,0,1,0,0.439712,6.0,0.640773,69
3f933d86-467d-455f-8396-1b99834d15d7,"Decision-Making Technology for Autonomous Vehicles Learning-Based Methods, Applications and Future Outlook",35,0.603251,0.872597,"Autonomous vehicles have a great potential in the application of both civil
and military fields, and have become the focus of research with the rapid
development of science and economy. This article proposes a brief review on
learning-based decision-making technology for autonomous vehicles since it is
significant for safer and efficient performance of autonomous vehicles.
Firstly, the basic outline of decision-making technology is provided. Secondly,
related works about learning-based decision-making methods for autonomous
vehicles are mainly reviewed with the comparison to classical decision-making
methods. In addition, applications of decision-making methods in existing
autonomous vehicles are summarized. Finally, promising research topics in the
future study of decision-making technology for autonomous vehicles are
prospected.",0,1,0,0,0,0,0.575511,5.0,0.647219,64
2921ea9e-62ca-487b-9e57-e1ee2af273da,Are Multilingual Models Effective in Code-Switching?,58,0.330543,0.858403,"Multilingual language models have shown decent performance in multilingual
and cross-lingual natural language understanding tasks. However, the power of
these multilingual models in code-switching tasks has not been fully explored.
In this paper, we study the effectiveness of multilingual language models to
understand their capability and adaptability to the mixed-language setting by
considering the inference speed, performance, and number of parameters to
measure their practicality. We conduct experiments in three language pairs on
named entity recognition and part-of-speech tagging and compare them with
existing methods, such as using bilingual embeddings and multilingual
meta-embeddings. Our findings suggest that pre-trained multilingual models do
not necessarily guarantee high-quality representations on code-switching, while
using meta-embeddings achieves similar results with significantly fewer
parameters.",0,1,0,0,0,0,0.260764,6.0,0.532282,51
7e7cead7-8b40-494b-bcd9-d4e3bf469736,From Universal Language Model to Downstream Task: Improving RoBERTa-Based Vietnamese Hate Speech Detection,11,0.239616,0.351364,"Natural language processing is a fast-growing field of artificial
intelligence. Since the Transformer was introduced by Google in 2017, a large
number of language models such as BERT, GPT, and ELMo have been inspired by
this architecture. These models were trained on huge datasets and achieved
state-of-the-art results on natural language understanding. However,
fine-tuning a pre-trained language model on much smaller datasets for
downstream tasks requires a carefully-designed pipeline to mitigate problems of
the datasets such as lack of training data and imbalanced data. In this paper,
we propose a pipeline to adapt the general-purpose RoBERTa language model to a
specific text classification task: Vietnamese Hate Speech Detection. We first
tune the PhoBERT on our dataset by re-training the model on the Masked Language
Model task; then, we employ its encoder for text classification. In order to
preserve pre-trained weights while learning new feature representations, we
further utilize different training techniques: layer freezing, block-wise
learning rate, and label smoothing. Our experiments proved that our proposed
pipeline boosts the performance significantly, achieving a new state-of-the-art
on Vietnamese Hate Speech Detection campaign with 0.7221 F1 score.",0,1,0,0,1,0,0.877385,10.0,0.913188,38
1c200c83-a01c-4c6b-a820-cf3436ffff3e,Heterogeneous Ensemble for ESG Ratings Prediction,12,0.142212,0.811175,"Over the past years, topics ranging from climate change to human rights have
seen increasing importance for investment decisions. Hence, investors (asset
managers and asset owners) who wanted to incorporate these issues started to
assess companies based on how they handle such topics. For this assessment,
investors rely on specialized rating agencies that issue ratings along the
environmental, social and governance (ESG) dimensions. Such ratings allow them
to make investment decisions in favor of sustainability. However, rating
agencies base their analysis on subjective assessment of sustainability
reports, not provided by every company. Furthermore, due to human labor
involved, rating agencies are currently facing the challenge to scale up the
coverage in a timely manner.
  In order to alleviate these challenges and contribute to the overall goal of
supporting sustainability, we propose a heterogeneous ensemble model to predict
ESG ratings using fundamental data. This model is based on feedforward neural
network, CatBoost and XGBoost ensemble members. Given the public availability
of fundamental data, the proposed method would allow cost-efficient and
scalable creation of initial ESG ratings (also for companies without
sustainability reporting). Using our approach we are able to explain 54% of the
variation in ratings R2 using fundamental data and outperform prior work in
this area.",0,1,0,0,1,0,0.0371047,12.0,0.59295,62
26854539-f6bf-49c1-b070-c156524a636d,Distilling Image Classifiers in Object Detectors,8,0.0780989,0.259563,"Knowledge distillation constitutes a simple yet effective way to improve the
performance of a compact student network by exploiting the knowledge of a more
powerful teacher. Nevertheless, the knowledge distillation literature remains
limited to the scenario where the student and the teacher tackle the same task.
Here, we investigate the problem of transferring knowledge not only across
architectures but also across tasks. To this end, we study the case of object
detection and, instead of following the standard detector-to-detector
distillation approach, introduce a classifier-to-detector knowledge transfer
framework. In particular, we propose strategies to exploit the classification
teacher to improve both the detector's recognition accuracy and localization
performance. Our experiments on several detectors with different backbones
demonstrate the effectiveness of our approach, allowing us to outperform the
state-of-the-art detector-to-detector distillation methods.",1,1,1,0,1,0,0.979689,8.0,0.968833,58
2928d929-9172-482c-be89-9ff660669554,Uncertainty-aware Mean Teacher for Source-free Unsupervised Domain Adaptive 3D Object Detection,20,0.0895923,0.529067,"Pseudo-label based self training approaches are a popular method for
source-free unsupervised domain adaptation. However, their efficacy depends on
the quality of the labels generated by the source trained model. These labels
may be incorrect with high confidence, rendering thresholding methods
ineffective. In order to avoid reinforcing errors caused by label noise, we
propose an uncertainty-aware mean teacher framework which implicitly filters
incorrect pseudo-labels during training. Leveraging model uncertainty allows
the mean teacher network to perform implicit filtering by down-weighing losses
corresponding uncertain pseudo-labels. Effectively, we perform automatic
soft-sampling of pseudo-labeled data while aligning predictions from the
student and teacher networks. We demonstrate our method on several domain
adaptation scenarios, from cross-dataset to cross-weather conditions, and
achieve state-of-the-art performance in these cases, on the KITTI lidar target
dataset.",1,1,0,0,1,0,0.719147,5.0,0.725904,35
c1c606b6-48ac-4862-b9c4-b77ed10f1cf4,Improving Conversational Recommendation Systems' Quality with Context-Aware Item Meta Information,23,0.355841,0.76854,"Conversational recommendation systems (CRS) engage with users by inferring
user preferences from dialog history, providing accurate recommendations, and
generating appropriate responses. Previous CRSs use knowledge graph (KG) based
recommendation modules and integrate KG with language models for response
generation. Although KG-based approaches prove effective, two issues remain to
be solved. First, KG-based approaches ignore the information in the
conversational context but only rely on entity relations and bag of words to
recommend items. Second, it requires substantial engineering efforts to
maintain KGs that model domain-specific relations, thus leading to less
flexibility. In this paper, we propose a simple yet effective architecture
comprising a pre-trained language model (PLM) and an item metadata encoder. The
encoder learns to map item metadata to embeddings that can reflect the semantic
information in the dialog context. The PLM then consumes the semantic-aligned
item embeddings together with dialog context to generate high-quality
recommendations and responses. Instead of modeling entity relations with KGs,
our model reduces engineering complexity by directly converting each item to an
embedding. Experimental results on the benchmark dataset ReDial show that our
model obtains state-of-the-art results on both recommendation and response
generation tasks.",0,1,0,0,1,0,0.869536,9.0,0.900208,36
9c7054cc-92eb-4680-a045-f348897eb0c9,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,36,0.330281,0.862294,"Retrieval-augmented generation models have shown state-of-the-art performance
across many knowledge-intensive NLP tasks such as open question answering and
fact verification. These models are trained to generate the final output given
the retrieved passages, which can be irrelevant to the original query, leading
to learning spurious cues or answer memorization. This work introduces a method
to incorporate the evidentiality of passages -- whether a passage contains
correct evidence to support the output -- into training the generator. We
introduce a multi-task learning framework to jointly generate the final output
and predict the evidentiality of each passage, leveraging a new task-agnostic
method to obtain silver evidentiality labels for supervision. Our experiments
on five datasets across three knowledge-intensive tasks show that our new
evidentiality-guided generator significantly outperforms its direct counterpart
with the same-size model and advances the state of the art on FaVIQ-Ambig. We
attribute these improvements to both the auxiliary multi-task learning and
silver evidentiality mining techniques.",1,1,0,0,1,0,0.76204,5.0,0.750436,67
792f748c-1b66-44d2-8339-88a3f9f1b8a7,Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts,22,0.175283,0.677814,"This paper investigates the model-based methods in multi-agent reinforcement
learning (MARL). We specify the dynamics sample complexity and the opponent
sample complexity in MARL, and conduct a theoretic analysis of return
discrepancy upper bound. To reduce the upper bound with the intention of low
sample complexity during the whole learning process, we propose a novel
decentralized model-based MARL method, named Adaptive Opponent-wise Rollout
Policy Optimization (AORPO). In AORPO, each agent builds its multi-agent
environment model, consisting of a dynamics model and multiple opponent models,
and trains its policy with the adaptive opponent-wise rollout. We further prove
the theoretic convergence of AORPO under reasonable assumptions. Empirical
experiments on competitive and cooperative tasks demonstrate that AORPO can
achieve improved sample efficiency with comparable asymptotic performance over
the compared MARL methods.",1,0,0,0,0,0,0.735541,6.0,0.779299,45
318b686d-2094-47de-b021-146695bd05c1,Conditional Training with Bounding Map for Universal Lesion Detection,8,0.0167432,0.105574,"Universal Lesion Detection (ULD) in computed tomography plays an essential
role in computer-aided diagnosis. Promising ULD results have been reported by
coarse-to-fine two-stage detection approaches, but such two-stage ULD methods
still suffer from issues like imbalance of positive v.s. negative anchors
during object proposal and insufficient supervision problem during localization
regression and classification of the region of interest (RoI) proposals. While
leveraging pseudo segmentation masks such as bounding map (BM) can reduce the
above issues to some degree, it is still an open problem to effectively handle
the diverse lesion shapes and sizes in ULD. In this paper, we propose a
BM-based conditional training for two-stage ULD, which can (i) reduce positive
vs. negative anchor imbalance via BM-based conditioning (BMC) mechanism for
anchor sampling instead of traditional IoU-based rule; and (ii) adaptively
compute size-adaptive BM (ABM) from lesion bounding box, which is used for
improving lesion localization accuracy via ABMsupervised segmentation.
Experiments with four state-of-the-art methods show that the proposed approach
can bring an almost free detection accuracy improvement without requiring
expensive lesion mask annotations.",0,0,0,0,0,0,0.219221,4.0,0.248517,33
ee2b6ef2-b969-4961-8f6b-99a4d464640a,Deceptive Decision-Making Under Uncertainty,6,0.0680201,0.1568,"We study the design of autonomous agents that are capable of deceiving
outside observers about their intentions while carrying out tasks in
stochastic, complex environments. By modeling the agent's behavior as a Markov
decision process, we consider a setting where the agent aims to reach one of
multiple potential goals while deceiving outside observers about its true goal.
We propose a novel approach to model observer predictions based on the
principle of maximum entropy and to efficiently generate deceptive strategies
via linear programming. The proposed approach enables the agent to exhibit a
variety of tunable deceptive behaviors while ensuring the satisfaction of
probabilistic constraints on the behavior. We evaluate the performance of the
proposed approach via comparative user studies and present a case study on the
streets of Manhattan, New York, using real travel time distributions.",0,0,0,0,0,0,0.0163569,13.0,0.560438,42
fc13c6ee-f76d-4af4-a5ba-05b0832c2015,Hyperdimensional computing as a framework for systematic aggregation of image descriptors,34,0.0894863,0.911302,"Image and video descriptors are an omnipresent tool in computer vision and
its application fields like mobile robotics. Many hand-crafted and in
particular learned image descriptors are numerical vectors with a potentially
(very) large number of dimensions. Practical considerations like memory
consumption or time for comparisons call for the creation of compact
representations. In this paper, we use hyperdimensional computing (HDC) as an
approach to systematically combine information from a set of vectors in a
single vector of the same dimensionality. HDC is a known technique to perform
symbolic processing with distributed representation in numerical vectors with
thousands of dimensions. We present a HDC implementation that is suitable for
processing the output of existing and future (deep-learning based) image
descriptors. We discuss how this can be used as a framework to process
descriptors together with additional knowledge by simple and fast vector
operations. A concrete outcome is a novel HDC-based approach to aggregate a set
of local image descriptors together with their image positions in a single
holistic descriptor. The comparison to available holistic descriptors and
aggregation methods on a series of standard mobile robotics place recognition
experiments shows a 20% improvement in average performance compared to
runner-up and 3.6x better worst-case performance.",0,0,0,0,0,0,0.0219506,11.0,0.507516,67
d188ae8d-ba70-4401-894d-1eaf1d7de9de,"Equity and Artificial Intelligence in Education: Will ""AIEd"" Amplify or Alleviate Inequities in Education?",26,0.406249,0.760799,"The development of educational AI (AIEd) systems has often been motivated by
their potential to promote educational equity and reduce achievement gaps
across different groups of learners -- for example, by scaling up the benefits
of one-on-one human tutoring to a broader audience, or by filling gaps in
existing educational services. Given these noble intentions, why might AIEd
systems have inequitable impacts in practice? In this chapter, we discuss four
lenses that can be used to examine how and why AIEd systems risk amplifying
existing inequities. Building from these lenses, we then outline possible paths
towards more equitable futures for AIEd, while highlighting debates surrounding
each proposal. In doing so, we hope to provoke new conversations around the
design of equitable AIEd, and to push ongoing conversations in the field
forward.",0,0,0,0,0,0,0.557426,6.0,0.697696,83
8f3fea97-b0ce-46cd-b2db-ebfa6ca4fec7,Restore from Restored: Single-image Inpainting,3,0.021128,0.0790689,"Recent image inpainting methods show promising results due to the power of
deep learning, which can explore external information available from a large
training dataset. However, many state-of-the-art inpainting networks are still
limited in exploiting internal information available in the given input image
at test time. To mitigate this problem, we present a novel and efficient
self-supervised fine-tuning algorithm that can adapt the parameters of fully
pre-trained inpainting networks without using ground-truth target images. We
update the parameters of the pre-trained state-of-the-art inpainting networks
by utilizing existing self-similar patches within the given input image without
changing network architecture and improve the inpainting quality by a large
margin. Qualitative and quantitative experimental results demonstrate the
superiority of the proposed algorithm, and we achieve state-of-the-art
inpainting results on publicly available numerous benchmark datasets.",0,1,0,0,1,0,0.945577,8.0,0.932381,46
b687c40a-64f0-4db1-8111-30744c37927b,Transformer over Pre-trained Transformer for Neural Text Segmentation with Enhanced Topic Coherence,30,0.537748,0.470557,"This paper proposes a transformer over transformer framework, called
Transformer$^2$, to perform neural text segmentation. It consists of two
components: bottom-level sentence encoders using pre-trained transformers, and
an upper-level transformer-based segmentation model based on the sentence
embeddings. The bottom-level component transfers the pre-trained knowledge
learned from large external corpora under both single and pair-wise supervised
NLP tasks to model the sentence embeddings for the documents. Given the
sentence embeddings, the upper-level transformer is trained to recover the
segmentation boundaries as well as the topic labels of each sentence. Equipped
with a multi-task loss and the pre-trained knowledge, Transformer$^2$ can
better capture the semantic coherence within the same segments. Our experiments
show that (1) Transformer$^2$ manages to surpass state-of-the-art text
segmentation models in terms of a commonly-used semantic coherence measure; (2)
in most cases, both single and pair-wise pre-trained knowledge contribute to
the model performance; (3) bottom-level sentence encoders pre-trained on
specific languages yield better performance than those pre-trained on specific
domains.",0,1,0,0,1,0,0.318414,14.0,0.816551,31
5a7e5a57-50fe-4454-a49d-353451cda097,"A Unified Model for Zero-shot Music Source Separation, Transcription and Synthesis",21,0.827697,0.791669,"We propose a unified model for three inter-related tasks: 1) to
\textit{separate} individual sound sources from a mixed music audio, 2) to
\textit{transcribe} each sound source to MIDI notes, and 3) to\textit{
synthesize} new pieces based on the timbre of separated sources. The model is
inspired by the fact that when humans listen to music, our minds can not only
separate the sounds of different instruments, but also at the same time
perceive high-level representations such as score and timbre. To mirror such
capability computationally, we designed a pitch-timbre disentanglement module
based on a popular encoder-decoder neural architecture for source separation.
The key inductive biases are vector-quantization for pitch representation and
pitch-transformation invariant for timbre representation. In addition, we
adopted a query-by-example method to achieve \textit{zero-shot} learning, i.e.,
the model is capable of doing source separation, transcription, and synthesis
for \textit{unseen} instruments. The current design focuses on audio mixtures
of two monophonic instruments. Experimental results show that our model
outperforms existing multi-task baselines, and the transcribed score serves as
a powerful auxiliary for separation tasks.",1,0,0,0,0,0,0.898529,6.0,0.869706,30
1edc65fd-cf75-4423-8d13-53dd056e80ba,Generalizing to New Domains by Mapping Natural Language to Lifted LTL,8,0.0114667,0.122125,"Recent work on using natural language to specify commands to robots has
grounded that language to LTL. However, mapping natural language task
specifications to LTL task specifications using language models require
probability distributions over finite vocabulary. Existing state-of-the-art
methods have extended this finite vocabulary to include unseen terms from the
input sequence to improve output generalization. However, novel
out-of-vocabulary atomic propositions cannot be generated using these methods.
To overcome this, we introduce an intermediate contextual query representation
which can be learned from single positive task specification examples,
associating a contextual query with an LTL template. We demonstrate that this
intermediate representation allows for generalization over unseen object
references, assuming accurate groundings are available. We compare our method
of mapping natural language task specifications to intermediate contextual
queries against state-of-the-art CopyNet models capable of translating natural
language to LTL, by evaluating whether correct LTL for manipulation and
navigation task specifications can be output, and show that our method
outperforms the CopyNet model on unseen object references. We demonstrate that
the grounded LTL our method outputs can be used for planning in a simulated
OO-MDP environment. Finally, we discuss some common failure modes encountered
when translating natural language task specifications to grounded LTL.",0,0,0,0,0,0,0.00134133,12.0,0.314761,16
b799f386-8b1a-4cbf-9670-bee00ca626d3,Operational Learning-based Boundary Estimation in Electromagnetic Medical Imaging,5,0.0267624,0.233539,"Incorporating boundaries of the imaging object as a priori information to
imaging algorithms can significantly improve the performance of electromagnetic
medical imaging systems. To avoid overly complicating the system by using
different sensors and the adverse effect of the subject's movement, a
learning-based method is proposed to estimate the boundary (external contour)
of the imaged object using the same electromagnetic imaging data. While imaging
techniques may discard the reflection coefficients for being dominant and
uninformative for imaging, these parameters are made use of for boundary
detection. The learned model is verified through independent clinical human
trials by using a head imaging system with a 16-element antenna array that
works across the band 0.7-1.6 GHz. The evaluation demonstrated that the model
achieves average dissimilarity of 0.012 in Hu-moment while detecting head
boundary. The model enables fast scan and image creation while eliminating the
need for additional devices for accurate boundary estimation.",0,1,0,0,0,0,0.000639427,17.0,0.472703,39
4bfaddf4-a15b-4ba6-aa8d-6eb3250d431c,"Induce, Edit, Retrieve: Language Grounded Multimodal Schema for Instructional Video Retrieval",13,0.208827,0.586721,"Schemata are structured representations of complex tasks that can aid
artificial intelligence by allowing models to break down complex tasks into
intermediate steps. We propose a novel system that induces schemata from web
videos and generalizes them to capture unseen tasks with the goal of improving
video retrieval performance. Our system proceeds in three major phases: (1)
Given a task with related videos, we construct an initial schema for a task
using a joint video-text model to match video segments with text representing
steps from wikiHow; (2) We generalize schemata to unseen tasks by leveraging
language models to edit the text within existing schemata. Through
generalization, we can allow our schemata to cover a more extensive range of
tasks with a small amount of learning data; (3) We conduct zero-shot
instructional video retrieval with the unseen task names as the queries. Our
schema-guided approach outperforms existing methods for video retrieval, and we
demonstrate that the schemata induced by our system are better than those
generated by other models.",0,1,0,0,0,0,0.783465,6.0,0.802639,59
5586297d-bc04-4903-95bc-f0453d7e4060,Meta Back-translation,22,0.0524374,0.628129,"Back-translation is an effective strategy to improve the performance of
Neural Machine Translation~(NMT) by generating pseudo-parallel data. However,
several recent works have found that better translation quality of the
pseudo-parallel data does not necessarily lead to better final translation
models, while lower-quality but more diverse data often yields stronger
results. In this paper, we propose a novel method to generate pseudo-parallel
data from a pre-trained back-translation model. Our method is a meta-learning
algorithm which adapts a pre-trained back-translation model so that the
pseudo-parallel data it generates would train a forward-translation model to do
well on a validation set. In our evaluations in both the standard datasets WMT
En-De'14 and WMT En-Fr'14, as well as a multilingual translation setting, our
method leads to significant improvements over strong baselines. Our code will
be made available.",1,1,0,0,0,1,0.387691,6.0,0.613045,37
13cd67d8-d303-4333-8ae4-1009a21b33ef,Self-Training with Weak Supervision,73,0.35306,0.908477,"State-of-the-art deep neural networks require large-scale labeled training
data that is often expensive to obtain or not available for many tasks. Weak
supervision in the form of domain-specific rules has been shown to be useful in
such settings to automatically generate weakly labeled training data. However,
learning with weak rules is challenging due to their inherent heuristic and
noisy nature. An additional challenge is rule coverage and overlap, where prior
work on weak supervision only considers instances that are covered by weak
rules, thus leaving valuable unlabeled data behind.
  In this work, we develop a weak supervision framework (ASTRA) that leverages
all the available data for a given task. To this end, we leverage task-specific
unlabeled data through self-training with a model (student) that considers
contextualized representations and predicts pseudo-labels for instances that
may not be covered by weak rules. We further develop a rule attention network
(teacher) that learns how to aggregate student pseudo-labels with weak rule
labels, conditioned on their fidelity and the underlying context of an
instance. Finally, we construct a semi-supervised learning objective for
end-to-end training with unlabeled data, domain-specific rules, and a small
amount of labeled data. Extensive experiments on six benchmark datasets for
text classification demonstrate the effectiveness of our approach with
significant improvements over state-of-the-art baselines.",1,1,0,0,1,0,0.578502,7.0,0.749187,43
6c3485fb-09b6-4d42-abd0-ceab0efb561a,TNTC: two-stream network with transformer-based complementarity for gait-based emotion recognition,13,0.125205,0.577302,"Recognizing the human emotion automatically from visual characteristics plays
a vital role in many intelligent applications. Recently, gait-based emotion
recognition, especially gait skeletons-based characteristic, has attracted much
attention, while many available methods have been proposed gradually. The
popular pipeline is to first extract affective features from joint skeletons,
and then aggregate the skeleton joint and affective features as the feature
vector for classifying the emotion. However, the aggregation procedure of these
emerged methods might be rigid, resulting in insufficiently exploiting the
complementary relationship between skeleton joint and affective features.
Meanwhile, the long range dependencies in both spatial and temporal domains of
the gait sequence are scarcely considered. To address these issues, we propose
a novel two-stream network with transformer-based complementarity, termed as
TNTC. Skeleton joint and affective features are encoded into two individual
images as the inputs of two streams, respectively. A new transformer-based
complementarity module (TCM) is proposed to bridge the complementarity between
two streams hierarchically via capturing long range dependencies. Experimental
results demonstrate TNTC outperforms state-of-the-art methods on the latest
dataset in terms of accuracy.",0,1,0,0,1,0,0.294514,5.0,0.467501,19
1b93aaf9-09ee-4884-a5e8-a5420d27c929,Scaling Up Influence Functions,62,0.197697,0.98674,"We address efficient calculation of influence functions for tracking
predictions back to the training data. We propose and analyze a new approach to
speeding up the inverse Hessian calculation based on Arnoldi iteration. With
this improvement, we achieve, to the best of our knowledge, the first
successful implementation of influence functions that scales to full-size
(language and vision) Transformer models with several hundreds of millions of
parameters. We evaluate our approach on image classification and
sequence-to-sequence tasks with tens to a hundred of millions of training
examples. Our code will be available at
https://github.com/google-research/jax-influence.",0,1,0,0,0,0,0.254409,7.0,0.594993,42
b7e3c3cc-9dcf-46c0-9d77-d88f584f7986,PLNet: Plane and Line Priors for Unsupervised Indoor Depth Estimation,19,0.247037,0.620535,"Unsupervised learning of depth from indoor monocular videos is challenging as
the artificial environment contains many textureless regions. Fortunately, the
indoor scenes are full of specific structures, such as planes and lines, which
should help guide unsupervised depth learning. This paper proposes PLNet that
leverages the plane and line priors to enhance the depth estimation. We first
represent the scene geometry using local planar coefficients and impose the
smoothness constraint on the representation. Moreover, we enforce the planar
and linear consistency by randomly selecting some sets of points that are
probably coplanar or collinear to construct simple and effective consistency
losses. To verify the proposed method's effectiveness, we further propose to
evaluate the flatness and straightness of the predicted point cloud on the
reliable planar and linear regions. The regularity of these regions indicates
quality indoor reconstruction. Experiments on NYU Depth V2 and ScanNet show
that PLNet outperforms existing methods. The code is available at
\url{https://github.com/HalleyJiang/PLNet}.",1,1,0,0,1,0,0.698832,10.0,0.857296,62
117dcb7f-14c6-4719-97f2-0f60d8ce154d,Cascaded Fast and Slow Models for Efficient Semantic Code Search,8,0.173427,0.128663,"The goal of natural language semantic code search is to retrieve a
semantically relevant code snippet from a fixed set of candidates using a
natural language query. Existing approaches are neither effective nor efficient
enough towards a practical semantic code search system. In this paper, we
propose an efficient and accurate semantic code search framework with cascaded
fast and slow models, in which a fast transformer encoder model is learned to
optimize a scalable index for fast retrieval followed by learning a slow
classification-based re-ranking model to improve the performance of the top K
results from the fast retrieval. To further reduce the high memory cost of
deploying two separate models in practice, we propose to jointly train the fast
and slow model based on a single transformer encoder with shared parameters.
The proposed cascaded approach is not only efficient and scalable, but also
achieves state-of-the-art results with an average mean reciprocal ranking (MRR)
score of 0.7795 (across 6 programming languages) as opposed to the previous
state-of-the-art result of 0.713 MRR on the CodeSearchNet benchmark.",0,1,0,0,1,0,0.991139,3.0,0.981223,24
1e830f19-4e94-4799-a832-a97013123838,Automated Seed Quality Testing System using GAN & Active Learning,2,0.0231468,0.268866,"Quality assessment of agricultural produce is a crucial step in minimizing
food stock wastage. However, this is currently done manually and often requires
expert supervision, especially in smaller seeds like corn. We propose a novel
computer vision-based system for automating this process. We build a novel seed
image acquisition setup, which captures both the top and bottom views. Dataset
collection for this problem has challenges of data annotation costs/time and
class imbalance. We address these challenges by i.) using a Conditional
Generative Adversarial Network (CGAN) to generate real-looking images for the
classes with lesser images and ii.) annotate a large dataset with minimal
expert human intervention by using a Batch Active Learning (BAL) based
annotation tool. We benchmark different image classification models on the
dataset obtained. We are able to get accuracies of up to 91.6% for testing the
physical purity of seed samples.",0,1,0,1,0,0,0.739209,5.0,0.737248,23
a5b10270-bc00-410d-b13b-e0775edfc5ad,Combined Person Classification with Airborne Optical Sectioning,13,0.186192,0.480478,"Fully autonomous drones have been demonstrated to find lost or injured
persons under strongly occluding forest canopy. Airborne Optical Sectioning
(AOS), a novel synthetic aperture imaging technique, together with
deep-learning-based classification enables high detection rates under realistic
search-and-rescue conditions. We demonstrate that false detections can be
significantly suppressed and true detections boosted by combining
classifications from multiple AOS rather than single integral images. This
improves classification rates especially in the presence of occlusion. To make
this possible, we modified the AOS imaging process to support large overlaps
between subsequent integrals, enabling real-time and on-board scanning and
processing of groundspeeds up to 10 m/s.",1,1,0,0,0,0,0.0416019,14.0,0.659437,59
9c6f0a02-4006-4409-951f-33f8583e6308,FreSaDa: A French Satire Data Set for Cross-Domain Satire Detection,7,0.0864531,0.0464226,"In this paper, we introduce FreSaDa, a French Satire Data Set, which is
composed of 11,570 articles from the news domain. In order to avoid reporting
unreasonably high accuracy rates due to the learning of characteristics
specific to publication sources, we divided our samples into training,
validation and test, such that the training publication sources are distinct
from the validation and test publication sources. This gives rise to a
cross-domain (cross-source) satire detection task. We employ two classification
methods as baselines for our new data set, one based on low-level features
(character n-grams) and one based on high-level features (average of CamemBERT
word embeddings). As an additional contribution, we present an unsupervised
domain adaptation method based on regarding the pairwise similarities (given by
the dot product) between the training samples and the validation samples as
features. By including these domain-specific features, we attain significant
improvements for both character n-grams and CamemBERT embeddings.",0,1,1,1,0,0,0.159494,8.0,0.580054,41
79cb7ed7-c281-4f94-b697-0362f2a2e5ab,Random Dilated Shapelet Transform: A New Approach for Time Series Shapelets,13,0.177025,0.373723,"Shapelet-based algorithms are widely used for time series classification
because of their ease of interpretation, but they are currently outperformed by
recent state-of-the-art approaches. We present a new formulation of time series
shapelets including the notion of dilation, and we introduce a new shapelet
feature to enhance their discriminative power for classification. Experiments
performed on 112 datasets show that our method improves on the state-of-the-art
shapelet algorithm, and achieves comparable accuracy to recent state-of-the-art
approaches, without sacrificing neither scalability, nor interpretability.",1,1,0,0,1,0,0.77237,6.0,0.797104,24
2c6dbf55-4e02-43cc-8e01-1f856b2c167d,Optimal Energy Shaping via Neural Approximators,7,0.0576072,0.214555,"We introduce optimal energy shaping as an enhancement of classical
passivity-based control methods. A promising feature of passivity theory,
alongside stability, has traditionally been claimed to be intuitive performance
tuning along the execution of a given task. However, a systematic approach to
adjust performance within a passive control framework has yet to be developed,
as each method relies on few and problem-specific practical insights. Here, we
cast the classic energy-shaping control design process in an optimal control
framework; once a task-dependent performance metric is defined, an optimal
solution is systematically obtained through an iterative procedure relying on
neural networks and gradient-based optimization. The proposed method is
validated on state-regulation tasks.",0,0,0,0,0,0,0.46521,7.0,0.703138,49
ed665413-bc9a-4ba5-acc3-78433bb2495d,LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech,61,0.370178,0.571684,"Self-Supervised Learning (SSL) using huge unlabeled data has been
successfully explored for image and natural language processing. Recent works
also investigated SSL from speech. They were notably successful to improve
performance on downstream tasks such as automatic speech recognition (ASR).
While these works suggest it is possible to reduce dependence on labeled data
for building efficient speech systems, their evaluation was mostly made on ASR
and using multiple and heterogeneous experimental settings (most of them for
English). This questions the objective comparison of SSL approaches and the
evaluation of their impact on building speech systems. In this paper, we
propose LeBenchmark: a reproducible framework for assessing SSL from speech. It
not only includes ASR (high and low resource) tasks but also spoken language
understanding, speech translation and emotion recognition. We also focus on
speech technologies in a language different than English: French. SSL models of
different sizes are trained from carefully sourced and documented datasets.
Experiments show that SSL is beneficial for most but not all tasks which
confirms the need for exhaustive and reliable benchmarks to evaluate its real
impact. LeBenchmark is shared with the scientific community for reproducible
research in SSL from speech.",0,1,0,0,0,0,0.782707,4.0,0.703387,51
08ab36e3-5b4d-4e5d-92cd-437da8c1a170,Multi-Factors Aware Dual-Attentional Knowledge Tracing,29,0.398488,0.858319,"With the increasing demands of personalized learning, knowledge tracing has
become important which traces students' knowledge states based on their
historical practices. Factor analysis methods mainly use two kinds of factors
which are separately related to students and questions to model students'
knowledge states. These methods use the total number of attempts of students to
model students' learning progress and hardly highlight the impact of the most
recent relevant practices. Besides, current factor analysis methods ignore rich
information contained in questions. In this paper, we propose Multi-Factors
Aware Dual-Attentional model (MF-DAKT) which enriches question representations
and utilizes multiple factors to model students' learning progress based on a
dual-attentional mechanism. More specifically, we propose a novel
student-related factor which records the most recent attempts on relevant
concepts of students to highlight the impact of recent exercises. To enrich
questions representations, we use a pre-training method to incorporate two
kinds of question information including questions' relation and difficulty
level. We also add a regularization term about questions' difficulty level to
restrict pre-trained question representations to fine-tuning during the process
of predicting students' performance. Moreover, we apply a dual-attentional
mechanism to differentiate contributions of factors and factor interactions to
final prediction in different practice records. At last, we conduct experiments
on several real-world datasets and results show that MF-DAKT can outperform
existing knowledge tracing methods. We also conduct several studies to validate
the effects of each component of MF-DAKT.",1,1,0,0,1,0,0.75449,12.0,0.894182,45
13a4ed34-7efb-48c2-843e-0ad9b93419d2,Camouflaged Object Segmentation with Distraction Mining,205,0.479694,0.964602,"Camouflaged object segmentation (COS) aims to identify objects that are
""perfectly"" assimilate into their surroundings, which has a wide range of
valuable applications. The key challenge of COS is that there exist high
intrinsic similarities between the candidate objects and noise background. In
this paper, we strive to embrace challenges towards effective and efficient
COS. To this end, we develop a bio-inspired framework, termed Positioning and
Focus Network (PFNet), which mimics the process of predation in nature.
Specifically, our PFNet contains two key modules, i.e., the positioning module
(PM) and the focus module (FM). The PM is designed to mimic the detection
process in predation for positioning the potential target objects from a global
perspective and the FM is then used to perform the identification process in
predation for progressively refining the coarse prediction via focusing on the
ambiguous regions. Notably, in the FM, we develop a novel distraction mining
strategy for distraction discovery and removal, to benefit the performance of
estimation. Extensive experiments demonstrate that our PFNet runs in real-time
(72 FPS) and significantly outperforms 18 cutting-edge models on three
challenging datasets under four standard metrics.",0,1,0,0,1,0,0.499936,6.0,0.670644,69
9e97201f-6f65-4d83-ab8e-05b486d7f1df,Sample Efficient Linear Meta-Learning by Alternating Minimization,17,0.0683941,0.346386,"Meta-learning synthesizes and leverages the knowledge from a given set of
tasks to rapidly learn new tasks using very little data. Meta-learning of
linear regression tasks, where the regressors lie in a low-dimensional
subspace, is an extensively-studied fundamental problem in this domain.
However, existing results either guarantee highly suboptimal estimation errors,
or require $\Omega(d)$ samples per task (where $d$ is the data dimensionality)
thus providing little gain over separately learning each task. In this work, we
study a simple alternating minimization method (MLLAM), which alternately
learns the low-dimensional subspace and the regressors. We show that, for a
constant subspace dimension MLLAM obtains nearly-optimal estimation error,
despite requiring only $\Omega(\log d)$ samples per task. However, the number
of samples required per task grows logarithmically with the number of tasks. To
remedy this in the low-noise regime, we propose a novel task subset selection
scheme that ensures the same strong statistical guarantee as MLLAM, even with
bounded number of samples per task for arbitrarily large number of tasks.",0,0,0,0,1,0,0.00985881,18.0,0.654229,37
1d340fe6-7d08-4264-8fc1-5db24afd2d4f,Path Based Hierarchical Clustering on Knowledge Graphs,2,0.0,0.0705861,"Knowledge graphs have emerged as a widely adopted medium for storing
relational data, making methods for automatically reasoning with them highly
desirable. In this paper, we present a novel approach for inducing a hierarchy
of subject clusters, building upon our earlier work done in taxonomy induction.
Our method first constructs a tag hierarchy before assigning subjects to
clusters on this hierarchy. We quantitatively demonstrate our method's ability
to induce a coherent cluster hierarchy on three real-world datasets.",1,1,0,0,0,0,0.0216336,21.0,0.741332,16
3ab67cd9-bdff-4123-9ce0-cf014b143fbf,A Fitness Landscape View on the Tuning of an Asynchronous Master-Worker EA for Nuclear Reactor Design,1,0.00136818,0.0201915,"In the context of the introduction of intermittent renewable energies, we
propose to optimize the main variables of the control rods of a nuclear power
plant to improve its capability to load-follow. The design problem is a
black-box combinatorial optimization problem with expensive evaluation based on
a multi-physics simulator. Therefore, we use a parallel asynchronous
master-worker Evolutionary Algorithm scaling up to thousand computing units.
One main issue is the tuning of the algorithm parameters. A fitness landscape
analysis is conducted on this expensive real-world problem to show that it
would be possible to tune the mutation parameters according to the low-cost
estimation of the fitness landscape features.",0,1,0,0,0,0,9.9007e-08,22.0,0.193749,23
230b68da-8758-40c5-bfeb-7ac97fde2859,Understanding Hard Negatives in Noise Contrastive Estimation,45,0.518788,0.668259,"The choice of negative examples is important in noise contrastive estimation.
Recent works find that hard negatives -- highest-scoring incorrect examples
under the model -- are effective in practice, but they are used without a
formal justification. We develop analytical tools to understand the role of
hard negatives. Specifically, we view the contrastive loss as a biased
estimator of the gradient of the cross-entropy loss, and show both
theoretically and empirically that setting the negative distribution to be the
model distribution results in bias reduction. We also derive a general form of
the score function that unifies various architectures used in text retrieval.
By combining hard negatives with appropriate score functions, we obtain strong
results on the challenging task of zero-shot entity linking.",1,0,0,0,0,0,0.971142,4.0,0.914052,40
fe36f343-ef38-41ab-90b2-0836c3821e68,Fast Graph Sampling for Short Video Summarization using Gershgorin Disc Alignment,2,0.0448514,0.13193,"We study the problem of efficiently summarizing a short video into several
keyframes, leveraging recent progress in fast graph sampling. Specifically, we
first construct a similarity path graph (SPG) $\mathcal{G}$, represented by
graph Laplacian matrix $\mathbf{L}$, where the similarities between adjacent
frames are encoded as positive edge weights. We show that maximizing the
smallest eigenvalue $\lambda_{\min}(\mathbf{B})$ of a coefficient matrix
$\mathbf{B} = \text{diag}(\mathbf{a}) + \mu \mathbf{L}$, where $\mathbf{a}$ is
the binary keyframe selection vector, is equivalent to minimizing a worst-case
signal reconstruction error. We prove that, after partitioning $\mathcal{G}$
into $Q$ sub-graphs $\{\mathcal{G}^q\}^Q_{q=1}$, the smallest Gershgorin circle
theorem (GCT) lower bound of $Q$ corresponding coefficient matrices -- $\min_q
\lambda^-_{\min}(\mathbf{B}^q)$ -- is a lower bound for
$\lambda_{\min}(\mathbf{B})$. This inspires a fast graph sampling algorithm to
iteratively partition $\mathcal{G}$ into $Q$ sub-graphs using $Q$ samples
(keyframes), while maximizing $\lambda^-_{\min}(\mathbf{B}^q)$ for each
sub-graph $\mathcal{G}^q$. Experimental results show that our algorithm
achieves comparable video summarization performance as state-of-the-art
methods, at a substantially reduced complexity.",0,0,0,0,0,0,0.342781,15.0,0.834829,27
404679ce-9f3c-4334-a5b4-9c5dbacd921d,Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds,71,0.314155,0.837574,"Current 3D single object tracking approaches track the target based on a
feature comparison between the target template and the search area. However,
due to the common occlusion in LiDAR scans, it is non-trivial to conduct
accurate feature comparisons on severe sparse and incomplete shapes. In this
work, we exploit the ground truth bounding box given in the first frame as a
strong cue to enhance the feature description of the target object, enabling a
more accurate feature comparison in a simple yet effective way. In particular,
we first propose the BoxCloud, an informative and robust representation, to
depict an object using the point-to-box relation. We further design an
efficient box-aware feature fusion module, which leverages the aforementioned
BoxCloud for reliable feature matching and embedding. Integrating the proposed
general components into an existing model P2B, we construct a superior
box-aware tracker (BAT). Experiments confirm that our proposed BAT outperforms
the previous state-of-the-art by a large margin on both KITTI and NuScenes
benchmarks, achieving a 15.2% improvement in terms of precision while running
~20% faster.",0,1,0,0,1,0,0.72264,5.0,0.727865,42
50769881-4bc6-4b54-b2f4-0cb162699fa4,UDALM: Unsupervised Domain Adaptation through Language Modeling,47,0.294016,0.710637,"In this work we explore Unsupervised Domain Adaptation (UDA) of pretrained
language models for downstream tasks. We introduce UDALM, a fine-tuning
procedure, using a mixed classification and Masked Language Model loss, that
can adapt to the target domain distribution in a robust and sample efficient
manner. Our experiments show that performance of models trained with the mixed
loss scales with the amount of available target data and the mixed loss can be
effectively used as a stopping criterion during UDA training. Furthermore, we
discuss the relationship between A-distance and the target error and explore
some limitations of the Domain Adversarial Training approach. Our method is
evaluated on twelve domain pairs of the Amazon Reviews Sentiment dataset,
yielding $91.74\%$ accuracy, which is an $1.11\%$ absolute improvement over the
state-of-the-art.",1,1,0,0,1,0,0.684928,6.0,0.75577,62
ce3741f4-c283-4e10-b068-ef9ac2fc09bb,Active Learning by Acquiring Contrastive Examples,136,0.280809,0.985551,"Common acquisition functions for active learning use either uncertainty or
diversity sampling, aiming to select difficult and diverse data points from the
pool of unlabeled data, respectively. In this work, leveraging the best of both
worlds, we propose an acquisition function that opts for selecting
\textit{contrastive examples}, i.e. data points that are similar in the model
feature space and yet the model outputs maximally different predictive
likelihoods. We compare our approach, CAL (Contrastive Active Learning), with a
diverse set of acquisition functions in four natural language understanding
tasks and seven datasets. Our experiments show that CAL performs consistently
better or equal than the best performing baseline across all tasks, on both
in-domain and out-of-domain data. We also conduct an extensive ablation study
of our method and we further analyze all actively acquired datasets showing
that CAL achieves a better trade-off between uncertainty and diversity compared
to other strategies.",1,1,1,0,1,1,0.221642,8.0,0.625818,55
e2a85c95-64b8-4cc5-b876-6928529cf0c3,Two stages for visual object tracking,1,0.00531526,0.0289097,"Siamese-based trackers have achived promising performance on visual object
tracking tasks. Most existing Siamese-based trackers contain two separate
branches for tracking, including classification branch and bounding box
regression branch. In addition, image segmentation provides an alternative way
to obetain the more accurate target region. In this paper, we propose a novel
tracker with two-stages: detection and segmentation. The detection stage is
capable of locating the target by Siamese networks. Then more accurate tracking
results are obtained by segmentation module given the coarse state estimation
in the first stage. We conduct experiments on four benchmarks. Our approach
achieves state-of-the-art results, with the EAO of 52.6$\%$ on VOT2016,
51.3$\%$ on VOT2018, and 39.0$\%$ on VOT2019 datasets, respectively.",0,1,0,0,1,0,0.922412,6.0,0.88819,26
a96463aa-4ab7-4293-b481-4824f825c511,Is Everything in Order? A Simple Way to Order Sentences,20,0.100968,0.446188,"The task of organizing a shuffled set of sentences into a coherent text has
been used to evaluate a machine's understanding of causal and temporal
relations. We formulate the sentence ordering task as a conditional
text-to-marker generation problem. We present Reorder-BART (Re-BART) that
leverages a pre-trained Transformer-based model to identify a coherent order
for a given set of shuffled sentences. The model takes a set of shuffled
sentences with sentence-specific markers as input and generates a sequence of
position markers of the sentences in the ordered text. Re-BART achieves the
state-of-the-art performance across 7 datasets in Perfect Match Ratio (PMR) and
Kendall's tau ($\tau$). We perform evaluations in a zero-shot setting,
showcasing that our model is able to generalize well across other datasets. We
additionally perform several experiments to understand the functioning and
limitations of our framework.",1,1,0,0,1,0,0.0641755,9.0,0.519712,34
