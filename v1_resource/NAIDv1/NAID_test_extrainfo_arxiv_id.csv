id,title,cites,TNCSI,TNCSI_SP,abstract,OA,is_practical,new_task,new_dataset,SOTA,is_broad,RQM,SMP,ARQ,Ref_num
http://arxiv.org/abs/2005.13156v1,MT-Adapted Datasheets for Datasets: Template and Repository,11,0.0183772,0.206388,"In this report we are taking the standardized model proposed by Gebru et al.
(2018) for documenting the popular machine translation datasets of the EuroParl
(Koehn, 2005) and News-Commentary (Barrault et al., 2019). Within this
documentation process, we have adapted the original datasheet to the particular
case of data consumers within the Machine Translation area. We are also
proposing a repository for collecting the adapted datasheets in this research
area",0,1,0,0,0,0,0.608958,3.0,0.442519,17
http://arxiv.org/abs/2006.16324v1,Universal linguistic inductive biases via meta-learning,23,0.0778299,0.403932,"How do learners acquire languages from the limited data available to them?
This process must involve some inductive biases - factors that affect how a
learner generalizes - but it is unclear which inductive biases can explain
observed patterns in language acquisition. To facilitate computational modeling
aimed at addressing this question, we introduce a framework for giving
particular linguistic inductive biases to a neural network model; such a model
can then be used to empirically explore the effects of those inductive biases.
This framework disentangles universal inductive biases, which are encoded in
the initial values of a neural network's parameters, from non-universal
factors, which the neural network must learn from data in a given language. The
initial state that encodes the inductive biases is found with meta-learning, a
technique through which a model discovers how to acquire new languages more
easily via exposure to many possible languages. By controlling the properties
of the languages that are used during meta-learning, we can control the
inductive biases that meta-learning imparts. We demonstrate this framework with
a case study based on syllable structure. First, we specify the inductive
biases that we intend to give our model, and then we translate those inductive
biases into a space of languages from which a model can meta-learn. Finally,
using existing analysis techniques, we verify that our approach has imparted
the linguistic inductive biases that it was intended to impart.",0,0,0,0,0,0,0.0142305,17.0,0.655609,37
http://arxiv.org/abs/2010.04974v1,Distilling a Deep Neural Network into a Takagi-Sugeno-Kang Fuzzy Inference System,6,0.0591655,0.113084,"Deep neural networks (DNNs) demonstrate great success in classification
tasks. However, they act as black boxes and we don't know how they make
decisions in a particular classification task. To this end, we propose to
distill the knowledge from a DNN into a fuzzy inference system (FIS), which is
Takagi-Sugeno-Kang (TSK)-type in this paper. The model has the capability to
express the knowledge acquired by a DNN based on fuzzy rules, thus explaining a
particular decision much easier. Knowledge distillation (KD) is applied to
create a TSK-type FIS that generalizes better than one directly from the
training data, which is guaranteed through experiments in this paper. To
further improve the performances, we modify the baseline method of KD and
obtain good results.",0,0,0,0,0,0,0.754725,9.0,0.858985,25
http://arxiv.org/abs/2009.07616v3,Parallel Interactive Networks for Multi-Domain Dialogue State Generation,12,0.294149,0.336597,"The dependencies between system and user utterances in the same turn and
across different turns are not fully considered in existing multidomain
dialogue state tracking (MDST) models. In this study, we argue that the
incorporation of these dependencies is crucial for the design of MDST and
propose Parallel Interactive Networks (PIN) to model these dependencies.
Specifically, we integrate an interactive encoder to jointly model the in-turn
dependencies and cross-turn dependencies. The slot-level context is introduced
to extract more expressive features for different slots. And a distributed copy
mechanism is utilized to selectively copy words from historical system
utterances or historical user utterances. Empirical studies demonstrated the
superiority of the proposed PIN model.",0,1,0,0,0,0,0.839789,9.0,0.888397,37
http://arxiv.org/abs/2012.11960v1,A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring of Answer Transcriptions in Video Job Interviews,3,0.00616166,0.0220961,"We address the task of automatically scoring the competency of candidates
based on textual features, from the automatic speech recognition (ASR)
transcriptions in the asynchronous video job interview (AVI). The key challenge
is how to construct the dependency relation between questions and answers, and
conduct the semantic level interaction for each question-answer (QA) pair.
However, most of the recent studies in AVI focus on how to represent questions
and answers better, but ignore the dependency information and interaction
between them, which is critical for QA evaluation. In this work, we propose a
Hierarchical Reasoning Graph Neural Network (HRGNN) for the automatic
assessment of question-answer pairs. Specifically, we construct a
sentence-level relational graph neural network to capture the dependency
information of sentences in or between the question and the answer. Based on
these graphs, we employ a semantic-level reasoning graph attention network to
model the interaction states of the current QA session. Finally, we propose a
gated recurrent unit encoder to represent the temporal question-answer pairs
for the final prediction. Empirical results conducted on CHNAT (a real-world
dataset) validate that our proposed model significantly outperforms
text-matching based benchmark models. Ablation studies and experimental results
with 10 random seeds also show the effectiveness and stability of our models.",0,0,0,0,1,0,0.158052,6.0,0.438419,45
http://arxiv.org/abs/2004.01387v1,A Deep Ensemble Multi-Agent Reinforcement Learning Approach for Air Traffic Control,12,0.144825,0.533495,"Air traffic control is an example of a highly challenging operational problem
that is readily amenable to human expertise augmentation via decision support
technologies. In this paper, we propose a new intelligent decision making
framework that leverages multi-agent reinforcement learning (MARL) to
dynamically suggest adjustments of aircraft speeds in real-time. The goal of
the system is to enhance the ability of an air traffic controller to provide
effective guidance to aircraft to avoid air traffic congestion, near-miss
situations, and to improve arrival timeliness. We develop a novel deep ensemble
MARL method that can concisely capture the complexity of the air traffic
control problem by learning to efficiently arbitrate between the decisions of a
local kernel-based RL model and a wider-reaching deep MARL model. The proposed
method is trained and evaluated on an open-source air traffic management
simulator developed by Eurocontrol. Extensive empirical results on a real-world
dataset including thousands of aircraft demonstrate the feasibility of using
multi-agent RL for the problem of en-route air traffic control and show that
our proposed deep ensemble MARL method significantly outperforms three
state-of-the-art benchmark approaches.",1,1,0,0,1,0,0.287016,11.0,0.755157,43
http://arxiv.org/abs/2005.12522v3,What Are People Asking About COVID-19? A Question Classification Dataset,33,0.104509,0.717213,"We present COVID-Q, a set of 1,690 questions about COVID-19 from 13 sources,
which we annotate into 15 question categories and 207 question clusters. The
most common questions in our dataset asked about transmission, prevention, and
societal effects of COVID, and we found that many questions that appeared in
multiple sources were not answered by any FAQ websites of reputable
organizations such as the CDC and FDA. We post our dataset publicly at
https://github.com/JerryWeiAI/COVID-Q. For classifying questions into 15
categories, a BERT baseline scored 58.1% accuracy when trained on 20 examples
per category, and for a question clustering task, a BERT + triplet loss
baseline achieved 49.5% accuracy. We hope COVID-Q can help either for direct
use in developing applied systems or as a domain-specific resource for model
evaluation.",0,1,0,1,0,0,0.939386,1.0,0.421332,17
http://arxiv.org/abs/2005.01244v2,NTIRE 2020 Challenge on Image and Video Deblurring,30,0.786945,0.696924,"Motion blur is one of the most common degradation artifacts in dynamic scene
photography. This paper reviews the NTIRE 2020 Challenge on Image and Video
Deblurring. In this challenge, we present the evaluation results from 3
competition tracks as well as the proposed solutions. Track 1 aims to develop
single-image deblurring methods focusing on restoration quality. On Track 2,
the image deblurring methods are executed on a mobile platform to find the
balance of the running speed and the restoration accuracy. Track 3 targets
developing video deblurring methods that exploit the temporal relation between
input frames. In each competition, there were 163, 135, and 102 registered
participants and in the final testing phase, 9, 4, and 7 teams competed. The
winning methods demonstrate the state-ofthe-art performance on image and video
deblurring tasks.",0,1,0,0,1,0,0.96978,5.0,0.928623,100
http://arxiv.org/abs/2003.10129v1,Multi-Plateau Ensemble for Endoscopic Artefact Segmentation and Detection,3,0.164475,0.123789,"Endoscopic artefact detection challenge consists of 1) Artefact detection, 2)
Semantic segmentation, and 3) Out-of-sample generalisation. For Semantic
segmentation task, we propose a multi-plateau ensemble of FPN (Feature Pyramid
Network) with EfficientNet as feature extractor/encoder. For Object detection
task, we used a three model ensemble of RetinaNet with Resnet50 Backbone and
FasterRCNN (FPN + DC5) with Resnext101 Backbone}. A PyTorch implementation to
our approach to the problem is available at
https://github.com/ubamba98/EAD2020.",1,1,0,0,0,0,0.992855,6.0,0.998034,15
http://arxiv.org/abs/2010.06060v2,BioMegatron: Larger Biomedical Domain Language Model,118,0.775084,0.745951,"There has been an influx of biomedical domain-specific language models,
showing language models pre-trained on biomedical text perform better on
biomedical domain benchmarks than those trained on general domain text corpora
such as Wikipedia and Books. Yet, most works do not study the factors affecting
each domain language application deeply. Additionally, the study of model size
on domain-specific models has been mostly missing. We empirically study and
evaluate several factors that can affect performance on domain language
applications, such as the sub-word vocabulary set, model size, pre-training
corpus, and domain transfer. We show consistent improvements on benchmarks with
our larger BioMegatron model trained on a larger domain corpus, contributing to
our understanding of domain language model applications. We demonstrate
noticeable improvements over the previous state-of-the-art (SOTA) on standard
biomedical NLP benchmarks of named entity recognition, relation extraction, and
question answering. Model checkpoints and code are available at
[https://ngc.nvidia.com] and [https://github.com/NVIDIA/NeMo].",1,1,0,0,1,0,0.985082,4.0,0.95672,27
http://arxiv.org/abs/2004.07478v1,Multi-Objective Evolutionary approach for the Performance Improvement of Learners using Ensembling Feature selection and Discretization Technique on Medical data,7,0.208641,0.174434,"Biomedical data is filled with continuous real values; these values in the
feature set tend to create problems like underfitting, the curse of
dimensionality and increase in misclassification rate because of higher
variance. In response, pre-processing techniques on dataset minimizes the side
effects and have shown success in maintaining the adequate accuracy. Feature
selection and discretization are the two necessary preprocessing steps that
were effectively employed to handle the data redundancies in the biomedical
data. However, in the previous works, the absence of unified effort by
integrating feature selection and discretization together in solving the data
redundancy problem leads to the disjoint and fragmented field. This paper
proposes a novel multi-objective based dimensionality reduction framework,
which incorporates both discretization and feature reduction as an ensemble
model for performing feature selection and discretization. Selection of optimal
features and the categorization of discretized and non-discretized features
from the feature subset is governed by the multi-objective genetic algorithm
(NSGA-II). The two objective, minimizing the error rate during the feature
selection and maximizing the information gain while discretization is
considered as fitness criteria.",0,1,0,0,0,0,0.105738,21.0,0.819006,58
http://arxiv.org/abs/2009.03782v1,Analysis and Prediction of Deforming 3D Shapes using Oriented Bounding Boxes and LSTM Autoencoders,6,0.0132951,0.202273,"For sequences of complex 3D shapes in time we present a general approach to
detect patterns for their analysis and to predict the deformation by making use
of structural components of the complex shape. We incorporate long short-term
memory (LSTM) layers into an autoencoder to create low dimensional
representations that allow the detection of patterns in the data and
additionally detect the temporal dynamics in the deformation behavior. This is
achieved with two decoders, one for reconstruction and one for prediction of
future time steps of the sequence. In a preprocessing step the components of
the studied object are converted to oriented bounding boxes which capture the
impact of plastic deformation and allow reducing the dimensionality of the data
describing the structure. The architecture is tested on the results of 196 car
crash simulations of a model with 133 different components, where material
properties are varied. In the latent representation we can detect patterns in
the plastic deformation for the different components. The predicted bounding
boxes give an estimate of the final simulation result and their quality is
improved in comparison to different baselines.",0,0,0,0,0,0,0.00764085,12.0,0.460012,31
http://arxiv.org/abs/2004.06627v3,An Application of Deep Reinforcement Learning to Algorithmic Trading,116,0.325194,0.977655,"This scientific research paper presents an innovative approach based on deep
reinforcement learning (DRL) to solve the algorithmic trading problem of
determining the optimal trading position at any point in time during a trading
activity in stock markets. It proposes a novel DRL trading strategy so as to
maximise the resulting Sharpe ratio performance indicator on a broad range of
stock markets. Denominated the Trading Deep Q-Network algorithm (TDQN), this
new trading strategy is inspired from the popular DQN algorithm and
significantly adapted to the specific algorithmic trading problem at hand. The
training of the resulting reinforcement learning (RL) agent is entirely based
on the generation of artificial trajectories from a limited set of stock market
historical data. In order to objectively assess the performance of trading
strategies, the research paper also proposes a novel, more rigorous performance
assessment methodology. Following this new performance assessment approach,
promising results are reported for the TDQN strategy.",1,1,0,0,0,0,0.18556,10.0,0.680706,48
http://arxiv.org/abs/2004.13513v3,PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning,487,0.860329,1.0,"Lifelong learning has attracted much attention, but existing works still
struggle to fight catastrophic forgetting and accumulate knowledge over long
stretches of incremental learning. In this work, we propose PODNet, a model
inspired by representation learning. By carefully balancing the compromise
between remembering the old classes and learning new ones, PODNet fights
catastrophic forgetting, even over very long runs of small incremental tasks
--a setting so far unexplored by current works. PODNet innovates on existing
art with an efficient spatial-based distillation-loss applied throughout the
model and a representation comprising multiple proxy vectors for each class. We
validate those innovations thoroughly, comparing PODNet with three
state-of-the-art models on three datasets: CIFAR100, ImageNet100, and
ImageNet1000. Our results showcase a significant advantage of PODNet over
existing art, with accuracy gains of 12.10, 6.51, and 2.85 percentage points,
respectively. Code is available at
https://github.com/arthurdouillard/incremental_learning.pytorch",1,0,0,0,1,0,0.915253,7.0,0.899143,40
http://arxiv.org/abs/2001.03893v1,Complementary Network with Adaptive Receptive Fields for Melanoma Segmentation,13,0.387584,0.106923,"Automatic melanoma segmentation in dermoscopic images is essential in
computer-aided diagnosis of skin cancer. Existing methods may suffer from the
hole and shrink problems with limited segmentation performance. To tackle these
issues, we propose a novel complementary network with adaptive receptive filed
learning. Instead of regarding the segmentation task independently, we
introduce a foreground network to detect melanoma lesions and a background
network to mask non-melanoma regions. Moreover, we propose adaptive atrous
convolution (AAC) and knowledge aggregation module (KAM) to fill holes and
alleviate the shrink problems. AAC explicitly controls the receptive field at
multiple scales and KAM convolves shallow feature maps by dilated convolutions
with adaptive receptive fields, which are adjusted according to deep feature
maps. In addition, a novel mutual loss is proposed to utilize the dependency
between the foreground and background networks, thereby enabling the
reciprocally influence within these two networks. Consequently, this mutual
training strategy enables the semi-supervised learning and improve the
boundary-sensitivity. Training with Skin Imaging Collaboration (ISIC) 2018 skin
lesion segmentation dataset, our method achieves a dice co-efficient of 86.4%
and shows better performance compared with state-of-the-art melanoma
segmentation methods.",1,1,0,0,1,0,0.992662,6.0,0.997133,8
http://arxiv.org/abs/2010.07785v1,Response Selection for Multi-Party Conversations with Dynamic Topic Tracking,39,0.131214,0.831651,"While participants in a multi-party multi-turn conversation simultaneously
engage in multiple conversation topics, existing response selection methods are
developed mainly focusing on a two-party single-conversation scenario. Hence,
the prolongation and transition of conversation topics are ignored by current
methods. In this work, we frame response selection as a dynamic topic tracking
task to match the topic between the response and relevant conversation context.
With this new formulation, we propose a novel multi-task learning framework
that supports efficient encoding through large pretrained models with only two
utterances at once to perform dynamic topic disentanglement and response
selection. We also propose Topic-BERT an essential pretraining step to embed
topic information into BERT with self-supervised learning. Experimental results
on the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response
selection and topic disentanglement tasks outperforming existing methods by a
good margin.",1,1,1,0,1,0,0.229376,5.0,0.409124,44
http://arxiv.org/abs/2010.01678v2,Optimal Neural Program Synthesis from Multimodal Specifications,17,0.142359,0.260493,"Multimodal program synthesis, which leverages different types of user input
to synthesize a desired program, is an attractive way to scale program
synthesis to challenging settings; however, it requires integrating noisy
signals from the user, like natural language, with hard constraints on the
program's behavior. This paper proposes an optimal neural synthesis approach
where the goal is to find a program that satisfies user-provided constraints
while also maximizing the program's score with respect to a neural model.
Specifically, we focus on multimodal synthesis tasks in which the user intent
is expressed using a combination of natural language (NL) and input-output
examples. At the core of our method is a top-down recurrent neural model that
places distributions over abstract syntax trees conditioned on the NL input.
This model not only allows for efficient search over the space of syntactically
valid programs, but it allows us to leverage automated program analysis
techniques for pruning the search space based on infeasibility of partial
programs with respect to the user's constraints. The experimental results on a
multimodal synthesis dataset (StructuredRegex) show that our method
substantially outperforms prior state-of-the-art techniques in terms of
accuracy and efficiency, and finds model-optimal programs more frequently.",0,0,0,0,1,0,0.441328,8.0,0.731201,48
http://arxiv.org/abs/2012.14905v4,Meta Learning Backpropagation And Improving It,52,0.192452,0.650729,"Many concepts have been proposed for meta learning with neural networks
(NNs), e.g., NNs that learn to reprogram fast weights, Hebbian plasticity,
learned learning rules, and meta recurrent NNs. Our Variable Shared Meta
Learning (VSML) unifies the above and demonstrates that simple weight-sharing
and sparsity in an NN is sufficient to express powerful learning algorithms
(LAs) in a reusable fashion. A simple implementation of VSML where the weights
of a neural network are replaced by tiny LSTMs allows for implementing the
backpropagation LA solely by running in forward-mode. It can even meta learn
new LAs that differ from online backpropagation and generalize to datasets
outside of the meta training distribution without explicit gradient
calculation. Introspection reveals that our meta learned LAs learn through fast
association in a way that is qualitatively different from gradient descent.",0,0,0,0,0,0,0.253018,7.0,0.594083,63
http://arxiv.org/abs/2009.04091v1,Deep Metric Learning Meets Deep Clustering: An Novel Unsupervised Approach for Feature Embedding,10,0.042818,0.162289,"Unsupervised Deep Distance Metric Learning (UDML) aims to learn sample
similarities in the embedding space from an unlabeled dataset. Traditional UDML
methods usually use the triplet loss or pairwise loss which requires the mining
of positive and negative samples w.r.t. anchor data points. This is, however,
challenging in an unsupervised setting as the label information is not
available. In this paper, we propose a new UDML method that overcomes that
challenge. In particular, we propose to use a deep clustering loss to learn
centroids, i.e., pseudo labels, that represent semantic classes. During
learning, these centroids are also used to reconstruct the input samples. It
hence ensures the representativeness of centroids - each centroid represents
visually similar samples. Therefore, the centroids give information about
positive (visually similar) and negative (visually dissimilar) samples. Based
on pseudo labels, we propose a novel unsupervised metric loss which enforces
the positive concentration and negative separation of samples in the embedding
space. Experimental results on benchmarking datasets show that the proposed
approach outperforms other UDML methods.",0,0,0,0,0,0,0.640632,10.0,0.84137,55
http://arxiv.org/abs/2007.15813v1,Language Modelling for Source Code with Transformer-XL,8,0.0370432,0.100889,"It has been found that software, like natural language texts, exhibits
""naturalness"", which can be captured by statistical language models. In recent
years, neural language models have been proposed to represent the naturalness
of software through deep learning. In this paper, we conduct an experimental
evaluation of state-of-the-art neural language models for source code,
including RNN-based models and Transformer-XL based models. Through experiments
on a large-scale Python code corpus, we find that the Transformer-XL model
outperforms RNN-based models (including LSTM and GRU models) in capturing the
naturalness of software, with far less computational cost.",1,1,0,0,1,0,0.40259,9.0,0.747474,35
http://arxiv.org/abs/2005.09496v1,RoadText-1K: Text Detection & Recognition Dataset for Driving Videos,44,0.156411,0.72002,"Perceiving text is crucial to understand semantics of outdoor scenes and
hence is a critical requirement to build intelligent systems for driver
assistance and self-driving. Most of the existing datasets for text detection
and recognition comprise still images and are mostly compiled keeping text in
mind. This paper introduces a new ""RoadText-1K"" dataset for text in driving
videos. The dataset is 20 times larger than the existing largest dataset for
text in videos. Our dataset comprises 1000 video clips of driving without any
bias towards text and with annotations for text bounding boxes and
transcriptions in every frame. State of the art methods for text detection,
recognition and tracking are evaluated on the new dataset and the results
signify the challenges in unconstrained driving videos compared to existing
datasets. This suggests that RoadText-1K is suited for research and development
of reading systems, robust enough to be incorporated into more complex
downstream tasks like driver assistance and self-driving. The dataset can be
found at http://cvit.iiit.ac.in/research/projects/cvit-projects/roadtext-1k",0,1,1,1,0,0,0.0460388,9.0,0.481752,50
http://arxiv.org/abs/2001.11591v2,Scalable and Customizable Benchmark Problems for Many-Objective Optimization,24,0.105648,0.633756,"Solving many-objective problems (MaOPs) is still a significant challenge in
the multi-objective optimization (MOO) field. One way to measure algorithm
performance is through the use of benchmark functions (also called test
functions or test suites), which are artificial problems with a well-defined
mathematical formulation, known solutions and a variety of features and
difficulties. In this paper we propose a parameterized generator of scalable
and customizable benchmark problems for MaOPs. It is able to generate problems
that reproduce features present in other benchmarks and also problems with some
new features. We propose here the concept of generative benchmarking, in which
one can generate an infinite number of MOO problems, by varying parameters that
control specific features that the problem should have: scalability in the
number of variables and objectives, bias, deceptiveness, multimodality, robust
and non-robust solutions, shape of the Pareto front, and constraints. The
proposed Generalized Position-Distance (GPD) tunable benchmark generator uses
the position-distance paradigm, a basic approach to building test functions,
used in other benchmarks such as Deb, Thiele, Laumanns and Zitzler (DTLZ),
Walking Fish Group (WFG) and others. It includes scalable problems in any
number of variables and objectives and it presents Pareto fronts with different
characteristics. The resulting functions are easy to understand and visualize,
easy to implement, fast to compute and their Pareto optimal solutions are
known.",0,0,0,1,0,0,0.162584,7.0,0.523059,60
http://arxiv.org/abs/2006.08818v1,Explaining reputation assessments,5,0.0766586,0.120162,"Reputation is crucial to enabling human or software agents to select among
alternative providers. Although several effective reputation assessment methods
exist, they typically distil reputation into a numerical representation, with
no accompanying explanation of the rationale behind the assessment. Such
explanations would allow users or clients to make a richer assessment of
providers, and tailor selection according to their preferences and current
context. In this paper, we propose an approach to explain the rationale behind
assessments from quantitative reputation models, by generating arguments that
are combined to form explanations. Our approach adapts, extends and combines
existing approaches for explaining decisions made using multi-attribute
decision models in the context of reputation. We present example argument
templates, and describe how to select their parameters using explanation
algorithms. Our proposal was evaluated by means of a user study, which followed
an existing protocol. Our results give evidence that although explanations
present a subset of the information of trust scores, they are sufficient to
equally evaluate providers recommended based on their trust score. Moreover,
when explanation arguments reveal implicit model information, they are less
persuasive than scores.",0,0,0,0,0,0,0.0269448,25.0,0.791609,41
http://arxiv.org/abs/2012.05545v2,Image Captioning with Context-Aware Auxiliary Guidance,23,0.0873986,0.318292,"Image captioning is a challenging computer vision task, which aims to
generate a natural language description of an image. Most recent researches
follow the encoder-decoder framework which depends heavily on the previous
generated words for the current prediction. Such methods can not effectively
take advantage of the future predicted information to learn complete semantics.
In this paper, we propose Context-Aware Auxiliary Guidance (CAAG) mechanism
that can guide the captioning model to perceive global contexts. Upon the
captioning model, CAAG performs semantic attention that selectively
concentrates on useful information of the global predictions to reproduce the
current generation. To validate the adaptability of the method, we apply CAAG
to three popular captioners and our proposal achieves competitive performance
on the challenging Microsoft COCO image captioning benchmark, e.g. 132.2
CIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official
online evaluation server.",0,1,0,0,0,1,0.490346,9.0,0.777341,44
http://arxiv.org/abs/2012.06131v2,Learning Omni-frequency Region-adaptive Representations for Real Image Super-Resolution,28,0.0899734,0.573891,"Traditional single image super-resolution (SISR) methods that focus on
solving single and uniform degradation (i.e., bicubic down-sampling), typically
suffer from poor performance when applied into real-world low-resolution (LR)
images due to the complicated realistic degradations. The key to solving this
more challenging real image super-resolution (RealSR) problem lies in learning
feature representations that are both informative and content-aware. In this
paper, we propose an Omni-frequency Region-adaptive Network (ORNet) to address
both challenges, here we call features of all low, middle and high frequencies
omni-frequency features. Specifically, we start from the frequency perspective
and design a Frequency Decomposition (FD) module to separate different
frequency components to comprehensively compensate the information lost for
real LR image. Then, considering the different regions of real LR image have
different frequency information lost, we further design a Region-adaptive
Frequency Aggregation (RFA) module by leveraging dynamic convolution and
spatial attention to adaptively restore frequency components for different
regions. The extensive experiments endorse the effective, and scenario-agnostic
nature of our OR-Net for RealSR.",0,0,0,0,0,0,0.659238,5.0,0.692869,40
http://arxiv.org/abs/2006.07845v2,Towards Gender-Neutral Face Descriptors for Mitigating Bias in Face Recognition,12,0.023074,0.283927,"State-of-the-art deep networks implicitly encode gender information while
being trained for face recognition. Gender is often viewed as an important
attribute with respect to identifying faces. However, the implicit encoding of
gender information in face descriptors has two major issues: (a.) It makes the
descriptors susceptible to privacy leakage, i.e. a malicious agent can be
trained to predict the face gender from such descriptors. (b.) It appears to
contribute to gender bias in face recognition, i.e. we find a significant
difference in the recognition accuracy of DCNNs on male and female faces.
Therefore, we present a novel `Adversarial Gender De-biasing algorithm
(AGENDA)' to reduce the gender information present in face descriptors obtained
from previously trained face recognition networks. We show that AGENDA
significantly reduces gender predictability of face descriptors. Consequently,
we are also able to reduce gender bias in face verification while maintaining
reasonable recognition performance.",0,1,0,0,0,0,0.237747,5.0,0.417337,47
http://arxiv.org/abs/2006.10742v2,Learning Invariant Representations for Reinforcement Learning without Reconstruction,379,0.3532,0.89826,"We study how representation learning can accelerate reinforcement learning
from rich observations, such as images, without relying either on domain
knowledge or pixel-reconstruction. Our goal is to learn representations that
both provide for effective downstream control and invariance to task-irrelevant
details. Bisimulation metrics quantify behavioral similarity between states in
continuous MDPs, which we propose using to learn robust latent representations
which encode only the task-relevant information from observations. Our method
trains encoders such that distances in latent space equal bisimulation
distances in state space. We demonstrate the effectiveness of our method at
disregarding task-irrelevant information using modified visual MuJoCo tasks,
where the background is replaced with moving distractors and natural videos,
while achieving SOTA performance. We also test a first-person highway driving
task where our method learns invariance to clouds, weather, and time of day.
Finally, we provide generalization results drawn from properties of
bisimulation metrics, and links to causal inference.",0,1,0,0,1,0,0.26382,5.0,0.441462,39
http://arxiv.org/abs/2007.06267v2,BoxE: A Box Embedding Model for Knowledge Base Completion,130,0.871713,0.998257,"Knowledge base completion (KBC) aims to automatically infer missing facts by
exploiting information already present in a knowledge base (KB). A promising
approach for KBC is to embed knowledge into latent spaces and make predictions
from learned embeddings. However, existing embedding models are subject to at
least one of the following limitations: (1) theoretical inexpressivity, (2)
lack of support for prominent inference patterns (e.g., hierarchies), (3) lack
of support for KBC over higher-arity relations, and (4) lack of support for
incorporating logical rules. Here, we propose a spatio-translational embedding
model, called BoxE, that simultaneously addresses all these limitations. BoxE
embeds entities as points, and relations as a set of hyper-rectangles (or
boxes), which spatially characterize basic logical properties. This seemingly
simple abstraction yields a fully expressive model offering a natural encoding
for many desired logical properties. BoxE can both capture and inject rules
from rich classes of rule languages, going well beyond individual inference
patterns. By design, BoxE naturally applies to higher-arity KBs. We conduct a
detailed experimental analysis, and show that BoxE achieves state-of-the-art
performance, both on benchmark knowledge graphs and on more general KBs, and we
empirically show the power of integrating logical rules.",0,0,0,0,1,0,0.815921,8.0,0.864588,49
http://arxiv.org/abs/2001.06988v2,Deep learning generates custom-made logistic regression models for explaining how breast cancer subtypes are classified,3,0.0691437,0.187778,"Differentiating the intrinsic subtypes of breast cancer is crucial for
deciding the best treatment strategy. Deep learning can predict the subtypes
from genetic information more accurately than conventional statistical methods,
but to date, deep learning has not been directly utilized to examine which
genes are associated with which subtypes. To clarify the mechanisms embedded in
the intrinsic subtypes, we developed an explainable deep learning model called
a point-wise linear (PWL) model that generates a custom-made logistic
regression for each patient. Logistic regression, which is familiar to both
physicians and medical informatics researchers, allows us to analyze the
importance of the feature variables, and the PWL model harnesses these
practical abilities of logistic regression. In this study, we show that
analyzing breast cancer subtypes is clinically beneficial for patients and one
of the best ways to validate the capability of the PWL model. First, we trained
the PWL model with RNA-seq data to predict PAM50 intrinsic subtypes and applied
it to the 41/50 genes of PAM50 through the subtype prediction task. Second, we
developed a deep enrichment analysis method to reveal the relationships between
the PAM50 subtypes and the copy numbers of breast cancer. Our findings showed
that the PWL model utilized genes relevant to the cell cycle-related pathways.
These preliminary successes in breast cancer subtype analysis demonstrate the
potential of our analysis strategy to clarify the mechanisms underlying breast
cancer and improve overall clinical outcomes.",0,1,0,0,0,0,0.759177,13.0,0.903371,63
http://arxiv.org/abs/2009.11278v1,"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers",90,0.937006,0.72156,"Mirroring the success of masked language models, vision-and-language
counterparts like ViLBERT, LXMERT and UNITER have achieved state of the art
performance on a variety of multimodal discriminative tasks like visual
question answering and visual grounding. Recent work has also successfully
adapted such models towards the generative task of image captioning. This begs
the question: Can these models go the other way and generate images from pieces
of text? Our analysis of a popular representative from this model family -
LXMERT - finds that it is unable to generate rich and semantically meaningful
imagery with its current training setup. We introduce X-LXMERT, an extension to
LXMERT with training refinements including: discretizing visual
representations, using uniform masking with a large range of masking ratios and
aligning the right pre-training datasets to the right objectives which enables
it to paint. X-LXMERT's image generation capabilities rival state of the art
generative models while its question answering and captioning abilities remains
comparable to LXMERT. Finally, we demonstrate the generality of these training
refinements by adding image generation capabilities into UNITER to produce
X-UNITER.",1,1,0,0,0,0,0.987632,5.0,0.974099,74
http://arxiv.org/abs/2009.02978v2,Light Field View Synthesis via Aperture Disparity and Warping Confidence Map,19,0.196013,0.48776,"This paper presents a learning-based approach to synthesize the view from an
arbitrary camera position given a sparse set of images. A key challenge for
this novel view synthesis arises from the reconstruction process, when the
views from different input images may not be consistent due to obstruction in
the light path. We overcome this by jointly modeling the epipolar property and
occlusion in designing a convolutional neural network. We start by defining and
computing the aperture disparity map, which approximates the parallax and
measures the pixel-wise shift between two views. While this relates to
free-space rendering and can fail near the object boundaries, we further
develop a warping confidence map to address pixel occlusion in these
challenging regions. The proposed method is evaluated on diverse real-world and
synthetic light field scenes, and it shows better performance over several
state-of-the-art techniques.",0,1,0,0,1,0,0.33895,9.0,0.723166,67
http://arxiv.org/abs/2004.13270v1,Assessing the Bilingual Knowledge Learned by Neural Machine Translation Models,5,0.0123388,0.124167,"Machine translation (MT) systems translate text between different languages
by automatically learning in-depth knowledge of bilingual lexicons, grammar and
semantics from the training examples. Although neural machine translation (NMT)
has led the field of MT, we have a poor understanding on how and why it works.
In this paper, we bridge the gap by assessing the bilingual knowledge learned
by NMT models with phrase table -- an interpretable table of bilingual
lexicons. We extract the phrase table from the training examples that an NMT
model correctly predicts. Extensive experiments on widely-used datasets show
that the phrase table is reasonable and consistent against language pairs and
random seeds. Equipped with the interpretable phrase table, we find that NMT
models learn patterns from simple to complex and distill essential bilingual
knowledge from the training examples. We also revisit some advances that
potentially affect the learning of bilingual knowledge (e.g.,
back-translation), and report some interesting findings. We believe this work
opens a new angle to interpret NMT with statistic models, and provides
empirical supports for recent advances in improving NMT models.",0,0,0,0,0,0,0.283287,7.0,0.613027,54
http://arxiv.org/abs/2010.15067v1,Graph-based Topic Extraction from Vector Embeddings of Text Documents: Application to a Corpus of News Articles,7,0.0186994,0.243558,"Production of news content is growing at an astonishing rate. To help manage
and monitor the sheer amount of text, there is an increasing need to develop
efficient methods that can provide insights into emerging content areas, and
stratify unstructured corpora of text into `topics' that stem intrinsically
from content similarity. Here we present an unsupervised framework that brings
together powerful vector embeddings from natural language processing with tools
from multiscale graph partitioning that can reveal natural partitions at
different resolutions without making a priori assumptions about the number of
clusters in the corpus. We show the advantages of graph-based clustering
through end-to-end comparisons with other popular clustering and topic
modelling methods, and also evaluate different text vector embeddings, from
classic Bag-of-Words to Doc2Vec to the recent transformers based model Bert.
This comparative work is showcased through an analysis of a corpus of US news
coverage during the presidential election year of 2016.",0,1,0,0,0,1,0.0394307,15.0,0.678493,27
http://arxiv.org/abs/2012.10074v1,Mention Extraction and Linking for SQL Query Generation,25,0.264173,0.67589,"On the WikiSQL benchmark, state-of-the-art text-to-SQL systems typically take
a slot-filling approach by building several dedicated models for each type of
slots. Such modularized systems are not only complex butalso of limited
capacity for capturing inter-dependencies among SQL clauses. To solve these
problems, this paper proposes a novel extraction-linking approach, where a
unified extractor recognizes all types of slot mentions appearing in the
question sentence before a linker maps the recognized columns to the table
schema to generate executable SQL queries. Trained with automatically generated
annotations, the proposed method achieves the first place on the WikiSQL
benchmark.",0,1,0,0,1,0,0.942939,6.0,0.907109,30
http://arxiv.org/abs/2003.09288v2,FedNER: Privacy-preserving Medical Named Entity Recognition with Federated Learning,49,0.520303,0.847974,"Medical named entity recognition (NER) has wide applications in intelligent
healthcare. Sufficient labeled data is critical for training accurate medical
NER model. However, the labeled data in a single medical platform is usually
limited. Although labeled datasets may exist in many different medical
platforms, they cannot be directly shared since medical data is highly
privacy-sensitive. In this paper, we propose a privacy-preserving medical NER
method based on federated learning, which can leverage the labeled data in
different platforms to boost the training of medical NER model and remove the
need of exchanging raw data among different platforms. Since the labeled data
in different platforms usually has some differences in entity type and
annotation criteria, instead of constraining different platforms to share the
same model, we decompose the medical NER model in each platform into a shared
module and a private module. The private module is used to capture the
characteristics of the local data in each platform, and is updated using local
labeled data. The shared module is learned across different medical platform to
capture the shared NER knowledge. Its local gradients from different platforms
are aggregated to update the global shared module, which is further delivered
to each platform to update their local shared modules. Experiments on three
publicly available datasets validate the effectiveness of our method.",0,1,0,0,0,0,0.603368,9.0,0.812481,36
http://arxiv.org/abs/2012.06434v2,Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations,40,0.34715,0.48802,"Neural implicit functions have emerged as a powerful representation for
surfaces in 3D. Such a function can encode a high quality surface with
intricate details into the parameters of a deep neural network. However,
optimizing for the parameters for accurate and robust reconstructions remains a
challenge, especially when the input data is noisy or incomplete. In this work,
we develop a hybrid neural surface representation that allows us to impose
geometry-aware sampling and regularization, which significantly improves the
fidelity of reconstructions. We propose to use \emph{iso-points} as an explicit
representation for a neural implicit function. These points are computed and
updated on-the-fly during training to capture important geometric features and
impose geometric constraints on the optimization. We demonstrate that our
method can be adopted to improve state-of-the-art techniques for reconstructing
neural implicit surfaces from multi-view images or point clouds. Quantitative
and qualitative evaluations show that, compared with existing sampling and
optimization methods, our approach allows faster convergence, better
generalization, and accurate recovery of details and topology.",0,1,0,0,0,0,0.909358,5.0,0.853276,55
http://arxiv.org/abs/2010.11085v1,NeuSpell: A Neural Spelling Correction Toolkit,55,0.820103,0.832819,"We introduce NeuSpell, an open-source toolkit for spelling correction in
English. Our toolkit comprises ten different models, and benchmarks them on
naturally occurring misspellings from multiple sources. We find that many
systems do not adequately leverage the context around the misspelt token. To
remedy this, (i) we train neural models using spelling errors in context,
synthetically constructed by reverse engineering isolated misspellings; and
(ii) use contextual representations. By training on our synthetic examples,
correction rates improve by 9% (absolute) compared to the case when models are
trained on randomly sampled character perturbations. Using richer contextual
representations boosts the correction rate by another 3%. Our toolkit enables
practitioners to use our proposed and existing spelling correction systems,
both via a unified command line, as well as a web interface. Among many
potential applications, we demonstrate the utility of our spell-checkers in
combating adversarial misspellings. The toolkit can be accessed at
neuspell.github.io. Code and pretrained models are available at
http://github.com/neuspell/neuspell.",1,1,0,0,1,0,0.944829,9.0,0.939372,25
http://arxiv.org/abs/2006.16309v2,Adversarial Learning for Debiasing Knowledge Graph Embeddings,29,0.24269,0.54722,"Knowledge Graphs (KG) are gaining increasing attention in both academia and
industry. Despite their diverse benefits, recent research have identified
social and cultural biases embedded in the representations learned from KGs.
Such biases can have detrimental consequences on different population and
minority groups as applications of KG begin to intersect and interact with
social spheres. This paper aims at identifying and mitigating such biases in
Knowledge Graph (KG) embeddings. As a first step, we explore popularity bias --
the relationship between node popularity and link prediction accuracy. In case
of node2vec graph embeddings, we find that prediction accuracy of the embedding
is negatively correlated with the degree of the node. However, in case of
knowledge-graph embeddings (KGE), we observe an opposite trend. As a second
step, we explore gender bias in KGE, and a careful examination of popular KGE
algorithms suggest that sensitive attribute like the gender of a person can be
predicted from the embedding. This implies that such biases in popular KGs is
captured by the structural properties of the embedding. As a preliminary
solution to debiasing KGs, we introduce a novel framework to filter out the
sensitive attribute information from the KG embeddings, which we call FAN
(Filtering Adversarial Network). We also suggest the applicability of FAN for
debiasing other network embeddings which could be explored in future work.",0,0,0,0,0,0,0.33315,11.0,0.77156,29
http://arxiv.org/abs/2011.08090v1,Explainable Artificial Intelligence Recommendation System by Leveraging the Semantics of Adverse Childhood Experiences: Proof-of-Concept Prototype Development,27,0.151385,0.542446,"The study of adverse childhood experiences and their consequences has emerged
over the past 20 years. In this study, we aimed to leverage explainable
artificial intelligence, and propose a proof-of-concept prototype for a
knowledge-driven evidence-based recommendation system to improve surveillance
of adverse childhood experiences. We used concepts from an ontology that we
have developed to build and train a question-answering agent using the Google
DialogFlow engine. In addition to the question-answering agent, the initial
prototype includes knowledge graph generation and recommendation components
that leverage third-party graph technology. To showcase the framework
functionalities, we here present a prototype design and demonstrate the main
features through four use case scenarios motivated by an initiative currently
implemented at a children hospital in Memphis, Tennessee. Ongoing development
of the prototype requires implementing an optimization algorithm of the
recommendations, incorporating a privacy layer through a personal health
library, and conducting a clinical trial to assess both usability and
usefulness of the implementation. This semantic-driven explainable artificial
intelligence prototype can enhance health care practitioners ability to provide
explanations for the decisions they make.",0,1,0,0,0,0,0.28032,5.0,0.455742,25
http://arxiv.org/abs/2011.07213v1,PLAS: Latent Action Space for Offline Reinforcement Learning,123,0.90137,0.881189,"The goal of offline reinforcement learning is to learn a policy from a fixed
dataset, without further interactions with the environment. This setting will
be an increasingly more important paradigm for real-world applications of
reinforcement learning such as robotics, in which data collection is slow and
potentially dangerous. Existing off-policy algorithms have limited performance
on static datasets due to extrapolation errors from out-of-distribution
actions. This leads to the challenge of constraining the policy to select
actions within the support of the dataset during training. We propose to simply
learn the Policy in the Latent Action Space (PLAS) such that this requirement
is naturally satisfied. We evaluate our method on continuous control benchmarks
in simulation and a deformable object manipulation task with a physical robot.
We demonstrate that our method provides competitive performance consistently
across various continuous control tasks and different types of datasets,
outperforming existing offline reinforcement learning methods with explicit
constraints. Videos and code are available at
https://sites.google.com/view/latent-policy.",1,1,0,0,0,0,0.967359,6.0,0.936807,26
http://arxiv.org/abs/2003.04774v3,ENTMOOT: A Framework for Optimization over Ensemble Tree Models,37,0.0678172,0.416516,"Gradient boosted trees and other regression tree models perform well in a
wide range of real-world, industrial applications. These tree models (i) offer
insight into important prediction features, (ii) effectively manage sparse
data, and (iii) have excellent prediction capabilities. Despite their
advantages, they are generally unpopular for decision-making tasks and
black-box optimization, which is due to their difficult-to optimize structure
and the lack of a reliable uncertainty measure. ENTMOOT is our new framework
for integrating (already trained) tree models into larger optimization
problems. The contributions of ENTMOOT include: (i) explicitly introducing a
reliable uncertainty measure that is compatible with tree models, (ii) solving
the larger optimization problems that incorporate these uncertainty aware tree
models, (iii) proving that the solutions are globally optimal, i.e. no better
solution exists. In particular, we show how the ENTMOOT approach allows a
simple integration of tree models into decision-making and black-box
optimization, where it proves as a strong competitor to commonly-used
frameworks.",0,1,0,0,0,0,0.014636,13.0,0.55182,83
http://arxiv.org/abs/2010.04383v1,"Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation",16,0.407872,0.369851,"AMR-to-text generation is used to transduce Abstract Meaning Representation
structures (AMR) into text. A key challenge in this task is to efficiently
learn effective graph representations. Previously, Graph Convolution Networks
(GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to
capture non-local information and additionally, they follow a local
(first-order) information aggregation scheme. To account for these issues,
larger and deeper GCN models are required to capture more complex interactions.
In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight
Dynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local
interactions by synthesizing higher order information from the input graphs. We
further develop two novel parameter saving strategies based on the group graph
convolutions and weight tied convolutions to reduce memory usage and model
complexity. With the help of these strategies, we are able to train a model
with fewer parameters while maintaining the model capacity. Experiments
demonstrate that LDGCNs outperform state-of-the-art models on two benchmark
datasets for AMR-to-text generation with significantly fewer parameters.",1,1,0,0,1,0,0.981553,5.0,0.955013,49
http://arxiv.org/abs/2004.14992v3,How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking,74,0.0554707,0.453702,"Attribution methods assess the contribution of inputs to the model
prediction. One way to do so is erasure: a subset of inputs is considered
irrelevant if it can be removed without affecting the prediction. Though
conceptually simple, erasure's objective is intractable and approximate search
remains expensive with modern deep NLP models. Erasure is also susceptible to
the hindsight bias: the fact that an input can be dropped does not mean that
the model `knows' it can be dropped. The resulting pruning is over-aggressive
and does not reflect how the model arrives at the prediction. To deal with
these challenges, we introduce Differentiable Masking. DiffMask learns to
mask-out subsets of the input while maintaining differentiability. The decision
to include or disregard an input token is made with a simple model based on
intermediate hidden layers of the analyzed model. First, this makes the
approach efficient because we predict rather than search. Second, as with
probing classifiers, this reveals what the network `knows' at the corresponding
layers. This lets us not only plot attribution heatmaps but also analyze how
decisions are formed across network layers. We use DiffMask to study BERT
models on sentiment classification and question answering.",1,1,0,0,0,1,0.517674,4.0,0.518666,70
http://arxiv.org/abs/2006.14769v3,Supermasks in Superposition,229,0.87179,0.806673,"We present the Supermasks in Superposition (SupSup) model, capable of
sequentially learning thousands of tasks without catastrophic forgetting. Our
approach uses a randomly initialized, fixed base network and for each task
finds a subnetwork (supermask) that achieves good performance. If task identity
is given at test time, the correct subnetwork can be retrieved with minimal
memory usage. If not provided, SupSup can infer the task using gradient-based
optimization to find a linear superposition of learned supermasks which
minimizes the output entropy. In practice we find that a single gradient step
is often sufficient to identify the correct mask, even among 2500 tasks. We
also showcase two promising extensions. First, SupSup models can be trained
entirely without task identity information, as they may detect when they are
uncertain about new data and allocate an additional supermask for the new
training distribution. Finally the entire, growing set of supermasks can be
stored in a constant-sized reservoir by implicitly storing them as attractors
in a fixed-sized Hopfield network.",0,0,0,0,0,0,0.94087,6.0,0.905023,64
http://arxiv.org/abs/2005.02539v2,Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback,57,0.862453,0.866089,"We study the task of semantic parse correction with natural language
feedback. Given a natural language utterance, most semantic parsing systems
pose the problem as one-shot translation where the utterance is mapped to a
corresponding logical form. In this paper, we investigate a more interactive
scenario where humans can further interact with the system by providing
free-form natural language feedback to correct the system when it generates an
inaccurate interpretation of an initial utterance. We focus on natural language
to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL
interpretations and the corresponding natural language feedback. We compare
various reference models for the correction task and show that incorporating
such a rich form of feedback can significantly improve the overall semantic
parsing accuracy while retaining the flexibility of natural language
interaction. While we estimated human correction accuracy is 81.5%, our best
model achieves only 25.1%, which leaves a large gap for improvement in future
research. SPLASH is publicly available at https://aka.ms/Splash_dataset.",1,1,0,1,0,0,0.938434,6.0,0.902626,61
http://arxiv.org/abs/2006.08143v1,Anomalous Motion Detection on Highway Using Deep Learning,9,0.080419,0.249481,"Research in visual anomaly detection draws much interest due to its
applications in surveillance. Common datasets for evaluation are constructed
using a stationary camera overlooking a region of interest. Previous research
has shown promising results in detecting spatial as well as temporal anomalies
in these settings. The advent of self-driving cars provides an opportunity to
apply visual anomaly detection in a more dynamic application yet no dataset
exists in this type of environment. This paper presents a new anomaly detection
dataset - the Highway Traffic Anomaly (HTA) dataset - for the problem of
detecting anomalous traffic patterns from dash cam videos of vehicles on
highways. We evaluate state-of-the-art deep learning anomaly detection models
and propose novel variations to these methods. Our results show that
state-of-the-art models built for settings with a stationary camera do not
translate well to a more dynamic environment. The proposed variations to these
SoTA methods show promising results on the new HTA dataset.",1,1,1,1,0,0,0.640479,8.0,0.80166,17
http://arxiv.org/abs/2009.08295v4,Neural Rough Differential Equations for Long Time Series,94,0.610967,0.940683,"Neural controlled differential equations (CDEs) are the continuous-time
analogue of recurrent neural networks, as Neural ODEs are to residual networks,
and offer a memory-efficient continuous-time way to model functions of
potentially irregular time series. Existing methods for computing the forward
pass of a Neural CDE involve embedding the incoming time series into path
space, often via interpolation, and using evaluations of this path to drive the
hidden state. Here, we use rough path theory to extend this formulation.
Instead of directly embedding into path space, we instead represent the input
signal over small time intervals through its \textit{log-signature}, which are
statistics describing how the signal drives a CDE. This is the approach for
solving \textit{rough differential equations} (RDEs), and correspondingly we
describe our main contribution as the introduction of Neural RDEs. This
extension has a purpose: by generalising the Neural CDE approach to a broader
class of driving signals, we demonstrate particular advantages for tackling
long time series. In this regime, we demonstrate efficacy on problems of length
up to 17k observations and observe significant training speed-ups, improvements
in model performance, and reduced memory requirements compared to existing
approaches.",1,0,0,0,0,0,0.77933,6.0,0.800565,40
http://arxiv.org/abs/2002.09673v1,Incorporating Effective Global Information via Adaptive Gate Attention for Text Classification,4,0.00708466,0.057667,"The dominant text classification studies focus on training classifiers using
textual instances only or introducing external knowledge (e.g., hand-craft
features and domain expert knowledge). In contrast, some corpus-level
statistical features, like word frequency and distribution, are not well
exploited. Our work shows that such simple statistical information can enhance
classification performance both efficiently and significantly compared with
several baseline models. In this paper, we propose a classifier with gate
mechanism named Adaptive Gate Attention model with Global Information (AGA+GI),
in which the adaptive gate mechanism incorporates global statistical features
into latent semantic features and the attention layer captures dependency
relationship within the sentence. To alleviate the overfitting issue, we
propose a novel Leaky Dropout mechanism to improve generalization ability and
performance stability. Our experiments show that the proposed method can
achieve better accuracy than CNN-based and RNN-based approaches without global
information on several benchmarks.",0,1,0,0,1,1,0.0886429,12.0,0.667789,30
http://arxiv.org/abs/2001.08116v1,Q-Learning in enormous action spaces via amortized approximate maximization,51,0.068462,0.336256,"Applying Q-learning to high-dimensional or continuous action spaces can be
difficult due to the required maximization over the set of possible actions.
Motivated by techniques from amortized inference, we replace the expensive
maximization over all actions with a maximization over a small subset of
possible actions sampled from a learned proposal distribution. The resulting
approach, which we dub Amortized Q-learning (AQL), is able to handle discrete,
continuous, or hybrid action spaces while maintaining the benefits of
Q-learning. Our experiments on continuous control tasks with up to 21
dimensional actions show that AQL outperforms D3PG (Barth-Maron et al, 2018)
and QT-Opt (Kalashnikov et al, 2018). Experiments on structured discrete action
spaces demonstrate that AQL can efficiently learn good policies in spaces with
thousands of discrete actions.",0,1,0,0,1,0,0.377504,6.0,0.607342,42
http://arxiv.org/abs/2003.02050v2,Learning to Transfer Texture from Clothing Images to 3D Humans,93,0.718506,0.703734,"In this paper, we present a simple yet effective method to automatically
transfer textures of clothing images (front and back) to 3D garments worn on
top SMPL, in real time. We first automatically compute training pairs of images
with aligned 3D garments using a custom non-rigid 3D to 2D registration method,
which is accurate but slow. Using these pairs, we learn a mapping from pixels
to the 3D garment surface. Our idea is to learn dense correspondences from
garment image silhouettes to a 2D-UV map of a 3D garment surface using shape
information alone, completely ignoring texture, which allows us to generalize
to the wide range of web images. Several experiments demonstrate that our model
is more accurate than widely used baselines such as thin-plate-spline warping
and image-to-image translation networks while being orders of magnitude faster.
Our model opens the door for applications such as virtual try-on, and allows
for generation of 3D humans with varied textures which is necessary for
learning.",0,1,0,0,0,0,0.85734,5.0,0.8114,89
http://arxiv.org/abs/2002.05822v1,Frequency-based Search-control in Dyna,14,0.0509304,0.218439,"Model-based reinforcement learning has been empirically demonstrated as a
successful strategy to improve sample efficiency. In particular, Dyna is an
elegant model-based architecture integrating learning and planning that
provides huge flexibility of using a model. One of the most important
components in Dyna is called search-control, which refers to the process of
generating state or state-action pairs from which we query the model to acquire
simulated experiences. Search-control is critical in improving learning
efficiency. In this work, we propose a simple and novel search-control strategy
by searching high frequency regions of the value function. Our main intuition
is built on Shannon sampling theorem from signal processing, which indicates
that a high frequency signal requires more samples to reconstruct. We
empirically show that a high frequency function is more difficult to
approximate. This suggests a search-control strategy: we should use states from
high frequency regions of the value function to query the model to acquire more
samples. We develop a simple strategy to locally measure the frequency of a
function by gradient and hessian norms, and provide theoretical justification
for this approach. We then apply our strategy to search-control in Dyna, and
conduct experiments to show its property and effectiveness on benchmark
domains.",0,0,0,0,0,0,0.0306543,16.0,0.682569,50
http://arxiv.org/abs/2005.10674v1,An Analysis of Regularized Approaches for Constrained Machine Learning,2,0.0182012,0.0307758,"Regularization-based approaches for injecting constraints in Machine Learning
(ML) were introduced to improve a predictive model via expert knowledge. We
tackle the issue of finding the right balance between the loss (the accuracy of
the learner) and the regularization term (the degree of constraint
satisfaction). The key results of this paper is the formal demonstration that
this type of approach cannot guarantee to find all optimal solutions. In
particular, in the non-convex case there might be optima for the constrained
problem that do not correspond to any multiplier value.",0,0,0,0,0,0,0.690964,4.0,0.637808,9
http://arxiv.org/abs/2001.10340v1,Deep Learning for Hindi Text Classification: A Comparison,39,0.0669731,0.40874,"Natural Language Processing (NLP) and especially natural language text
analysis have seen great advances in recent times. Usage of deep learning in
text processing has revolutionized the techniques for text processing and
achieved remarkable results. Different deep learning architectures like CNN,
LSTM, and very recent Transformer have been used to achieve state of the art
results variety on NLP tasks. In this work, we survey a host of deep learning
architectures for text classification tasks. The work is specifically concerned
with the classification of Hindi text. The research in the classification of
morphologically rich and low resource Hindi language written in Devanagari
script has been limited due to the absence of large labeled corpus. In this
work, we used translated versions of English data-sets to evaluate models based
on CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based
on BERT and LASER are also compared to evaluate their effectiveness for the
Hindi language. The paper also serves as a tutorial for popular text
classification techniques.",0,1,0,0,0,0,0.609446,7.0,0.76127,11
http://arxiv.org/abs/2003.06258v1,Belief Propagation Reloaded: Learning BP-Layers for Labeling Problems,19,0.101267,0.362843,"It has been proposed by many researchers that combining deep neural networks
with graphical models can create more efficient and better regularized
composite models. The main difficulties in implementing this in practice are
associated with a discrepancy in suitable learning objectives as well as with
the necessity of approximations for the inference. In this work we take one of
the simplest inference methods, a truncated max-product Belief Propagation, and
add what is necessary to make it a proper component of a deep learning model:
We connect it to learning formulations with losses on marginals and compute the
backprop operation. This BP-Layer can be used as the final or an intermediate
block in convolutional neural networks (CNNs), allowing us to design a
hierarchical model composing BP inference and CNNs at different scale levels.
The model is applicable to a range of dense prediction problems, is
well-trainable and provides parameter-efficient and robust solutions in stereo,
optical flow and semantic segmentation.",1,1,0,0,0,0,0.165056,9.0,0.630881,56
http://arxiv.org/abs/2004.13781v2,Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem,63,0.28653,0.703971,"The celebrated Seq2Seq technique and its numerous variants achieve excellent
performance on many tasks such as neural machine translation, semantic parsing,
and math word problem solving. However, these models either only consider input
objects as sequences while ignoring the important structural information for
encoding, or they simply treat output objects as sequence outputs instead of
structural objects for decoding. In this paper, we present a novel
Graph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder
and a hierarchical tree decoder, that encodes an augmented graph-structured
input and decodes a tree-structured output. In particular, we investigated our
model for solving two problems, neural semantic parsing and math word problem.
Our extensive experiments demonstrate that our Graph2Tree model outperforms or
matches the performance of other state-of-the-art models on these tasks.",0,0,0,0,1,0,0.492373,6.0,0.666995,56
http://arxiv.org/abs/2010.00928v1,Image-based underwater 3D reconstruction for Cultural Heritage: from image collection to 3D. Critical steps and considerations,4,0.0898142,0.0967494,"Underwater Cultural Heritage (CH) sites are widely spread; from ruins in
coastlines up to shipwrecks in deep. The documentation and preservation of this
heritage is an obligation of the mankind, dictated also by the international
treaties like the Convention on the Protection of the Underwater Cultural
Her-itage which fosters the use of ""non-destructive techniques and survey
meth-ods in preference over the recovery of objects"". However, submerged CH
lacks in protection and monitoring in regards to the land CH and nowadays
recording and documenting, for digital preservation as well as dissemination
through VR to wide public, is of most importance. At the same time, it is most
difficult to document it, due to inherent restrictions posed by the
environ-ment. In order to create high detailed textured 3D models, optical
sensors and photogrammetric techniques seems to be the best solution. This
chapter dis-cusses critical aspects of all phases of image based underwater 3D
reconstruc-tion process, from data acquisition and data preparation using
colour restora-tion and colour enhancement algorithms to Structure from Motion
(SfM) and Multi-View Stereo (MVS) techniques to produce an accurate, precise
and complete 3D model for a number of applications.",0,1,0,0,0,0,0.0506852,14.0,0.673881,71
http://arxiv.org/abs/2005.10984v1,RankPose: Learning Generalised Feature with Rank Supervision for Head Pose Estimation,12,0.201377,0.254886,"We address the challenging problem of RGB image-based head pose estimation.
We first reformulate head pose representation learning to constrain it to a
bounded space. Head pose represented as vector projection or vector angles
shows helpful to improving performance. Further, a ranking loss combined with
MSE regression loss is proposed. The ranking loss supervises a neural network
with paired samples of the same person and penalises incorrect ordering of pose
prediction. Analysis on this new loss function suggests it contributes to a
better local feature extractor, where features are generalised to Abstract
Landmarks which are pose-related features instead of pose-irrelevant
information such as identity, age, and lighting. Extensive experiments show
that our method significantly outperforms the current state-of-the-art schemes
on public datasets: AFLW2000 and BIWI. Our model achieves significant
improvements over previous SOTA MAE on AFLW2000 and BIWI from 4.50 to 3.66 and
from 4.0 to 3.71 respectively. Source code will be made available at:
https://github.com/seathiefwang/RankHeadPose.",1,1,0,0,1,0,0.949834,10.0,0.948664,25
http://arxiv.org/abs/2001.11905v3,Verifying Tree Ensembles by Reasoning about Potential Instances,8,0.0343709,0.114256,"Imagine being able to ask questions to a black box model such as ""Which
adversarial examples exist?"", ""Does a specific attribute have a
disproportionate effect on the model's prediction?"" or ""What kind of
predictions could possibly be made for a partially described example?"" This
last question is particularly important if your partial description does not
correspond to any observed example in your data, as it provides insight into
how the model will extrapolate to unseen data. These capabilities would be
extremely helpful as they would allow a user to better understand the model's
behavior, particularly as it relates to issues such as robustness, fairness,
and bias. In this paper, we propose such an approach for an ensemble of trees.
Since, in general, this task is intractable we present a strategy that (1) can
prune part of the input space given the question asked to simplify the problem;
and (2) follows a divide and conquer approach that is incremental and can
always return some answers and indicates which parts of the input domains are
still uncertain. The usefulness of our approach is shown on a diverse set of
use cases.",0,0,0,0,0,0,0.542232,5.0,0.628777,28
http://arxiv.org/abs/2012.05217v1,Positional Encoding as Spatial Inductive Bias in GANs,78,0.170017,0.759816,"SinGAN shows impressive capability in learning internal patch distribution
despite its limited effective receptive field. We are interested in knowing how
such a translation-invariant convolutional generator could capture the global
structure with just a spatially i.i.d. input. In this work, taking SinGAN and
StyleGAN2 as examples, we show that such capability, to a large extent, is
brought by the implicit positional encoding when using zero padding in the
generators. Such positional encoding is indispensable for generating images
with high fidelity. The same phenomenon is observed in other generative
architectures such as DCGAN and PGGAN. We further show that zero padding leads
to an unbalanced spatial bias with a vague relation between locations. To offer
a better spatial inductive bias, we investigate alternative positional
encodings and analyze their effects. Based on a more flexible positional
encoding explicitly, we propose a new multi-scale training strategy and
demonstrate its effectiveness in the state-of-the-art unconditional generator
StyleGAN2. Besides, the explicit spatial inductive bias substantially improve
SinGAN for more versatile image manipulation.",0,0,0,0,0,0,0.76987,6.0,0.79587,57
http://arxiv.org/abs/2011.11715v4,Multi-task Language Modeling for Improving Speech Recognition of Rare Words,26,0.0429296,0.405201,"End-to-end automatic speech recognition (ASR) systems are increasingly
popular due to their relative architectural simplicity and competitive
performance. However, even though the average accuracy of these systems may be
high, the performance on rare content words often lags behind hybrid ASR
systems. To address this problem, second-pass rescoring is often applied
leveraging upon language modeling. In this paper, we propose a second-pass
system with multi-task learning, utilizing semantic targets (such as intent and
slot prediction) to improve speech recognition performance. We show that our
rescoring model trained with these additional tasks outperforms the baseline
rescoring model, trained with only the language modeling task, by 1.4% on a
general test and by 2.6% on a rare word test set in terms of word-error-rate
relative (WERR). Our best ASR system with multi-task LM shows 4.6% WERR
deduction compared with RNN Transducer only ASR baseline for rare words
recognition.",0,1,0,0,0,0,0.106962,6.0,0.368551,34
http://arxiv.org/abs/2001.04753v2,Deep Image Compression using Decoder Side Information,22,0.0586719,0.554671,"We present a Deep Image Compression neural network that relies on side
information, which is only available to the decoder. We base our algorithm on
the assumption that the image available to the encoder and the image available
to the decoder are correlated, and we let the network learn these correlations
in the training phase.
  Then, at run time, the encoder side encodes the input image without knowing
anything about the decoder side image and sends it to the decoder. The decoder
then uses the encoded input image and the side information image to reconstruct
the original image.
  This problem is known as Distributed Source Coding in Information Theory, and
we discuss several use cases for this technology. We compare our algorithm to
several image compression algorithms and show that adding decoder-only side
information does indeed improve results. Our code is publicly available at
https://github.com/ayziksha/DSIN.",1,1,0,0,0,0,0.0402832,13.0,0.63071,39
http://arxiv.org/abs/2012.02613v1,FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity Annotation,7,0.0245547,0.457616,"Sentiment analysis and opinion mining is an important task with obvious
application areas in social media, e.g. when indicating hate speech and fake
news. In our survey of previous work, we note that there is no large-scale
social media data set with sentiment polarity annotations for Finnish. This
publications aims to remedy this shortcoming by introducing a 27,000 sentence
data set annotated independently with sentiment polarity by three native
annotators. We had the same three annotators for the whole data set, which
provides a unique opportunity for further studies of annotator behaviour over
time. We analyse their inter-annotator agreement and provide two baselines to
validate the usefulness of the data set.",0,1,1,1,0,0,0.00517202,13.0,0.471436,81
http://arxiv.org/abs/2007.03496v3,AutoAssign: Differentiable Label Assignment for Dense Object Detection,167,0.686328,0.767573,"Determining positive/negative samples for object detection is known as label
assignment. Here we present an anchor-free detector named AutoAssign. It
requires little human knowledge and achieves appearance-aware through a fully
differentiable weighting mechanism. During training, to both satisfy the prior
distribution of data and adapt to category characteristics, we present Center
Weighting to adjust the category-specific prior distributions. To adapt to
object appearances, Confidence Weighting is proposed to adjust the specific
assign strategy of each instance. The two weighting modules are then combined
to generate positive and negative weights to adjust each location's confidence.
Extensive experiments on the MS COCO show that our method steadily surpasses
other best sampling strategies by large margins with various backbones.
Moreover, our best model achieves 52.1% AP, outperforming all existing
one-stage detectors. Besides, experiments on other datasets, e.g., PASCAL VOC,
Objects365, and WiderFace, demonstrate the broad applicability of AutoAssign.",0,1,0,0,1,0,0.981771,4.0,0.94451,34
http://arxiv.org/abs/2010.08738v1,RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling,48,0.854666,0.869778,"In order to alleviate the shortage of multi-domain data and to capture
discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a
large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic
Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn
semantically annotated dialogues, with more than 150K utterances spanning over
12 domains, which is larger than all previous annotated H2H conversational
datasets. Both single- and multi-domain dialogues are constructed, accounting
for 65% and 35%, respectively. Each dialogue is labeled with comprehensive
dialogue annotations, including dialogue goal in the form of natural language
description, domain, dialogue states and acts at both the user and system side.
In addition to traditional dialogue annotations, we especially provide
linguistic annotations on discourse phenomena, e.g., ellipsis and coreference,
in dialogues, which are useful for dialogue coreference and ellipsis resolution
tasks. Apart from the fully annotated dataset, we also present a detailed
description of the data collection procedure, statistics and analysis of the
dataset. A series of benchmark models and results are reported, including
natural language understanding (intent detection & slot filling), dialogue
state tracking and dialogue context-to-text generation, as well as coreference
and ellipsis resolution, which facilitate the baseline comparison for future
research on this corpus.",1,1,0,1,0,0,0.962463,5.0,0.91583,34
http://arxiv.org/abs/2012.03457v1,VideoMix: Rethinking Data Augmentation for Video Classification,61,0.18851,0.718393,"State-of-the-art video action classifiers often suffer from overfitting. They
tend to be biased towards specific objects and scene cues, rather than the
foreground action content, leading to sub-optimal generalization performances.
Recent data augmentation strategies have been reported to address the
overfitting problems in static image classifiers. Despite the effectiveness on
the static image classifiers, data augmentation has rarely been studied for
videos. For the first time in the field, we systematically analyze the efficacy
of various data augmentation strategies on the video classification task. We
then propose a powerful augmentation strategy VideoMix. VideoMix creates a new
training video by inserting a video cuboid into another video. The ground truth
labels are mixed proportionally to the number of voxels from each video. We
show that VideoMix lets a model learn beyond the object and scene biases and
extract more robust cues for action recognition. VideoMix consistently
outperforms other augmentation baselines on Kinetics and the challenging
Something-Something-V2 benchmarks. It also improves the weakly-supervised
action localization performance on THUMOS'14. VideoMix pretrained models
exhibit improved accuracies on the video detection task (AVA).",1,1,0,0,1,0,0.765072,7.0,0.823011,42
http://arxiv.org/abs/2007.04298v2,Building Interpretable Interaction Trees for Deep NLP Models,32,0.158535,0.627721,"This paper proposes a method to disentangle and quantify interactions among
words that are encoded inside a DNN for natural language processing. We
construct a tree to encode salient interactions extracted by the DNN. Six
metrics are proposed to analyze properties of interactions between constituents
in a sentence. The interaction is defined based on Shapley values of words,
which are considered as an unbiased estimation of word contributions to the
network prediction. Our method is used to quantify word interactions encoded
inside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental
results have provided a new perspective to understand these DNNs, and have
demonstrated the effectiveness of our method.",0,0,0,0,0,0,0.261562,7.0,0.599608,52
http://arxiv.org/abs/2001.09684v2,Challenges and Countermeasures for Adversarial Attacks on Deep Reinforcement Learning,100,0.641102,0.94202,"Deep Reinforcement Learning (DRL) has numerous applications in the real world
thanks to its outstanding ability in quickly adapting to the surrounding
environments. Despite its great advantages, DRL is susceptible to adversarial
attacks, which precludes its use in real-life critical systems and applications
(e.g., smart grids, traffic controls, and autonomous vehicles) unless its
vulnerabilities are addressed and mitigated. Thus, this paper provides a
comprehensive survey that discusses emerging attacks in DRL-based systems and
the potential countermeasures to defend against these attacks. We first cover
some fundamental backgrounds about DRL and present emerging adversarial attacks
on machine learning techniques. We then investigate more details of the
vulnerabilities that the adversary can exploit to attack DRL along with the
state-of-the-art countermeasures to prevent such attacks. Finally, we highlight
open issues and research challenges for developing solutions to deal with
attacks for DRL-based intelligent systems.",0,1,0,0,0,0,0.795302,4.0,0.712979,141
http://arxiv.org/abs/2002.11018v1,Breaking Batch Normalization for better explainability of Deep Neural Networks through Layer-wise Relevance Propagation,17,0.119974,0.378995,"The lack of transparency of neural networks stays a major break for their
use. The Layerwise Relevance Propagation technique builds heat-maps
representing the relevance of each input in the model s decision. The relevance
spreads backward from the last to the first layer of the Deep Neural Network.
Layer-wise Relevance Propagation does not manage normalization layers, in this
work we suggest a method to include normalization layers. Specifically, we
build an equivalent network fusing normalization layers and convolutional or
fully connected layers. Heatmaps obtained with our method on MNIST and CIFAR 10
datasets are more accurate for convolutional layers. Our study also prevents
from using Layerwise Relevance Propagation with networks including a
combination of connected layers and normalization layer.",0,1,0,0,0,0,0.919181,9.0,0.923672,38
http://arxiv.org/abs/2007.10681v1,Neural Machine Translation with Error Correction,64,0.146934,0.894663,"Neural machine translation (NMT) generates the next target token given as
input the previous ground truth target tokens during training while the
previous generated target tokens during inference, which causes discrepancy
between training and inference as well as error propagation, and affects the
translation accuracy. In this paper, we introduce an error correction mechanism
into NMT, which corrects the error information in the previous generated tokens
to better predict the next token. Specifically, we introduce two-stream
self-attention from XLNet into NMT decoder, where the query stream is used to
predict the next token, and meanwhile the content stream is used to correct the
error information from the previous predicted tokens. We leverage scheduled
sampling to simulate the prediction errors during training. Experiments on
three IWSLT translation datasets and two WMT translation datasets demonstrate
that our method achieves improvements over Transformer baseline and scheduled
sampling. Further experimental analyses also verify the effectiveness of our
proposed error correction mechanism to improve the translation quality.",1,1,0,0,0,0,0.512001,5.0,0.611699,29
http://arxiv.org/abs/2005.14672v4,"Massive Choice, Ample Tasks (MaChAmp): A Toolkit for Multi-task Learning in NLP",100,0.204121,0.676639,"Transfer learning, particularly approaches that combine multi-task learning
with pre-trained contextualized embeddings and fine-tuning, have advanced the
field of Natural Language Processing tremendously in recent years. In this
paper we present MaChAmp, a toolkit for easy fine-tuning of contextualized
embeddings in multi-task settings. The benefits of MaChAmp are its flexible
configuration options, and the support of a variety of natural language
processing tasks in a uniform toolkit, from text classification and sequence
labeling to dependency parsing, masked language modeling, and text generation.",0,1,0,0,0,1,0.0734251,6.0,0.302827,200
http://arxiv.org/abs/2007.03876v1,Audio-Visual Understanding of Passenger Intents for In-Cabin Conversational Agents,6,0.180861,0.127283,"Building multimodal dialogue understanding capabilities situated in the
in-cabin context is crucial to enhance passenger comfort in autonomous vehicle
(AV) interaction systems. To this end, understanding passenger intents from
spoken interactions and vehicle vision systems is a crucial component for
developing contextual and visually grounded conversational agents for AV.
Towards this goal, we explore AMIE (Automated-vehicle Multimodal In-cabin
Experience), the in-cabin agent responsible for handling multimodal
passenger-vehicle interactions. In this work, we discuss the benefits of a
multimodal understanding of in-cabin utterances by incorporating
verbal/language input together with the non-verbal/acoustic and visual clues
from inside and outside the vehicle. Our experimental results outperformed
text-only baselines as we achieved improved performances for intent detection
with a multimodal approach.",0,1,0,1,0,0,0.820668,7.0,0.847432,28
http://arxiv.org/abs/2012.13293v1,Fuzzy Commitments Offer Insufficient Protection to Biometric Templates Produced by Deep Learning,8,0.299183,0.677118,"In this work, we study the protection that fuzzy commitments offer when they
are applied to facial images, processed by the state of the art deep learning
facial recognition systems. We show that while these systems are capable of
producing great accuracy, they produce templates of too little entropy. As a
result, we present a reconstruction attack that takes a protected template, and
reconstructs a facial image. The reconstructed facial images greatly resemble
the original ones. In the simplest attack scenario, more than 78% of these
reconstructed templates succeed in unlocking an account (when the system is
configured to 0.1% FAR). Even in the ""hardest"" settings (in which we take a
reconstructed image from one system and use it in a different system, with
different feature extraction process) the reconstructed image offers 50 to 120
times higher success rates than the system's FAR.",0,1,0,0,0,0,0.473538,18.0,0.88593,55
http://arxiv.org/abs/2002.10698v3,Hierarchical Conditional Relation Networks for Video Question Answering,223,0.917839,0.836393,"Video question answering (VideoQA) is challenging as it requires modeling
capacity to distill dynamic visual artifacts and distant relations and to
associate them with linguistic concepts. We introduce a general-purpose
reusable neural unit called Conditional Relation Network (CRN) that serves as a
building block to construct more sophisticated structures for representation
and reasoning over video. CRN takes as input an array of tensorial objects and
a conditioning feature, and computes an array of encoded output objects. Model
building becomes a simple exercise of replication, rearrangement and stacking
of these reusable units for diverse modalities and contextual information. This
design thus supports high-order relational and multi-step reasoning. The
resulting architecture for VideoQA is a CRN hierarchy whose branches represent
sub-videos or clips, all sharing the same question as the contextual condition.
Our evaluations on well-known datasets achieved new SoTA results, demonstrating
the impact of building a general-purpose reasoning unit on complex domains such
as VideoQA.",0,0,0,0,1,0,0.667044,5.0,0.697128,51
http://arxiv.org/abs/2006.04148v1,Interactive Extractive Search over Biomedical Corpora,27,0.475519,0.681742,"We present a system that allows life-science researchers to search a
linguistically annotated corpus of scientific texts using patterns over
dependency graphs, as well as using patterns over token sequences and a
powerful variant of boolean keyword queries. In contrast to previous attempts
to dependency-based search, we introduce a light-weight query language that
does not require the user to know the details of the underlying linguistic
representations, and instead to query the corpus by providing an example
sentence coupled with simple markup. Search is performed at an interactive
speed due to efficient linguistic graph-indexing and retrieval engine. This
allows for rapid exploration, development and refinement of user queries. We
demonstrate the system using example workflows over two corpora: the PubMed
corpus including 14,446,243 PubMed abstracts and the CORD-19 dataset, a
collection of over 45,000 research papers focused on COVID-19 research. The
system is publicly available at https://allenai.github.io/spike",0,1,0,0,0,0,0.392448,7.0,0.670578,23
http://arxiv.org/abs/2006.15435v1,Mind The Facts: Knowledge-Boosted Coherent Abstractive Text Summarization,38,0.442394,0.616702,"Neural models have become successful at producing abstractive summaries that
are human-readable and fluent. However, these models have two critical
shortcomings: they often don't respect the facts that are either included in
the source article or are known to humans as commonsense knowledge, and they
don't produce coherent summaries when the source article is long. In this work,
we propose a novel architecture that extends Transformer encoder-decoder
architecture in order to improve on these shortcomings. First, we incorporate
entity-level knowledge from the Wikidata knowledge graph into the
encoder-decoder architecture. Injecting structural world knowledge from
Wikidata helps our abstractive summarization model to be more fact-aware.
Second, we utilize the ideas used in Transformer-XL language model in our
proposed encoder-decoder architecture. This helps our model with producing
coherent summaries even when the source article is long. We test our model on
CNN/Daily Mail summarization dataset and show improvements on ROUGE scores over
the baseline Transformer model. We also include model predictions for which our
model accurately conveys the facts, while the baseline Transformer model
doesn't.",0,0,0,0,0,0,0.992927,7.0,0.998606,16
http://arxiv.org/abs/2007.12741v2,Consistent Transcription and Translation of Speech,17,0.116121,0.417627,"The conventional paradigm in speech translation starts with a speech
recognition step to generate transcripts, followed by a translation step with
the automatic transcripts as input. To address various shortcomings of this
paradigm, recent work explores end-to-end trainable direct models that
translate without transcribing. However, transcripts can be an indispensable
output in practical applications, which often display transcripts alongside the
translations to users.
  We make this common requirement explicit and explore the task of jointly
transcribing and translating speech. While high accuracy of transcript and
translation are crucial, even highly accurate systems can suffer from
inconsistencies between both outputs that degrade the user experience. We
introduce a methodology to evaluate consistency and compare several modeling
approaches, including the traditional cascaded approach and end-to-end models.
We find that direct models are poorly suited to the joint
transcription/translation task, but that end-to-end models that feature a
coupled inference procedure are able to achieve strong consistency. We further
introduce simple techniques for directly optimizing for consistency, and
analyze the resulting trade-offs between consistency, transcription accuracy,
and translation accuracy.",0,1,0,0,0,0,0.162874,10.0,0.666336,44
http://arxiv.org/abs/2009.01385v1,Noise-Aware Texture-Preserving Low-Light Enhancement,6,0.122836,0.139189,"A simple and effective low-light image enhancement method based on a
noise-aware texture-preserving retinex model is proposed in this work. The new
method, called NATLE, attempts to strike a balance between noise removal and
natural texture preservation through a low-complexity solution. Its cost
function includes an estimated piece-wise smooth illumination map and a
noise-free texture-preserving reflectance map. Afterwards, illumination is
adjusted to form the enhanced image together with the reflectance map.
Extensive experiments are conducted on common low-light image enhancement
datasets to demonstrate the superior performance of NATLE.",0,1,0,0,0,0,0.985334,6.0,0.97182,17
http://arxiv.org/abs/2002.10420v1,Boosting rare benthic macroinvertebrates taxa identification with one-class classification,12,0.442736,0.508268,"Insect monitoring is crucial for understanding the consequences of rapid
ecological changes, but taxa identification currently requires tedious manual
expert work and cannot be scaled-up efficiently. Deep convolutional neural
networks (CNNs), provide a viable way to significantly increase the
biomonitoring volumes. However, taxa abundances are typically very imbalanced
and the amounts of training images for the rarest classes are simply too low
for deep CNNs. As a result, the samples from the rare classes are often
completely missed, while detecting them has biological importance. In this
paper, we propose combining the trained deep CNN with one-class classifiers to
improve the rare species identification. One-class classification models are
traditionally trained with much fewer samples and they can provide a mechanism
to indicate samples potentially belonging to the rare classes for human
inspection. Our experiments confirm that the proposed approach may indeed
support moving towards partial automation of the taxa identification task.",0,1,0,0,0,0,0.615565,5.0,0.669109,28
http://arxiv.org/abs/2002.06000v1,Extended Markov Games to Learn Multiple Tasks in Multi-Agent Reinforcement Learning,15,0.12313,0.274831,"The combination of Formal Methods with Reinforcement Learning (RL) has
recently attracted interest as a way for single-agent RL to learn multiple-task
specifications. In this paper we extend this convergence to multi-agent
settings and formally define Extended Markov Games as a general mathematical
model that allows multiple RL agents to concurrently learn various
non-Markovian specifications. To introduce this new model we provide formal
definitions and proofs as well as empirical tests of RL algorithms running on
this framework. Specifically, we use our model to train two different
logic-based multi-agent RL algorithms to solve diverse settings of
non-Markovian co-safe LTL specifications.",1,0,0,0,0,0,0.556915,7.0,0.74068,37
http://arxiv.org/abs/2012.04474v1,Rotation-Invariant Autoencoders for Signals on Spheres,5,0.0233624,0.317525,"Omnidirectional images and spherical representations of $3D$ shapes cannot be
processed with conventional 2D convolutional neural networks (CNNs) as the
unwrapping leads to large distortion. Using fast implementations of spherical
and $SO(3)$ convolutions, researchers have recently developed deep learning
methods better suited for classifying spherical images. These newly proposed
convolutional layers naturally extend the notion of convolution to functions on
the unit sphere $S^2$ and the group of rotations $SO(3)$ and these layers are
equivariant to 3D rotations. In this paper, we consider the problem of
unsupervised learning of rotation-invariant representations for spherical
images. In particular, we carefully design an autoencoder architecture
consisting of $S^2$ and $SO(3)$ convolutional layers. As 3D rotations are often
a nuisance factor, the latent space is constrained to be exactly invariant to
these input transformations. As the rotation information is discarded in the
latent space, we craft a novel rotation-invariant loss function for training
the network. Extensive experiments on multiple datasets demonstrate the
usefulness of the learned representations on clustering, retrieval and
classification applications.",0,0,0,0,0,0,0.389148,7.0,0.669016,48
http://arxiv.org/abs/2012.05999v1,An IoT Framework for Heart Disease Prediction based on MDCNN Classifier,154,0.841027,0.998481,"Nowadays, heart disease is the leading cause of death worldwide. Predicting
heart disease is a complex task since it requires experience along with
advanced knowledge. Internet of Things (IoT) technology has lately been adopted
in healthcare systems to collect sensor values for heart disease diagnosis and
prediction. Many researchers have focused on the diagnosis of heart disease,
yet the accuracy of the diagnosis results is low. To address this issue, an IoT
framework is proposed to evaluate heart disease more accurately using a
Modified Deep Convolutional Neural Network (MDCNN). The smartwatch and heart
monitor device that is attached to the patient monitors the blood pressure and
electrocardiogram (ECG). The MDCNN is utilized for classifying the received
sensor data into normal and abnormal. The performance of the system is analyzed
by comparing the proposed MDCNN with existing deep learning neural networks and
logistic regression. The results demonstrate that the proposed MDCNN based
heart disease prediction system performs better than other methods. The
proposed method shows that for the maximum number of records, the MDCNN
achieves an accuracy of 98.2 which is better than existing classifiers.",0,1,0,0,1,0,0.543906,5.0,0.629712,47
http://arxiv.org/abs/2008.00948v3,Frame-To-Frame Consistent Semantic Segmentation,7,0.073522,0.083668,"In this work, we aim for temporally consistent semantic segmentation
throughout frames in a video. Many semantic segmentation algorithms process
images individually which leads to an inconsistent scene interpretation due to
illumination changes, occlusions and other variations over time. To achieve a
temporally consistent prediction, we train a convolutional neural network (CNN)
which propagates features through consecutive frames in a video using a
convolutional long short term memory (ConvLSTM) cell. Besides the temporal
feature propagation, we penalize inconsistencies in our loss function. We show
in our experiments that the performance improves when utilizing video
information compared to single frame prediction. The mean intersection over
union (mIoU) metric on the Cityscapes validation set increases from 45.2 % for
the single frames to 57.9 % for video data after implementing the ConvLSTM to
propagate features trough time on the ESPNet. Most importantly, inconsistency
decreases from 4.5 % to 1.3 % which is a reduction by 71.1 %. Our results
indicate that the added temporal information produces a frame-to-frame
consistent and more accurate image understanding compared to single frame
processing. Code and videos are available at
https://github.com/mrebol/f2f-consistent-semantic-segmentation",1,1,0,0,0,0,0.951138,9.0,0.943934,29
http://arxiv.org/abs/2008.03522v1,Unravelling Small Sample Size Problems in the Deep Learning World,26,0.141484,0.525289,"The growth and success of deep learning approaches can be attributed to two
major factors: availability of hardware resources and availability of large
number of training samples. For problems with large training databases, deep
learning models have achieved superlative performances. However, there are a
lot of \textit{small sample size or $S^3$} problems for which it is not
feasible to collect large training databases. It has been observed that deep
learning models do not generalize well on $S^3$ problems and specialized
solutions are required. In this paper, we first present a review of deep
learning algorithms for small sample size problems in which the algorithms are
segregated according to the space in which they operate, i.e. input space,
model space, and feature space. Secondly, we present Dynamic Attention Pooling
approach which focuses on extracting global information from the most
discriminative sub-part of the feature map. The performance of the proposed
dynamic attention pooling is analyzed with state-of-the-art ResNet model on
relatively small publicly available datasets such as SVHN, C10, C100, and
TinyImageNet.",0,1,0,0,0,0,0.42484,8.0,0.724795,100
http://arxiv.org/abs/2002.11660v1,An Optimal Procedure to Check Pareto-Optimality in House Markets with Single-Peaked Preferences,2,0.0635063,0.0430604,"Recently, the problem of allocating one resource per agent with initial
endowments (house markets) has seen a renewed interest: indeed, while in the
domain of strict preferences the Top Trading Cycle algorithm is known to be the
only procedure guaranteeing Pareto-optimality, individual rationality, and
strategy proofness. However, the situation differs in the single-peaked domain.
Indeed, Bade presented the Crawler, an alternative procedure enjoying the same
properties, with the additional advantage of being implementable in obviously
dominant strategies. In this paper we further investigate the Crawler and
propose the Diver, a variant which checks optimally whether an allocation is
Pareto-optimal for single-peaked preferences, thus improving over known
techniques used for checking Pareto-optimality in more general domains. We also
prove that the Diver is asymptotically optimal in terms of communication
complexity.",0,0,0,0,0,0,0.0470195,29.0,0.839909,23
http://arxiv.org/abs/2003.02232v2,Interactive Robot Training for Non-Markov Tasks,15,0.0574962,0.292294,"Defining sound and complete specifications for robots using formal languages
is challenging, while learning formal specifications directly from
demonstrations can lead to over-constrained task policies. In this paper, we
propose a Bayesian interactive robot training framework that allows the robot
to learn from both demonstrations provided by a teacher, and that teacher's
assessments of the robot's task executions. We also present an active learning
approach -- inspired by uncertainty sampling -- to identify the task execution
with the most uncertain degree of acceptability. Through a simulated
experiment, we demonstrate that our active learning approach identifies a
teacher's intended task specification with an equivalent or greater similarity
when compared to an approach that learns purely from demonstrations. Finally,
we demonstrate the efficacy of our approach in a real-world setting through a
user-study based on teaching a robot to set a dinner table.",0,0,0,0,0,0,0.335886,5.0,0.499452,40
http://arxiv.org/abs/2006.04700v1,Multimodal Future Localization and Emergence Prediction for Objects in Egocentric View with a Reachability Prior,29,0.247413,0.708708,"In this paper, we investigate the problem of anticipating future dynamics,
particularly the future location of other vehicles and pedestrians, in the view
of a moving vehicle. We approach two fundamental challenges: (1) the partial
visibility due to the egocentric view with a single RGB camera and considerable
field-of-view change due to the egomotion of the vehicle; (2) the multimodality
of the distribution of future states. In contrast to many previous works, we do
not assume structural knowledge from maps. We rather estimate a reachability
prior for certain classes of objects from the semantic map of the present image
and propagate it into the future using the planned egomotion. Experiments show
that the reachability prior combined with multi-hypotheses learning improves
multimodal prediction of the future location of tracked objects and, for the
first time, the emergence of new objects. We also demonstrate promising
zero-shot transfer to unseen datasets. Source code is available at
$\href{https://github.com/lmb-freiburg/FLN-EPN-RPN}{\text{this https URL.}}$",1,1,0,0,0,0,0.786484,5.0,0.764993,68
http://arxiv.org/abs/2010.05981v2,Shape-Texture Debiased Neural Network Training,94,0.434608,0.994214,"Shape and texture are two prominent and complementary cues for recognizing
objects. Nonetheless, Convolutional Neural Networks are often biased towards
either texture or shape, depending on the training dataset. Our ablation shows
that such bias degenerates model performance. Motivated by this observation, we
develop a simple algorithm for shape-texture debiased learning. To prevent
models from exclusively attending on a single cue in representation learning,
we augment training data with images with conflicting shape and texture
information (eg, an image of chimpanzee shape but with lemon texture) and, most
importantly, provide the corresponding supervisions from shape and texture
simultaneously.
  Experiments show that our method successfully improves model performance on
several image recognition benchmarks and adversarial robustness. For example,
by training on ImageNet, it helps ResNet-152 achieve substantial improvements
on ImageNet (+1.2%), ImageNet-A (+5.2%), ImageNet-C (+8.3%) and
Stylized-ImageNet (+11.1%), and on defending against FGSM adversarial attacker
on ImageNet (+14.4%). Our method also claims to be compatible with other
advanced data augmentation strategies, eg, Mixup, and CutMix. The code is
available here: https://github.com/LiYingwei/ShapeTextureDebiasedTraining.",0,1,0,0,1,1,0.925859,8.0,0.918345,48
http://arxiv.org/abs/2001.06693v1,Fair Transfer of Multiple Style Attributes in Text,2,0.0143097,0.015396,"To preserve anonymity and obfuscate their identity on online platforms users
may morph their text and portray themselves as a different gender or
demographic. Similarly, a chatbot may need to customize its communication style
to improve engagement with its audience. This manner of changing the style of
written text has gained significant attention in recent years. Yet these past
research works largely cater to the transfer of single style attributes. The
disadvantage of focusing on a single style alone is that this often results in
target text where other existing style attributes behave unpredictably or are
unfairly dominated by the new style. To counteract this behavior, it would be
nice to have a style transfer mechanism that can transfer or control multiple
styles simultaneously and fairly. Through such an approach, one could obtain
obfuscated or written text incorporated with a desired degree of multiple soft
styles such as female-quality, politeness, or formalness.
  In this work, we demonstrate that the transfer of multiple styles cannot be
achieved by sequentially performing multiple single-style transfers. This is
because each single style-transfer step often reverses or dominates over the
style incorporated by a previous transfer step. We then propose a neural
network architecture for fairly transferring multiple style attributes in a
given text. We test our architecture on the Yelp data set to demonstrate our
superior performance as compared to existing one-style transfer steps performed
in a sequence.",0,0,0,0,0,0,0.775643,6.0,0.798728,18
http://arxiv.org/abs/2007.12681v2,Data science and AI in FinTech: An overview,48,0.273133,0.78638,"Financial technology (FinTech) has been playing an increasingly critical role
in driving modern economies, society, technology, and many other areas. Smart
FinTech is the new-generation FinTech, largely inspired and empowered by data
science and new-generation AI and (DSAI) techniques. Smart FinTech synthesizes
broad DSAI and transforms finance and economies to drive intelligent,
automated, whole-of-business and personalized economic and financial
businesses, services and systems. The research on data science and AI in
FinTech involves many latest progress made in smart FinTech for BankingTech,
TradeTech, LendTech, InsurTech, WealthTech, PayTech, RiskTech,
cryptocurrencies, and blockchain, and the DSAI techniques including complex
system methods, quantitative methods, intelligent interactions, recognition and
responses, data analytics, deep learning, federated learning,
privacy-preserving processing, augmentation, optimization, and system
intelligence enhancement. Here, we present a highly dense research overview of
smart financial businesses and their challenges, the smart FinTech ecosystem,
the DSAI techniques to enable smart FinTech, and some research directions of
smart FinTech futures to the DSAI communities.",0,0,0,0,0,0,0.632656,3.0,0.464006,66
http://arxiv.org/abs/2010.11151v2,Logistic Q-Learning,36,0.0488276,0.298355,"We propose a new reinforcement learning algorithm derived from a regularized
linear-programming formulation of optimal control in MDPs. The method is
closely related to the classic Relative Entropy Policy Search (REPS) algorithm
of Peters et al. (2010), with the key difference that our method introduces a
Q-function that enables efficient exact model-free implementation. The main
feature of our algorithm (called QREPS) is a convex loss function for policy
evaluation that serves as a theoretically sound alternative to the widely used
squared Bellman error. We provide a practical saddle-point optimization method
for minimizing this loss function and provide an error-propagation analysis
that relates the quality of the individual updates to the performance of the
output policy. Finally, we demonstrate the effectiveness of our method on a
range of benchmark problems.",1,0,0,0,0,0,0.0278019,10.0,0.482198,69
http://arxiv.org/abs/2010.03034v1,Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers,32,0.277667,0.472721,"With the growth of computing power neural machine translation (NMT) models
also grow accordingly and become better. However, they also become harder to
deploy on edge devices due to memory constraints. To cope with this problem, a
common practice is to distill knowledge from a large and accurately-trained
teacher network (T) into a compact student network (S). Although knowledge
distillation (KD) is useful in most cases, our study shows that existing KD
techniques might not be suitable enough for deep NMT engines, so we propose a
novel alternative. In our model, besides matching T and S predictions we have a
combinatorial mechanism to inject layer-level supervision from T to S. In this
paper, we target low-resource settings and evaluate our translation engines for
Portuguese--English, Turkish--English, and English--German directions. Students
trained using our technique have 50% fewer parameters and can still deliver
comparable results to those of 12-layer teachers.",1,1,0,0,0,0,0.97133,6.0,0.943008,21
http://arxiv.org/abs/2010.11853v1,STAR: A Schema-Guided Dialog Dataset for Transfer Learning,35,0.493849,0.703862,"We present STAR, a schema-guided task-oriented dialog dataset consisting of
127,833 utterances and knowledge base queries across 5,820 task-oriented
dialogs in 13 domains that is especially designed to facilitate task and domain
transfer learning in task-oriented dialog. Furthermore, we propose a scalable
crowd-sourcing paradigm to collect arbitrarily large datasets of the same
quality as STAR. Moreover, we introduce novel schema-guided dialog models that
use an explicit description of the task(s) to generalize from known to unknown
tasks. We demonstrate the effectiveness of these models, particularly for
zero-shot generalization across tasks and domains.",1,1,1,1,0,0,0.981902,3.0,0.926614,41
http://arxiv.org/abs/2006.07084v3,Investigating the Impact of Pre-processing and Prediction Aggregation on the DeepFake Detection Task,21,0.553879,0.0958762,"Recent advances in content generation technologies (widely known as
DeepFakes) along with the online proliferation of manipulated media content
render the detection of such manipulations a task of increasing importance.
Even though there are many DeepFake detection methods, only a few focus on the
impact of dataset preprocessing and the aggregation of frame-level to
video-level prediction on model performance. In this paper, we propose a
pre-processing step to improve the training data quality and examine its effect
on the performance of DeepFake detection. We also propose and evaluate the
effect of video-level prediction aggregation approaches. Experimental results
show that the proposed pre-processing approach leads to considerable
improvements in the performance of detection models, and the proposed
prediction aggregation scheme further boosts the detection efficiency in cases
where there are multiple faces in a video.",0,1,0,0,0,0,0.987315,4.0,0.966181,41
http://arxiv.org/abs/2007.06068v2,Visualizing Classification Structure of Large-Scale Classifiers,1,0.00122585,0.0120767,"We propose a measure to compute class similarity in large-scale
classification based on prediction scores. Such measure has not been formally
pro-posed in the literature. We show how visualizing the class similarity
matrix can reveal hierarchical structures and relationships that govern the
classes. Through examples with various classifiers, we demonstrate how such
structures can help in analyzing the classification behavior and in inferring
potential corner cases. The source code for one example is available as a
notebook at https://github.com/bilalsal/blocks",1,0,1,0,0,0,0.0221376,9.0,0.399029,38
http://arxiv.org/abs/2004.02275v1,The two-echelon routing problem with truck and drones,14,0.250983,0.436881,"In this paper, we study novel variants of the well-known two-echelon vehicle
routing problem in which a truck works on the first echelon to transport
parcels and a fleet of drones to intermediate depots while in the second
echelon, the drones are used to deliver parcels from intermediate depots to
customers. The objective is to minimize the completion time instead of the
transportation cost as in classical 2-echelon vehicle routing problems.
Depending on the context, a drone can be launched from the truck at an
intermediate depot once (single trip drone) or several times (multiple trip
drone). Mixed Integer Linear Programming (MILP) models are first proposed to
formulate mathematically the problems and solve to optimality small-size
instances. To handle larger instances, a metaheuristic based on the idea of
Greedy Randomized Adaptive Search Procedure (GRASP) is introduced. Experimental
results obtained on instances of different contexts are reported and analyzed.",0,1,1,0,0,0,0.812762,8.0,0.863325,41
http://arxiv.org/abs/2003.00429v1,Deep Learning for Content-based Personalized Viewport Prediction of 360-Degree VR Videos,24,0.844957,0.797673,"In this paper, the problem of head movement prediction for virtual reality
videos is studied. In the considered model, a deep learning network is
introduced to leverage position data as well as video frame content to predict
future head movement. For optimizing data input into this neural network, data
sample rate, reduced data, and long-period prediction length are also explored
for this model. Simulation results show that the proposed approach yields
16.1\% improvement in terms of prediction accuracy compared to a baseline
approach that relies only on the position data.",0,1,0,0,0,0,0.984113,6.0,0.968634,17
http://arxiv.org/abs/2011.13253v1,Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking,67,0.694498,0.920875,"The rapid advancement of technology in online communication via social media
platforms has led to a prolific rise in the spread of misinformation and fake
news. Fake news is especially rampant in the current COVID-19 pandemic, leading
to people believing in false and potentially harmful claims and stories.
Detecting fake news quickly can alleviate the spread of panic, chaos and
potential health hazards. We developed a two stage automated pipeline for
COVID-19 fake news detection using state of the art machine learning models for
natural language processing. The first model leverages a novel fact checking
algorithm that retrieves the most relevant facts concerning user claims about
particular COVID-19 claims. The second model verifies the level of truth in the
claim by computing the textual entailment between the claim and the true facts
retrieved from a manually curated COVID-19 dataset. The dataset is based on a
publicly available knowledge source consisting of more than 5000 COVID-19 false
claims and verified explanations, a subset of which was internally annotated
and cross-validated to train and evaluate our models. We evaluate a series of
models based on classical text-based features to more contextual Transformer
based models and observe that a model pipeline based on BERT and ALBERT for the
two stages respectively yields the best results.",0,1,0,1,0,0,0.885453,6.0,0.860633,28
http://arxiv.org/abs/2006.07982v2,ShapeFlow: Learnable Deformations Among 3D Shapes,43,0.472635,0.610527,"We present ShapeFlow, a flow-based model for learning a deformation space for
entire classes of 3D shapes with large intra-class variations. ShapeFlow allows
learning a multi-template deformation space that is agnostic to shape topology,
yet preserves fine geometric details. Different from a generative space where a
latent vector is directly decoded into a shape, a deformation space decodes a
vector into a continuous flow that can advect a source shape towards a target.
Such a space naturally allows the disentanglement of geometric style (coming
from the source) and structural pose (conforming to the target). We parametrize
the deformation between geometries as a learned continuous flow field via a
neural network and show that such deformations can be guaranteed to have
desirable properties, such as be bijectivity, freedom from self-intersections,
or volume preservation. We illustrate the effectiveness of this learned
deformation space for various downstream applications, including shape
generation via deformation, geometric style transfer, unsupervised learning of
a consistent parameterization for entire classes of shapes, and shape
interpolation.",0,0,0,0,0,0,0.942451,5.0,0.887935,68
http://arxiv.org/abs/2002.01808v5,K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters,469,0.836952,1.0,"We study the problem of injecting knowledge into large pre-trained models
like BERT and RoBERTa. Existing methods typically update the original
parameters of pre-trained models when injecting knowledge. However, when
multiple kinds of knowledge are injected, the historically injected knowledge
would be flushed away. To address this, we propose K-Adapter, a framework that
retains the original parameters of the pre-trained model fixed and supports the
development of versatile knowledge-infused model. Taking RoBERTa as the
backbone model, K-Adapter has a neural adapter for each kind of infused
knowledge, like a plug-in connected to RoBERTa. There is no information flow
between different adapters, thus multiple adapters can be efficiently trained
in a distributed way. As a case study, we inject two kinds of knowledge in this
work, including (1) factual knowledge obtained from automatically aligned
text-triplets on Wikipedia and Wikidata and (2) linguistic knowledge obtained
via dependency parsing. Results on three knowledge-driven tasks, including
relation classification, entity typing, and question answering, demonstrate
that each adapter improves the performance and the combination of both adapters
brings further improvements. Further analysis indicates that K-Adapter captures
versatile knowledge than RoBERTa.",1,1,0,1,0,0,0.895857,3.0,0.735603,53
http://arxiv.org/abs/2010.03546v1,Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing,80,0.582316,0.949082,"Task-oriented semantic parsing is a critical component of virtual assistants,
which is responsible for understanding the user's intents (set reminder, play
music, etc.). Recent advances in deep learning have enabled several approaches
to successfully parse more complex queries (Gupta et al., 2018; Rongali et
al.,2020), but these models require a large amount of annotated training data
to parse queries on new domains (e.g. reminder, music).
  In this paper, we focus on adapting task-oriented semantic parsers to
low-resource domains, and propose a novel method that outperforms a supervised
neural model at a 10-fold data reduction. In particular, we identify two
fundamental factors for low-resource domain adaptation: better representation
learning and better training techniques. Our representation learning uses BART
(Lewis et al., 2019) to initialize our model which outperforms encoder-only
pre-trained representations used in previous work. Furthermore, we train with
optimization-based meta-learning (Finn et al., 2017) to improve generalization
to low-resource domains. This approach significantly outperforms all baseline
methods in the experiments on a newly collected multi-domain task-oriented
semantic parsing dataset (TOPv2), which we release to the public.",0,1,0,1,1,0,0.868294,5.0,0.819442,33
http://arxiv.org/abs/2008.02002v1,Fast top-K Cosine Similarity Search through XOR-Friendly Binary Quantization on GPUs,5,0.0590937,0.218792,"We explore the use of GPU for accelerating large scale nearest neighbor
search and we propose a fast vector-quantization-based exhaustive nearest
neighbor search algorithm that can achieve high accuracy without any indexing
construction specifically designed for cosine similarity. This algorithm uses a
novel XOR-friendly binary quantization method to encode floating-point numbers
such that high-complexity multiplications can be optimized as low-complexity
bitwise operations. Experiments show that, our quantization method takes short
preprocessing time, and helps make the search speed of our exhaustive search
method much more faster than that of popular approximate nearest neighbor
algorithms when high accuracy is needed.",0,1,0,0,1,0,0.789585,18.0,0.935244,28
http://arxiv.org/abs/2009.00508v1,A High-Level Description and Performance Evaluation of Pupil Invisible,32,0.54106,0.436994,"Head-mounted eye trackers promise convenient access to reliable gaze data in
unconstrained environments. Due to several limitations, however, often they can
only partially deliver on this promise.
  Among those are the following: (i) the necessity of performing a device setup
and calibration prior to every use of the eye tracker, (ii) a lack of
robustness of gaze-estimation results against perturbations, such as outdoor
lighting conditions and unavoidable slippage of the eye tracker on the head of
the subject, and (iii) behavioral distortion resulting from social awkwardness,
due to the unnatural appearance of current head-mounted eye trackers.
  Recently, Pupil Labs released Pupil Invisible glasses, a head-mounted eye
tracker engineered to tackle these limitations. Here, we present an extensive
evaluation of its gaze-estimation capabilities. To this end, we designed a
data-collection protocol and evaluation scheme geared towards providing a
faithful portrayal of the real-world usage of Pupil Invisible glasses.
  In particular, we develop a geometric framework for gauging gaze-estimation
accuracy that goes beyond reporting mean angular accuracy. We demonstrate that
Pupil Invisible glasses, without the need of a calibration, provide gaze
estimates which are robust to perturbations, including outdoor lighting
conditions and slippage of the headset.",0,1,1,0,0,0,0.578471,8.0,0.780528,62
http://arxiv.org/abs/2008.00247v1,Meta-DRN: Meta-Learning for 1-Shot Image Segmentation,5,0.0042763,0.0432955,"Modern deep learning models have revolutionized the field of computer vision.
But, a significant drawback of most of these models is that they require a
large number of labelled examples to generalize properly. Recent developments
in few-shot learning aim to alleviate this requirement. In this paper, we
propose a novel lightweight CNN architecture for 1-shot image segmentation. The
proposed model is created by taking inspiration from well-performing
architectures for semantic segmentation and adapting it to the 1-shot domain.
We train our model using 4 meta-learning algorithms that have worked well for
image classification and compare the results. For the chosen dataset, our
proposed model has a 70% lower parameter count than the benchmark, while having
better or comparable mean IoU scores using all 4 of the meta-learning
algorithms.",0,1,0,0,0,0,0.439093,5.0,0.568545,33
http://arxiv.org/abs/2007.10961v1,Procrustean Regression Networks: Learning 3D Structure of Non-Rigid Objects from 2D Annotations,16,0.113129,0.30304,"We propose a novel framework for training neural networks which is capable of
learning 3D information of non-rigid objects when only 2D annotations are
available as ground truths. Recently, there have been some approaches that
incorporate the problem setting of non-rigid structure-from-motion (NRSfM) into
deep learning to learn 3D structure reconstruction. The most important
difficulty of NRSfM is to estimate both the rotation and deformation at the
same time, and previous works handle this by regressing both of them. In this
paper, we resolve this difficulty by proposing a loss function wherein the
suitable rotation is automatically determined. Trained with the cost function
consisting of the reprojection error and the low-rank term of aligned shapes,
the network learns the 3D structures of such objects as human skeletons and
faces during the training, whereas the testing is done in a single-frame basis.
The proposed method can handle inputs with missing entries and experimental
results validate that the proposed framework shows superior reconstruction
performance to the state-of-the-art method on the Human 3.6M, 300-VW, and
SURREAL datasets, even though the underlying network structure is very simple.",0,1,0,0,1,0,0.352027,9.0,0.728404,48
http://arxiv.org/abs/2002.12292v2,RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments,145,0.182603,0.692327,"Exploration in sparse reward environments remains one of the key challenges
of model-free reinforcement learning. Instead of solely relying on extrinsic
rewards provided by the environment, many state-of-the-art methods use
intrinsic rewards to encourage exploration. However, we show that existing
methods fall short in procedurally-generated environments where an agent is
unlikely to visit a state more than once. We propose a novel type of intrinsic
reward which encourages the agent to take actions that lead to significant
changes in its learned state representation. We evaluate our method on multiple
challenging procedurally-generated tasks in MiniGrid, as well as on tasks with
high-dimensional observations used in prior work. Our experiments demonstrate
that this approach is more sample efficient than existing exploration methods,
particularly for procedurally-generated MiniGrid environments. Furthermore, we
analyze the learned behavior as well as the intrinsic reward received by our
agent. In contrast to previous approaches, our intrinsic reward does not
diminish during the course of training and it rewards the agent substantially
more for interacting with objects that it can control.",0,1,0,0,0,0,0.154096,6.0,0.433815,67
http://arxiv.org/abs/2011.09839v1,Modular Multi Target Tracking Using LSTM Networks,6,0.0581373,0.212897,"The process of association and tracking of sensor detections is a key element
in providing situational awareness. When the targets in the scenario are dense
and exhibit high maneuverability, Multi-Target Tracking (MTT) becomes a
challenging task. The conventional techniques to solve such NP-hard
combinatorial optimization problem involves multiple complex models and
requires tedious tuning of parameters, failing to provide an acceptable
performance within the computational constraints. This paper proposes a model
free end-to-end approach for airborne target tracking system using sensor
measurements, integrating all the key elements of multi target tracking --
association, prediction and filtering using deep learning with memory. The
challenging task of association is performed using the Bi-Directional Long
short-term memory (LSTM) whereas filtering and prediction are done using LSTM
models. The proposed modular blocks can be independently trained and used in
multitude of tracking applications including non co-operative (e.g., radar) and
co-operative sensors (e.g., AIS, IFF, ADS-B). Such modular blocks also enhances
the interpretability of the deep learning application. It is shown that
performance of the proposed technique outperforms conventional state of the art
technique Joint Probabilistic Data Association with Interacting Multiple Model
(JPDA-IMM) filter.",0,1,0,0,1,0,0.176066,12.0,0.729078,23
http://arxiv.org/abs/2005.00743v3,Synthesizer: Rethinking Self-Attention in Transformer Models,69,0.228739,0.640444,"The dot product self-attention is known to be central and indispensable to
state-of-the-art Transformer models. But is it really required? This paper
investigates the true importance and contribution of the dot product-based
self-attention mechanism on the performance of Transformer models. Via
extensive experiments, we find that (1) random alignment matrices surprisingly
perform quite competitively and (2) learning attention weights from token-token
(query-key) interactions is useful but not that important after all. To this
end, we propose \textsc{Synthesizer}, a model that learns synthetic attention
weights without token-token interactions. In our experiments, we first show
that simple Synthesizers achieve highly competitive performance when compared
against vanilla Transformer models across a range of tasks, including machine
translation, language modeling, text generation and GLUE/SuperGLUE benchmarks.
When composed with dot product attention, we find that Synthesizers
consistently outperform Transformers. Moreover, we conduct additional
comparisons of Synthesizers against Dynamic Convolutions, showing that simple
Random Synthesizer is not only $60\%$ faster but also improves perplexity by a
relative $3.5\%$. Finally, we show that simple factorized Synthesizers can
outperform Linformers on encoding only tasks.",0,0,0,0,0,0,0.929446,5.0,0.873128,29
http://arxiv.org/abs/2009.07994v2,AAG: Self-Supervised Representation Learning by Auxiliary Augmentation with GNT-Xent Loss,1,0.00755032,0.00963709,"Self-supervised representation learning is an emerging research topic for its
powerful capacity in learning with unlabeled data. As a mainstream
self-supervised learning method, augmentation-based contrastive learning has
achieved great success in various computer vision tasks that lack manual
annotations. Despite current progress, the existing methods are often limited
by extra cost on memory or storage, and their performance still has large room
for improvement. Here we present a self-supervised representation learning
method, namely AAG, which is featured by an auxiliary augmentation strategy and
GNT-Xent loss. The auxiliary augmentation is able to promote the performance of
contrastive learning by increasing the diversity of images. The proposed
GNT-Xent loss enables a steady and fast training process and yields competitive
accuracy. Experiment results demonstrate the superiority of AAG to previous
state-of-the-art methods on CIFAR10, CIFAR100, and SVHN. Especially, AAG
achieves 94.5% top-1 accuracy on CIFAR10 with batch size 64, which is 0.5%
higher than the best result of SimCLR with batch size 1024.",0,1,0,0,1,1,0.911092,7.0,0.896342,33
http://arxiv.org/abs/2002.05196v3,Archimedean Choice Functions: an Axiomatic Foundation for Imprecise Decision Making,10,0.0181905,0.218668,"If uncertainty is modelled by a probability measure, decisions are typically
made by choosing the option with the highest expected utility. If an imprecise
probability model is used instead, this decision rule can be generalised in
several ways. We here focus on two such generalisations that apply to sets of
probability measures: E-admissibility and maximality. Both of them can be
regarded as special instances of so-called choice functions, a very general
mathematical framework for decision making. For each of these two decision
rules, we provide a set of necessary and sufficient conditions on choice
functions that uniquely characterises this rule, thereby providing an axiomatic
foundation for imprecise decision making with sets of probabilities. A
representation theorem for Archimedean choice functions in terms of coherent
lower previsions lies at the basis of both results.",0,0,0,0,0,0,8.08876e-05,17.0,0.351068,16
http://arxiv.org/abs/2002.00119v1,Improving Domain-Adapted Sentiment Classification by Deep Adversarial Mutual Learning,35,0.151236,0.722962,"Domain-adapted sentiment classification refers to training on a labeled
source domain to well infer document-level sentiment on an unlabeled target
domain. Most existing relevant models involve a feature extractor and a
sentiment classifier, where the feature extractor works towards learning
domain-invariant features from both domains, and the sentiment classifier is
trained only on the source domain to guide the feature extractor. As such, they
lack a mechanism to use sentiment polarity lying in the target domain. To
improve domain-adapted sentiment classification by learning sentiment from the
target domain as well, we devise a novel deep adversarial mutual learning
approach involving two groups of feature extractors, domain discriminators,
sentiment classifiers, and label probers. The domain discriminators enable the
feature extractors to obtain domain-invariant features. Meanwhile, the label
prober in each group explores document sentiment polarity of the target domain
through the sentiment prediction generated by the classifier in the peer group,
and guides the learning of the feature extractor in its own group. The proposed
approach achieves the mutual learning of the two groups in an end-to-end
manner. Experiments on multiple public datasets indicate our method obtains the
state-of-the-art performance, validating the effectiveness of mutual learning
through label probers.",1,1,0,0,1,0,0.449122,10.0,0.787345,35
http://arxiv.org/abs/2009.05132v1,1st Place Solution to Google Landmark Retrieval 2020,9,0.0635623,0.143634,"This paper presents the 1st place solution to the Google Landmark Retrieval
2020 Competition on Kaggle. The solution is based on metric learning to
classify numerous landmark classes, and uses transfer learning with two train
datasets, fine-tuning on bigger images, adjusting loss weight for cleaner
samples, and esemble to enhance the model's performance further. Finally, it
scored 0.38677 mAP@100 on the private leaderboard.",0,1,0,0,0,0,0.914391,3.0,0.763299,5
http://arxiv.org/abs/2010.14202v3,A Clarifying Question Selection System from NTES_ALONG in Convai3 Challenge,7,0.0520949,0.227139,"This paper presents the participation of NetEase Game AI Lab team for the
ClariQ challenge at Search-oriented Conversational AI (SCAI) EMNLP workshop in
2020. The challenge asks for a complete conversational information retrieval
system that can understanding and generating clarification questions. We
propose a clarifying question selection system which consists of response
understanding, candidate question recalling and clarifying question ranking. We
fine-tune a RoBERTa model to understand user's responses and use an enhanced
BM25 model to recall the candidate questions. In clarifying question ranking
stage, we reconstruct the training dataset and propose two models based on
ELECTRA. Finally we ensemble the models by summing up their output
probabilities and choose the question with the highest probability as the
clarification question. Experiments show that our ensemble ranking model
outperforms in the document relevance task and achieves the best recall@[20,30]
metrics in question relevance task. And in multi-turn conversation evaluation
in stage2, our system achieve the top score of all document relevance metrics.",0,1,0,0,0,0,0.975882,3.0,0.90186,7
http://arxiv.org/abs/2008.12295v3,Reducing Drift in Structure From Motion Using Extended Features,8,0.0356477,0.355992,"Low-frequency long-range errors (drift) are an endemic problem in 3D
structure from motion, and can often hamper reasonable reconstructions of the
scene. In this paper, we present a method to dramatically reduce scale and
positional drift by using extended structural features such as planes and
vanishing points. Unlike traditional feature matches, our extended features are
able to span non-overlapping input images, and hence provide long-range
constraints on the scale and shape of the reconstruction. We add these features
as additional constraints to a state-of-the-art global structure from motion
algorithm and demonstrate that the added constraints enable the reconstruction
of particularly drift-prone sequences such as long, low field-of-view videos
without inertial measurements. Additionally, we provide an analysis of the
drift-reducing capabilities of these constraints by evaluating on a synthetic
dataset. Our structural features are able to significantly reduce drift for
scenes that contain long-spanning man-made structures, such as aligned rows of
windows or planar building facades.",1,1,0,0,0,0,0.0112254,16.0,0.619164,62
http://arxiv.org/abs/2011.07164v1,Language Models not just for Pre-training: Fast Online Neural Noisy Channel Modeling,7,0.0172315,0.249138,"Pre-training models on vast quantities of unlabeled data has emerged as an
effective approach to improving accuracy on many NLP tasks. On the other hand,
traditional machine translation has a long history of leveraging unlabeled data
through noisy channel modeling. The same idea has recently been shown to
achieve strong improvements for neural machine translation. Unfortunately,
na\""{i}ve noisy channel modeling with modern sequence to sequence models is up
to an order of magnitude slower than alternatives. We address this issue by
introducing efficient approximations to make inference with the noisy channel
approach as fast as strong ensembles while increasing accuracy. We also show
that the noisy channel approach can outperform strong pre-training results by
achieving a new state of the art on WMT Romanian-English translation.",0,1,0,0,1,0,0.522115,5.0,0.617454,37
http://arxiv.org/abs/2002.08777v1,Do you comply with AI? -- Personalized explanations of learning algorithms and their impact on employees' compliance behavior,28,0.156529,0.451108,"Machine Learning algorithms are technological key enablers for artificial
intelligence (AI). Due to the inherent complexity, these learning algorithms
represent black boxes and are difficult to comprehend, therefore influencing
compliance behavior. Hence, compliance with the recommendations of such
artifacts, which can impact employees' task performance significantly, is still
subject to research - and personalization of AI explanations seems to be a
promising concept in this regard. In our work, we hypothesize that, based on
varying backgrounds like training, domain knowledge and demographic
characteristics, individuals have different understandings and hence mental
models about the learning algorithm. Personalization of AI explanations,
related to the individuals' mental models, may thus be an instrument to affect
compliance and therefore employee task performance. Our preliminary results
already indicate the importance of personalized explanations in industry
settings and emphasize the importance of this research endeavor.",0,0,0,0,0,0,0.0352168,12.0,0.588517,30
http://arxiv.org/abs/2004.14543v3,TAVAT: Token-Aware Virtual Adversarial Training for Language Understanding,23,0.0326136,0.145442,"Gradient-based adversarial training is widely used in improving the
robustness of neural networks, while it cannot be easily adapted to natural
language processing tasks since the embedding space is discrete. In natural
language processing fields, virtual adversarial training is introduced since
texts are discrete and cannot be perturbed by gradients directly.
Alternatively, virtual adversarial training, which generates perturbations on
the embedding space, is introduced in NLP tasks. Despite its success, existing
virtual adversarial training methods generate perturbations roughly constrained
by Frobenius normalization balls. To craft fine-grained perturbations, we
propose a Token-Aware Virtual Adversarial Training method. We introduce a
token-level accumulated perturbation vocabulary to initialize the perturbations
better and use a token-level normalization ball to constrain these
perturbations pertinently. Experiments show that our method improves the
performance of pre-trained models such as BERT and ALBERT in various tasks by a
considerable margin. The proposed method improves the score of the GLUE
benchmark from 78.3 to 80.9 using BERT model and it also enhances the
performance of sequence labeling and text classification tasks.",0,1,0,0,0,0,0.782563,6.0,0.802185,29
http://arxiv.org/abs/2006.00067v2,Automated Measurements of Key Morphological Features of Human Embryos for IVF,19,0.176421,0.62351,"A major challenge in clinical In-Vitro Fertilization (IVF) is selecting the
highest quality embryo to transfer to the patient in the hopes of achieving a
pregnancy. Time-lapse microscopy provides clinicians with a wealth of
information for selecting embryos. However, the resulting movies of embryos are
currently analyzed manually, which is time consuming and subjective. Here, we
automate feature extraction of time-lapse microscopy of human embryos with a
machine-learning pipeline of five convolutional neural networks (CNNs). Our
pipeline consists of (1) semantic segmentation of the regions of the embryo,
(2) regression predictions of fragment severity, (3) classification of the
developmental stage, and object instance segmentation of (4) cells and (5)
pronuclei. Our approach greatly speeds up the measurement of quantitative,
biologically relevant features that may aid in embryo selection.",0,1,0,0,0,0,0.239972,10.0,0.709739,35
http://arxiv.org/abs/2012.04572v2,I'm Sorry for Your Loss: Spectrally-Based Audio Distances Are Bad at Pitch,27,0.422114,0.440072,"Growing research demonstrates that synthetic failure modes imply poor
generalization. We compare commonly used audio-to-audio losses on a synthetic
benchmark, measuring the pitch distance between two stationary sinusoids. The
results are surprising: many have poor sense of pitch direction. These
shortcomings are exposed using simple rank assumptions. Our task is trivial for
humans but difficult for these audio distances, suggesting significant progress
can be made in self-supervised audio learning by improving current losses.",0,0,0,0,0,0,0.891843,6.0,0.864991,76
http://arxiv.org/abs/2002.02210v3,From Data to Actions in Intelligent Transportation Systems: a Prescription of Functional Requirements for Model Actionability,34,0.233672,0.738571,"Advances in Data Science permeate every field of Transportation Science and
Engineering, resulting in developments in the transportation sector that {are}
data-driven. Nowadays, Intelligent Transportation Systems (ITS) could be
arguably approached as a ``story'' intensively producing and consuming large
amounts of data. A~diversity of sensing devices densely spread over the
infrastructure, vehicles or the travelers' personal devices act as sources of
data flows that are eventually fed {into} software running on automatic
devices, actuators or control systems producing, in~turn, complex information
flows {among} users, traffic managers, data analysts, traffic modeling
scientists, etc. These~information flows provide enormous opportunities to
improve model development and decision-making. This work aims to describe how
data, coming from diverse ITS sources, can be used to learn and adapt
data-driven models for efficiently operating ITS assets, systems and processes;
in~other words, for data-based models to fully become \emph{actionable}.
Grounded in this described data modeling pipeline for ITS, we~define the
characteristics, engineering requisites and challenges intrinsic to its three
compounding stages, namely, data fusion, adaptive learning and model
evaluation. We~deliberately generalize model learning to be adaptive, since,
in~the core of our paper is the firm conviction that most learners will have to
adapt to the ever-changing phenomenon scenario underlying the majority of ITS
applications. Finally, we~provide a prospect of current research lines within
Data Science that can bring notable advances to data-based ITS modeling, which
will eventually bridge the gap towards the practicality and actionability of
such models.",0,0,0,0,0,0,0.0601857,10.0,0.561112,234
http://arxiv.org/abs/2002.02079v1,Forensic Scanner Identification Using Machine Learning,7,0.184159,0.271064,"Due to the increasing availability and functionality of image editing tools,
many forensic techniques such as digital image authentication, source
identification and tamper detection are important for forensic image analysis.
In this paper, we describe a machine learning based system to address the
forensic analysis of scanner devices. The proposed system uses deep-learning to
automatically learn the intrinsic features from various scanned images. Our
experimental results show that high accuracy can be achieved for source scanner
identification. The proposed system can also generate a reliability map that
indicates the manipulated regions in an scanned image.",0,1,0,0,0,0,0.846931,22.0,0.955462,20
http://arxiv.org/abs/2010.08788v1,Discovering Pattern Structure Using Differentiable Compositing,25,0.2013,0.422503,"Patterns, which are collections of elements arranged in regular or
near-regular arrangements, are an important graphic art form and widely used
due to their elegant simplicity and aesthetic appeal. When a pattern is encoded
as a flat image without the underlying structure, manually editing the pattern
is tedious and challenging as one has to both preserve the individual element
shapes and their original relative arrangements. State-of-the-art deep learning
frameworks that operate at the pixel level are unsuitable for manipulating such
patterns. Specifically, these methods can easily disturb the shapes of the
individual elements or their arrangement, and thus fail to preserve the latent
structures of the input patterns. We present a novel differentiable compositing
operator using pattern elements and use it to discover structures, in the form
of a layered representation of graphical objects, directly from raw pattern
images. This operator allows us to adapt current deep learning based image
methods to effectively handle patterns. We evaluate our method on a range of
patterns and demonstrate superiority in the context of pattern manipulations
when compared against state-of-the-art",0,1,0,0,0,0,0.271208,10.0,0.723971,69
http://arxiv.org/abs/2007.09450v2,Analysis of Bayesian Networks via Prob-Solvable Loops,12,0.0287358,0.284374,"Prob-solvable loops are probabilistic programs with polynomial assignments
over random variables and parametrised distributions, for which the full
automation of moment-based invariant generation is decidable. In this paper we
extend Prob-solvable loops with new features essential for encoding Bayesian
networks (BNs). We show that various BNs, such as discrete, Gaussian,
conditional linear Gaussian and dynamic BNs, can be naturally encoded as
Prob-solvable loops. Thanks to these encodings, we can automatically solve
several BN related problems, including exact inference, sensitivity analysis,
filtering and computing the expected number of rejecting samples in
sampling-based procedures. We evaluate our work on a number of BN benchmarks,
using automated invariant generation within Prob-solvable loop analysis.",0,0,0,0,0,0,7.35542e-05,21.0,0.470148,47
http://arxiv.org/abs/2010.12771v2,On Learning Text Style Transfer with Direct Rewards,38,0.430842,0.444886,"In most cases, the lack of parallel corpora makes it impossible to directly
train supervised models for the text style transfer task. In this paper, we
explore training algorithms that instead optimize reward functions that
explicitly consider different aspects of the style-transferred outputs. In
particular, we leverage semantic similarity metrics originally used for
fine-tuning neural machine translation models to explicitly assess the
preservation of content between system outputs and input texts. We also
investigate the potential weaknesses of the existing automatic metrics and
propose efficient strategies of using these metrics for training. The
experimental results show that our model provides significant gains in both
automatic and human evaluation over strong baselines, indicating the
effectiveness of our proposed methods and training strategies.",1,0,0,0,0,0,0.909346,5.0,0.853265,45
http://arxiv.org/abs/2006.04562v2,Towards an Argument Mining Pipeline Transforming Texts to Argument Graphs,19,0.334101,0.365927,"This paper targets the automated extraction of components of argumentative
information and their relations from natural language text. Moreover, we
address a current lack of systems to provide complete argumentative structure
from arbitrary natural language text for general usage. We present an argument
mining pipeline as a universally applicable approach for transforming German
and English language texts to graph-based argument representations. We also
introduce new methods for evaluating the results based on existing benchmark
argument structures. Our results show that the generated argument graphs can be
beneficial to detect new connections between different statements of an
argumentative text. Our pipeline implementation is publicly available on
GitHub.",1,0,0,1,0,0,0.549223,9.0,0.795932,28
http://arxiv.org/abs/2007.02609v2,Relevance Transformer: Generating Concise Code Snippets with Relevance Feedback,11,0.0276489,0.18938,"Tools capable of automatic code generation have the potential to augment
programmer's capabilities. While straightforward code retrieval is incorporated
into many IDEs, an emerging area is explicit code generation. Code generation
is currently approached as a Machine Translation task, with Recurrent Neural
Network (RNN) based encoder-decoder architectures trained on code-description
pairs. In this work we introduce and study modern Transformer architectures for
this task. We further propose a new model called the Relevance Transformer that
incorporates external knowledge using pseudo-relevance feedback. The Relevance
Transformer biases the decoding process to be similar to existing retrieved
code while enforcing diversity. We perform experiments on multiple standard
benchmark datasets for code generation including Django, Hearthstone, and
CoNaLa. The results show improvements over state-of-the-art methods based on
BLEU evaluation. The Relevance Transformer model shows the potential of
Transformer-based architectures for code generation and introduces a method of
incorporating pseudo-relevance feedback during inference.",0,1,0,0,1,0,0.0664776,10.0,0.571387,19
http://arxiv.org/abs/2004.14646v1,Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning,118,0.281708,0.716815,"Learning a good representation is an essential component for deep
reinforcement learning (RL). Representation learning is especially important in
multitask and partially observable settings where building a representation of
the unknown environment is crucial to solve the tasks. Here we introduce
Prediction of Bootstrap Latents (PBL), a simple and flexible self-supervised
representation learning algorithm for multitask deep RL. PBL builds on
multistep predictive representations of future observations, and focuses on
capturing structured information about environment dynamics. Specifically, PBL
trains its representation by predicting latent embeddings of future
observations. These latent embeddings are themselves trained to be predictive
of the aforementioned representations. These predictions form a bootstrapping
effect, allowing the agent to learn more about the key aspects of the
environment dynamics. In addition, by defining prediction tasks completely in
latent space, PBL provides the flexibility of using multimodal observations
involving pixel images, language instructions, rewards and more. We show in our
experiments that PBL delivers across-the-board improved performance over state
of the art deep RL agents in the DMLab-30 and Atari-57 multitask setting.",1,1,0,0,1,0,0.606288,6.0,0.720047,53
http://arxiv.org/abs/2007.15240v1,Action2Motion: Conditioned Generation of 3D Human Motions,262,0.991055,1.0,"Action recognition is a relatively established task, where givenan input
sequence of human motion, the goal is to predict its ac-tion category. This
paper, on the other hand, considers a relativelynew problem, which could be
thought of as an inverse of actionrecognition: given a prescribed action type,
we aim to generateplausible human motion sequences in 3D. Importantly, the set
ofgenerated motions are expected to maintain itsdiversityto be ableto explore
the entire action-conditioned motion space; meanwhile,each sampled sequence
faithfully resembles anaturalhuman bodyarticulation dynamics. Motivated by
these objectives, we followthe physics law of human kinematics by adopting the
Lie Algebratheory to represent thenaturalhuman motions; we also propose
atemporal Variational Auto-Encoder (VAE) that encourages adiversesampling of
the motion space. A new 3D human motion dataset, HumanAct12, is also
constructed. Empirical experiments overthree distinct human motion datasets
(including ours) demonstratethe effectiveness of our approach.",0,0,0,1,0,0,0.895205,6.0,0.867341,38
http://arxiv.org/abs/2005.04544v5,"Unified Models of Human Behavioral Agents in Bandits, Contextual Bandits and RL",24,0.204336,0.574901,"Artificial behavioral agents are often evaluated based on their consistent
behaviors and performance to take sequential actions in an environment to
maximize some notion of cumulative reward. However, human decision making in
real life usually involves different strategies and behavioral trajectories
that lead to the same empirical outcome. Motivated by clinical literature of a
wide range of neurological and psychiatric disorders, we propose here a more
general and flexible parametric framework for sequential decision making that
involves a two-stream reward processing mechanism. We demonstrated that this
framework is flexible and unified enough to incorporate a family of problems
spanning multi-armed bandits (MAB), contextual bandits (CB) and reinforcement
learning (RL), which decompose the sequential decision making process in
different levels. Inspired by the known reward processing abnormalities of many
mental disorders, our clinically-inspired agents demonstrated interesting
behavioral trajectories and comparable performance on simulated tasks with
particular reward distributions, a real-world dataset capturing human
decision-making in gambling tasks, and the PacMan game across different reward
stationarities in a lifelong learning setting.",1,0,0,0,0,0,0.015545,19.0,0.696546,48
http://arxiv.org/abs/2005.06618v2,Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective Learning,17,0.399434,0.617107,"Human society had a long history of suffering from cognitive biases leading
to social prejudices and mass injustice. The prevalent existence of cognitive
biases in large volumes of historical data can pose a threat of being
manifested as unethical and seemingly inhuman predictions as outputs of AI
systems trained on such data. To alleviate this problem, we propose a
bias-aware multi-objective learning framework that given a set of identity
attributes (e.g. gender, ethnicity etc.) and a subset of sensitive categories
of the possible classes of prediction outputs, learns to reduce the frequency
of predicting certain combinations of them, e.g. predicting stereotypes such as
`most blacks use abusive language', or `fear is a virtue of women'. Our
experiments conducted on an emotion prediction task with balanced class priors
shows that a set of baseline bias-agnostic models exhibit cognitive biases with
respect to gender, such as women are prone to be afraid whereas men are more
prone to be angry. In contrast, our proposed bias-aware multi-objective
learning methodology is shown to reduce such biases in the predictied emotions.",0,0,0,0,0,0,0.985391,3.0,0.943947,32
http://arxiv.org/abs/2009.01972v1,Attribute Adaptive Margin Softmax Loss using Privileged Information,5,0.228939,0.565402,"We present a novel framework to exploit privileged information for
recognition which is provided only during the training phase. Here, we focus on
recognition task where images are provided as the main view and soft biometric
traits (attributes) are provided as the privileged data (only available during
training phase). We demonstrate that more discriminative feature space can be
learned by enforcing a deep network to adjust adaptive margins between classes
utilizing attributes. This tight constraint also effectively reduces the class
imbalance inherent in the local data neighborhood, thus carving more balanced
class boundaries locally and using feature space more efficiently. Extensive
experiments are performed on five different datasets and the results show the
superiority of our method compared to the state-of-the-art models in both tasks
of face recognition and person re-identification.",0,1,0,0,1,0,0.991389,9.0,0.994411,37
http://arxiv.org/abs/2003.11342v1,Circumventing Outliers of AutoAugment with Knowledge Distillation,53,0.141869,0.384668,"AutoAugment has been a powerful algorithm that improves the accuracy of many
vision tasks, yet it is sensitive to the operator space as well as
hyper-parameters, and an improper setting may degenerate network optimization.
This paper delves deep into the working mechanism, and reveals that AutoAugment
may remove part of discriminative information from the training image and so
insisting on the ground-truth label is no longer the best option. To relieve
the inaccuracy of supervision, we make use of knowledge distillation that
refers to the output of a teacher model to guide network training. Experiments
are performed in standard image classification benchmarks, and demonstrate the
effectiveness of our approach in suppressing noise of data augmentation and
stabilizing training. Upon the cooperation of knowledge distillation and
AutoAugment, we claim the new state-of-the-art on ImageNet classification with
a top-1 accuracy of 85.8%.",0,1,0,0,1,1,0.874988,6.0,0.853769,60
http://arxiv.org/abs/2007.09919v2,Robust Tracking against Adversarial Attacks,37,0.178965,0.715763,"While deep convolutional neural networks (CNNs) are vulnerable to adversarial
attacks, considerably few efforts have been paid to construct robust deep
tracking algorithms against adversarial attacks. Current studies on adversarial
attack and defense mainly reside in a single image. In this work, we first
attempt to generate adversarial examples on top of video sequences to improve
the tracking robustness against adversarial attacks. To this end, we take
temporal motion into consideration when generating lightweight perturbations
over the estimated tracking results frame-by-frame. On one hand, we add the
temporal perturbations into the original video sequences as adversarial
examples to greatly degrade the tracking performance. On the other hand, we
sequentially estimate the perturbations from input sequences and learn to
eliminate their effect for performance restoration. We apply the proposed
adversarial attack and defense approaches to state-of-the-art deep tracking
algorithms. Extensive evaluations on the benchmark datasets demonstrate that
our defense method not only eliminates the large performance drops caused by
adversarial attacks, but also achieves additional performance gains when deep
trackers are not under adversarial attacks.",1,1,0,0,0,0,0.910856,6.0,0.878883,48
http://arxiv.org/abs/2010.02646v1,On the Sparsity of Neural Machine Translation Models,11,0.0269445,0.349342,"Modern neural machine translation (NMT) models employ a large number of
parameters, which leads to serious over-parameterization and typically causes
the underutilization of computational resources. In response to this problem,
we empirically investigate whether the redundant parameters can be reused to
achieve better performance. Experiments and analyses are systematically
conducted on different datasets and NMT architectures. We show that: 1) the
pruned parameters can be rejuvenated to improve the baseline model by up to
+0.8 BLEU points; 2) the rejuvenated parameters are reallocated to enhance the
ability of modeling low-level lexical information.",0,1,0,0,0,0,0.294097,7.0,0.619401,29
http://arxiv.org/abs/2008.00238v1,An Explainable Machine Learning Model for Early Detection of Parkinson's Disease using LIME on DaTscan Imagery,134,0.246347,0.771375,"Parkinson's disease (PD) is a degenerative and progressive neurological
condition. Early diagnosis can improve treatment for patients and is performed
through dopaminergic imaging techniques like the SPECT DaTscan. In this study,
we propose a machine learning model that accurately classifies any given
DaTscan as having Parkinson's disease or not, in addition to providing a
plausible reason for the prediction. This is kind of reasoning is done through
the use of visual indicators generated using Local Interpretable Model-Agnostic
Explainer (LIME) methods. DaTscans were drawn from the Parkinson's Progression
Markers Initiative database and trained on a CNN (VGG16) using transfer
learning, yielding an accuracy of 95.2%, a sensitivity of 97.5%, and a
specificity of 90.9%. Keeping model interpretability of paramount importance,
especially in the healthcare field, this study utilises LIME explanations to
distinguish PD from non-PD, using visual superpixels on the DaTscans. It could
be concluded that the proposed system, in union with its measured
interpretability and accuracy may effectively aid medical workers in the early
diagnosis of Parkinson's Disease.",0,1,0,0,1,0,0.196982,7.0,0.553372,36
http://arxiv.org/abs/2005.10406v2,Training Keyword Spotting Models on Non-IID Data with Federated Learning,59,0.249901,0.522181,"We demonstrate that a production-quality keyword-spotting model can be
trained on-device using federated learning and achieve comparable false accept
and false reject rates to a centrally-trained model. To overcome the
algorithmic constraints associated with fitting on-device data (which are
inherently non-independent and identically distributed), we conduct thorough
empirical studies of optimization algorithms and hyperparameter configurations
using large-scale federated simulations. To overcome resource constraints, we
replace memory intensive MTR data augmentation with SpecAugment, which reduces
the false reject rate by 56%. Finally, to label examples (given the zero
visibility into on-device data), we explore teacher-student training.",0,1,0,0,0,0,0.81732,4.0,0.7303,44
http://arxiv.org/abs/2012.14978v1,Few-Shot Named Entity Recognition: A Comprehensive Study,74,0.991026,0.914388,"This paper presents a comprehensive study to efficiently build named entity
recognition (NER) systems when a small number of in-domain labeled data is
available. Based upon recent Transformer-based self-supervised pre-trained
language models (PLMs), we investigate three orthogonal schemes to improve the
model generalization ability for few-shot settings: (1) meta-learning to
construct prototypes for different entity types, (2) supervised pre-training on
noisy web data to extract entity-related generic representations and (3)
self-training to leverage unlabeled in-domain data. Different combinations of
these schemes are also considered. We perform extensive empirical comparisons
on 10 public NER datasets with various proportions of labeled data, suggesting
useful insights for future research. Our experiments show that (i) in the
few-shot learning setting, the proposed NER schemes significantly improve or
outperform the commonly used baseline, a PLM-based linear classifier fine-tuned
on domain labels; (ii) We create new state-of-the-art results on both few-shot
and training-free settings compared with existing methods. We will release our
code and pre-trained models for reproducible research.",0,1,0,0,1,0,0.987525,5.0,0.973704,69
http://arxiv.org/abs/2004.00963v1,An anytime tree search algorithm for the 2018 ROADEF/EURO challenge glass cutting problem,20,0.0525744,0.732202,"In this article, we present the anytime tree search algorithm we designed for
the 2018 ROADEF/EURO challenge glass cutting problem proposed by the French
company Saint-Gobain. The resulting program was ranked first among 64
participants. Its key components are: a new search algorithm called Memory
Bounded A* (MBA*) with guide functions, a symmetry breaking strategy, and a
pseudo-dominance rule. We perform a comprehensive study of these components
showing that each of them contributes to the algorithm global performances. In
addition, we designed a second tree search algorithm fully based on the
pseudo-dominance rule and dedicated to some of the challenge instances with
strong precedence constraints. On these instances, it finds the best-known
solutions very quickly.",0,1,0,0,0,0,1.29799e-05,15.0,0.142564,42
http://arxiv.org/abs/2011.06153v1,Augmenting BERT Carefully with Underrepresented Linguistic Features,2,0.0521459,0.0512443,"Fine-tuned Bidirectional Encoder Representations from Transformers
(BERT)-based sequence classification models have proven to be effective for
detecting Alzheimer's Disease (AD) from transcripts of human speech. However,
previous research shows it is possible to improve BERT's performance on various
tasks by augmenting the model with additional information. In this work, we use
probing tasks as introspection techniques to identify linguistic information
not well-represented in various layers of BERT, but important for the AD
detection task. We supplement these linguistic features in which
representations from BERT are found to be insufficient with hand-crafted
features externally, and show that jointly fine-tuning BERT in combination with
these features improves the performance of AD classification by upto 5\% over
fine-tuned BERT alone.",0,1,0,0,0,0,0.890493,5.0,0.83687,21
http://arxiv.org/abs/2004.12331v1,Neural Topic Modeling with Bidirectional Adversarial Training,72,0.361736,0.67637,"Recent years have witnessed a surge of interests of using neural topic models
for automatic topic extraction from text, since they avoid the complicated
mathematical derivations for model inference as in traditional topic models
such as Latent Dirichlet Allocation (LDA). However, these models either
typically assume improper prior (e.g. Gaussian or Logistic Normal) over latent
topic space or could not infer topic distribution for a given document. To
address these limitations, we propose a neural topic modeling approach, called
Bidirectional Adversarial Topic (BAT) model, which represents the first attempt
of applying bidirectional adversarial training for neural topic modeling. The
proposed BAT builds a two-way projection between the document-topic
distribution and the document-word distribution. It uses a generator to capture
the semantic patterns from texts and an encoder for topic inference.
Furthermore, to incorporate word relatedness information, the Bidirectional
Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To
verify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are
used in our experiments. The experimental results show that BAT and
Gaussian-BAT obtain more coherent topics, outperforming several competitive
baselines. Moreover, when performing text clustering based on the extracted
topics, our models outperform all the baselines, with more significant
improvements achieved by Gaussian-BAT where an increase of near 6\% is observed
in accuracy.",0,0,0,0,0,0,0.776985,9.0,0.866264,35
http://arxiv.org/abs/2010.04862v2,Remarks on Optimal Scores for Speaker Recognition,8,0.0377316,0.20812,"In this article, we first establish the theory of optimal scores for speaker
recognition. Our analysis shows that the minimum Bayes risk (MBR) decisions for
both the speaker identification and speaker verification tasks can be based on
a normalized likelihood (NL). When the underlying generative model is a linear
Gaussian, the NL score is mathematically equivalent to the PLDA likelihood
ratio, and the empirical scores based on cosine distance and Euclidean distance
can be seen as approximations of this linear Gaussian NL score under some
conditions. We discuss a number of properties of the NL score and perform a
simple simulation experiment to demonstrate the properties of the NL score.",0,0,0,0,0,0,0.0543936,11.0,0.591535,34
http://arxiv.org/abs/2010.11796v2,CryptoGRU: Low Latency Privacy-Preserving Text Analysis With GRU,12,0.120118,0.503716,"Billions of text analysis requests containing private emails, personal text
messages, and sensitive online reviews, are processed by recurrent neural
networks (RNNs) deployed on public clouds every day. Although prior secure
networks combine homomorphic encryption (HE) and garbled circuit (GC) to
preserve users' privacy, naively adopting the HE and GC hybrid technique to
implement RNNs suffers from long inference latency due to slow activation
functions. In this paper, we present a HE and GC hybrid gated recurrent unit
(GRU) network, CryptoGRU, for low-latency secure inferences. CryptoGRU replaces
computationally expensive GC-based $tanh$ with fast GC-based $ReLU$, and then
quantizes $sigmoid$ and $ReLU$ with a smaller bit length to accelerate
activations in a GRU. We evaluate CryptoGRU with multiple GRU models trained on
4 public datasets. Experimental results show CryptoGRU achieves top-notch
accuracy and improves the secure inference latency by up to $138\times$ over
one of state-of-the-art secure networks on the Penn Treebank dataset.",1,1,0,0,1,0,0.743536,9.0,0.855401,25
http://arxiv.org/abs/2001.03632v1,Does syntax need to grow on trees? Sources of hierarchical inductive bias in sequence-to-sequence networks,87,0.0873274,0.611458,"Learners that are exposed to the same training data might generalize
differently due to differing inductive biases. In neural network models,
inductive biases could in theory arise from any aspect of the model
architecture. We investigate which architectural factors affect the
generalization behavior of neural sequence-to-sequence models trained on two
syntactic tasks, English question formation and English tense reinflection. For
both tasks, the training set is consistent with a generalization based on
hierarchical structure and a generalization based on linear order. All
architectural factors that we investigated qualitatively affected how models
generalized, including factors with no clear connection to hierarchical
structure. For example, LSTMs and GRUs displayed qualitatively different
inductive biases. However, the only factor that consistently contributed a
hierarchical bias across tasks was the use of a tree-structured model rather
than a model with sequential recurrence, suggesting that human-like syntactic
generalization requires architectural syntactic structure.",1,0,0,0,0,0,0.000462729,16.0,0.419527,55
http://arxiv.org/abs/2011.09039v1,Sequence-Level Mixed Sample Data Augmentation,82,0.210784,0.648983,"Despite their empirical success, neural networks still have difficulty
capturing compositional aspects of natural language. This work proposes a
simple data augmentation approach to encourage compositional behavior in neural
models for sequence-to-sequence problems. Our approach, SeqMix, creates new
synthetic examples by softly combining input/output sequences from the training
set. We connect this approach to existing techniques such as SwitchOut and word
dropout, and show that these techniques are all approximating variants of a
single objective. SeqMix consistently yields approximately 1.0 BLEU improvement
on five different translation datasets over strong Transformer baselines. On
tasks that require strong compositional generalization such as SCAN and
semantic parsing, SeqMix also offers further improvements.",1,1,0,0,0,1,0.443612,7.0,0.693803,22
http://arxiv.org/abs/2004.14325v3,Don't Neglect the Obvious: On the Role of Unambiguous Words in Word Sense Disambiguation,11,0.0974426,0.669189,"State-of-the-art methods for Word Sense Disambiguation (WSD) combine two
different features: the power of pre-trained language models and a propagation
method to extend the coverage of such models. This propagation is needed as
current sense-annotated corpora lack coverage of many instances in the
underlying sense inventory (usually WordNet). At the same time, unambiguous
words make for a large portion of all words in WordNet, while being poorly
covered in existing sense-annotated corpora. In this paper, we propose a simple
method to provide annotations for most unambiguous words in a large corpus. We
introduce the UWA (Unambiguous Word Annotations) dataset and show how a
state-of-the-art propagation-based model can use it to extend the coverage and
quality of its word sense embeddings by a significant margin, improving on its
original results on WSD.",0,1,0,1,0,0,0.423958,7.0,0.685083,33
http://arxiv.org/abs/2010.07650v2,Altruist: Argumentative Explanations through Local Interpretations of Predictive Models,9,0.0817951,0.247979,"Explainable AI is an emerging field providing solutions for acquiring
insights into automated systems' rationale. It has been put on the AI map by
suggesting ways to tackle key ethical and societal issues. Existing explanation
techniques are often not comprehensible to the end user. Lack of evaluation and
selection criteria also makes it difficult for the end user to choose the most
suitable technique. In this study, we combine logic-based argumentation with
Interpretable Machine Learning, introducing a preliminary meta-explanation
methodology that identifies the truthful parts of feature importance oriented
interpretations. This approach, in addition to being used as a meta-explanation
technique, can be used as an evaluation or selection tool for multiple feature
importance techniques. Experimentation strongly indicates that an ensemble of
multiple interpretation techniques yields considerably more truthful
explanations.",1,0,0,0,0,0,0.16809,9.0,0.633101,47
http://arxiv.org/abs/2008.11604v1,Cross-Spectral Periocular Recognition with Conditional Adversarial Networks,10,0.459935,0.47334,"This work addresses the challenge of comparing periocular images captured in
different spectra, which is known to produce significant drops in performance
in comparison to operating in the same spectrum. We propose the use of
Conditional Generative Adversarial Networks, trained to con-vert periocular
images between visible and near-infrared spectra, so that biometric
verification is carried out in the same spectrum. The proposed setup allows the
use of existing feature methods typically optimized to operate in a single
spectrum. Recognition experiments are done using a number of off-the-shelf
periocular comparators based both on hand-crafted features and CNN descriptors.
Using the Hong Kong Polytechnic University Cross-Spectral Iris Images Database
(PolyU) as benchmark dataset, our experiments show that cross-spectral
performance is substantially improved if both images are converted to the same
spectrum, in comparison to matching features extracted from images in different
spectra. In addition to this, we fine-tune a CNN based on the ResNet50
architecture, obtaining a cross-spectral periocular performance of EER=1%, and
GAR>99% @ FAR=1%, which is comparable to the state-of-the-art with the PolyU
database.",1,1,0,0,1,0,0.906846,9.0,0.917214,34
http://arxiv.org/abs/2007.14943v1,Simultaneously Learning Corrections and Error Models for Geometry-based Visual Odometry Methods,8,0.070393,0.322954,"This paper fosters the idea that deep learning methods can be used to
complement classical visual odometry pipelines to improve their accuracy and to
associate uncertainty models to their estimations. We show that the biases
inherent to the visual odometry process can be faithfully learned and
compensated for, and that a learning architecture associated with a
probabilistic loss function can jointly estimate a full covariance matrix of
the residual errors, defining an error model capturing the heteroscedasticity
of the process. Experiments on autonomous driving image sequences assess the
possibility to concurrently improve visual odometry and estimate an error
associated with its outputs.",0,1,0,0,0,0,0.518883,9.0,0.786456,19
http://arxiv.org/abs/2007.02501v1,Learning Motion Flows for Semi-supervised Instrument Segmentation from Robotic Surgical Video,30,0.108425,0.463466,"Performing low hertz labeling for surgical videos at intervals can greatly
releases the burden of surgeons. In this paper, we study the semi-supervised
instrument segmentation from robotic surgical videos with sparse annotations.
Unlike most previous methods using unlabeled frames individually, we propose a
dual motion based method to wisely learn motion flows for segmentation
enhancement by leveraging temporal dynamics. We firstly design a flow predictor
to derive the motion for jointly propagating the frame-label pairs given the
current labeled frame. Considering the fast instrument motion, we further
introduce a flow compensator to estimate intermediate motion within continuous
frames, with a novel cycle learning strategy. By exploiting generated data
pairs, our framework can recover and even enhance temporal consistency of
training sequences to benefit segmentation. We validate our framework with
binary, part, and type tasks on 2017 MICCAI EndoVis Robotic Instrument
Segmentation Challenge dataset. Results show that our method outperforms the
state-of-the-art semi-supervised methods by a large margin, and even exceeds
fully supervised training on two tasks.",1,1,0,0,1,0,0.384068,5.0,0.533234,27
http://arxiv.org/abs/2005.10790v1,The Frankfurt Latin Lexicon: From Morphological Expansion and Word Embeddings to SemioGraphs,5,0.538576,0.441679,"In this article we present the Frankfurt Latin Lexicon (FLL), a lexical
resource for Medieval Latin that is used both for the lemmatization of Latin
texts and for the post-editing of lemmatizations. We describe recent advances
in the development of lemmatizers and test them against the Capitularies corpus
(comprising Frankish royal edicts, mid-6th to mid-9th century), a corpus
created as a reference for processing Medieval Latin. We also consider the
post-correction of lemmatizations using a limited crowdsourcing process aimed
at continuous review and updating of the FLL. Starting from the texts resulting
from this lemmatization process, we describe the extension of the FLL by means
of word embeddings, whose interactive traversing by means of SemioGraphs
completes the digital enhanced hermeneutic circle. In this way, the article
argues for a more comprehensive understanding of lemmatization, encompassing
classical machine learning as well as intellectual post-corrections and, in
particular, human computation in the form of interpretation processes based on
graph representations of the underlying lexical resources.",0,0,0,0,0,0,0.89253,9.0,0.910312,61
http://arxiv.org/abs/2007.06404v1,Fashion-IQ 2020 Challenge 2nd Place Team's Solution,7,0.0616175,0.237346,"This paper is dedicated to team VAA's approach submitted to the Fashion-IQ
challenge in CVPR 2020. Given a pair of the image and the text, we present a
novel multimodal composition method, RTIC, that can effectively combine the
text and the image modalities into a semantic space. We extract the image and
the text features that are encoded by the CNNs and the sequential models (e.g.,
LSTM or GRU), respectively. To emphasize the meaning of the residual of the
feature between the target and candidate, the RTIC is composed of N-blocks with
channel-wise attention modules. Then, we add the encoded residual to the
feature of the candidate image to obtain a synthesized feature. We also
explored an ensemble strategy with variants of models and achieved a
significant boost in performance comparing to the best single model. Finally,
our approach achieved 2nd place in the Fashion-IQ 2020 Challenge with a test
score of 48.02 on the leaderboard.",0,1,0,0,0,0,0.938007,7.0,0.916182,25
http://arxiv.org/abs/2010.03300v1,CD-UAP: Class Discriminative Universal Adversarial Perturbation,55,0.269122,0.710065,"A single universal adversarial perturbation (UAP) can be added to all natural
images to change most of their predicted class labels. It is of high practical
relevance for an attacker to have flexible control over the targeted classes to
be attacked, however, the existing UAP method attacks samples from all classes.
In this work, we propose a new universal attack method to generate a single
perturbation that fools a target network to misclassify only a chosen group of
classes, while having limited influence on the remaining classes. Since the
proposed attack generates a universal adversarial perturbation that is
discriminative to targeted and non-targeted classes, we term it class
discriminative universal adversarial perturbation (CD-UAP). We propose one
simple yet effective algorithm framework, under which we design and compare
various loss function configurations tailored for the class discriminative
universal attack. The proposed approach has been evaluated with extensive
experiments on various benchmark datasets. Additionally, our proposed approach
achieves state-of-the-art performance for the original task of UAP attacking
all classes, which demonstrates the effectiveness of our approach.",0,1,1,0,1,0,0.872232,6.0,0.852012,30
http://arxiv.org/abs/2009.05387v3,IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding,212,0.73238,0.992581,"Although Indonesian is known to be the fourth most frequently used language
over the internet, the research progress on this language in the natural
language processing (NLP) is slow-moving due to a lack of available resources.
In response, we introduce the first-ever vast resource for the training,
evaluating, and benchmarking on Indonesian natural language understanding
(IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence
classification to pair-sentences sequence labeling with different levels of
complexity. The datasets for the tasks lie in different domains and styles to
ensure task diversity. We also provide a set of Indonesian pre-trained models
(IndoBERT) trained from a large and clean Indonesian dataset Indo4B collected
from publicly available sources such as social media texts, blogs, news, and
websites. We release baseline models for all twelve tasks, as well as the
framework for benchmark evaluation, and thus it enables everyone to benchmark
their system performances.",0,1,1,1,1,0,0.607656,4.0,0.581003,39
http://arxiv.org/abs/2010.15413v3,Measuring and Harnessing Transference in Multi-Task Learning,13,0.0292439,0.15222,"Multi-task learning can leverage information learned by one task to benefit
the training of other tasks. Despite this capacity, naive formulations often
degrade performance and in particular, identifying the tasks that would benefit
from co-training remains a challenging design question. In this paper, we
analyze the dynamics of information transfer, or transference, across tasks
throughout training. Specifically, we develop a similarity measure that can
quantify transference among tasks and use this quantity to both better
understand the optimization dynamics of multi-task learning as well as improve
overall learning performance. In the latter case, we propose two methods to
leverage our transference metric. The first operates at a macro-level by
selecting which tasks should train together while the second functions at a
micro-level by determining how to combine task gradients at each training step.
We find these methods can lead to significant improvement over prior work on
three supervised multi-task learning benchmarks and one multi-task
reinforcement learning paradigm.",0,0,0,0,0,0,0.514902,6.0,0.677796,62
http://arxiv.org/abs/2004.09124v1,Compositionality and Generalization in Emergent Languages,110,0.820262,0.329889,"Natural language allows us to refer to novel composite concepts by combining
expressions denoting their parts according to systematic rules, a property
known as \emph{compositionality}. In this paper, we study whether the language
emerging in deep multi-agent simulations possesses a similar ability to refer
to novel primitive combinations, and whether it accomplishes this feat by
strategies akin to human-language compositionality. Equipped with new ways to
measure compositionality in emergent languages inspired by disentanglement in
representation learning, we establish three main results. First, given
sufficiently large input spaces, the emergent language will naturally develop
the ability to refer to novel composite concepts. Second, there is no
correlation between the degree of compositionality of an emergent language and
its ability to generalize. Third, while compositionality is not necessary for
generalization, it provides an advantage in terms of language transmission: The
more compositional a language is, the more easily it will be picked up by new
learners, even when the latter differ in architecture from the original agents.
We conclude that compositionality does not arise from simple generalization
pressure, but if an emergent language does chance upon it, it will be more
likely to survive and thrive.",0,0,0,0,0,0,0.772957,5.0,0.756874,51
http://arxiv.org/abs/2004.13203v1,A Summary of the First Workshop on Language Technology for Language Documentation and Revitalization,6,0.0163376,0.152436,"Despite recent advances in natural language processing and other language
technology, the application of such technology to language documentation and
conservation has been limited. In August 2019, a workshop was held at Carnegie
Mellon University in Pittsburgh to attempt to bring together language community
members, documentary linguists, and technologists to discuss how to bridge this
gap and create prototypes of novel and practical language revitalization
technologies. This paper reports the results of this workshop, including issues
discussed, and various conceived and implemented technologies for nine
languages: Arapaho, Cayuga, Inuktitut, Irish Gaelic, Kidaw'ida, Kwak'wala,
Ojibwe, San Juan Quiahije Chatino, and Seneca.",0,0,0,0,0,0,0.0117234,12.0,0.495857,56
http://arxiv.org/abs/2004.13866v1,Deflating Dataset Bias Using Synthetic Data Augmentation,45,0.660217,0.402041,"Deep Learning has seen an unprecedented increase in vision applications since
the publication of large-scale object recognition datasets and introduction of
scalable compute hardware. State-of-the-art methods for most vision tasks for
Autonomous Vehicles (AVs) rely on supervised learning and often fail to
generalize to domain shifts and/or outliers. Dataset diversity is thus key to
successful real-world deployment. No matter how big the size of the dataset,
capturing long tails of the distribution pertaining to task-specific
environmental factors is impractical. The goal of this paper is to investigate
the use of targeted synthetic data augmentation - combining the benefits of
gaming engine simulations and sim2real style transfer techniques - for filling
gaps in real datasets for vision tasks. Empirical studies on three different
computer vision tasks of practical use to AVs - parking slot detection, lane
detection and monocular depth estimation - consistently show that having
synthetic data in the training mix provides a significant boost in
cross-dataset generalization performance as compared to training on real data
only, for the same size of the training set.",0,1,0,0,0,0,0.986176,6.0,0.97414,47
http://arxiv.org/abs/2004.12363v1,Multi-Domain Dialogue Acts and Response Co-Generation,54,0.736863,0.984547,"Generating fluent and informative responses is of critical importance for
task-oriented dialogue systems. Existing pipeline approaches generally predict
multiple dialogue acts first and use them to assist response generation. There
are at least two shortcomings with such approaches. First, the inherent
structures of multi-domain dialogue acts are neglected. Second, the semantic
associations between acts and responses are not taken into account for response
generation. To address these issues, we propose a neural co-generation model
that generates dialogue acts and responses concurrently. Unlike those pipeline
approaches, our act generation module preserves the semantic structures of
multi-domain dialogue acts and our response generation module dynamically
attends to different acts as needed. We train the two modules jointly using an
uncertainty loss to adjust their task weights adaptively. Extensive experiments
are conducted on the large-scale MultiWOZ dataset and the results show that our
model achieves very favorable improvement over several state-of-the-art models
in both automatic and human evaluations.",1,1,0,0,1,0,0.934931,6.0,0.899285,32
http://arxiv.org/abs/2009.10056v1,Composed Variational Natural Language Generation for Few-shot Intents,31,0.158536,0.429035,"In this paper, we focus on generating training examples for few-shot intents
in the realistic imbalanced scenario. To build connections between existing
many-shot intents and few-shot intents, we consider an intent as a combination
of a domain and an action, and propose a composed variational natural language
generator (CLANG), a transformer-based conditional variational autoencoder.
CLANG utilizes two latent variables to represent the utterances corresponding
to two different independent parts (domain and action) in the intent, and the
latent variables are composed together to generate natural examples.
Additionally, to improve the generator learning, we adopt the contrastive
regularization loss that contrasts the in-class with the out-of-class utterance
generation given the intent. To evaluate the quality of the generated
utterances, experiments are conducted on the generalized few-shot intent
detection task. Empirical results show that our proposed model achieves
state-of-the-art performances on two real-world intent detection datasets.",0,1,0,0,1,0,0.725034,8.0,0.830758,36
http://arxiv.org/abs/2011.12548v1,Measuring Happiness Around the World Through Artificial Intelligence,1,0.00893793,0.101103,"In this work, we analyze the happiness levels of countries using an unbiased
emotion detector, artificial intelligence (AI). To date, researchers proposed
many factors that may affect happiness such as wealth, health and safety. Even
though these factors all seem relevant, there is no clear consensus between
sociologists on how to interpret these, and the models to estimate the cost of
these utilities include some assumptions. Researchers in social sciences have
been working on determination of the happiness levels in society and
exploration of the factors correlated with it through polls and different
statistical methods. In our work, by using artificial intelligence, we
introduce a different and relatively unbiased approach to this problem. By
using AI, we make no assumption about what makes a person happy, and leave the
decision to AI to detect the emotions from the faces of people collected from
publicly available street footages. We analyzed the happiness levels in eight
different cities around the world through available footage on the Internet and
found out that there is no statistically significant difference between
countries in terms of happiness.",0,1,0,0,0,1,0.449272,23.0,0.907561,29
http://arxiv.org/abs/2012.01300v1,Learning from others' mistakes: Avoiding dataset biases without modeling them,94,0.126732,0.567241,"State-of-the-art natural language processing (NLP) models often learn to
model dataset biases and surface form correlations instead of features that
target the intended underlying task. Previous work has demonstrated effective
methods to circumvent these issues when knowledge of the bias is available. We
consider cases where the bias issues may not be explicitly identified, and show
a method for training models that learn to ignore these problematic
correlations. Our approach relies on the observation that models with limited
capacity primarily learn to exploit biases in the dataset. We can leverage the
errors of such limited capacity models to train a more robust model in a
product of experts, thus bypassing the need to hand-craft a biased model. We
show the effectiveness of this method to retain improvements in
out-of-distribution settings even if no particular bias is targeted by the
biased model.",0,0,0,0,0,1,0.405974,5.0,0.547647,58
http://arxiv.org/abs/2007.12731v1,COVID-19 Knowledge Graph: Accelerating Information Retrieval and Discovery for Scientific Literature,68,0.782939,0.822422,"The coronavirus disease (COVID-19) has claimed the lives of over 350,000
people and infected more than 6 million people worldwide. Several search
engines have surfaced to provide researchers with additional tools to find and
retrieve information from the rapidly growing corpora on COVID-19. These
engines lack extraction and visualization tools necessary to retrieve and
interpret complex relations inherent to scientific literature. Moreover,
because these engines mainly rely upon semantic information, their ability to
capture complex global relationships across documents is limited, which reduces
the quality of similarity-based article recommendations for users. In this
work, we present the COVID-19 Knowledge Graph (CKG), a heterogeneous graph for
extracting and visualizing complex relationships between COVID-19 scientific
articles. The CKG combines semantic information with document topological
information for the application of similar document retrieval. The CKG is
constructed using the latent schema of the data, and then enriched with
biomedical entity information extracted from the unstructured text of articles
using scalable AWS technologies to form relations in the graph. Finally, we
propose a document similarity engine that leverages low-dimensional graph
embeddings from the CKG with semantic embeddings for similar article retrieval.
Analysis demonstrates the quality of relationships in the CKG and shows that it
can be used to uncover meaningful information in COVID-19 scientific articles.
The CKG helps power www.cord19.aws and is publicly available.",0,1,0,0,0,0,0.950242,7.0,0.927053,30
http://arxiv.org/abs/2012.01415v2,Prototype-based Incremental Few-Shot Semantic Segmentation,17,0.164695,0.338661,"Semantic segmentation models have two fundamental weaknesses: i) they require
large training sets with costly pixel-level annotations, and ii) they have a
static output space, constrained to the classes of the training set. Toward
addressing both problems, we introduce a new task, Incremental Few-Shot
Segmentation (iFSS). The goal of iFSS is to extend a pretrained segmentation
model with new classes from few annotated images and without access to old
training data. To overcome the limitations of existing models iniFSS, we
propose Prototype-based Incremental Few-Shot Segmentation (PIFS) that couples
prototype learning and knowledge distillation. PIFS exploits prototypes to
initialize the classifiers of new classes, fine-tuning the network to refine
its features representation. We design a prototype-based distillation loss on
the scores of both old and new class prototypes to avoid overfitting and
forgetting, and batch-renormalization to cope with non-i.i.d.few-shot data. We
create an extensive benchmark for iFSS showing that PIFS outperforms several
few-shot and incremental learning methods in all scenarios.",1,1,1,0,0,0,0.965561,6.0,0.934175,60
http://arxiv.org/abs/2011.07307v1,Meaningful Answer Generation of E-Commerce Question-Answering,31,0.378941,0.982855,"In e-commerce portals, generating answers for product-related questions has
become a crucial task. In this paper, we focus on the task of product-aware
answer generation, which learns to generate an accurate and complete answer
from large-scale unlabeled e-commerce reviews and product attributes. However,
safe answer problems pose significant challenges to text generation tasks, and
e-commerce question-answering task is no exception. To generate more meaningful
answers, in this paper, we propose a novel generative neural model, called the
Meaningful Product Answer Generator (MPAG), which alleviates the safe answer
problem by taking product reviews, product attributes, and a prototype answer
into consideration. Product reviews and product attributes are used to provide
meaningful content, while the prototype answer can yield a more diverse answer
pattern. To this end, we propose a novel answer generator with a review
reasoning module and a prototype answer reader. Our key idea is to obtain the
correct question-aware information from a large scale collection of reviews and
learn how to write a coherent and meaningful answer from an existing prototype
answer. To be more specific, we propose a read-and-write memory consisting of
selective writing units to conduct reasoning among these reviews. We then
employ a prototype reader consisting of comprehensive matching to extract the
answer skeleton from the prototype answer. Finally, we propose an answer editor
to generate the final answer by taking the question and the above parts as
input. Conducted on a real-world dataset collected from an e-commerce platform,
extensive experimental results show that our model achieves state-of-the-art
performance in terms of both automatic metrics and human evaluations. Human
evaluation also demonstrates that our model can consistently generate specific
and proper answers.",0,1,0,0,1,0,0.652163,6.0,0.740845,90
http://arxiv.org/abs/2007.01682v2,Improving auto-encoder novelty detection using channel attention and entropy minimization,2,0.0112722,0.0270327,"Novelty detection is a important research area which mainly solves the
classification problem of inliers which usually consists of normal samples and
outliers composed of abnormal samples. Auto-encoder is often used for novelty
detection. However, the generalization ability of the auto-encoder may cause
the undesirable reconstruction of abnormal elements and reduce the
identification ability of the model. To solve the problem, we focus on the
perspective of better reconstructing the normal samples as well as retaining
the unique information of normal samples to improve the performance of
auto-encoder for novelty detection. Firstly, we introduce attention mechanism
into the task. Under the action of attention mechanism, auto-encoder can pay
more attention to the representation of inlier samples through adversarial
training. Secondly, we apply the information entropy into the latent layer to
make it sparse and constrain the expression of diversity. Experimental results
on three public datasets show that the proposed method achieves comparable
performance compared with previous popular approaches.",0,1,0,0,0,0,0.957367,5.0,0.907918,31
http://arxiv.org/abs/2003.13661v2,Multi-Task Reinforcement Learning with Soft Modularization,141,0.751804,0.832122,"Multi-task learning is a very challenging problem in reinforcement learning.
While training multiple tasks jointly allow the policies to share parameters
across different tasks, the optimization problem becomes non-trivial: It
remains unclear what parameters in the network should be reused across tasks,
and how the gradients from different tasks may interfere with each other. Thus,
instead of naively sharing parameters across tasks, we introduce an explicit
modularization technique on policy representation to alleviate this
optimization issue. Given a base policy network, we design a routing network
which estimates different routing strategies to reconfigure the base network
for each task. Instead of directly selecting routes for each task, our
task-specific policy uses a method called soft modularization to softly combine
all the possible routes, which makes it suitable for sequential tasks. We
experiment with various robotics manipulation tasks in simulation and show our
method improves both sample efficiency and performance over strong baselines by
a large margin.",1,1,0,0,0,0,0.856552,6.0,0.842361,48
http://arxiv.org/abs/2010.08995v1,Construction and Application of Teaching System Based on Crowdsourcing Knowledge Graph,10,0.0290889,0.143958,"Through the combination of crowdsourcing knowledge graph and teaching system,
research methods to generate knowledge graph and its applications. Using two
crowdsourcing approaches, crowdsourcing task distribution and reverse captcha
generation, to construct knowledge graph in the field of teaching system.
Generating a complete hierarchical knowledge graph of the teaching domain by
nodes of school, student, teacher, course, knowledge point and exercise type.
The knowledge graph constructed in a crowdsourcing manner requires many users
to participate collaboratively with fully consideration of teachers' guidance
and users' mobilization issues. Based on the three subgraphs of knowledge
graph, prominent teacher, student learning situation and suitable learning
route could be visualized. Personalized exercises recommendation model is used
to formulate the personalized exercise by algorithm based on the knowledge
graph. Collaborative creation model is developed to realize the crowdsourcing
construction mechanism. Though unfamiliarity with the learning mode of
knowledge graph and learners' less attention to the knowledge structure, system
based on Crowdsourcing Knowledge Graph can still get high acceptance around
students and teachers",0,1,0,0,0,0,0.000121186,33.0,0.677953,15
http://arxiv.org/abs/2002.03723v1,Deep Frequent Spatial Temporal Learning for Face Anti-Spoofing,11,0.259763,0.526318,"Face anti-spoofing is crucial for the security of face recognition system, by
avoiding invaded with presentation attack. Previous works have shown the
effectiveness of using depth and temporal supervision for this task. However,
depth supervision is often considered only in a single frame, and temporal
supervision is explored by utilizing certain signals which is not robust to the
change of scenes. In this work, motivated by two stream ConvNets, we propose a
novel two stream FreqSaptialTemporalNet for face anti-spoofing which
simultaneously takes advantage of frequent, spatial and temporal information.
Compared with existing methods which mine spoofing cues in multi-frame RGB
image, we make multi-frame spectrum image as one input stream for the
discriminative deep neural network, encouraging the primary difference between
live and fake video to be automatically unearthed. Extensive experiments show
promising improvement results using the proposed architecture. Meanwhile, we
proposed a concise method to obtain a large amount of spoofing training data by
utilizing a frequent augmentation pipeline, which contributes detail
visualization between live and fake images as well as data insufficiency issue
when training large networks.",0,1,0,0,0,0,0.957652,7.0,0.934531,42
http://arxiv.org/abs/2010.04637v1,Recurrent babbling: evaluating the acquisition of grammar from limited input data,12,0.0171507,0.0989184,"Recurrent Neural Networks (RNNs) have been shown to capture various aspects
of syntax from raw linguistic input. In most previous experiments, however,
learning happens over unrealistic corpora, which do not reflect the type and
amount of data a child would be exposed to. This paper remedies this state of
affairs by training a Long Short-Term Memory network (LSTM) over a
realistically sized subset of child-directed input. The behaviour of the
network is analysed over time using a novel methodology which consists in
quantifying the level of grammatical abstraction in the model's generated
output (its ""babbling""), compared to the language it has been exposed to. We
show that the LSTM indeed abstracts new structuresas learning proceeds.",0,0,0,0,0,0,0.109067,6.0,0.371992,74
http://arxiv.org/abs/2011.00890v1,Emergent Communication Pretraining for Few-Shot Machine Translation,17,0.0282583,0.349419,"While state-of-the-art models that rely upon massively multilingual
pretrained encoders achieve sample efficiency in downstream applications, they
still require abundant amounts of unlabelled text. Nevertheless, most of the
world's languages lack such resources. Hence, we investigate a more radical
form of unsupervised knowledge transfer in the absence of linguistic data. In
particular, for the first time we pretrain neural networks via emergent
communication from referential games. Our key assumption is that grounding
communication on images---as a crude approximation of real-world
environments---inductively biases the model towards learning natural languages.
On the one hand, we show that this substantially benefits machine translation
in few-shot settings. On the other hand, this also provides an extrinsic
evaluation protocol to probe the properties of emergent languages ex vitro.
Intuitively, the closer they are to natural languages, the higher the gains
from pretraining on them should be. For instance, in this work we measure the
influence of communication success and maximum sequence length on downstream
performances. Finally, we introduce a customised adapter layer and annealing
strategies for the regulariser of maximum-a-posteriori inference during
fine-tuning. These turn out to be crucial to facilitate knowledge transfer and
prevent catastrophic forgetting. Compared to a recurrent baseline, our method
yields gains of $59.0\%$$\sim$$147.6\%$ in BLEU score with only $500$ NMT
training instances and $65.1\%$$\sim$$196.7\%$ with $1,000$ NMT training
instances across four language pairs. These proof-of-concept results reveal the
potential of emergent communication pretraining for both natural language
processing tasks in resource-poor settings and extrinsic evaluation of
artificial languages.",1,0,0,0,0,0,0.290522,6.0,0.553532,94
http://arxiv.org/abs/2004.11892v1,Template-Based Question Generation from Retrieved Sentences for Improved Unsupervised Question Answering,70,0.113945,0.414329,"Question Answering (QA) is in increasing demand as the amount of information
available online and the desire for quick access to this content grows. A
common approach to QA has been to fine-tune a pretrained language model on a
task-specific labeled dataset. This paradigm, however, relies on scarce, and
costly to obtain, large-scale human-labeled data. We propose an unsupervised
approach to training QA models with generated pseudo-training data. We show
that generating questions for QA training by applying a simple template on a
related, retrieved sentence rather than the original context sentence improves
downstream QA performance by allowing the model to learn more complex
context-question relationships. Training a QA model on this data gives a
relative improvement over a previous unsupervised model in F1 score on the
SQuAD dataset by about 14%, and 20% when the answer is a named entity,
achieving state-of-the-art performance on SQuAD for unsupervised QA.",1,1,0,0,1,0,0.885653,2.0,0.582303,14
http://arxiv.org/abs/2008.01187v1,PhraseCut: Language-based Image Segmentation in the Wild,84,0.0694652,0.515276,"We consider the problem of segmenting image regions given a natural language
phrase, and study it on a novel dataset of 77,262 images and 345,486
phrase-region pairs. Our dataset is collected on top of the Visual Genome
dataset and uses the existing annotations to generate a challenging set of
referring phrases for which the corresponding regions are manually annotated.
Phrases in our dataset correspond to multiple regions and describe a large
number of object and stuff categories as well as their attributes such as
color, shape, parts, and relationships with other entities in the image. Our
experiments show that the scale and diversity of concepts in our dataset poses
significant challenges to the existing state-of-the-art. We systematically
handle the long-tail nature of these concepts and present a modular approach to
combine category, attribute, and relationship cues that outperforms existing
approaches.",1,1,1,1,0,0,0.0918824,6.0,0.341853,43
http://arxiv.org/abs/2006.08599v1,"""Notic My Speech"" -- Blending Speech Patterns With Multimedia",3,0.0313923,0.0606727,"Speech as a natural signal is composed of three parts - visemes (visual part
of speech), phonemes (spoken part of speech), and language (the imposed
structure). However, video as a medium for the delivery of speech and a
multimedia construct has mostly ignored the cognitive aspects of speech
delivery. For example, video applications like transcoding and compression have
till now ignored the fact how speech is delivered and heard. To close the gap
between speech understanding and multimedia video applications, in this paper,
we show the initial experiments by modelling the perception on visual speech
and showing its use case on video compression. On the other hand, in the visual
speech recognition domain, existing studies have mostly modeled it as a
classification problem, while ignoring the correlations between views,
phonemes, visemes, and speech perception. This results in solutions which are
further away from how human perception works. To bridge this gap, we propose a
view-temporal attention mechanism to model both the view dependence and the
visemic importance in speech recognition and understanding. We conduct
experiments on three public visual speech recognition datasets. The
experimental results show that our proposed method outperformed the existing
work by 4.99% in terms of the viseme error rate. Moreover, we show that there
is a strong correlation between our model's understanding of multi-view speech
and the human perception. This characteristic benefits downstream applications
such as video compression and streaming where a significant number of less
important frames can be compressed or eliminated while being able to maximally
preserve human speech understanding with good user experience.",0,0,0,0,1,0,0.251111,11.0,0.740891,50
http://arxiv.org/abs/2008.04381v2,Bipartite Graph Reasoning GANs for Person Image Generation,54,0.564409,0.479556,"We present a novel Bipartite Graph Reasoning GAN (BiGraphGAN) for the
challenging person image generation task. The proposed graph generator mainly
consists of two novel blocks that aim to model the pose-to-pose and
pose-to-image relations, respectively. Specifically, the proposed Bipartite
Graph Reasoning (BGR) block aims to reason the crossing long-range relations
between the source pose and the target pose in a bipartite graph, which
mitigates some challenges caused by pose deformation. Moreover, we propose a
new Interaction-and-Aggregation (IA) block to effectively update and enhance
the feature representation capability of both person's shape and appearance in
an interactive way. Experiments on two challenging and public datasets, i.e.,
Market-1501 and DeepFashion, show the effectiveness of the proposed BiGraphGAN
in terms of objective quantitative scores and subjective visual realness. The
source code and trained models are available at
https://github.com/Ha0Tang/BiGraphGAN.",1,1,0,0,1,0,0.951785,4.0,0.874953,45
http://arxiv.org/abs/2008.05503v1,Multi-level Stress Assessment Using Multi-domain Fusion of ECG Signal,19,0.216608,0.561095,"Stress analysis and assessment of affective states of mind using ECG as a
physiological signal is a burning research topic in biomedical signal
processing. However, existing literature provides only binary assessment of
stress, while multiple levels of assessment may be more beneficial for
healthcare applications. Furthermore, in present research, ECG signal for
stress analysis is examined independently in spatial domain or in transform
domains but the advantage of fusing these domains has not been fully utilized.
To get the maximum advantage of fusing diferent domains, we introduce a dataset
with multiple stress levels and then classify these levels using a novel deep
learning approach by converting ECG signal into signal images based on R-R
peaks without any feature extraction. Moreover, We made signal images
multimodal and multidomain by converting them into time-frequency and frequency
domain using Gabor wavelet transform (GWT) and Discrete Fourier Transform (DFT)
respectively. Convolutional Neural networks (CNNs) are used to extract features
from different modalities and then decision level fusion is performed for
improving the classification accuracy. The experimental results on an in-house
dataset collected with 15 users show that with proposed fusion framework and
using ECG signal to image conversion, we reach an average accuracy of 85.45%.",0,1,1,1,0,0,0.843163,2.0,0.503561,12
http://arxiv.org/abs/2009.06510v1,At your Command! An Empirical Study on How LaypersonsTeach Robots New Functions,2,0.0114901,0.0624147,"Even though intelligent systems such as Siri or Google Assistant are
enjoyable (and useful) dialog partners, users can only access predefined
functionality. Enabling end-users to extend the functionality of intelligent
systems will be the next big thing. To promote research in this area we carried
out an empirical study on how laypersons teach robots new functions by means of
natural language instructions. The result is a labeled corpus consisting of
3168 submissions given by 870 subjects. The analysis of the dataset revealed
that many participants used certain wordings to express their wish to teach new
functionality; two corresponding trigrams are among the most frequent. On the
contrary, more than one third (36.93%) did not verbalize the teaching intent at
all. We labeled the semantic constituents in the utterances: declaration
(including the name of the function) and intermediate steps. The full corpus is
publicly available: http://dx.doi.org/10.21227/zecn-6c61",0,0,1,1,0,0,0.00290132,12.0,0.379119,31
http://arxiv.org/abs/2003.09108v1,FocalMix: Semi-Supervised Learning for 3D Medical Image Detection,107,0.886143,0.848645,"Applying artificial intelligence techniques in medical imaging is one of the
most promising areas in medicine. However, most of the recent success in this
area highly relies on large amounts of carefully annotated data, whereas
annotating medical images is a costly process. In this paper, we propose a
novel method, called FocalMix, which, to the best of our knowledge, is the
first to leverage recent advances in semi-supervised learning (SSL) for 3D
medical image detection. We conducted extensive experiments on two widely used
datasets for lung nodule detection, LUNA16 and NLST. Results show that our
proposed SSL methods can achieve a substantial improvement of up to 17.3% over
state-of-the-art supervised learning approaches with 400 unlabeled CT scans.",0,1,1,0,1,0,0.855375,6.0,0.841658,43
http://arxiv.org/abs/2004.14035v1,The Holy Grail of Quantum Artificial Intelligence: Major Challenges in Accelerating the Machine Learning Pipeline,19,0.372963,0.566086,"We discuss the synergetic connection between quantum computing and artificial
intelligence. After surveying current approaches to quantum artificial
intelligence and relating them to a formal model for machine learning
processes, we deduce four major challenges for the future of quantum artificial
intelligence: (i) Replace iterative training with faster quantum algorithms,
(ii) distill the experience of larger amounts of data into the training
process, (iii) allow quantum and classical components to be easily combined and
exchanged, and (iv) build tools to thoroughly analyze whether observed benefits
really stem from quantum properties of the algorithm.",0,0,0,0,0,0,0.856269,6.0,0.842192,50
http://arxiv.org/abs/2007.02092v2,Customized Handling of Unintended Interface Operation in Assistive Robots,9,0.076445,0.345033,"We present an assistance system that reasons about a human's intended actions
during robot teleoperation in order to provide appropriate corrections for
unintended behavior. We model the human's physical interaction with a control
interface during robot teleoperation and distinguish between intended and
measured physical actions explicitly. By reasoning over the unobserved
intentions using model-based inference techniques, our assistive system
provides customized corrections on a user's issued commands. We validate our
algorithm with a 10-person human subject study in which we evaluate the
performance of the proposed assistance paradigms. Our results show that the
assistance paradigms helped to significantly reduce task completion time,
number of mode switches, cognitive workload, and user frustration and improve
overall user satisfaction.",1,1,0,0,0,0,0.0416066,11.0,0.566567,31
http://arxiv.org/abs/2005.08392v1,Vector-Quantized Autoregressive Predictive Coding,101,0.556403,0.818885,"Autoregressive Predictive Coding (APC), as a self-supervised objective, has
enjoyed success in learning representations from large amounts of unlabeled
data, and the learned representations are rich for many downstream tasks.
However, the connection between low self-supervised loss and strong performance
in downstream tasks remains unclear. In this work, we propose Vector-Quantized
Autoregressive Predictive Coding (VQ-APC), a novel model that produces
quantized representations, allowing us to explicitly control the amount of
information encoded in the representations. By studying a sequence of
increasingly limited models, we reveal the constituents of the learned
representations. In particular, we confirm the presence of information with
probing tasks, while showing the absence of information with mutual
information, uncovering the model's preference in preserving speech information
as its capacity becomes constrained. We find that there exists a point where
phonetic and speaker information are amplified to maximize a self-supervised
objective. As a byproduct, the learned codes for a particular model capacity
correspond well to English phones.",1,0,0,0,0,0,0.952843,3.0,0.8357,25
http://arxiv.org/abs/2004.06871v3,TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue,287,0.999544,0.998825,"The underlying difference of linguistic patterns between general text and
task-oriented dialogue makes existing pre-trained language models less useful
in practice. In this work, we unify nine human-human and multi-turn
task-oriented dialogue datasets for language modeling. To better model dialogue
behavior during pre-training, we incorporate user and system tokens into the
masked language modeling. We propose a contrastive objective function to
simulate the response selection task. Our pre-trained task-oriented dialogue
BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream
task-oriented dialogue applications, including intention recognition, dialogue
state tracking, dialogue act prediction, and response selection. We also show
that TOD-BERT has a stronger few-shot ability that can mitigate the data
scarcity problem for task-oriented dialogue.",1,1,0,1,0,0,0.988955,2.0,0.947959,49
http://arxiv.org/abs/2001.01447v1,Improving Entity Linking by Modeling Latent Entity Type Information,56,0.333265,0.659993,"Existing state of the art neural entity linking models employ attention-based
bag-of-words context model and pre-trained entity embeddings bootstrapped from
word embeddings to assess topic level context compatibility. However, the
latent entity type information in the immediate context of the mention is
neglected, which causes the models often link mentions to incorrect entities
with incorrect type. To tackle this problem, we propose to inject latent entity
type information into the entity embeddings based on pre-trained BERT. In
addition, we integrate a BERT-based entity similarity score into the local
context model of a state-of-the-art model to better capture latent entity type
information. Our model significantly outperforms the state-of-the-art entity
linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis
demonstrates that our model corrects most of the type errors produced by the
direct baseline.",1,1,0,0,1,0,0.368397,9.0,0.734771,35
http://arxiv.org/abs/2003.11597v1,COVID-19 Image Data Collection,966,0.869823,0.999969,"This paper describes the initial COVID-19 open image data collection. It was
created by assembling medical images from websites and publications and
currently contains 123 frontal view X-rays.",1,1,0,1,0,0,0.965011,1.0,0.600335,30
http://arxiv.org/abs/2009.08049v1,Image Retrieval for Structure-from-Motion via Graph Convolutional Network,16,0.0398039,0.39034,"Conventional image retrieval techniques for Structure-from-Motion (SfM)
suffer from the limit of effectively recognizing repetitive patterns and cannot
guarantee to create just enough match pairs with high precision and high
recall. In this paper, we present a novel retrieval method based on Graph
Convolutional Network (GCN) to generate accurate pairwise matches without
costly redundancy. We formulate image retrieval task as a node binary
classification problem in graph data: a node is marked as positive if it shares
the scene overlaps with the query image. The key idea is that we find that the
local context in feature space around a query image contains rich information
about the matchable relation between this image and its neighbors. By
constructing a subgraph surrounding the query image as input data, we adopt a
learnable GCN to exploit whether nodes in the subgraph have overlapping regions
with the query photograph. Experiments demonstrate that our method performs
remarkably well on the challenging dataset of highly ambiguous and duplicated
scenes. Besides, compared with state-of-the-art matchable retrieval methods,
the proposed approach significantly reduces useless attempted matches without
sacrificing the accuracy and completeness of reconstruction.",0,1,0,0,1,0,0.107185,10.0,0.621352,62
http://arxiv.org/abs/2011.00596v2,Bracketing Encodings for 2-Planar Dependency Parsing,13,0.0973994,0.280937,"We present a bracketing-based encoding that can be used to represent any
2-planar dependency tree over a sentence of length n as a sequence of n labels,
hence providing almost total coverage of crossing arcs in sequence labeling
parsing. First, we show that existing bracketing encodings for parsing as
labeling can only handle a very mild extension of projective trees. Second, we
overcome this limitation by taking into account the well-known property of
2-planarity, which is present in the vast majority of dependency syntactic
structures in treebanks, i.e., the arcs of a dependency tree can be split into
two planes such that arcs in a given plane do not cross. We take advantage of
this property to design a method that balances the brackets and that encodes
the arcs belonging to each of those planes, allowing for almost unrestricted
non-projectivity (round 99.9% coverage) in sequence labeling parsing. The
experiments show that our linearizations improve over the accuracy of the
original bracketing encoding in highly non-projective treebanks (on average by
0.4 LAS), while achieving a similar speed. Also, they are especially suitable
when PoS tags are not used as input parameters to the models.",1,1,0,1,0,0,0.0757013,7.0,0.406958,28
http://arxiv.org/abs/2011.13464v1,Meta-learning in natural and artificial intelligence,87,0.304109,0.820967,"Meta-learning, or learning to learn, has gained renewed interest in recent
years within the artificial intelligence community. However, meta-learning is
incredibly prevalent within nature, has deep roots in cognitive science and
psychology, and is currently studied in various forms within neuroscience. The
aim of this review is to recast previous lines of research in the study of
biological intelligence within the lens of meta-learning, placing these works
into a common framework. More recent points of interaction between AI and
neuroscience will be discussed, as well as interesting new directions that
arise under this perspective.",0,0,0,0,0,1,0.413534,10.0,0.776253,80
http://arxiv.org/abs/2012.12235v1,Unadversarial Examples: Designing Objects for Robust Vision,49,0.106573,0.718685,"We study a class of realistic computer vision settings wherein one can
influence the design of the objects being recognized. We develop a framework
that leverages this capability to significantly improve vision models'
performance and robustness. This framework exploits the sensitivity of modern
machine learning algorithms to input perturbations in order to design ""robust
objects,"" i.e., objects that are explicitly optimized to be confidently
detected or classified. We demonstrate the efficacy of the framework on a wide
variety of vision-based tasks ranging from standard benchmarks, to
(in-simulation) robotics, to real-world experiments. Our code can be found at
https://git.io/unadversarial .",1,0,0,0,0,0,0.231773,7.0,0.579644,66
http://arxiv.org/abs/2012.05300v1,Cross-lingual Word Sense Disambiguation using mBERT Embeddings with Syntactic Dependencies,6,0.371076,0.414749,"Cross-lingual word sense disambiguation (WSD) tackles the challenge of
disambiguating ambiguous words across languages given context. The pre-trained
BERT embedding model has been proven to be effective in extracting contextual
information of words, and have been incorporated as features into many
state-of-the-art WSD systems. In order to investigate how syntactic information
can be added into the BERT embeddings to result in both semantics- and
syntax-incorporated word embeddings, this project proposes the concatenated
embeddings by producing dependency parse tress and encoding the relative
relationships of words into the input embeddings. Two methods are also proposed
to reduce the size of the concatenated embeddings. The experimental results
show that the high dimensionality of the syntax-incorporated embeddings
constitute an obstacle for the classification task, which needs to be further
addressed in future studies.",0,1,0,0,0,0,0.718157,24.0,0.942781,13
http://arxiv.org/abs/2012.09015v2,ColorShapeLinks: A board game AI competition for educators and students,8,0.113058,0.604909,"ColorShapeLinks is an AI board game competition framework specially designed
for students and educators in videogame development, with openness and
accessibility in mind. The competition is based on an arbitrarily-sized version
of the Simplexity board game, the motto of which, ""simple to learn, complex to
master"", is curiously also applicable to AI agents. ColorShapeLinks offers
graphical and text-based frontends and a completely open and documented
development framework built using industry standard tools and following
software engineering best practices. ColorShapeLinks is not only a competition,
but both a game and a framework which educators and students can extend and use
to host their own competitions. It has been successfully used for running
internal competitions in AI classes, as well as for hosting an international AI
competition at the IEEE Conference on Games.",1,1,0,0,0,0,0.117254,6.0,0.38481,45
http://arxiv.org/abs/2001.07504v1,Combining Federated and Active Learning for Communication-efficient Distributed Failure Prediction in Aeronautics,13,0.242602,0.291722,"Machine Learning has proven useful in the recent years as a way to achieve
failure prediction for industrial systems. However, the high computational
resources necessary to run learning algorithms are an obstacle to its
widespread application. The sub-field of Distributed Learning offers a solution
to this problem by enabling the use of remote resources but at the expense of
introducing communication costs in the application that are not always
acceptable. In this paper, we propose a distributed learning approach able to
optimize the use of computational and communication resources to achieve
excellent learning model performances through a centralized architecture. To
achieve this, we present a new centralized distributed learning algorithm that
relies on the learning paradigms of Active Learning and Federated Learning to
offer a communication-efficient method that offers guarantees of model
precision on both the clients and the central server. We evaluate this method
on a public benchmark and show that its performances in terms of precision are
very close to state-of-the-art performance level of non-distributed learning
despite additional constraints.",0,1,0,0,0,0,0.38073,11.0,0.786814,17
http://arxiv.org/abs/2005.02066v1,Unsupervised Instance Segmentation in Microscopy Images via Panoptic Domain Adaptation and Task Re-weighting,67,0.224277,0.630455,"Unsupervised domain adaptation (UDA) for nuclei instance segmentation is
important for digital pathology, as it alleviates the burden of labor-intensive
annotation and domain shift across datasets. In this work, we propose a Cycle
Consistency Panoptic Domain Adaptive Mask R-CNN (CyC-PDAM) architecture for
unsupervised nuclei segmentation in histopathology images, by learning from
fluorescence microscopy images. More specifically, we first propose a nuclei
inpainting mechanism to remove the auxiliary generated objects in the
synthesized images. Secondly, a semantic branch with a domain discriminator is
designed to achieve panoptic-level domain adaptation. Thirdly, in order to
avoid the influence of the source-biased features, we propose a task
re-weighting mechanism to dynamically add trade-off weights for the
task-specific loss functions. Experimental results on three datasets indicate
that our proposed method outperforms state-of-the-art UDA methods
significantly, and demonstrates a similar performance as fully supervised
methods.",0,1,0,0,1,0,0.685627,6.0,0.756091,55
http://arxiv.org/abs/2010.05512v1,Automatic Quantification of Settlement Damage using Deep Learning of Satellite Images,1,0.0247017,0.080825,"Humanitarian disasters and political violence cause significant damage to our
living space. The reparation cost to homes, infrastructure, and the ecosystem
is often difficult to quantify in real-time. Real-time quantification is
critical to both informing relief operations, but also planning ahead for
rebuilding. Here, we use satellite images before and after major crisis around
the world to train a robust baseline Residual Network (ResNet) and a disaster
quantification Pyramid Scene Parsing Network (PSPNet). ResNet offers robustness
to poor image quality and can identify areas of destruction with high accuracy
(92\%), whereas PSPNet offers contextualised quantification of built
environment damage with good accuracy (84\%). As there are multiple damage
dimensions to consider (e.g. economic loss and fatalities), we fit a
multi-linear regression model to quantify the overall damage. To validate our
combined system of deep learning and regression modeling, we successfully match
our prediction to the ongoing recovery in the 2020 Beirut port explosion. These
innovations provide a better quantification of overall disaster magnitude and
inform intelligent humanitarian systems of unfolding disasters.",0,1,0,1,0,0,0.227213,7.0,0.576401,27
http://arxiv.org/abs/2005.14260v1,Overview: Computer vision and machine learning for microstructural characterization and analysis,120,0.29237,0.993483,"The characterization and analysis of microstructure is the foundation of
microstructural science, connecting the materials structure to its composition,
process history, and properties. Microstructural quantification traditionally
involves a human deciding a priori what to measure and then devising a
purpose-built method for doing so. However, recent advances in data science,
including computer vision (CV) and machine learning (ML) offer new approaches
to extracting information from microstructural images. This overview surveys CV
approaches to numerically encode the visual information contained in a
microstructural image, which then provides input to supervised or unsupervised
ML algorithms that find associations and trends in the high-dimensional image
representation. CV/ML systems for microstructural characterization and analysis
span the taxonomy of image analysis tasks, including image classification,
semantic segmentation, object detection, and instance segmentation. These tools
enable new approaches to microstructural analysis, including the development of
new, rich visual metrics and the discovery of
processing-microstructure-property relationships.",0,0,0,0,0,0,0.0300329,12.0,0.575026,131
http://arxiv.org/abs/2009.00953v1,Unsupervised Feature Learning by Autoencoder and Prototypical Contrastive Learning for Hyperspectral Classification,24,0.136161,0.678257,"Unsupervised learning methods for feature extraction are becoming more and
more popular. We combine the popular contrastive learning method (prototypical
contrastive learning) and the classic representation learning method
(autoencoder) to design an unsupervised feature learning network for
hyperspectral classification. Experiments have proved that our two proposed
autoencoder networks have good feature learning capabilities by themselves, and
the contrastive learning network we designed can better combine the features of
the two to learn more representative features. As a result, our method
surpasses other comparison methods in the hyperspectral classification
experiments, including some supervised methods. Moreover, our method maintains
a fast feature extraction speed than baseline methods. In addition, our method
reduces the requirements for huge computing resources, separates feature
extraction and contrastive learning, and allows more researchers to conduct
research and experiments on unsupervised contrastive learning.",0,1,0,0,1,0,0.666287,7.0,0.783368,57
http://arxiv.org/abs/2004.04564v2,Interpretability Analysis for Named Entity Recognition to Understand System Predictions and How They Can Improve,35,0.195803,0.643736,"Named Entity Recognition systems achieve remarkable performance on domains
such as English news. It is natural to ask: What are these models actually
learning to achieve this? Are they merely memorizing the names themselves? Or
are they capable of interpreting the text and inferring the correct entity type
from the linguistic context? We examine these questions by contrasting the
performance of several variants of LSTM-CRF architectures for named entity
recognition, with some provided only representations of the context as
features. We also perform similar experiments for BERT. We find that context
representations do contribute to system performance, but that the main factor
driving high performance is learning the name tokens themselves. We enlist
human annotators to evaluate the feasibility of inferring entity types from the
context alone and find that, while people are not able to infer the entity type
either for the majority of the errors made by the context-only system, there is
some room for improvement. A system should be able to recognize any name in a
predictive context correctly and our experiments indicate that current systems
may be further improved by such capability.",0,0,0,0,0,0,0.0152697,27.0,0.785791,37
http://arxiv.org/abs/2005.00844v4,Derivation of a Constant Velocity Motion Model for Visual Tracking,12,0.029119,0.350526,"Motion models play a great role in visual tracking applications for
predicting the possible locations of objects in the next frame. Unlike target
tracking in radar or aerospace domain which considers only points, object
tracking in computer vision involves sizes of objects. Constant velocity motion
model is the most widely used motion model for visual tracking, however, there
is no clear and understandable derivation involving sizes of objects specially
for new researchers joining this research field. In this document, we derive
the constant velocity motion model that incorporates sizes of objects that, we
think, can help the new researchers to adapt to it very quickly.",0,1,0,0,0,1,0.111625,7.0,0.465221,17
http://arxiv.org/abs/2011.06679v2,Trajectory Prediction in Autonomous Driving with a Lane Heading Auxiliary Loss,32,0.146516,0.506714,"Predicting a vehicle's trajectory is an essential ability for autonomous
vehicles navigating through complex urban traffic scenes. Bird's-eye-view
roadmap information provides valuable information for making trajectory
predictions, and while state-of-the-art models extract this information via
image convolution, auxiliary loss functions can augment patterns inferred from
deep learning by further encoding common knowledge of social and legal driving
behaviors. Since human driving behavior is inherently multimodal, models which
allow for multimodal output tend to outperform single-prediction models on
standard metrics. We propose a loss function which enhances such models by
enforcing expected driving rules on all predicted modes. Our contribution to
trajectory prediction is twofold; we propose a new metric which addresses
failure cases of the off-road rate metric by penalizing trajectories that
oppose the ascribed heading (flow direction) of a driving lane, and we show
this metric to be differentiable and therefore suitable as an auxiliary loss
function. We then use this auxiliary loss to extend the the standard multiple
trajectory prediction (MTP) and MultiPath models, achieving improved results on
the nuScenes prediction benchmark by predicting trajectories which better
conform to the lane-following rules of the road.",0,1,0,0,0,0,0.812743,3.0,0.635512,41
http://arxiv.org/abs/2007.09062v1,Multi-scale Interactive Network for Salient Object Detection,493,0.958468,0.990901,"Deep-learning based salient object detection methods achieve great progress.
However, the variable scale and unknown category of salient objects are great
challenges all the time. These are closely related to the utilization of
multi-level and multi-scale features. In this paper, we propose the aggregate
interaction modules to integrate the features from adjacent levels, in which
less noise is introduced because of only using small up-/down-sampling rates.
To obtain more efficient multi-scale features from the integrated features, the
self-interaction modules are embedded in each decoder unit. Besides, the class
imbalance issue caused by the scale variation weakens the effect of the binary
cross entropy loss and results in the spatial inconsistency of the predictions.
Therefore, we exploit the consistency-enhanced loss to highlight the
fore-/back-ground difference and preserve the intra-class consistency.
Experimental results on five benchmark datasets demonstrate that the proposed
method without any post-processing performs favorably against 23
state-of-the-art approaches. The source code will be publicly available at
https://github.com/lartpang/MINet.",1,1,0,0,1,0,0.901813,6.0,0.872085,57
http://arxiv.org/abs/2005.00558v2,POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training,78,0.258498,0.822672,"Large-scale pre-trained language models, such as BERT and GPT-2, have
achieved excellent performance in language representation learning and
free-form text generation. However, these models cannot be directly employed to
generate text under specified lexical constraints. To address this challenge,
we present POINTER (PrOgressive INsertion-based TransformER), a simple yet
novel insertion-based approach for hard-constrained text generation. The
proposed method operates by progressively inserting new tokens between existing
tokens in a parallel manner. This procedure is recursively applied until a
sequence is completed. The resulting coarse-to-fine hierarchy makes the
generation process intuitive and interpretable. We pre-train our model with the
proposed progressive insertion-based objective on a 12GB Wikipedia dataset, and
fine-tune it on downstream hard-constrained generation tasks.
Non-autoregressive decoding yields an empirically logarithmic time complexity
during inference time. Experimental results on both News and Yelp datasets
demonstrate that POINTER achieves state-of-the-art performance on constrained
text generation. We released the pre-trained models and the source code to
facilitate future research (https://github.com/dreasysnail/POINTER).",0,1,0,0,1,0,0.852881,3.0,0.680356,58
http://arxiv.org/abs/2002.09084v1,On the impressive performance of randomly weighted encoders in summarization tasks,5,0.0316393,0.0692752,"In this work, we investigate the performance of untrained randomly
initialized encoders in a general class of sequence to sequence models and
compare their performance with that of fully-trained encoders on the task of
abstractive summarization. We hypothesize that random projections of an input
text have enough representational power to encode the hierarchical structure of
sentences and semantics of documents. Using a trained decoder to produce
abstractive text summaries, we empirically demonstrate that architectures with
untrained randomly initialized encoders perform competitively with respect to
the equivalent architectures with fully-trained encoders. We further find that
the capacity of the encoder not only improves overall model generalization but
also closes the performance gap between untrained randomly initialized and
full-trained encoders. To our knowledge, it is the first time that general
sequence to sequence models with attention are assessed for trained and
randomly projected representations on abstractive summarization.",0,0,0,0,0,1,0.801706,6.0,0.811959,35
http://arxiv.org/abs/2012.07551v2,Towards unsupervised phone and word segmentation using self-supervised vector-quantized neural networks,32,0.294853,0.744355,"We investigate segmenting and clustering speech into low-bitrate phone-like
sequences without supervision. We specifically constrain pretrained
self-supervised vector-quantized (VQ) neural networks so that blocks of
contiguous feature vectors are assigned to the same code, thereby giving a
variable-rate segmentation of the speech into discrete units. Two segmentation
methods are considered. In the first, features are greedily merged until a
prespecified number of segments are reached. The second uses dynamic
programming to optimize a squared error with a penalty term to encourage fewer
but longer segments. We show that these VQ segmentation methods can be used
without alteration across a wide range of tasks: unsupervised phone
segmentation, ABX phone discrimination, same-different word discrimination, and
as inputs to a symbolic word segmentation algorithm. The penalized dynamic
programming method generally performs best. While performance on individual
tasks is only comparable to the state-of-the-art in some cases, in all tasks a
reasonable competing approach is outperformed at a substantially lower bitrate.",1,0,0,0,0,0,0.373736,5.0,0.526248,45
http://arxiv.org/abs/2008.02708v1,Deep reinforcement learning to detect brain lesions on MRI: a proof-of-concept application of reinforcement learning to medical images,15,0.0557675,0.283495,"Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated
data sets. 2) Non-generalizability that limits deployment to new scanners /
institutions. And 3) Inadequate explainability and interpretability. We believe
that reinforcement learning can address all three shortcomings, with robust and
intuitive algorithms trainable on small datasets. To the best of our knowledge,
reinforcement learning has not been directly applied to computer vision tasks
for radiological images. In this proof-of-principle work, we train a deep
reinforcement learning network to predict brain tumor location.
  Materials and Methods: Using the BraTS brain tumor imaging database, we
trained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We
did so in concert with image exploration, with rewards and punishments designed
to localize lesions. To compare with supervised deep learning, we trained a
keypoint detection convolutional neural network on the same 70 images. We
applied both approaches to a separate 30 image testing set.
  Results: Reinforcement learning predictions consistently improved during
training, whereas those of supervised deep learning quickly diverged.
Reinforcement learning predicted testing set lesion locations with 85%
accuracy, compared to roughly 7% accuracy for the supervised deep network.
  Conclusion: Reinforcement learning predicted lesions with high accuracy,
which is unprecedented for such a small training set. We believe that
reinforcement learning can propel radiology AI well past the inherent
limitations of supervised deep learning, with more clinician-driven research
and finally toward true clinical applicability.",0,0,0,0,0,0,0.326283,8.0,0.682694,37
http://arxiv.org/abs/2002.12645v2,Comparison of Speech Representations for Automatic Quality Estimation in Multi-Speaker Text-to-Speech Synthesis,23,0.501624,0.608725,"We aim to characterize how different speakers contribute to the perceived
output quality of multi-speaker Text-to-Speech (TTS) synthesis. We
automatically rate the quality of TTS using a neural network (NN) trained on
human mean opinion score (MOS) ratings. First, we train and evaluate our NN
model on 13 different TTS and voice conversion (VC) systems from the ASVSpoof
2019 Logical Access (LA) Dataset. Since it is not known how best to represent
speech for this task, we compare 8 different representations alongside MOSNet
frame-based features. Our representations include image-based spectrogram
features and x-vector embeddings that explicitly model different types of noise
such as T60 reverberation time. Our NN predicts MOS with a high correlation to
human judgments. We report prediction correlation and error. A key finding is
the quality achieved for certain speakers seems consistent, regardless of the
TTS or VC system. It is widely accepted that some speakers give higher quality
than others for building a TTS system: our method provides an automatic way to
identify such speakers. Finally, to see if our quality prediction models
generalize, we predict quality scores for synthetic speech using a separate
multi-speaker TTS system that was trained on LibriTTS data, and conduct our own
MOS listening test to compare human ratings with our NN predictions.",1,1,0,0,0,0,0.838382,5.0,0.798156,30
http://arxiv.org/abs/2009.05778v1,Micro-Facial Expression Recognition Based on Deep-Rooted Learning Algorithm,10,0.116649,0.494766,"Facial expressions are important cues to observe human emotions. Facial
expression recognition has attracted many researchers for years, but it is
still a challenging topic since expression features vary greatly with the head
poses, environments, and variations in the different persons involved. In this
work, three major steps are involved to improve the performance of micro-facial
expression recognition. First, an Adaptive Homomorphic Filtering is used for
face detection and rotation rectification processes. Secondly, Micro-facial
features were used to extract the appearance variations of a testing
image-spatial analysis. The features of motion information are used for
expression recognition in a sequence of facial images. An effective
Micro-Facial Expression Based Deep-Rooted Learning (MFEDRL) classifier is
proposed in this paper to better recognize spontaneous micro-expressions by
learning parameters on the optimal features. This proposed method includes two
loss functions such as cross entropy loss function and centre loss function.
Then the performance of the algorithm will be evaluated using recognition rate
and false measures. Simulation results show that the predictive performance of
the proposed method outperforms that of the existing classifiers such as
Convolutional Neural Network (CNN), Deep Neural Network (DNN), Artificial
Neural Network (ANN), Support Vector Machine (SVM), and k-Nearest Neighbours
(KNN) in terms of accuracy and Mean Absolute Error (MAE).",0,1,0,0,1,0,0.164333,11.0,0.697557,31
http://arxiv.org/abs/2007.05676v3,Learning Object Depth from Camera Motion and Video Object Segmentation,2,0.0132275,0.0263854,"Video object segmentation, i.e., the separation of a target object from
background in video, has made significant progress on real and challenging
videos in recent years. To leverage this progress in 3D applications, this
paper addresses the problem of learning to estimate the depth of segmented
objects given some measurement of camera motion (e.g., from robot kinematics or
vehicle odometry). We achieve this by, first, introducing a diverse, extensible
dataset and, second, designing a novel deep network that estimates the depth of
objects using only segmentation masks and uncalibrated camera movement. Our
data-generation framework creates artificial object segmentations that are
scaled for changes in distance between the camera and object, and our network
learns to estimate object depth even with segmentation errors. We demonstrate
our approach across domains using a robot camera to locate objects from the YCB
dataset and a vehicle camera to locate obstacles while driving.",1,1,0,1,0,0,0.243826,9.0,0.679528,60
http://arxiv.org/abs/2003.05218v1,Keyfilter-Aware Real-Time UAV Object Tracking,37,0.773428,0.590525,"Correlation filter-based tracking has been widely applied in unmanned aerial
vehicle (UAV) with high efficiency. However, it has two imperfections, i.e.,
boundary effect and filter corruption. Several methods enlarging the search
area can mitigate boundary effect, yet introducing undesired background
distraction. Existing frame-by-frame context learning strategies for repressing
background distraction nevertheless lower the tracking speed. Inspired by
keyframe-based simultaneous localization and mapping, keyfilter is proposed in
visual tracking for the first time, in order to handle the above issues
efficiently and effectively. Keyfilters generated by periodically selected
keyframes learn the context intermittently and are used to restrain the
learning of filters, so that 1) context awareness can be transmitted to all the
filters via keyfilter restriction, and 2) filter corruption can be repressed.
Compared to the state-of-the-art results, our tracker performs better on two
challenging benchmarks, with enough speed for UAV real-time applications.",1,1,0,0,1,0,0.964411,9.0,0.955027,40
http://arxiv.org/abs/2003.02639v1,Phase transitions in a decentralized graph-based approach to human language,2,0.00492497,0.0336577,"Zipf's law establishes a scaling behavior for word-frequencies in large text
corpora. The appearance of Zipfian properties in human language has been
previously explained as an optimization problem for the interests of speakers
and hearers. On the other hand, human-like vocabularies can be viewed as
bipartite graphs. The aim here is double: within a bipartite-graph approach to
human vocabularies, to propose a decentralized language game model for the
formation of Zipfian properties. To do this, we define a language game, in
which a population of artificial agents is involved in idealized linguistic
interactions. Numerical simulations show the appearance of a phase transition
from an initially disordered state to three possible phases for language
formation. Our results suggest that Zipfian properties in language seem to
arise partly from decentralized linguistic interactions between agents endowed
with bipartite word-meaning mappings.",0,0,0,0,0,0,3.10198e-05,17.0,0.294688,34
http://arxiv.org/abs/2010.04914v1,Helpfulness as a Key Metric of Human-Robot Collaboration,10,0.166145,0.484605,"As robotic teammates become more common in society, people will assess the
robots' roles in their interactions along many dimensions. One such dimension
is effectiveness: people will ask whether their robotic partners are
trustworthy and effective collaborators. This begs a crucial question: how can
we quantitatively measure the helpfulness of a robotic partner for a given task
at hand? This paper seeks to answer this question with regards to the
interactive robot's decision making. We describe a clear, concise, and
task-oriented metric applicable to many different planning and execution
paradigms. The proposed helpfulness metric is fundamental to assessing the
benefit that a partner has on a team for a given task. In this paper, we define
helpfulness, illustrate it on concrete examples from a variety of domains,
discuss its properties and ramifications for planning interactions with humans,
and present preliminary results.",0,0,0,0,0,0,0.0279244,13.0,0.602034,32
http://arxiv.org/abs/2004.14928v3,Language Model Prior for Low-Resource Neural Machine Translation,48,0.11236,0.720873,"The scarcity of large parallel corpora is an important obstacle for neural
machine translation. A common solution is to exploit the knowledge of language
models (LM) trained on abundant monolingual data. In this work, we propose a
novel approach to incorporate a LM as prior in a neural translation model (TM).
Specifically, we add a regularization term, which pushes the output
distributions of the TM to be probable under the LM prior, while avoiding wrong
predictions when the TM ""disagrees"" with the LM. This objective relates to
knowledge distillation, where the LM can be viewed as teaching the TM about the
target language. The proposed approach does not compromise decoding speed,
because the LM is used only at training time, unlike previous work that
requires it during inference. We present an analysis of the effects that
different methods have on the distributions of the TM. Results on two
low-resource machine translation datasets show clear improvements even with
limited monolingual data.",1,0,0,0,0,0,0.468666,6.0,0.655379,60
http://arxiv.org/abs/2001.09671v1,Explaining with Counter Visual Attributes and Examples,13,0.067721,0.242189,"In this paper, we aim to explain the decisions of neural networks by
utilizing multimodal information. That is counter-intuitive attributes and
counter visual examples which appear when perturbed samples are introduced.
Different from previous work on interpreting decisions using saliency maps,
text, or visual patches we propose to use attributes and counter-attributes,
and examples and counter-examples as part of the visual explanations. When
humans explain visual decisions they tend to do so by providing attributes and
examples. Hence, inspired by the way of human explanations in this paper we
provide attribute-based and example-based explanations. Moreover, humans also
tend to explain their visual decisions by adding counter-attributes and
counter-examples to explain what is not seen. We introduce directed
perturbations in the examples to observe which attribute values change when
classifying the examples into the counter classes. This delivers intuitive
counter-attributes and counter-examples. Our experiments with both coarse and
fine-grained datasets show that attributes provide discriminating and
human-understandable intuitive and counter-intuitive explanations.",0,0,0,0,0,0,0.856637,6.0,0.842412,40
http://arxiv.org/abs/2007.11430v1,Learning Disentangled Feature Representation for Hybrid-distorted Image Restoration,29,0.0944513,0.695152,"Hybrid-distorted image restoration (HD-IR) is dedicated to restore real
distorted image that is degraded by multiple distortions. Existing HD-IR
approaches usually ignore the inherent interference among hybrid distortions
which compromises the restoration performance. To decompose such interference,
we introduce the concept of Disentangled Feature Learning to achieve the
feature-level divide-and-conquer of hybrid distortions. Specifically, we
propose the feature disentanglement module (FDM) to distribute feature
representations of different distortions into different channels by revising
gain-control-based normalization. We also propose a feature aggregation module
(FAM) with channel-wise attention to adaptively filter out the distortion
representations and aggregate useful content information from different
channels for the construction of raw image. The effectiveness of the proposed
scheme is verified by visualizing the correlation matrix of features and
channel responses of different distortions. Extensive experimental results also
prove superior performance of our approach compared with the latest HD-IR
schemes.",0,1,0,0,1,0,0.695462,5.0,0.712728,45
http://arxiv.org/abs/2011.06346v1,Multi-View Dynamic Heterogeneous Information Network Embedding,4,0.112886,0.198982,"Most existing Heterogeneous Information Network (HIN) embedding methods focus
on static environments while neglecting the evolving characteristic of
realworld networks. Although several dynamic embedding methods have been
proposed, they are merely designed for homogeneous networks and cannot be
directly applied in heterogeneous environment. To tackle above challenges, we
propose a novel framework for incorporating temporal information into HIN
embedding, denoted as Multi-View Dynamic HIN Embedding (MDHNE), which can
efficiently preserve evolution patterns of implicit relationships from
different views in updating node representations over time. We first transform
HIN to a series of homogeneous networks corresponding to different views. Then
our proposed MDHNE applies Recurrent Neural Network (RNN) to incorporate
evolving pattern of complex network structure and semantic relationships
between nodes into latent embedding spaces, and thus the node representations
from multiple views can be learned and updated when HIN evolves over time.
Moreover, we come up with an attention based fusion mechanism, which can
automatically infer weights of latent representations corresponding to
different views by minimizing the objective function specific for different
mining tasks. Extensive experiments clearly demonstrate that our MDHNE model
outperforms state-of-the-art baselines on three real-world dynamic datasets for
different network mining tasks.",0,0,0,0,1,0,0.95492,7.0,0.931678,34
http://arxiv.org/abs/2011.01612v2,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,43,0.930873,0.804343,"We introduce XED, a multilingual fine-grained emotion dataset. The dataset
consists of human-annotated Finnish (25k) and English sentences (30k), as well
as projected annotations for 30 additional languages, providing new resources
for many low-resource languages. We use Plutchik's core emotions to annotate
the dataset with the addition of neutral to create a multilabel multiclass
dataset. The dataset is carefully evaluated using language-specific BERT models
and SVMs to show that XED performs on par with other similar datasets and is
therefore a useful tool for sentiment analysis and emotion detection.",0,1,1,1,0,0,0.930909,8.0,0.921689,46
http://arxiv.org/abs/2008.11469v1,SMAP: Single-Shot Multi-Person Absolute 3D Pose Estimation,76,0.211631,0.843578,"Recovering multi-person 3D poses with absolute scales from a single RGB image
is a challenging problem due to the inherent depth and scale ambiguity from a
single view. Addressing this ambiguity requires to aggregate various cues over
the entire image, such as body sizes, scene layouts, and inter-person
relationships. However, most previous methods adopt a top-down scheme that
first performs 2D pose detection and then regresses the 3D pose and scale for
each detected person individually, ignoring global contextual cues. In this
paper, we propose a novel system that first regresses a set of 2.5D
representations of body parts and then reconstructs the 3D absolute poses based
on these 2.5D representations with a depth-aware part association algorithm.
Such a single-shot bottom-up scheme allows the system to better learn and
reason about the inter-person depth relationship, improving both 3D and 2D pose
estimation. The experiments demonstrate that the proposed approach achieves the
state-of-the-art performance on the CMU Panoptic and MuPoTS-3D datasets and is
applicable to in-the-wild videos.",1,1,0,0,1,0,0.545521,6.0,0.692179,44
http://arxiv.org/abs/2011.14679v1,CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the Wild,89,0.569223,0.906369,"Human pose estimation from single images is a challenging problem in computer
vision that requires large amounts of labeled training data to be solved
accurately. Unfortunately, for many human activities (\eg outdoor sports) such
training data does not exist and is hard or even impossible to acquire with
traditional motion capture systems. We propose a self-supervised approach that
learns a single image 3D pose estimator from unlabeled multi-view data. To this
end, we exploit multi-view consistency constraints to disentangle the observed
2D pose into the underlying 3D pose and camera rotation. In contrast to most
existing methods, we do not require calibrated cameras and can therefore learn
from moving cameras. Nevertheless, in the case of a static camera setup, we
present an optional extension to include constant relative camera rotations
over multiple views into our framework. Key to the success are new, unbiased
reconstruction objectives that mix information across views and training
samples. The proposed approach is evaluated on two benchmark datasets
(Human3.6M and MPII-INF-3DHP) and on the in-the-wild SkiPose dataset.",0,1,0,0,1,0,0.739407,5.0,0.737361,55
http://arxiv.org/abs/2009.13954v2,Beneficial Perturbation Network for designing general adaptive artificial intelligence systems,13,0.110066,0.0927939,"The human brain is the gold standard of adaptive learning. It not only can
learn and benefit from experience, but also can adapt to new situations. In
contrast, deep neural networks only learn one sophisticated but fixed mapping
from inputs to outputs. This limits their applicability to more dynamic
situations, where input to output mapping may change with different contexts. A
salient example is continual learning - learning new independent tasks
sequentially without forgetting previous tasks. Continual learning of multiple
tasks in artificial neural networks using gradient descent leads to
catastrophic forgetting, whereby a previously learned mapping of an old task is
erased when learning new mappings for new tasks. Here, we propose a new
biologically plausible type of deep neural network with extra, out-of-network,
task-dependent biasing units to accommodate these dynamic situations. This
allows, for the first time, a single network to learn potentially unlimited
parallel input to output mappings, and to switch on the fly between them at
runtime. Biasing units are programmed by leveraging beneficial perturbations
(opposite to well-known adversarial perturbations) for each task. Beneficial
perturbations for a given task bias the network toward that task, essentially
switching the network into a different mode to process that task. This largely
eliminates catastrophic interference between tasks. Our approach is
memory-efficient and parameter-efficient, can accommodate many tasks, and
achieves state-of-the-art performance across different tasks and domains.",0,0,1,0,1,1,0.767062,8.0,0.845866,57
http://arxiv.org/abs/2011.03168v4,Neural Stochastic Contraction Metrics for Learning-based Control and Estimation,34,0.0909798,0.505913,"We present Neural Stochastic Contraction Metrics (NSCM), a new design
framework for provably-stable robust control and estimation for a class of
stochastic nonlinear systems. It uses a spectrally-normalized deep neural
network to construct a contraction metric, sampled via simplified convex
optimization in the stochastic setting. Spectral normalization constrains the
state-derivatives of the metric to be Lipschitz continuous, thereby ensuring
exponential boundedness of the mean squared distance of system trajectories
under stochastic disturbances. The NSCM framework allows autonomous agents to
approximate optimal stable control and estimation policies in real-time, and
outperforms existing nonlinear control and estimation techniques including the
state-dependent Riccati equation, iterative LQR, EKF, and the deterministic
neural contraction metric, as illustrated in simulation results.",1,1,0,0,0,0,0.0200582,11.0,0.499233,32
http://arxiv.org/abs/2005.00975v2,Efficient Second-Order TreeCRF for Neural Dependency Parsing,91,0.349041,0.869399,"In the deep learning (DL) era, parsing models are extremely simplified with
little hurt on performance, thanks to the remarkable capability of multi-layer
BiLSTMs in context representation. As the most popular graph-based dependency
parser due to its high efficiency and performance, the biaffine parser directly
scores single dependencies under the arc-factorization assumption, and adopts a
very simple local token-wise cross-entropy training loss. This paper for the
first time presents a second-order TreeCRF extension to the biaffine parser.
For a long time, the complexity and inefficiency of the inside-outside
algorithm hinder the popularity of TreeCRF. To address this issue, we propose
an effective way to batchify the inside and Viterbi algorithms for direct large
matrix operation on GPUs, and to avoid the complex outside algorithm via
efficient back-propagation. Experiments and analysis on 27 datasets from 13
languages clearly show that techniques developed before the DL era, such as
structural learning (global TreeCRF loss) and high-order modeling are still
useful, and can further boost parsing performance over the state-of-the-art
biaffine parser, especially for partially annotated training data. We release
our code at https://github.com/yzhangcs/crfpar.",1,0,0,0,0,0,0.0908921,9.0,0.559972,49
http://arxiv.org/abs/2006.12030v1,DO-Conv: Depthwise Over-parameterized Convolutional Layer,119,0.978099,0.973137,"Convolutional layers are the core building blocks of Convolutional Neural
Networks (CNNs). In this paper, we propose to augment a convolutional layer
with an additional depthwise convolution, where each input channel is convolved
with a different 2D kernel. The composition of the two convolutions constitutes
an over-parameterization, since it adds learnable parameters, while the
resulting linear operation can be expressed by a single convolution layer. We
refer to this depthwise over-parameterized convolutional layer as DO-Conv. We
show with extensive experiments that the mere replacement of conventional
convolutional layers with DO-Conv layers boosts the performance of CNNs on many
classical vision tasks, such as image classification, detection, and
segmentation. Moreover, in the inference phase, the depthwise convolution is
folded into the conventional convolution, reducing the computation to be
exactly equivalent to that of a convolutional layer without
over-parameterization. As DO-Conv introduces performance gains without
incurring any computational complexity increase for inference, we advocate it
as an alternative to the conventional convolutional layer. We open-source a
reference implementation of DO-Conv in Tensorflow, PyTorch and GluonCV at
https://github.com/yangyanli/DO-Conv.",1,1,0,0,0,1,0.977474,7.0,0.960535,36
http://arxiv.org/abs/2011.03327v4,Fighting an Infodemic: COVID-19 Fake News Dataset,276,0.992439,0.999971,"Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news
and rumors are rampant on social media. Believing in rumors can cause
significant harm. This is further exacerbated at the time of a pandemic. To
tackle this, we curate and release a manually annotated dataset of 10,700
social media posts and articles of real and fake news on COVID-19. We benchmark
the annotated dataset with four machine learning baselines - Decision Tree,
Logistic Regression, Gradient Boost, and Support Vector Machine (SVM). We
obtain the best performance of 93.46% F1-score with SVM. The data and code is
available at: https://github.com/parthpatwa/covid19-fake-news-dectection",1,1,0,1,1,0,0.759729,9.0,0.860603,23
http://arxiv.org/abs/2004.06793v1,Probabilistic Model of Narratives Over Topical Trends in Social Media: A Discrete Time Model,14,0.275051,0.613605,"Online social media platforms are turning into the prime source of news and
narratives about worldwide events. However,a systematic summarization-based
narrative extraction that can facilitate communicating the main underlying
events is lacking. To address this issue, we propose a novel event-based
narrative summary extraction framework. Our proposed framework is designed as a
probabilistic topic model, with categorical time distribution, followed by
extractive text summarization. Our topic model identifies topics' recurrence
over time with a varying time resolution. This framework not only captures the
topic distributions from the data, but also approximates the user activity
fluctuations over time. Furthermore, we define significance-dispersity
trade-off (SDT) as a comparison measure to identify the topic with the highest
lifetime attractiveness in a timestamped corpus. We evaluate our model on a
large corpus of Twitter data, including more than one million tweets in the
domain of the disinformation campaigns conducted against the White Helmets of
Syria. Our results indicate that the proposed framework is effective in
identifying topical trends, as well as extracting narrative summaries from text
corpus with timestamped data.",0,0,0,0,0,0,0.469137,7.0,0.704811,45
http://arxiv.org/abs/2002.03627v1,End-to-End Facial Deep Learning Feature Compression with Teacher-Student Enhancement,5,0.0416366,0.212356,"In this paper, we propose a novel end-to-end feature compression scheme by
leveraging the representation and learning capability of deep neural networks,
towards intelligent front-end equipped analysis with promising accuracy and
efficiency. In particular, the extracted features are compactly coded in an
end-to-end manner by optimizing the rate-distortion cost to achieve
feature-in-feature representation. In order to further improve the compression
performance, we present a latent code level teacher-student enhancement model,
which could efficiently transfer the low bit-rate representation into a high
bit rate one. Such a strategy further allows us to adaptively shift the
representation cost to decoding computations, leading to more flexible feature
compression with enhanced decoding capability. We verify the effectiveness of
the proposed model with the facial feature, and experimental results reveal
better compression performance in terms of rate-accuracy compared with existing
models.",0,1,0,0,0,0,0.564633,11.0,0.83692,26
http://arxiv.org/abs/2005.00282v1,Multi-Camera Trajectory Forecasting: Pedestrian Trajectory Prediction in a Network of Cameras,16,0.393773,0.389381,"We introduce the task of multi-camera trajectory forecasting (MCTF), where
the future trajectory of an object is predicted in a network of cameras. Prior
works consider forecasting trajectories in a single camera view. Our work is
the first to consider the challenging scenario of forecasting across multiple
non-overlapping camera views. This has wide applicability in tasks such as
re-identification and multi-target multi-camera tracking. To facilitate
research in this new area, we release the Warwick-NTU Multi-camera Forecasting
Database (WNMF), a unique dataset of multi-camera pedestrian trajectories from
a network of 15 synchronized cameras. To accurately label this large dataset
(600 hours of video footage), we also develop a semi-automated annotation
method. An effective MCTF model should proactively anticipate where and when a
person will re-appear in the camera network. In this paper, we consider the
task of predicting the next camera a pedestrian will re-appear after leaving
the view of another camera, and present several baseline approaches for this.
The labeled database is available online:
https://github.com/olly-styles/Multi-Camera-Trajectory-Forecasting.",1,0,1,1,0,0,0.983155,7.0,0.97108,16
http://arxiv.org/abs/2007.16162v3,Imitative Planning using Conditional Normalizing Flow,6,0.035343,0.197014,"A popular way to plan trajectories in dynamic urban scenarios for Autonomous
Vehicles is to rely on explicitly specified and hand crafted cost functions,
coupled with random sampling in the trajectory space to find the minimum cost
trajectory. Such methods require a high number of samples to find a low-cost
trajectory and might end up with a highly suboptimal trajectory given the
planning time budget. We explore the application of normalizing flows for
improving the performance of trajectory planning for autonomous vehicles (AVs).
Our key insight is to learn a sampling policy in a low-dimensional latent space
of expert-like trajectories, out of which the best sample is selected for
execution. By modeling the trajectory planner's cost manifold as an energy
function, we learn a scene conditioned mapping from the prior to a Boltzmann
distribution over the AV control space. Finally, we demonstrate the
effectiveness of our approach on real-world datasets over IL and
hand-constructed trajectory sampling techniques.",0,1,0,0,0,0,0.882917,5.0,0.830729,40
http://arxiv.org/abs/2010.12645v2,Towards Safe Policy Improvement for Non-Stationary MDPs,31,0.271893,0.708082,"Many real-world sequential decision-making problems involve critical systems
with financial risks and human-life risks. While several works in the past have
proposed methods that are safe for deployment, they assume that the underlying
problem is stationary. However, many real-world problems of interest exhibit
non-stationarity, and when stakes are high, the cost associated with a false
stationarity assumption may be unacceptable. We take the first steps towards
ensuring safety, with high confidence, for smoothly-varying non-stationary
decision problems. Our proposed method extends a type of safe algorithm, called
a Seldonian algorithm, through a synthesis of model-free reinforcement learning
with time-series analysis. Safety is ensured using sequential hypothesis
testing of a policy's forecasted performance, and confidence intervals are
obtained using wild bootstrap.",0,1,0,0,0,0,0.168335,11.0,0.699955,70
http://arxiv.org/abs/2008.10849v2,LSTM Networks for Online Cross-Network Recommendations,19,0.492831,0.153466,"Cross-network recommender systems use auxiliary information from multiple
source networks to create holistic user profiles and improve recommendations in
a target network. However, we find two major limitations in existing
cross-network solutions that reduce overall recommender performance. Existing
models (1) fail to capture complex non-linear relationships in user
interactions, and (2) are designed for offline settings hence, not updated
online with incoming interactions to capture the dynamics in the recommender
environment. We propose a novel multi-layered Long Short-Term Memory (LSTM)
network based online solution to mitigate these issues. The proposed model
contains three main extensions to the standard LSTM: First, an attention gated
mechanism to capture long-term user preference changes. Second, a higher order
interaction layer to alleviate data sparsity. Third, time aware LSTM cell gates
to capture irregular time intervals between user interactions. We illustrate
our solution using auxiliary information from Twitter and Google Plus to
improve recommendations on YouTube. Extensive experiments show that the
proposed model consistently outperforms state-of-the-art in terms of accuracy,
diversity and novelty.",0,1,0,0,1,0,0.814538,6.0,0.818712,49
http://arxiv.org/abs/2010.01245v2,Consensus Clustering With Unsupervised Representation Learning,17,0.145376,0.249334,"Recent advances in deep clustering and unsupervised representation learning
are based on the idea that different views of an input image (generated through
data augmentation techniques) must either be closer in the representation
space, or have a similar cluster assignment. Bootstrap Your Own Latent (BYOL)
is one such representation learning algorithm that has achieved
state-of-the-art results in self-supervised image classification on ImageNet
under the linear evaluation protocol. However, the utility of the learnt
features of BYOL to perform clustering is not explored. In this work, we study
the clustering ability of BYOL and observe that features learnt using BYOL may
not be optimal for clustering. We propose a novel consensus clustering based
loss function, and train BYOL with the proposed loss in an end-to-end way that
improves the clustering ability and outperforms similar clustering based
methods on some popular computer vision datasets.",1,1,0,0,0,0,0.960983,10.0,0.95673,57
http://arxiv.org/abs/2007.05892v1,PA-GAN: Progressive Attention Generative Adversarial Network for Facial Attribute Editing,25,0.321257,0.664587,"Facial attribute editing aims to manipulate attributes on the human face,
e.g., adding a mustache or changing the hair color. Existing approaches suffer
from a serious compromise between correct attribute generation and preservation
of the other information such as identity and background, because they edit the
attributes in the imprecise area. To resolve this dilemma, we propose a
progressive attention GAN (PA-GAN) for facial attribute editing. In our
approach, the editing is progressively conducted from high to low feature level
while being constrained inside a proper attribute area by an attention mask at
each level. This manner prevents undesired modifications to the irrelevant
regions from the beginning, and then the network can focus more on correctly
generating the attributes within a proper boundary at each level. As a result,
our approach achieves correct attribute editing with irrelevant details much
better preserved compared with the state-of-the-arts. Codes are released at
https://github.com/LynnHo/PA-GAN-Tensorflow.",1,1,0,0,1,0,0.843162,6.0,0.83452,42
http://arxiv.org/abs/2005.05085v1,Comparison and Benchmarking of AI Models and Frameworks on Mobile Devices,47,0.231356,0.720113,"Due to increasing amounts of data and compute resources, deep learning
achieves many successes in various domains. The application of deep learning on
the mobile and embedded devices is taken more and more attentions, benchmarking
and ranking the AI abilities of mobile and embedded devices becomes an urgent
problem to be solved. Considering the model diversity and framework diversity,
we propose a benchmark suite, AIoTBench, which focuses on the evaluation of the
inference abilities of mobile and embedded devices. AIoTBench covers three
typical heavy-weight networks: ResNet50, InceptionV3, DenseNet121, as well as
three light-weight networks: SqueezeNet, MobileNetV2, MnasNet. Each network is
implemented by three frameworks which are designed for mobile and embedded
devices: Tensorflow Lite, Caffe2, Pytorch Mobile. To compare and rank the AI
capabilities of the devices, we propose two unified metrics as the AI scores:
Valid Images Per Second (VIPS) and Valid FLOPs Per Second (VOPS). Currently, we
have compared and ranked 5 mobile devices using our benchmark. This list will
be extended and updated soon after.",0,1,1,0,0,0,0.771559,8.0,0.847528,47
http://arxiv.org/abs/2009.13158v2,Trainable Structure Tensors for Autonomous Baggage Threat Detection Under Extreme Occlusion,33,0.0285509,0.209801,"Detecting baggage threats is one of the most difficult tasks, even for expert
officers. Many researchers have developed computer-aided screening systems to
recognize these threats from the baggage X-ray scans. However, all of these
frameworks are limited in identifying the contraband items under extreme
occlusion. This paper presents a novel instance segmentation framework that
utilizes trainable structure tensors to highlight the contours of the occluded
and cluttered contraband items (by scanning multiple predominant orientations),
while simultaneously suppressing the irrelevant baggage content. The proposed
framework has been extensively tested on four publicly available X-ray datasets
where it outperforms the state-of-the-art frameworks in terms of mean average
precision scores. Furthermore, to the best of our knowledge, it is the only
framework that has been validated on combined grayscale and colored scans
obtained from four different types of X-ray scanners.",1,1,0,0,1,0,0.03694,6.0,0.185144,48
http://arxiv.org/abs/2003.09986v1,Toward Tag-free Aspect Based Sentiment Analysis: A Multiple Attention Network Approach,11,0.182371,0.29451,"Existing aspect based sentiment analysis (ABSA) approaches leverage various
neural network models to extract the aspect sentiments via learning
aspect-specific feature representations. However, these approaches heavily rely
on manual tagging of user reviews according to the predefined aspects as the
input, a laborious and time-consuming process. Moreover, the underlying methods
do not explain how and why the opposing aspect level polarities in a user
review lead to the overall polarity. In this paper, we tackle these two
problems by designing and implementing a new Multiple-Attention Network (MAN)
approach for more powerful ABSA without the need for aspect tags using two new
tag-free data sets crawled directly from TripAdvisor
({https://www.tripadvisor.com}). With the Self- and Position-Aware attention
mechanism, MAN is capable of extracting both aspect level and overall
sentiments from the text reviews using the aspect level and overall customer
ratings, and it can also detect the vital aspect(s) leading to the overall
sentiment polarity among different aspects via a new aspect ranking scheme. We
carry out extensive experiments to demonstrate the strong performance of MAN
compared to other state-of-the-art ABSA approaches and the explainability of
our approach by visualizing and interpreting attention weights in case studies.",1,1,0,1,1,0,0.777876,9.0,0.86656,48
http://arxiv.org/abs/2004.11540v2,Deep Global Registration,384,0.919247,1.0,"We present Deep Global Registration, a differentiable framework for pairwise
registration of real-world 3D scans. Deep global registration is based on three
modules: a 6-dimensional convolutional network for correspondence confidence
prediction, a differentiable Weighted Procrustes algorithm for closed-form pose
estimation, and a robust gradient-based SE(3) optimizer for pose refinement.
Experiments demonstrate that our approach outperforms state-of-the-art methods,
both learning-based and classical, on real-world data.",1,1,0,0,1,0,0.747376,9.0,0.856626,54
http://arxiv.org/abs/2012.01468v1,Video Anomaly Detection by Estimating Likelihood of Representations,12,0.222702,0.232695,"Video anomaly detection is a challenging task not only because it involves
solving many sub-tasks such as motion representation, object localization and
action recognition, but also because it is commonly considered as an
unsupervised learning problem that involves detecting outliers. Traditionally,
solutions to this task have focused on the mapping between video frames and
their low-dimensional features, while ignoring the spatial connections of those
features. Recent solutions focus on analyzing these spatial connections by
using hard clustering techniques, such as K-Means, or applying neural networks
to map latent features to a general understanding, such as action attributes.
In order to solve video anomaly in the latent feature space, we propose a deep
probabilistic model to transfer this task into a density estimation problem
where latent manifolds are generated by a deep denoising autoencoder and
clustered by expectation maximization. Evaluations on several benchmarks
datasets show the strengths of our model, achieving outstanding performance on
challenging datasets.",0,1,0,0,1,0,0.989621,7.0,0.987089,45
http://arxiv.org/abs/2011.15128v1,Animating Pictures with Eulerian Motion Fields,45,0.349802,0.676088,"In this paper, we demonstrate a fully automatic method for converting a still
image into a realistic animated looping video. We target scenes with continuous
fluid motion, such as flowing water and billowing smoke. Our method relies on
the observation that this type of natural motion can be convincingly reproduced
from a static Eulerian motion description, i.e. a single, temporally constant
flow field that defines the immediate motion of a particle at a given 2D
location. We use an image-to-image translation network to encode motion priors
of natural scenes collected from online videos, so that for a new photo, we can
synthesize a corresponding motion field. The image is then animated using the
generated motion through a deep warping technique: pixels are encoded as deep
features, those features are warped via Eulerian motion, and the resulting
warped feature maps are decoded as images. In order to produce continuous,
seamlessly looping video textures, we propose a novel video looping technique
that flows features both forward and backward in time and then blends the
results. We demonstrate the effectiveness and robustness of our method by
applying it to a large collection of examples including beaches, waterfalls,
and flowing rivers.",0,1,0,0,0,0,0.274975,7.0,0.607994,36
http://arxiv.org/abs/2004.01278v1,"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention",19,0.0814055,0.420398,"Attentive video modeling is essential for action recognition in unconstrained
videos due to their rich yet redundant information over space and time.
However, introducing attention in a deep neural network for action recognition
is challenging for two reasons. First, an effective attention module needs to
learn what (objects and their local motion patterns), where (spatially), and
when (temporally) to focus on. Second, a video attention module must be
efficient because existing action recognition models already suffer from high
computational cost. To address both challenges, a novel What-Where-When (W3)
video attention module is proposed. Departing from existing alternatives, our
W3 module models all three facets of video attention jointly. Crucially, it is
extremely efficient by factorizing the high-dimensional video feature data into
low-dimensional meaningful spaces (1D channel vector for `what' and 2D spatial
tensors for `where'), followed by lightweight temporal attention reasoning.
Extensive experiments show that our attention model brings significant
improvements to existing action recognition models, achieving new
state-of-the-art performance on a number of benchmarks.",0,1,0,0,1,0,0.811955,5.0,0.780806,65
http://arxiv.org/abs/2005.02771v1,Unsupervised Neural Aspect Search with Related Terms Extraction,2,0.0174931,0.049856,"The tasks of aspect identification and term extraction remain challenging in
natural language processing. While supervised methods achieve high scores, it
is hard to use them in real-world applications due to the lack of labelled
datasets. Unsupervised approaches outperform these methods on several tasks,
but it is still a challenge to extract both an aspect and a corresponding term,
particularly in the multi-aspect setting. In this work, we present a novel
unsupervised neural network with convolutional multi-attention mechanism, that
allows extracting pairs (aspect, term) simultaneously, and demonstrate the
effectiveness on the real-world dataset. We apply a special loss aimed to
improve the quality of multi-aspect extraction. The experimental study
demonstrates, what with this loss we increase the precision not only on this
joint setting but also on aspect prediction only.",0,0,0,0,0,0,0.352221,8.0,0.694541,12
http://arxiv.org/abs/2004.08501v2,Finding Berries: Segmentation and Counting of Cranberries using Point Supervision and Shape Priors,21,0.333518,0.569918,"Precision agriculture has become a key factor for increasing crop yields by
providing essential information to decision makers. In this work, we present a
deep learning method for simultaneous segmentation and counting of cranberries
to aid in yield estimation and sun exposure predictions. Notably, supervision
is done using low cost center point annotations. The approach, named Triple-S
Network, incorporates a three-part loss with shape priors to promote better
fitting to objects of known shape typical in agricultural scenes. Our results
improve overall segmentation performance by more than 6.74% and counting
results by 22.91% when compared to state-of-the-art. To train and evaluate the
network, we have collected the CRanberry Aerial Imagery Dataset (CRAID), the
largest dataset of aerial drone imagery from cranberry fields. This dataset
will be made publicly available.",0,1,0,1,1,0,0.799931,10.0,0.886623,52
http://arxiv.org/abs/2001.04233v1,State Representation and Polyomino Placement for the Game Patchwork,1,0.0148851,0.0516434,"Modern board games are a rich source of entertainment for many people, but
also contain interesting and challenging structures for game playing research
and implementing game playing agents. This paper studies the game Patchwork, a
two player strategy game using polyomino tile drafting and placement. The core
polyomino placement mechanic is implemented in a constraint model using regular
constraints, extending and improving the model in (Lagerkvist, Pesant, 2008)
with: explicit rotation handling; optional placements; and new constraints for
resource usage. Crucial for implementing good game playing agents is to have
great heuristics for guiding the search when faced with large branching
factors. This paper divides placing tiles into two parts: a policy used for
placing parts and an evaluation used to select among different placements.
Policies are designed based on classical packing literature as well as common
standard constraint programming heuristics. For evaluation, global propagation
guided regret is introduced, choosing placements based on not ruling out later
placements. Extensive evaluations are performed, showing the importance of
using a good evaluation and that the proposed global propagation guided regret
is a very effective guide.",0,1,0,0,0,0,0.00927764,22.0,0.714321,26
http://arxiv.org/abs/2004.03459v2,Hierarchical Image Classification using Entailment Cone Embeddings,44,0.171758,0.637672,"Image classification has been studied extensively, but there has been limited
work in using unconventional, external guidance other than traditional
image-label pairs for training. We present a set of methods for leveraging
information about the semantic hierarchy embedded in class labels. We first
inject label-hierarchy knowledge into an arbitrary CNN-based classifier and
empirically show that availability of such external semantic information in
conjunction with the visual semantics from images boosts overall performance.
Taking a step further in this direction, we model more explicitly the
label-label and label-image interactions using order-preserving embeddings
governed by both Euclidean and hyperbolic geometries, prevalent in natural
language, and tailor them to hierarchical image classification and
representation learning. We empirically validate all the models on the
hierarchical ETHEC dataset.",0,0,0,0,0,0,0.491105,6.0,0.66638,28
http://arxiv.org/abs/2004.04917v1,Multimodal Categorization of Crisis Events in Social Media,59,0.845357,0.780773,"Recent developments in image classification and natural language processing,
coupled with the rapid growth in social media usage, have enabled fundamental
advances in detecting breaking events around the world in real-time. Emergency
response is one such area that stands to gain from these advances. By
processing billions of texts and images a minute, events can be automatically
detected to enable emergency response workers to better assess rapidly evolving
situations and deploy resources accordingly. To date, most event detection
techniques in this area have focused on image-only or text-only approaches,
limiting detection performance and impacting the quality of information
delivered to crisis response teams. In this paper, we present a new multimodal
fusion method that leverages both images and texts as input. In particular, we
introduce a cross-attention module that can filter uninformative and misleading
components from weak modalities on a sample by sample basis. In addition, we
employ a multimodal graph-based approach to stochastically transition between
embeddings of different multimodal pairs during training to better regularize
the learning process as well as dealing with limited training data by
constructing new matched pairs from different samples. We show that our method
outperforms the unimodal approaches and strong multimodal baselines by a large
margin on three crisis-related tasks.",0,1,0,0,1,0,0.913154,6.0,0.880674,83
http://arxiv.org/abs/2010.05229v1,Machine Translation of Mathematical Text,9,0.0150612,0.193043,"We have implemented a machine translation system, the PolyMath Translator,
for LaTeX documents containing mathematical text. The current implementation
translates English LaTeX to French LaTeX, attaining a BLEU score of 53.5 on a
held-out test corpus of mathematical sentences. It produces LaTeX documents
that can be compiled to PDF without further editing. The system first converts
the body of an input LaTeX document into English sentences containing math
tokens, using the pandoc universal document converter to parse LaTeX input. We
have trained a Transformer-based translator model, using OpenNMT, on a combined
corpus containing a small proportion of domain-specific sentences. Our full
system uses both this Transformer model and Google Translate, the latter being
used as a backup to better handle linguistic features that do not appear in our
training dataset. If the Transformer model does not have confidence in its
translation, as determined by a high perplexity score, then we use Google
Translate with a custom glossary. This backup was used 26% of the time on our
test corpus of mathematical sentences. The PolyMath Translator is available as
a web service at www.polymathtrans.ai.",0,1,0,0,0,0,0.0698031,6.0,0.294074,33
http://arxiv.org/abs/2006.11512v1,Sarcasm Detection in Tweets with BERT and GloVe Embeddings,33,0.654253,0.141696,"Sarcasm is a form of communication in whichthe person states opposite of what
he actually means. It is ambiguous in nature. In this paper, we propose using
machine learning techniques with BERT and GloVe embeddings to detect sarcasm in
tweets. The dataset is preprocessed before extracting the embeddings. The
proposed model also uses the context in which the user is reacting to along
with his actual response.",0,1,0,0,0,0,0.986416,16.0,0.990557,21
http://arxiv.org/abs/2011.09351v1,Learning Regular Expressions for Interpretable Medical Text Classification Using a Pool-based Simulated Annealing and Word-vector Models,1,0.0238334,0.0169784,"In this paper, we propose a rule-based engine composed of high quality and
interpretable regular expressions for medical text classification. The regular
expressions are auto generated by a constructive heuristic method and optimized
using a Pool-based Simulated Annealing (PSA) approach. Although existing Deep
Neural Network (DNN) methods present high quality performance in most Natural
Language Processing (NLP) applications, the solutions are regarded as
uninterpretable black boxes to humans. Therefore, rule-based methods are often
introduced when interpretable solutions are needed, especially in the medical
field. However, the construction of regular expressions can be extremely
labor-intensive for large data sets. This research aims to reduce the manual
efforts while maintaining high-quality solutions",0,1,0,0,0,0,0.239086,16.0,0.818321,22
http://arxiv.org/abs/2001.11302v2,A Deeper Look into Hybrid Images,2,0.0112046,0.0609005,"$Hybrid$ $images$ was first introduced by Olivia et al., that produced static
images with two interpretations such that the images changes as a function of
viewing distance. Hybrid images are built by studying human processing of
multiscale images and are motivated by masking studies in visual perception.
The first introduction of hybrid images showed that two images can be blend
together with a high pass filter and a low pass filter in such a way that when
the blended image is viewed from a distance, the high pass filter fades away
and the low pass filter becomes prominent. Our main aim here is to study and
review the original paper by changing and tweaking certain parameters to see
how they affect the quality of the blended image produced. We have used
exhaustively different set of images and filters to see how they function and
whether this can be used in a real time system or not.",0,1,0,0,0,0,0.944342,1.0,0.451308,15
http://arxiv.org/abs/2004.06753v1,A Simple Yet Strong Pipeline for HotpotQA,37,0.0619428,0.246701,"State-of-the-art models for multi-hop question answering typically augment
large-scale language models like BERT with additional, intuitively useful
capabilities such as named entity recognition, graph-based reasoning, and
question decomposition. However, does their strong performance on popular
multi-hop datasets really justify this added design complexity? Our results
suggest that the answer may be no, because even our simple pipeline based on
BERT, named Quark, performs surprisingly well. Specifically, on HotpotQA, Quark
outperforms these models on both question answering and support identification
(and achieves performance very close to a RoBERTa model). Our pipeline has
three steps: 1) use BERT to identify potentially relevant sentences
independently of each other; 2) feed the set of selected sentences as context
into a standard BERT span prediction model to choose an answer; and 3) use the
sentence selection model, now with the chosen answer, to produce supporting
sentences. The strong performance of Quark resurfaces the importance of
carefully exploring simple model designs before using popular benchmarks to
justify the value of complex techniques.",0,1,0,0,0,0,0.841278,2.0,0.500326,18
http://arxiv.org/abs/2002.04734v10,Fast Complete Algorithm for Multiplayer Nash Equilibrium,6,0.042743,0.373302,"We describe a new complete algorithm for computing Nash equilibrium in
multiplayer general-sum games, based on a quadratically-constrained feasibility
program formulation. We demonstrate that the algorithm runs significantly
faster than the prior fastest complete algorithm on several game classes
previously studied and that its runtimes even outperform the best incomplete
algorithms.",0,0,0,0,0,0,0.000427974,28.0,0.665512,25
http://arxiv.org/abs/2005.06510v1,Many-Objective Software Remodularization using NSGA-III,231,0.42938,0.984854,"Software systems nowadays are complex and difficult to maintain due to
continuous changes and bad design choices. To handle the complexity of systems,
software products are, in general, decomposed in terms of packages/modules
containing classes that are dependent. However, it is challenging to
automatically remodularize systems to improve their maintainability. The
majority of existing remodularization work mainly satisfy one objective which
is improving the structure of packages by optimizing coupling and cohesion. In
addition, most of existing studies are limited to only few operation types such
as move class and split packages. Many other objectives, such as the design
semantics, reducing the number of changes and maximizing the consistency with
development change history, are important to improve the quality of the
software by remodularizing it. In this paper, we propose a novel many-objective
search-based approach using NSGA-III. The process aims at finding the optimal
remodularization solutions that improve the structure of packages, minimize the
number of changes, preserve semantics coherence, and re-use the history of
changes. We evaluate the efficiency of our approach using four different
open-source systems and one automotive industry project, provided by our
industrial partner, through a quantitative and qualitative study conducted with
software engineers.",0,1,0,0,0,0,0.0248714,9.0,0.412121,101
http://arxiv.org/abs/2004.15003v3,Word Rotator's Distance,48,0.13796,0.841104,"A key principle in assessing textual similarity is measuring the degree of
semantic overlap between two texts by considering the word alignment. Such
alignment-based approaches are intuitive and interpretable; however, they are
empirically inferior to the simple cosine similarity between general-purpose
sentence vectors. To address this issue, we focus on and demonstrate the fact
that the norm of word vectors is a good proxy for word importance, and their
angle is a good proxy for word similarity. Alignment-based approaches do not
distinguish them, whereas sentence-vector approaches automatically use the norm
as the word importance. Accordingly, we propose a method that first decouples
word vectors into their norm and direction, and then computes alignment-based
similarity using earth mover's distance (i.e., optimal transport cost), which
we refer to as word rotator's distance. Besides, we find how to grow the norm
and direction of word vectors (vector converter), which is a new systematic
approach derived from sentence-vector estimation methods. On several textual
similarity datasets, the combination of these simple proposed methods
outperformed not only alignment-based approaches but also strong baselines. The
source code is available at https://github.com/eumesy/wrd",1,0,0,0,0,1,0.356877,8.0,0.6966,78
http://arxiv.org/abs/2009.11201v2,Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages,30,0.141657,0.477043,"Unsupervised translation has reached impressive performance on resource-rich
language pairs such as English-French and English-German. However, early
studies have shown that in more realistic settings involving low-resource, rare
languages, unsupervised translation performs poorly, achieving less than 3.0
BLEU. In this work, we show that multilinguality is critical to making
unsupervised systems practical for low-resource settings. In particular, we
present a single model for 5 low-resource languages (Gujarati, Kazakh, Nepali,
Sinhala, and Turkish) to and from English directions, which leverages
monolingual and auxiliary parallel data from other high-resource language pairs
via a three-stage training scheme. We outperform all current state-of-the-art
unsupervised baselines for these languages, achieving gains of up to 14.4 BLEU.
Additionally, we outperform a large collection of supervised WMT submissions
for various language pairs as well as match the performance of the current
state-of-the-art supervised model for Nepali-English. We conduct a series of
ablation studies to establish the robustness of our model under different
degrees of data quality, as well as to analyze the factors which led to the
superior performance of the proposed approach over traditional unsupervised
models.",0,1,0,0,1,0,0.681648,5.0,0.705123,53
http://arxiv.org/abs/2005.03358v1,Self-Supervised Human Depth Estimation from Monocular Videos,30,0.136764,0.654761,"Previous methods on estimating detailed human depth often require supervised
training with `ground truth' depth data. This paper presents a self-supervised
method that can be trained on YouTube videos without known depth, which makes
training data collection simple and improves the generalization of the learned
network. The self-supervised learning is achieved by minimizing a
photo-consistency loss, which is evaluated between a video frame and its
neighboring frames warped according to the estimated depth and the 3D non-rigid
motion of the human body. To solve this non-rigid motion, we first estimate a
rough SMPL model at each video frame and compute the non-rigid body motion
accordingly, which enables self-supervised learning on estimating the shape
details. Experiments demonstrate that our method enjoys better generalization
and performs much better on data in the wild.",0,1,0,0,0,0,0.842881,5.0,0.801231,54
http://arxiv.org/abs/2006.05646v1,Scalable Backdoor Detection in Neural Networks,21,0.27909,0.0924435,"Recently, it has been shown that deep learning models are vulnerable to
Trojan attacks, where an attacker can install a backdoor during training time
to make the resultant model misidentify samples contaminated with a small
trigger patch. Current backdoor detection methods fail to achieve good
detection performance and are computationally expensive. In this paper, we
propose a novel trigger reverse-engineering based approach whose computational
complexity does not scale with the number of labels, and is based on a measure
that is both interpretable and universal across different network and patch
types. In experiments, we observe that our method achieves a perfect score in
separating Trojaned models from pure models, which is an improvement over the
current state-of-the art method.",0,1,0,0,1,0,0.959464,4.0,0.888864,23
http://arxiv.org/abs/2009.06451v1,"Development of a Dataset and a Deep Learning Baseline Named Entity Recognizer for Three Low Resource Languages: Bhojpuri, Maithili and Magahi",4,0.0245966,0.152659,"In Natural Language Processing (NLP) pipelines, Named Entity Recognition
(NER) is one of the preliminary problems, which marks proper nouns and other
named entities such as Location, Person, Organization, Disease etc. Such
entities, without a NER module, adversely affect the performance of a machine
translation system. NER helps in overcoming this problem by recognising and
handling such entities separately, although it can be useful in Information
Extraction systems also. Bhojpuri, Maithili and Magahi are low resource
languages, usually known as Purvanchal languages. This paper focuses on the
development of a NER benchmark dataset for the Machine Translation systems
developed to translate from these languages to Hindi by annotating parts of
their available corpora. Bhojpuri, Maithili and Magahi corpora of sizes 228373,
157468 and 56190 tokens, respectively, were annotated using 22 entity labels.
The annotation considers coarse-grained annotation labels followed by the
tagset used in one of the Hindi NER datasets. We also report a Deep Learning
based baseline that uses an LSTM-CNNs-CRF model. The lower baseline F1-scores
from the NER tool obtained by using Conditional Random Fields models are 96.73
for Bhojpuri, 93.33 for Maithili and 95.04 for Magahi. The Deep Learning-based
technique (LSTM-CNNs-CRF) achieved 96.25 for Bhojpuri, 93.33 for Maithili and
95.44 for Magahi.",0,1,1,1,1,0,0.0027432,15.0,0.499554,43
http://arxiv.org/abs/2010.10566v1,Better Highlighting: Creating Sub-Sentence Summary Highlights,11,0.0425796,0.397802,"Amongst the best means to summarize is highlighting. In this paper, we aim to
generate summary highlights to be overlaid on the original documents to make it
easier for readers to sift through a large amount of text. The method allows
summaries to be understood in context to prevent a summarizer from distorting
the original meaning, of which abstractive summarizers usually fall short. In
particular, we present a new method to produce self-contained highlights that
are understandable on their own to avoid confusion. Our method combines
determinantal point processes and deep contextualized representations to
identify an optimal set of sub-sentence segments that are both important and
non-redundant to form summary highlights. To demonstrate the flexibility and
modeling power of our method, we conduct extensive experiments on summarization
datasets. Our analysis provides evidence that highlighting is a promising
avenue of research towards future summarization.",1,1,0,0,0,1,0.173475,8.0,0.591574,55
http://arxiv.org/abs/2010.11383v1,Exploit Multiple Reference Graphs for Semi-supervised Relation Extraction,8,0.0591801,0.22366,"Manual annotation of the labeled data for relation extraction is
time-consuming and labor-intensive. Semi-supervised methods can offer helping
hands for this problem and have aroused great research interests. Existing work
focuses on mapping the unlabeled samples to the classes to augment the labeled
dataset. However, it is hard to find an overall good mapping function,
especially for the samples with complicated syntactic components in one
sentence.
  To tackle this limitation, we propose to build the connection between the
unlabeled data and the labeled ones rather than directly mapping the unlabeled
samples to the classes. Specifically, we first use three kinds of information
to construct reference graphs, including entity reference, verb reference, and
semantics reference. The goal is to semantically or lexically connect the
unlabeled sample(s) to the labeled one(s). Then, we develop a Multiple
Reference Graph (MRefG) model to exploit the reference information for better
recognizing high-quality unlabeled samples. The effectiveness of our method is
demonstrated by extensive comparison experiments with the state-of-the-art
baselines on two public datasets.",0,1,0,0,1,0,0.508051,9.0,0.783022,39
http://arxiv.org/abs/2004.07193v2,A Transductive Approach for Video Object Segmentation,103,0.496293,0.717195,"Semi-supervised video object segmentation aims to separate a target object
from a video sequence, given the mask in the first frame. Most of current
prevailing methods utilize information from additional modules trained in other
domains like optical flow and instance segmentation, and as a result they do
not compete with other methods on common ground. To address this issue, we
propose a simple yet strong transductive method, in which additional modules,
datasets, and dedicated architectural designs are not needed. Our method takes
a label propagation approach where pixel labels are passed forward based on
feature similarity in an embedding space. Different from other propagation
methods, ours diffuses temporal information in a holistic manner which take
accounts of long-term object appearance. In addition, our method requires few
additional computational overhead, and runs at a fast $\sim$37 fps speed. Our
single model with a vanilla ResNet50 backbone achieves an overall score of 72.3
on the DAVIS 2017 validation set and 63.1 on the test set. This simple yet high
performing and efficient method can serve as a solid baseline that facilitates
future research. Code and models are available at
\url{https://github.com/microsoft/transductive-vos.pytorch}.",1,1,0,0,1,0,0.862007,7.0,0.867705,52
http://arxiv.org/abs/2012.10586v2,Finding Sparse Structures for Domain Specific Neural Machine Translation,25,0.06019,0.696148,"Neural machine translation often adopts the fine-tuning approach to adapt to
specific domains. However, nonrestricted fine-tuning can easily degrade on the
general domain and over-fit to the target domain. To mitigate the issue, we
propose Prune-Tune, a novel domain adaptation method via gradual pruning. It
learns tiny domain-specific sub-networks during fine-tuning on new domains.
Prune-Tune alleviates the over-fitting and the degradation problem without
model modification. Furthermore, Prune-Tune is able to sequentially learn a
single network with multiple disjoint domain-specific sub-networks for multiple
domains. Empirical experiment results show that Prune-Tune outperforms several
strong competitors in the target domain test set without sacrificing the
quality on the general domain in both single and multi-domain settings. The
source code and data are available at https://github.com/ohlionel/Prune-Tune.",1,1,0,0,1,0,0.181187,8.0,0.597578,48
http://arxiv.org/abs/2002.06735v2,SpotTheFake: An Initial Report on a New CNN-Enhanced Platform for Counterfeit Goods Detection,4,0.154733,0.383252,"The counterfeit goods trade represents nowadays more than 3.3% of the whole
world trade and thus it's a problem that needs now more than ever a lot of
attention and a reliable solution that would reduce the negative impact it has
over the modern society. This paper presents the design and early stage
development of a novel counterfeit goods detection platform that makes use of
the outstsanding learning capabilities of the classical VGG16 convolutional
model trained through the process of ""transfer learning"" and a multi-stage fake
detection procedure that proved to be not only reliable but also very robust in
the experiments we have conducted so far using an image dataset of various
goods which we gathered ourselves.",0,1,0,1,0,0,0.521448,12.0,0.840449,12
http://arxiv.org/abs/2007.03169v1,Spatial Semantic Embedding Network: Fast 3D Instance Segmentation with Deep Metric Learning,14,0.23,0.19895,"We propose spatial semantic embedding network (SSEN), a simple, yet efficient
algorithm for 3D instance segmentation using deep metric learning. The raw 3D
reconstruction of an indoor environment suffers from occlusions, noise, and is
produced without any meaningful distinction between individual entities. For
high-level intelligent tasks from a large scale scene, 3D instance segmentation
recognizes individual instances of objects. We approach the instance
segmentation by simply learning the correct embedding space that maps
individual instances of objects into distinct clusters that reflect both
spatial and semantic information. Unlike previous approaches that require
complex pre-processing or post-processing, our implementation is compact and
fast with competitive performance, maintaining scalability on large scenes with
high resolution voxels. We demonstrate the state-of-the-art performance of our
algorithm in the ScanNet 3D instance segmentation benchmark on AP score.",1,1,0,0,1,0,0.972965,6.0,0.94574,39
http://arxiv.org/abs/2007.05179v1,Current Advancements on Autonomous Mission Planning and Management Systems: an AUV and UAV perspective,58,0.753299,0.90043,"Advances in hardware technology have enabled more integration of
sophisticated software, triggering progress in the development and employment
of Unmanned Vehicles (UVs), and mitigating restraints for onboard intelligence.
As a result, UVs can now take part in more complex mission where continuous
transformation in environmental condition calls for a higher level of
situational responsiveness. This paper serves as an introduction to UVs mission
planning and management systems aiming to highlight some of the recent
developments in the field of autonomous underwater and aerial vehicles in
addition to stressing some possible future directions and discussing the
learned lessons. A comprehensive survey over autonomy assessment of UVs, and
different aspects of autonomy such as situation awareness, cognition, and
decision-making has been provided in this study. The paper separately explains
the humanoid and autonomous system's performance and highlights the role and
impact of a human in UVs operations.",0,0,0,0,0,0,0.00306051,16.0,0.537683,117
http://arxiv.org/abs/2006.08889v1,Exploiting Visual Semantic Reasoning for Video-Text Retrieval,31,0.33277,0.565548,"Video retrieval is a challenging research topic bridging the vision and
language areas and has attracted broad attention in recent years. Previous
works have been devoted to representing videos by directly encoding from
frame-level features. In fact, videos consist of various and abundant semantic
relations to which existing methods pay less attention. To address this issue,
we propose a Visual Semantic Enhanced Reasoning Network (ViSERN) to exploit
reasoning between frame regions. Specifically, we consider frame regions as
vertices and construct a fully-connected semantic correlation graph. Then, we
perform reasoning by novel random walk rule-based graph convolutional networks
to generate region features involved with semantic relations. With the benefit
of reasoning, semantic interactions between regions are considered, while the
impact of redundancy is suppressed. Finally, the region features are aggregated
to form frame-level features for further encoding to measure video-text
similarity. Extensive experiments on two public benchmark datasets validate the
effectiveness of our method by achieving state-of-the-art performance due to
the powerful semantic reasoning.",0,0,0,0,1,0,0.96623,9.0,0.956762,32
http://arxiv.org/abs/2005.04306v1,Knowledge Patterns,103,0.28407,0.812883,"This paper describes a new technique, called ""knowledge patterns"", for
helping construct axiom-rich, formal ontologies, based on identifying and
explicitly representing recurring patterns of knowledge (theory schemata) in
the ontology, and then stating how those patterns map onto domain-specific
concepts in the ontology. From a modeling perspective, knowledge patterns
provide an important insight into the structure of a formal ontology: rather
than viewing a formal ontology simply as a list of terms and axioms, knowledge
patterns views it as a collection of abstract, modular theories (the ""knowledge
patterns"") plus a collection of modeling decisions stating how different
aspects of the world can be modeled using those theories. Knowledge patterns
make both those abstract theories and their mappings to the domain of interest
explicit, thus making modeling decisions clear, and avoiding some of the
ontological confusion that can otherwise arise. In addition, from a
computational perspective, knowledge patterns provide a simple and
computationally efficient mechanism for facilitating knowledge reuse. We
describe the technique and an application built using them, and then critique
its strengths and weaknesses. We conclude that this technique enables us to
better explicate both the structure and modeling decisions made when
constructing a formal axiom-rich ontology.",0,0,0,0,0,0,1.4877e-14,58.0,0.423275,22
http://arxiv.org/abs/2010.02557v1,PolicyQA: A Reading Comprehension Dataset for Privacy Policies,33,0.898672,0.853616,"Privacy policy documents are long and verbose. A question answering (QA)
system can assist users in finding the information that is relevant and
important to them. Prior studies in this domain frame the QA task as retrieving
the most relevant text segment or a list of sentences from the policy document
given a question. On the contrary, we argue that providing users with a short
text span from policy documents reduces the burden of searching the target
information from a lengthy text segment. In this paper, we present PolicyQA, a
dataset that contains 25,017 reading comprehension style examples curated from
an existing corpus of 115 website privacy policies. PolicyQA provides 714
human-annotated questions written for a wide range of privacy practices. We
evaluate two existing neural QA models and perform rigorous analysis to reveal
the advantages and challenges offered by PolicyQA.",0,1,0,0,0,0,0.957143,9.0,0.948658,28
http://arxiv.org/abs/2011.07120v1,Streaming Attention-Based Models with Augmented Memory for End-to-End Speech Recognition,7,0.0628102,0.308336,"Attention-based models have been gaining popularity recently for their strong
performance demonstrated in fields such as machine translation and automatic
speech recognition. One major challenge of attention-based models is the need
of access to the full sequence and the quadratically growing computational cost
concerning the sequence length. These characteristics pose challenges,
especially for low-latency scenarios, where the system is often required to be
streaming. In this paper, we build a compact and streaming speech recognition
system on top of the end-to-end neural transducer architecture with
attention-based modules augmented with convolution. The proposed system equips
the end-to-end models with the streaming capability and reduces the large
footprint from the streaming attention-based model using augmented memory. On
the LibriSpeech dataset, our proposed system achieves word error rates 2.7% on
test-clean and 5.8% on test-other, to our best knowledge the lowest among
streaming approaches reported so far.",0,1,0,0,0,0,0.892083,4.0,0.797736,27
http://arxiv.org/abs/2004.09936v3,DIET: Lightweight Language Understanding for Dialogue Systems,137,0.625365,0.804272,"Large-scale pre-trained language models have shown impressive results on
language understanding benchmarks like GLUE and SuperGLUE, improving
considerably over other pre-training methods like distributed representations
(GloVe) and purely supervised approaches. We introduce the Dual Intent and
Entity Transformer (DIET) architecture, and study the effectiveness of
different pre-trained representations on intent and entity prediction, two
common dialogue language understanding tasks. DIET advances the state of the
art on a complex multi-domain NLU dataset and achieves similarly high
performance on other simpler datasets. Surprisingly, we show that there is no
clear benefit to using large pre-trained models for this task, and in fact DIET
improves upon the current state of the art even in a purely supervised setup
without any pre-trained embeddings. Our best performing model outperforms
fine-tuning BERT and is about six times faster to train.",1,1,0,0,1,0,0.92819,4.0,0.839741,49
http://arxiv.org/abs/2004.00945v2,PaStaNet: Toward Human Activity Knowledge Engine,124,0.467866,0.993355,"Existing image-based activity understanding methods mainly adopt direct
mapping, i.e. from image to activity concepts, which may encounter performance
bottleneck since the huge gap. In light of this, we propose a new path: infer
human part states first and then reason out the activities based on part-level
semantics. Human Body Part States (PaSta) are fine-grained action semantic
tokens, e.g. <hand, hold, something>, which can compose the activities and help
us step toward human activity knowledge engine. To fully utilize the power of
PaSta, we build a large-scale knowledge base PaStaNet, which contains 7M+ PaSta
annotations. And two corresponding models are proposed: first, we design a
model named Activity2Vec to extract PaSta features, which aim to be general
representations for various activities. Second, we use a PaSta-based Reasoning
method to infer activities. Promoted by PaStaNet, our method achieves
significant improvements, e.g. 6.4 and 13.9 mAP on full and one-shot sets of
HICO in supervised learning, and 3.2 and 4.2 mAP on V-COCO and images-based AVA
in transfer learning. Code and data are available at http://hake-mvig.cn/.",1,1,1,1,1,0,0.47584,10.0,0.795354,64
http://arxiv.org/abs/2010.12850v3,CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers,61,0.785539,0.706003,"Dialogue state trackers have made significant progress on benchmark datasets,
but their generalization capability to novel and realistic scenarios beyond the
held-out conversations is less understood. We propose controllable
counterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking
(DST) models on novel scenarios, i.e., would the system successfully tackle the
request if the user responded differently but still consistently with the
dialogue flow? CoCo leverages turn-level belief states as counterfactual
conditionals to produce novel conversation scenarios in two steps: (i)
counterfactual goal generation at turn-level by dropping and adding slots
followed by replacing slot values, (ii) counterfactual conversation generation
that is conditioned on (i) and consistent with the dialogue flow. Evaluating
state-of-the-art DST models on MultiWOZ dataset with CoCo-generated
counterfactuals results in a significant performance drop of up to 30.8% (from
49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used
techniques like paraphrasing only affect the accuracy by at most 2%. Human
evaluations show that COCO-generated conversations perfectly reflect the
underlying user goal with more than 95% accuracy and are as human-like as the
original conversations, further strengthening its reliability and promise to be
adopted as part of the robustness evaluation of DST models.",0,1,1,0,0,0,0.980979,3.0,0.922456,48
http://arxiv.org/abs/2010.02162v1,Knowledge Association with Hyperbolic Knowledge Graph Embeddings,71,0.498506,0.918601,"Capturing associations for knowledge graphs (KGs) through entity alignment,
entity type inference and other related tasks benefits NLP applications with
comprehensive knowledge representations. Recent related methods built on
Euclidean embeddings are challenged by the hierarchical structures and
different scales of KGs. They also depend on high embedding dimensions to
realize enough expressiveness. Differently, we explore with low-dimensional
hyperbolic embeddings for knowledge association. We propose a hyperbolic
relational graph neural network for KG embedding and capture knowledge
associations with a hyperbolic transformation. Extensive experiments on entity
alignment and type inference demonstrate the effectiveness and efficiency of
our method.",0,1,0,0,0,0,0.829817,4.0,0.74051,69
http://arxiv.org/abs/2004.09305v1,Joint Spatial-Temporal Optimization for Stereo 3D Object Tracking,15,0.207682,0.555632,"Directly learning multiple 3D objects motion from sequential images is
difficult, while the geometric bundle adjustment lacks the ability to localize
the invisible object centroid. To benefit from both the powerful object
understanding skill from deep neural network meanwhile tackle precise geometry
modeling for consistent trajectory estimation, we propose a joint
spatial-temporal optimization-based stereo 3D object tracking method. From the
network, we detect corresponding 2D bounding boxes on adjacent images and
regress an initial 3D bounding box. Dense object cues (local depth and local
coordinates) that associating to the object centroid are then predicted using a
region-based network. Considering both the instant localization accuracy and
motion consistency, our optimization models the relations between the object
centroid and observed cues into a joint spatial-temporal error function. All
historic cues will be summarized to contribute to the current estimation by a
per-frame marginalization strategy without repeated computation. Quantitative
evaluation on the KITTI tracking dataset shows our approach outperforms
previous image-based 3D tracking methods by significant margins. We also report
extensive results on multiple categories and larger datasets (KITTI raw and
Argoverse Tracking) for future benchmarking.",0,1,0,0,1,0,0.975083,5.0,0.939357,54
http://arxiv.org/abs/2012.04169v1,Improving Human-Labeled Data through Dynamic Automatic Conflict Resolution,10,0.147462,0.385633,"This paper develops and implements a scalable methodology for (a) estimating
the noisiness of labels produced by a typical crowdsourcing semantic annotation
task, and (b) reducing the resulting error of the labeling process by as much
as 20-30% in comparison to other common labeling strategies. Importantly, this
new approach to the labeling process, which we name Dynamic Automatic Conflict
Resolution (DACR), does not require a ground truth dataset and is instead based
on inter-project annotation inconsistencies. This makes DACR not only more
accurate but also available to a broad range of labeling tasks. In what follows
we present results from a text classification task performed at scale for a
commercial personal assistant, and evaluate the inherent ambiguity uncovered by
this annotation strategy as compared to other common labeling strategies.",0,1,0,0,0,1,0.0793171,17.0,0.758664,40
http://arxiv.org/abs/2011.05257v1,Medical Knowledge-enriched Textual Entailment Framework,7,0.0850517,0.0901526,"One of the cardinal tasks in achieving robust medical question answering
systems is textual entailment. The existing approaches make use of an ensemble
of pre-trained language models or data augmentation, often to clock higher
numbers on the validation metrics. However, two major shortcomings impede
higher success in identifying entailment: (1) understanding the focus/intent of
the question and (2) ability to utilize the real-world background knowledge to
capture the context beyond the sentence. In this paper, we present a novel
Medical Knowledge-Enriched Textual Entailment framework that allows the model
to acquire a semantic and global representation of the input medical text with
the help of a relevant domain-specific knowledge graph. We evaluate our
framework on the benchmark MEDIQA-RQE dataset and manifest that the use of
knowledge enriched dual-encoding mechanism help in achieving an absolute
improvement of 8.27% over SOTA language models. We have made the source code
available here.",1,1,0,0,1,0,0.693897,4.0,0.63983,27
http://arxiv.org/abs/2006.14135v2,Explainable CNN-attention Networks (C-Attention Network) for Automated Detection of Alzheimer's Disease,20,0.415922,0.292744,"In this work, we propose three explainable deep learning architectures to
automatically detect patients with Alzheimer`s disease based on their language
abilities. The architectures use: (1) only the part-of-speech features; (2)
only language embedding features and (3) both of these feature classes via a
unified architecture. We use self-attention mechanisms and interpretable
1-dimensional ConvolutionalNeural Network (CNN) to generate two types of
explanations of the model`s action: intra-class explanation and inter-class
explanation. The inter-class explanation captures the relative importance of
each of the different features in that class, while the inter-class explanation
captures the relative importance between the classes. Note that although we
have considered two classes of features in this paper, the architecture is
easily expandable to more classes because of its modularity. Extensive
experimentation and comparison with several recent models show that our method
outperforms these methods with an accuracy of 92.2% and F1 score of 0.952on the
DementiaBank dataset while being able to generate explanations. We show by
examples, how to generate these explanations using attention values.",0,1,0,0,1,0,0.90288,8.0,0.904651,46
http://arxiv.org/abs/2010.02523v1,Multi-task Learning for Multilingual Neural Machine Translation,63,0.244495,0.8939,"While monolingual data has been shown to be useful in improving bilingual
neural machine translation (NMT), effectively and efficiently leveraging
monolingual data for Multilingual NMT (MNMT) systems is a less explored area.
In this work, we propose a multi-task learning (MTL) framework that jointly
trains the model with the translation task on bitext data and two denoising
tasks on the monolingual data. We conduct extensive empirical studies on MNMT
systems with 10 language pairs from WMT datasets. We show that the proposed
approach can effectively improve the translation quality for both high-resource
and low-resource languages with large margin, achieving significantly better
results than the individual bilingual models. We also demonstrate the efficacy
of the proposed approach in the zero-shot setup for language pairs without
bitext training data. Furthermore, we show the effectiveness of MTL over
pre-training approaches for both NMT and cross-lingual transfer learning NLU
tasks; the proposed approach outperforms massive scale models trained on single
task.",0,1,0,0,0,0,0.679431,7.0,0.788505,56
http://arxiv.org/abs/2011.08785v1,PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization,539,0.867466,0.999994,"We present a new framework for Patch Distribution Modeling, PaDiM, to
concurrently detect and localize anomalies in images in a one-class learning
setting. PaDiM makes use of a pretrained convolutional neural network (CNN) for
patch embedding, and of multivariate Gaussian distributions to get a
probabilistic representation of the normal class. It also exploits correlations
between the different semantic levels of CNN to better localize anomalies.
PaDiM outperforms current state-of-the-art approaches for both anomaly
detection and localization on the MVTec AD and STC datasets. To match
real-world visual industrial inspection, we extend the evaluation protocol to
assess performance of anomaly localization algorithms on non-aligned dataset.
The state-of-the-art performance and low complexity of PaDiM make it a good
candidate for many industrial applications.",0,1,0,0,1,0,0.863313,4.0,0.769682,32
http://arxiv.org/abs/2010.02605v2,DaNetQA: a yes/no Question Answering Dataset for the Russian Language,10,0.0171338,0.0936418,"DaNetQA, a new question-answering corpus, follows (Clark et. al, 2019)
design: it comprises natural yes/no questions. Each question is paired with a
paragraph from Wikipedia and an answer, derived from the paragraph. The task is
to take both the question and a paragraph as input and come up with a yes/no
answer, i.e. to produce a binary output. In this paper, we present a
reproducible approach to DaNetQA creation and investigate transfer learning
methods for task and language transferring. For task transferring we leverage
three similar sentence modelling tasks: 1) a corpus of paraphrases,
Paraphraser, 2) an NLI task, for which we use the Russian part of XNLI, 3)
another question answering task, SberQUAD. For language transferring we use
English to Russian translation together with multilingual language fine-tuning.",1,1,1,1,0,0,0.37213,5.0,0.52515,25
http://arxiv.org/abs/2008.07792v2,ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for Mobile Manipulation,72,0.672141,0.99125,"Many Reinforcement Learning (RL) approaches use joint control signals
(positions, velocities, torques) as action space for continuous control tasks.
We propose to lift the action space to a higher level in the form of subgoals
for a motion generator (a combination of motion planner and trajectory
executor). We argue that, by lifting the action space and by leveraging
sampling-based motion planners, we can efficiently use RL to solve complex,
long-horizon tasks that could not be solved with existing RL methods in the
original action space. We propose ReLMoGen -- a framework that combines a
learned policy to predict subgoals and a motion generator to plan and execute
the motion needed to reach these subgoals. To validate our method, we apply
ReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation
problems where interactions with the environment are required to reach the
destination, and 2) Mobile Manipulation tasks, manipulation tasks that require
moving the robot base. These problems are challenging because they are usually
long-horizon, hard to explore during training, and comprise alternating phases
of navigation and interaction. Our method is benchmarked on a diverse set of
seven robotics tasks in photo-realistic simulation environments. In all
settings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and
Hierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding
transferability between different motion generators at test time, indicating a
great potential to transfer to real robots.",0,1,0,0,1,0,0.906995,5.0,0.851121,59
http://arxiv.org/abs/2004.14065v2,Automatically Identifying Gender Issues in Machine Translation using Perturbations,33,0.0557181,0.4281,"The successful application of neural methods to machine translation has
realized huge quality advances for the community. With these improvements, many
have noted outstanding challenges, including the modeling and treatment of
gendered language. While previous studies have identified issues using
synthetic examples, we develop a novel technique to mine examples from real
world data to explore challenges for deployed systems. We use our method to
compile an evaluation benchmark spanning examples for four languages from three
language families, which we publicly release to facilitate research. The
examples in our benchmark expose where model representations are gendered, and
the unintended consequences these gendered representations can have in
downstream application.",0,1,0,1,0,0,0.557962,4.0,0.546916,15
http://arxiv.org/abs/2010.02830v1,PRover: Proof Generation for Interpretable Reasoning over Rules,72,0.269577,0.998208,"Recent work by Clark et al. (2020) shows that transformers can act as 'soft
theorem provers' by answering questions over explicitly provided knowledge in
natural language. In our work, we take a step closer to emulating formal
theorem provers, by proposing PROVER, an interpretable transformer-based model
that jointly answers binary questions over rule-bases and generates the
corresponding proofs. Our model learns to predict nodes and edges corresponding
to proof graphs in an efficient constrained training paradigm. During
inference, a valid proof, satisfying a set of global constraints is generated.
We conduct experiments on synthetic, hand-authored, and human-paraphrased
rule-bases to show promising results for QA and proof generation, with strong
generalization performance. First, PROVER generates proofs with an accuracy of
87%, while retaining or improving performance on the QA task, compared to
RuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trained
on questions requiring lower depths of reasoning, it generalizes significantly
better to higher depths (up to 15% improvement). Third, PROVER obtains near
perfect QA accuracy of 98% using only 40% of the training data. However,
generating proofs for questions requiring higher depths of reasoning becomes
challenging, and the accuracy drops to 65% for 'depth 5', indicating
significant scope for future work. Our code and models are publicly available
at https://github.com/swarnaHub/PRover",1,0,0,0,0,0,0.603414,5.0,0.662491,49
http://arxiv.org/abs/2009.02780v1,UPB at SemEval-2020 Task 9: Identifying Sentiment in Code-Mixed Social Media Texts using Transformers and Multi-Task Learning,9,0.0958644,0.330586,"Sentiment analysis is a process widely used in opinion mining campaigns
conducted today. This phenomenon presents applications in a variety of fields,
especially in collecting information related to the attitude or satisfaction of
users concerning a particular subject. However, the task of managing such a
process becomes noticeably more difficult when it is applied in cultures that
tend to combine two languages in order to express ideas and thoughts. By
interleaving words from two languages, the user can express with ease, but at
the cost of making the text far less intelligible for those who are not
familiar with this technique, but also for standard opinion mining algorithms.
In this paper, we describe the systems developed by our team for SemEval-2020
Task 9 that aims to cover two well-known code-mixed languages: Hindi-English
and Spanish-English.
  We intend to solve this issue by introducing a solution that takes advantage
of several neural network approaches, as well as pre-trained word embeddings.
Our approach (multlingual BERT) achieves promising performance on the
Hindi-English task, with an average F1-score of 0.6850, registered on the
competition leaderboard, ranking our team 16th out of 62 participants. For the
Spanish-English task, we obtained an average F1-score of 0.7064 ranking our
team 17th out of 29 participants by using another multilingual
Transformer-based model, XLM-RoBERTa.",0,1,0,0,0,0,0.578466,7.0,0.749173,27
http://arxiv.org/abs/2009.04346v1,A Methodological Approach to Model CBR-based Systems,2,0.014355,0.111915,"Artificial intelligence (AI) has been used in various areas to support system
optimization and find solutions where the complexity makes it challenging to
use algorithmic and heuristics. Case-based Reasoning (CBR) is an AI technique
intensively exploited in domains like management, medicine, design,
construction, retail and smart grid. CBR is a technique for problem-solving and
captures new knowledge by using past experiences. One of the main CBR
deployment challenges is the target system modeling process. This paper
presents a straightforward methodological approach to model CBR-based
applications using the concepts of abstract and concrete models. Splitting the
modeling process with two models facilitates the allocation of expertise
between the application domain and the CBR technology. The methodological
approach intends to facilitate the CBR modeling process and to foster CBR use
in various areas outside computer science.",0,1,0,0,0,1,0.175864,5.0,0.349533,32
http://arxiv.org/abs/2005.07897v1,Glottal Source Estimation using an Automatic Chirp Decomposition,7,0.0171452,0.152803,"In a previous work, we showed that the glottal source can be estimated from
speech signals by computing the Zeros of the Z-Transform (ZZT). Decomposition
was achieved by separating the roots inside (causal contribution) and outside
(anticausal contribution) the unit circle. In order to guarantee a correct
deconvolution, time alignment on the Glottal Closure Instants (GCIs) was shown
to be essential. This paper extends the formalism of ZZT by evaluating the
Z-transform on a contour possibly different from the unit circle. A method is
proposed for determining automatically this contour by inspecting the root
distribution. The derived Zeros of the Chirp Z-Transform (ZCZT)-based technique
turns out to be much more robust to GCI location errors.",0,1,0,0,0,0,1.85607e-06,20.0,0.259676,20
http://arxiv.org/abs/2005.06821v1,A Semi-Supervised Assessor of Neural Architectures,58,0.211374,0.660491,"Neural architecture search (NAS) aims to automatically design deep neural
networks of satisfactory performance. Wherein, architecture performance
predictor is critical to efficiently value an intermediate neural architecture.
But for the training of this predictor, a number of neural architectures and
their corresponding real performance often have to be collected. In contrast
with classical performance predictor optimized in a fully supervised way, this
paper suggests a semi-supervised assessor of neural architectures. We employ an
auto-encoder to discover meaningful representations of neural architectures.
Taking each neural architecture as an individual instance in the search space,
we construct a graph to capture their intrinsic similarities, where both
labeled and unlabeled architectures are involved. A graph convolutional neural
network is introduced to predict the performance of architectures based on the
learned representations and their relation modeled by the graph. Extensive
experimental results on the NAS-Benchmark-101 dataset demonstrated that our
method is able to make a significant reduction on the required fully trained
architectures for finding efficient architectures.",0,0,0,0,0,0,0.761347,5.0,0.750031,54
http://arxiv.org/abs/2009.14178v1,Robust Detection of Objects under Periodic Motion with Gaussian Process Filtering,5,0.00437924,0.0350484,"Object Detection (OD) is an important task in Computer Vision with many
practical applications. For some use cases, OD must be done on videos, where
the object of interest has a periodic motion. In this paper, we formalize the
problem of periodic OD, which consists in improving the performance of an OD
model in the specific case where the object of interest is repeating similar
spatio-temporal trajectories with respect to the video frames. The proposed
approach is based on training a Gaussian Process to model the periodic motion,
and use it to filter out the erroneous predictions of the OD model. By
simulating various OD models and periodic trajectories, we demonstrate that
this filtering approach, which is entirely data-driven, improves the detection
performance by a large margin.",0,1,0,0,0,0,0.101341,7.0,0.450608,25
http://arxiv.org/abs/2007.05225v1,Miss the Point: Targeted Adversarial Attack on Multiple Landmark Detection,29,0.284019,0.362101,"Recent methods in multiple landmark detection based on deep convolutional
neural networks (CNNs) reach high accuracy and improve traditional clinical
workflow. However, the vulnerability of CNNs to adversarial-example attacks can
be easily exploited to break classification and segmentation tasks. This paper
is the first to study how fragile a CNN-based model on multiple landmark
detection to adversarial perturbations. Specifically, we propose a novel
Adaptive Targeted Iterative FGSM (ATI-FGSM) attack against the state-of-the-art
models in multiple landmark detection. The attacker can use ATI-FGSM to
precisely control the model predictions of arbitrarily selected landmarks,
while keeping other stationary landmarks still, by adding imperceptible
perturbations to the original image. A comprehensive evaluation on a public
dataset for cephalometric landmark detection demonstrates that the adversarial
examples generated by ATI-FGSM break the CNN-based network more effectively and
efficiently, compared with the original Iterative FGSM attack. Our work reveals
serious threats to patients' health. Furthermore, we discuss the limitations of
our method and provide potential defense directions, by investigating the
coupling effect of nearby landmarks, i.e., a major source of divergence in our
experiments. Our source code is available at
https://github.com/qsyao/attack_landmark_detection.",1,1,0,0,1,0,0.409543,8.0,0.718717,32
http://arxiv.org/abs/2009.12065v1,Design and Implementation of TAG: A Tabletop Games Framework,8,0.172114,0.598455,"This document describes the design and implementation of the Tabletop Games
framework (TAG), a Java-based benchmark for developing modern board games for
AI research. TAG provides a common skeleton for implementing tabletop games
based on a common API for AI agents, a set of components and classes to easily
add new games and an import module for defining data in JSON format. At
present, this platform includes the implementation of seven different tabletop
games that can also be used as an example for further developments.
Additionally, TAG also incorporates logging functionality that allows the user
to perform a detailed analysis of the game, in terms of action space, branching
factor, hidden information, and other measures of interest for Game AI
research. The objective of this document is to serve as a central point where
the framework can be described at length. TAG can be downloaded at:
https://github.com/GAIGResearch/TabletopGames",0,1,0,0,0,0,0.0310698,12.0,0.577899,14
http://arxiv.org/abs/2006.08173v3,Neural gradients are near-lognormal: improved quantized and sparse training,34,0.0199759,0.192381,"While training can mostly be accelerated by reducing the time needed to
propagate neural gradients back throughout the model, most previous works focus
on the quantization/pruning of weights and activations. These methods are often
not applicable to neural gradients, which have very different statistical
properties. Distinguished from weights and activations, we find that the
distribution of neural gradients is approximately lognormal. Considering this,
we suggest two closed-form analytical methods to reduce the computational and
memory burdens of neural gradients. The first method optimizes the
floating-point format and scale of the gradients. The second method accurately
sets sparsity thresholds for gradient pruning. Each method achieves
state-of-the-art results on ImageNet. To the best of our knowledge, this paper
is the first to (1) quantize the gradients to 6-bit floating-point formats, or
(2) achieve up to 85% gradient sparsity -- in each case without accuracy
degradation. Reference implementation accompanies the paper.",0,1,0,0,1,0,0.137278,5.0,0.295547,37
http://arxiv.org/abs/2006.14953v2,What they do when in doubt: a study of inductive biases in seq2seq learners,21,0.105003,0.25709,"Sequence-to-sequence (seq2seq) learners are widely used, but we still have
only limited knowledge about what inductive biases shape the way they
generalize. We address that by investigating how popular seq2seq learners
generalize in tasks that have high ambiguity in the training data. We use SCAN
and three new tasks to study learners' preferences for memorization,
arithmetic, hierarchical, and compositional reasoning. Further, we connect to
Solomonoff's theory of induction and propose to use description length as a
principled and sensitive measure of inductive biases.
  In our experimental study, we find that LSTM-based learners can learn to
perform counting, addition, and multiplication by a constant from a single
training example. Furthermore, Transformer and LSTM-based learners show a bias
toward the hierarchical induction over the linear one, while CNN-based learners
prefer the opposite. On the SCAN dataset, we find that CNN-based, and, to a
lesser degree, Transformer- and LSTM-based learners have a preference for
compositional generalization over memorization. Finally, across all our
experiments, description length proved to be a sensitive measure of inductive
biases.",1,0,0,0,0,0,0.713794,5.0,0.722908,54
http://arxiv.org/abs/2004.00306v1,Towards Achieving Adversarial Robustness by Enforcing Feature Consistency Across Bit Planes,29,0.113171,0.384342,"As humans, we inherently perceive images based on their predominant features,
and ignore noise embedded within lower bit planes. On the contrary, Deep Neural
Networks are known to confidently misclassify images corrupted with
meticulously crafted perturbations that are nearly imperceptible to the human
eye. In this work, we attempt to address this problem by training networks to
form coarse impressions based on the information in higher bit planes, and use
the lower bit planes only to refine their prediction. We demonstrate that, by
imposing consistency on the representations learned across differently
quantized images, the adversarial robustness of networks improves significantly
when compared to a normally trained model. Present state-of-the-art defenses
against adversarial attacks require the networks to be explicitly trained using
adversarial samples that are computationally expensive to generate. While such
methods that use adversarial training continue to achieve the best results,
this work paves the way towards achieving robustness without having to
explicitly train on adversarial samples. The proposed approach is therefore
faster, and also closer to the natural learning process in humans.",1,1,0,0,0,0,0.8965,6.0,0.868257,44
http://arxiv.org/abs/2003.05856v3,Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning,60,0.416195,0.284279,"Continual learning studies agents that learn from streams of tasks without
forgetting previous ones while adapting to new ones. Two recent
continual-learning scenarios have opened new avenues of research. In
meta-continual learning, the model is pre-trained to minimize catastrophic
forgetting of previous tasks. In continual-meta learning, the aim is to train
agents for faster remembering of previous tasks through adaptation. In their
original formulations, both methods have limitations. We stand on their
shoulders to propose a more general scenario, OSAKA, where an agent must
quickly solve new (out-of-distribution) tasks, while also requiring fast
remembering. We show that current continual learning, meta-learning,
meta-continual learning, and continual-meta learning techniques fail in this
new scenario. We propose Continual-MAML, an online extension of the popular
MAML algorithm as a strong baseline for this scenario. We empirically show that
Continual-MAML is better suited to the new scenario than the aforementioned
methodologies, as well as standard continual learning and meta-learning
approaches.",1,0,0,0,0,0,0.920843,4.0,0.830319,84
http://arxiv.org/abs/2005.04511v2,Finding Universal Grammatical Relations in Multilingual BERT,134,0.531474,0.698268,"Recent work has found evidence that Multilingual BERT (mBERT), a
transformer-based multilingual masked language model, is capable of zero-shot
cross-lingual transfer, suggesting that some aspects of its representations are
shared cross-lingually. To better understand this overlap, we extend recent
work on finding syntactic trees in neural networks' internal representations to
the multilingual setting. We show that subspaces of mBERT representations
recover syntactic tree distances in languages other than English, and that
these subspaces are approximately shared across languages. Motivated by these
results, we present an unsupervised analysis method that provides evidence
mBERT learns representations of syntactic dependency labels, in the form of
clusters which largely agree with the Universal Dependencies taxonomy. This
evidence suggests that even without explicit supervision, multilingual masked
language models learn certain linguistic universals.",1,0,0,0,0,0,0.963243,2.0,0.79276,33
http://arxiv.org/abs/2001.06570v3,Harmonic Convolutional Networks based on Discrete Cosine Transform,25,0.0221222,0.199358,"Convolutional neural networks (CNNs) learn filters in order to capture local
correlation patterns in feature space. We propose to learn these filters as
combinations of preset spectral filters defined by the Discrete Cosine
Transform (DCT). Our proposed DCT-based harmonic blocks replace conventional
convolutional layers to produce partially or fully harmonic versions of new or
existing CNN architectures. Using DCT energy compaction properties, we
demonstrate how the harmonic networks can be efficiently compressed by
truncating high-frequency information in harmonic blocks thanks to the
redundancies in the spectral domain. We report extensive experimental
validation demonstrating benefits of the introduction of harmonic blocks into
state-of-the-art CNN models in image classification, object detection and
semantic segmentation applications.",0,0,0,0,0,0,0.124169,7.0,0.48143,77
http://arxiv.org/abs/2011.09867v1,Exercise Hierarchical Feature Enhanced Knowledge Tracing,13,0.203766,0.354164,"Knowledge tracing is a fundamental task in the computer-aid educational
system. In this paper, we propose a hierarchical exercise feature enhanced
knowledge tracing framework, which could enhance the ability of knowledge
tracing by incorporating knowledge distribution, semantic features, and
difficulty features from exercise text. Extensive experiments show the high
performance of our framework.",0,1,0,0,0,0,0.418889,23.0,0.90346,10
http://arxiv.org/abs/2012.08117v1,"Writing Polishment with Simile: Task, Dataset and A Neural Approach",16,0.0595053,0.304925,"A simile is a figure of speech that directly makes a comparison, showing
similarities between two different things, e.g. ""Reading papers can be dull
sometimes,like watching grass grow"". Human writers often interpolate
appropriate similes into proper locations of the plain text to vivify their
writings. However, none of existing work has explored neural simile
interpolation, including both locating and generation. In this paper, we
propose a new task of Writing Polishment with Simile (WPS) to investigate
whether machines are able to polish texts with similes as we human do.
Accordingly, we design a two-staged Locate&Gen model based on transformer
architecture. Our model firstly locates where the simile interpolation should
happen, and then generates a location-specific simile. We also release a
large-scale Chinese Simile (CS) dataset containing 5 million similes with
context. The experimental results demonstrate the feasibility of WPS task and
shed light on the future research directions towards better automatic text
polishment.",1,0,1,1,0,0,0.586633,4.0,0.566651,44
http://arxiv.org/abs/2008.12842v1,HeteGCN: Heterogeneous Graph Convolutional Networks for Text Classification,70,0.342981,0.659824,"We consider the problem of learning efficient and inductive graph
convolutional networks for text classification with a large number of examples
and features. Existing state-of-the-art graph embedding based methods such as
predictive text embedding (PTE) and TextGCN have shortcomings in terms of
predictive performance, scalability and inductive capability. To address these
limitations, we propose a heterogeneous graph convolutional network (HeteGCN)
modeling approach that unites the best aspects of PTE and TextGCN together. The
main idea is to learn feature embeddings and derive document embeddings using a
HeteGCN architecture with different graphs used across layers. We simplify
TextGCN by dissecting into several HeteGCN models which (a) helps to study the
usefulness of individual models and (b) offers flexibility in fusing learned
embeddings from different models. In effect, the number of model parameters is
reduced significantly, enabling faster training and improving performance in
small labeled training set scenario. Our detailed experimental studies
demonstrate the efficacy of the proposed approach.",1,1,0,0,0,0,0.833035,12.0,0.914397,40
http://arxiv.org/abs/2010.10894v1,Learning to Decouple Relations: Few-Shot Relation Classification with Entity-Guided Attention and Confusion-Aware Training,34,0.291309,0.658722,"This paper aims to enhance the few-shot relation classification especially
for sentences that jointly describe multiple relations. Due to the fact that
some relations usually keep high co-occurrence in the same context, previous
few-shot relation classifiers struggle to distinguish them with few annotated
instances. To alleviate the above relation confusion problem, we propose CTEG,
a model equipped with two mechanisms to learn to decouple these easily-confused
relations. On the one hand, an Entity-Guided Attention (EGA) mechanism, which
leverages the syntactic relations and relative positions between each word and
the specified entity pair, is introduced to guide the attention to filter out
information causing confusion. On the other hand, a Confusion-Aware Training
(CAT) method is proposed to explicitly learn to distinguish relations by
playing a pushing-away game between classifying a sentence into a true relation
and its confusing relation. Extensive experiments are conducted on the FewRel
dataset, and the results show that our proposed model achieves comparable and
even much better results to strong baselines in terms of accuracy. Furthermore,
the ablation test and case study verify the effectiveness of our proposed EGA
and CAT, especially in addressing the relation confusion problem.",0,1,0,0,0,0,0.612729,7.0,0.762546,29
http://arxiv.org/abs/2001.11841v2,Learning Perception and Planning with Deep Active Inference,29,0.303195,0.267571,"Active inference is a process theory of the brain that states that all living
organisms infer actions in order to minimize their (expected) free energy.
However, current experiments are limited to predefined, often discrete, state
spaces. In this paper we use recent advances in deep learning to learn the
state space and approximate the necessary probability distributions to engage
in active inference.",0,0,0,0,0,0,0.263526,13.0,0.785077,12
http://arxiv.org/abs/2006.11376v1,StressGAN: A Generative Deep Learning Model for 2D Stress Distribution Prediction,17,0.617052,0.798396,"Using deep learning to analyze mechanical stress distributions has been
gaining interest with the demand for fast stress analysis methods. Deep
learning approaches have achieved excellent outcomes when utilized to speed up
stress computation and learn the physics without prior knowledge of underlying
equations. However, most studies restrict the variation of geometry or boundary
conditions, making these methods difficult to be generalized to unseen
configurations. We propose a conditional generative adversarial network (cGAN)
model for predicting 2D von Mises stress distributions in solid structures. The
cGAN learns to generate stress distributions conditioned by geometries, load,
and boundary conditions through a two-player minimax game between two neural
networks with no prior knowledge. By evaluating the generative network on two
stress distribution datasets under multiple metrics, we demonstrate that our
model can predict more accurate high-resolution stress distributions than a
baseline convolutional neural network model, given various and complex cases of
geometry, load and boundary conditions.",0,1,0,1,0,0,0.92383,7.0,0.90519,50
http://arxiv.org/abs/2009.02649v1,Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality,18,0.109805,0.35284,"Causality visualization can help people understand temporal chains of events,
such as messages sent in a distributed system, cause and effect in a historical
conflict, or the interplay between political actors over time. However, as the
scale and complexity of these event sequences grows, even these visualizations
can become overwhelming to use. In this paper, we propose the use of textual
narratives as a data-driven storytelling method to augment causality
visualization. We first propose a design space for how textual narratives can
be used to describe causal data. We then present results from a crowdsourced
user study where participants were asked to recover causality information from
two causality visualizations--causal graphs and Hasse diagrams--with and
without an associated textual narrative. Finally, we describe CAUSEWORKS, a
causality visualization system for understanding how specific interventions
influence a causal model. The system incorporates an automatic textual
narrative mechanism based on our design space. We validate CAUSEWORKS through
interviews with experts who used the system for understanding complex events.",0,0,0,0,0,0,0.00616592,16.0,0.581558,68
http://arxiv.org/abs/2010.03738v1,Multi-hop Inference for Question-driven Summarization,20,0.120915,0.471222,"Question-driven summarization has been recently studied as an effective
approach to summarizing the source document to produce concise but informative
answers for non-factoid questions. In this work, we propose a novel
question-driven abstractive summarization method, Multi-hop Selective Generator
(MSG), to incorporate multi-hop reasoning into question-driven summarization
and, meanwhile, provide justifications for the generated summaries.
Specifically, we jointly model the relevance to the question and the
interrelation among different sentences via a human-like multi-hop inference
module, which captures important sentences for justifying the summarized
answer. A gated selective pointer generator network with a multi-view coverage
mechanism is designed to integrate diverse information from different
perspectives. Experimental results show that the proposed method consistently
outperforms state-of-the-art methods on two non-factoid QA datasets, namely
WikiHow and PubMedQA.",0,0,0,0,1,0,0.0861687,8.0,0.497979,37
http://arxiv.org/abs/2011.05103v1,Does Social Support Expressed in Post Titles Elicit Comments in Online Substance Use Recovery Forums?,9,0.292705,0.581454,"Individuals recovering from substance use often seek social support
(emotional and informational) on online recovery forums, where they can both
write and comment on posts, expressing their struggles and successes. A common
challenge in these forums is that certain posts (some of which may be support
seeking) receive no comments. In this work, we use data from two Reddit
substance recovery forums:/r/Leaves and/r/OpiatesRecovery, to determine the
relationship between the social supports expressed in the titles of posts and
the number of comments they receive. We show that the types of social support
expressed in post titles that elicit comments vary from one substance use
recovery forum to the other.",0,1,0,0,0,0,0.844854,11.0,0.910269,20
http://arxiv.org/abs/2003.00575v2,FLIC: Fast Lidar Image Clustering,10,0.122025,0.270581,"Lidar sensors are widely used in various applications, ranging from
scientific fields over industrial use to integration in consumer products. With
an ever growing number of different driver assistance systems, they have been
introduced to automotive series production in recent years and are considered
an important building block for the practical realisation of autonomous
driving. However, due to the potentially large amount of Lidar points per scan,
tailored algorithms are required to identify objects (e.g. pedestrians or
vehicles) with high precision in a very short time. In this work, we propose an
algorithmic approach for real-time instance segmentation of Lidar sensor data.
We show how our method leverages the properties of the Euclidean distance to
retain three-dimensional measurement information, while being narrowed down to
a two-dimensional representation for fast computation. We further introduce
what we call ""skip connections"", to make our approach robust against
over-segmentation and improve assignment in cases of partial occlusion. Through
detailed evaluation on public data and comparison with established methods, we
show how these aspects enable state-of-the-art performance and runtime on a
single CPU core.",0,1,0,0,1,0,0.71081,4.0,0.651554,38
http://arxiv.org/abs/2012.05107v1,Towards Zero-shot Cross-lingual Image Retrieval,17,0.277548,0.413608,"There has been a recent spike in interest in multi-modal Language and Vision
problems. On the language side, most of these models primarily focus on English
since most multi-modal datasets are monolingual. We try to bridge this gap with
a zero-shot approach for learning multi-modal representations using
cross-lingual pre-training on the text side. We present a simple yet practical
approach for building a cross-lingual image retrieval model which trains on a
monolingual training dataset but can be used in a zero-shot cross-lingual
fashion during inference. We also introduce a new objective function which
tightens the text embedding clusters by pushing dissimilar texts from each
other. Finally, we introduce a new 1K multi-lingual MSCOCO2014 caption test
dataset (XTD10) in 7 languages that we collected using a crowdsourcing
platform. We use this as the test set for evaluating zero-shot model
performance across languages. XTD10 dataset is made publicly available here:
https://github.com/adobe-research/Cross-lingual-Test-Dataset-XTD10",1,1,1,1,0,0,0.579781,8.0,0.780978,38
http://arxiv.org/abs/2011.10640v1,Assessment and Linear Programming under Fuzzy Conditions,5,0.0699279,0.182675,"A new fuzzy method is developed using triangular/trapezoidal fuzzy numbers
for evaluating a group's mean performance, when qualitative grades instead of
numerical scores are used for assessing its members' individual performance.
Also, a new technique is developed for solving Linear Programming problems with
fuzzy coefficients and everyday life applications are presented to illustrate
our results.",0,0,0,0,0,0,0.00205899,30.0,0.740202,33
http://arxiv.org/abs/2008.00805v1,LT@Helsinki at SemEval-2020 Task 12: Multilingual or language-specific BERT?,10,0.22052,0.427187,"This paper presents the different models submitted by the LT@Helsinki team
for the SemEval 2020 Shared Task 12. Our team participated in sub-tasks A and
C; titled offensive language identification and offense target identification,
respectively. In both cases we used the so-called Bidirectional Encoder
Representation from Transformer (BERT), a model pre-trained by Google and
fine-tuned by us on the OLID and SOLID datasets. The results show that
offensive tweet classification is one of several language-based tasks where
BERT can achieve state-of-the-art results.",0,1,0,0,0,0,0.948967,5.0,0.89618,31
http://arxiv.org/abs/2001.04589v1,Faster Transformer Decoding: N-gram Masked Self-Attention,13,0.0657763,0.235103,"Motivated by the fact that most of the information relevant to the prediction
of target tokens is drawn from the source sentence $S=s_1, \ldots, s_S$, we
propose truncating the target-side window used for computing self-attention by
making an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show
that the $N$-gram masked self-attention model loses very little in BLEU score
for $N$ values in the range $4, \ldots, 8$, depending on the task.",0,1,0,0,0,0,0.761862,4.0,0.687915,8
http://arxiv.org/abs/2011.08820v1,REALab: An Embedded Perspective on Tampering,10,0.0138093,0.101919,"This paper describes REALab, a platform for embedded agency research in
reinforcement learning (RL). REALab is designed to model the structure of
tampering problems that may arise in real-world deployments of RL. Standard
Markov Decision Process (MDP) formulations of RL and simulated environments
mirroring the MDP structure assume secure access to feedback (e.g., rewards).
This may be unrealistic in settings where agents are embedded and can corrupt
the processes producing feedback (e.g., human supervisors, or an implemented
reward function). We describe an alternative Corrupt Feedback MDP formulation
and the REALab environment platform, which both avoid the secure feedback
assumption. We hope the design of REALab provides a useful perspective on
tampering problems, and that the platform may serve as a unit test for the
presence of tampering incentives in RL agent designs.",0,0,0,0,0,0,0.0443077,8.0,0.412067,87
http://arxiv.org/abs/2004.08541v1,Moire Image Restoration using Multi Level Hyper Vision Net,6,0.0543828,0.307467,"A moire pattern in the images is resulting from high frequency patterns
captured by the image sensor (colour filter array) that appear after
demosaicing. These Moire patterns would appear in natural images of scenes with
high frequency content. The Moire pattern can also vary intensely due to a
minimal change in the camera direction/positioning. Thus the Moire pattern
depreciates the quality of photographs. An important issue in demoireing
pattern is that the Moireing patterns have dynamic structure with varying
colors and forms. These challenges makes the demoireing more difficult than
many other image restoration tasks. Inspired by these challenges in demoireing,
a multilevel hyper vision net is proposed to remove the Moire pattern to
improve the quality of the images. As a key aspect, in this network we involved
residual channel attention block that can be used to extract and adaptively
fuse hierarchical features from all the layers efficiently. The proposed
algorithms has been tested with the NTIRE 2020 challenge dataset and thus
achieved 36.85 and 0.98 Peak to Signal Noise Ratio (PSNR) and Structural
Similarity (SSIM) Index respectively.",0,1,0,0,0,0,0.450984,9.0,0.764346,29
http://arxiv.org/abs/2006.05443v2,Variational Model-based Policy Optimization,9,0.0330458,0.164592,"Model-based reinforcement learning (RL) algorithms allow us to combine
model-generated data with those collected from interaction with the real system
in order to alleviate the data efficiency problem in RL. However, designing
such algorithms is often challenging because the bias in simulated data may
overshadow the ease of data generation. A potential solution to this challenge
is to jointly learn and improve model and policy using a universal objective
function. In this paper, we leverage the connection between RL and
probabilistic inference, and formulate such an objective function as a
variational lower-bound of a log-likelihood. This allows us to use expectation
maximization (EM) and iteratively fix a baseline policy and learn a variational
distribution, consisting of a model and a policy (E-step), followed by
improving the baseline policy given the learned variational distribution
(M-step). We propose model-based and model-free policy iteration (actor-critic)
style algorithms for the E-step and show how the variational distribution
learned by them can be used to optimize the M-step in a fully model-based
fashion. Our experiments on a number of continuous control tasks show that
despite being more complex, our model-based (E-step) algorithm, called {\em
variational model-based policy optimization} (VMBPO), is more sample-efficient
and robust to hyper-parameter tuning than its model-free (E-step) counterpart.
Using the same control tasks, we also compare VMBPO with several
state-of-the-art model-based and model-free RL algorithms and show its sample
efficiency and performance.",0,0,0,0,0,0,0.0429967,13.0,0.635833,48
http://arxiv.org/abs/2010.02587v1,Dissecting Span Identification Tasks with Performance Prediction,14,0.207953,0.210094,"Span identification (in short, span ID) tasks such as chunking, NER, or
code-switching detection, ask models to identify and classify relevant spans in
a text. Despite being a staple of NLP, and sharing a common structure, there is
little insight on how these tasks' properties influence their difficulty, and
thus little guidance on what model families work well on span ID tasks, and
why. We analyze span ID tasks via performance prediction, estimating how well
neural architectures do on different tasks. Our contributions are: (a) we
identify key properties of span ID tasks that can inform performance
prediction; (b) we carry out a large-scale experiment on English data, building
a model to predict performance for unseen span ID tasks that can support
architecture choices; (c), we investigate the parameters of the meta model,
yielding new insights on how model and task properties interact to affect span
ID performance. We find, e.g., that span frequency is especially important for
LSTMs, and that CRFs help when spans are infrequent and boundaries
non-distinctive.",1,0,0,0,0,1,0.770781,12.0,0.89816,67
http://arxiv.org/abs/2011.07577v1,Placement in Integrated Circuits using Cyclic Reinforcement Learning and Simulated Annealing,23,0.577031,0.69846,"Physical design and production of Integrated Circuits (IC) is becoming
increasingly more challenging as the sophistication in IC technology is
steadily increasing. Placement has been one of the most critical steps in IC
physical design. Through decades of research, partition-based, analytical-based
and annealing-based placers have been enriching the placement solution toolbox.
However, open challenges including long run time and lack of ability to
generalize continue to restrict wider applications of existing placement tools.
We devise a learning-based placement tool based on cyclic application of
Reinforcement Learning (RL) and Simulated Annealing (SA) by leveraging the
advancement of RL. Results show that the RL module is able to provide a better
initialization for SA and thus leads to a better final placement design.
Compared to other recent learning-based placers, our method is majorly
different with its combination of RL and SA. It leverages the RL model's
ability to quickly get a good rough solution after training and the heuristic's
ability to realize greedy improvements in the solution.",0,1,0,0,0,0,0.302743,17.0,0.845328,22
http://arxiv.org/abs/2004.01792v1,Privacy-Preserving Eye Videos using Rubber Sheet Model,10,0.41194,0.506752,"Video-based eye trackers estimate gaze based on eye images/videos. As
security and privacy concerns loom over technological advancements, tackling
such challenges is crucial. We present a new approach to handle privacy issues
in eye videos by replacing the current identifiable iris texture with a
different iris template in the video capture pipeline based on the Rubber Sheet
Model. We extend to image blending and median-value representations to
demonstrate that videos can be manipulated without significantly degrading
segmentation and pupil detection accuracy.",0,1,0,0,0,0,0.96259,3.0,0.860059,26
http://arxiv.org/abs/2012.06363v1,Cyclopean Geometry of Binocular Vision,37,0.595136,0.375063,"The geometry of binocular projection is analyzed, with reference to the
primate visual system. In particular, the effects of coordinated eye movements
on the retinal images are investigated. An appropriate oculomotor
parameterization is defined, and is shown to complement the classical version
and vergence angles. The midline horopter is identified, and subsequently used
to construct the epipolar geometry of the system. It is shown that the
Essential matrix can be obtained by combining the epipoles with the projection
of the midline horopter. A local model of the scene is adopted, in which depth
is measured relative to a plane containing the fixation point. The binocular
disparity field is given a symmetric parameterization, in which the unknown
scene-depths determine the location of corresponding image-features. The
resulting Cyclopean depth-map can be combined with the estimated oculomotor
parameters, to produce a local representation of the scene. The recovery of
visual direction and depth from retinal images is discussed, with reference to
the relevant psychophysical and neurophysiological literature.",0,0,0,0,0,0,0.0469172,32.0,0.854848,63
http://arxiv.org/abs/2005.00163v1,Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization,48,0.496887,0.530504,"Sequence-to-sequence (seq2seq) network is a well-established model for text
summarization task. It can learn to produce readable content; however, it falls
short in effectively identifying key regions of the source. In this paper, we
approach the content selection problem for clinical abstractive summarization
by augmenting salient ontological terms into the summarizer. Our experiments on
two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and
3,366 reports of OpenI) show that our model statistically significantly boosts
state-of-the-art results in terms of Rouge metrics (with improvements: 2.9%
RG-1, 2.5% RG-2, 1.9% RG-L), in the healthcare domain where any range of
improvement impacts patients' welfare.",1,1,0,0,1,0,0.861392,4.0,0.767923,29
http://arxiv.org/abs/2012.13235v1,Detecting Hateful Memes Using a Multimodal Deep Ensemble,34,0.571171,0.76722,"While significant progress has been made using machine learning algorithms to
detect hate speech, important technical challenges still remain to be solved in
order to bring their performance closer to human accuracy. We investigate
several of the most recent visual-linguistic Transformer architectures and
propose improvements to increase their performance for this task. The proposed
model outperforms the baselines by a large margin and ranks 5$^{th}$ on the
leaderboard out of 3,100+ participants.",1,1,0,0,1,0,0.990875,3.0,0.979143,15
http://arxiv.org/abs/2002.03153v2,Majority Voting and the Condorcet's Jury Theorem,1,0.00189621,0.0143352,"There is a striking relationship between a three hundred years old Political
Science theorem named ""Condorcet's jury theorem"" (1785), which states that
majorities are more likely to choose correctly when individual votes are often
correct and independent, and a modern Machine Learning concept called ""Strength
of Weak Learnability"" (1990), which describes a method for converting a weak
learning algorithm into one that achieves arbitrarily high accuracy and stands
in the basis of Ensemble Learning. Albeit the intuitive statement of
Condorcet's theorem, we could not find a compact and simple rigorous
mathematical proof of the theorem neither in classical handbooks of Machine
Learning nor in published papers. By all means we do not claim to discover or
reinvent a theory nor a result. We humbly want to offer a more publicly
available simple derivation of the theorem. We will find joy in seeing more
teachers of introduction-to-machine-learning courses use the proof we provide
here as an exercise to explain the motivation of ensemble learning.",0,0,0,0,0,0,2.10346e-07,41.0,0.585757,15
http://arxiv.org/abs/2011.07274v2,On Filter Generalization for Music Bandwidth Extension Using Deep Neural Networks,20,0.269029,0.889531,"In this paper, we address a sub-topic of the broad domain of audio
enhancement, namely musical audio bandwidth extension. We formulate the
bandwidth extension problem using deep neural networks, where a band-limited
signal is provided as input to the network, with the goal of reconstructing a
full-bandwidth output. Our main contribution centers on the impact of the
choice of low pass filter when training and subsequently testing the network.
For two different state of the art deep architectures, ResNet and U-Net, we
demonstrate that when the training and testing filters are matched,
improvements in signal-to-noise ratio (SNR) of up to 7dB can be obtained.
However, when these filters differ, the improvement falls considerably and
under some training conditions results in a lower SNR than the band-limited
input. To circumvent this apparent overfitting to filter shape, we propose a
data augmentation strategy which utilizes multiple low pass filters during
training and leads to improved generalization to unseen filtering conditions at
test time.",0,1,0,0,0,0,0.216451,9.0,0.664406,67
http://arxiv.org/abs/2005.00652v3,An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction,83,0.475883,0.682003,"Decisions of complex language understanding models can be rationalized by
limiting their inputs to a relevant subsequence of the original text. A
rationale should be as concise as possible without significantly degrading task
performance, but this balance can be difficult to achieve in practice. In this
paper, we show that it is possible to better manage this trade-off by
optimizing a bound on the Information Bottleneck (IB) objective. Our fully
unsupervised approach jointly learns an explainer that predicts sparse binary
masks over sentences, and an end-task predictor that considers only the
extracted rationale. Using IB, we derive a learning objective that allows
direct control of mask sparsity levels through a tunable sparse prior.
Experiments on ERASER benchmark tasks demonstrate significant gains over
norm-minimization techniques for both task performance and agreement with human
rationales. Furthermore, we find that in the semi-supervised setting, a modest
amount of gold rationales (25% of training examples) closes the gap with a
model that uses the full input.",1,1,0,0,0,0,0.911844,3.0,0.759299,42
http://arxiv.org/abs/2001.11690v2,C-DLinkNet: considering multi-level semantic features for human parsing,3,0.0278707,0.0984739,"Human parsing is an essential branch of semantic segmentation, which is a
fine-grained semantic segmentation task to identify the constituent parts of
human. The challenge of human parsing is to extract effective semantic features
to resolve deformation and multi-scale variations. In this work, we proposed an
end-to-end model called C-DLinkNet based on LinkNet, which contains a new
module named Smooth Module to combine the multi-level features in Decoder part.
C-DLinkNet is capable of producing competitive parsing performance compared
with the state-of-the-art methods with smaller input sizes and no additional
information, i.e., achiving mIoU=53.05 on the validation set of LIP dataset.",0,1,0,0,1,0,0.917647,6.0,0.884258,22
http://arxiv.org/abs/2003.11756v1,The 1st Challenge on Remote Physiological Signal Sensing (RePSS),24,0.44905,0.788872,"Remote measurement of physiological signals from videos is an emerging topic.
The topic draws great interests, but the lack of publicly available benchmark
databases and a fair validation platform are hindering its further development.
For this concern, we organize the first challenge on Remote Physiological
Signal Sensing (RePSS), in which two databases of VIPL and OBF are provided as
the benchmark for kin researchers to evaluate their approaches. The 1st
challenge of RePSS focuses on measuring the average heart rate from facial
videos, which is the basic problem of remote physiological measurement. This
paper presents an overview of the challenge, including data, protocol, analysis
of results and discussion. The top ranked solutions are highlighted to provide
insights for researchers, and future directions are outlined for this topic and
this challenge.",0,1,1,1,0,0,0.947312,6.0,0.911686,25
http://arxiv.org/abs/2011.00980v1,3D Multi-bodies: Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data,56,0.411337,0.786824,"We consider the problem of obtaining dense 3D reconstructions of humans from
single and partially occluded views. In such cases, the visual evidence is
usually insufficient to identify a 3D reconstruction uniquely, so we aim at
recovering several plausible reconstructions compatible with the input data. We
suggest that ambiguities can be modelled more effectively by parametrizing the
possible body shapes and poses via a suitable 3D model, such as SMPL for
humans. We propose to learn a multi-hypothesis neural network regressor using a
best-of-M loss, where each of the M hypotheses is constrained to lie on a
manifold of plausible human poses by means of a generative model. We show that
our method outperforms alternative approaches in ambiguous pose recovery on
standard benchmarks for 3D humans, and in heavily occluded versions of these
benchmarks.",0,1,0,0,0,0,0.967491,7.0,0.946003,49
http://arxiv.org/abs/2011.07990v1,"The Person Index Challenge: Extraction of Persons from Messy, Short Texts",3,0.0403008,0.0650522,"When persons are mentioned in texts with their first name, last name and/or
middle names, there can be a high variation which of their names are used, how
their names are ordered and if their names are abbreviated. If multiple persons
are mentioned consecutively in very different ways, especially short texts can
be perceived as ""messy"". Once ambiguous names occur, associations to persons
may not be inferred correctly. Despite these eventualities, in this paper we
ask how well an unsupervised algorithm can build a person index from short
texts. We define a person index as a structured table that distinctly catalogs
individuals by their names. First, we give a formal definition of the problem
and describe a procedure to generate ground truth data for future evaluations.
To give a first solution to this challenge, a baseline approach is implemented.
By using our proposed evaluation strategy, we test the performance of the
baseline and suggest further improvements. For future research the source code
is publicly available.",0,0,0,0,0,0,0.0297058,17.0,0.699364,13
http://arxiv.org/abs/2012.15115v2,Joint Verification and Reranking for Open Fact Checking Over Tables,19,0.16509,0.536703,"Structured information is an important knowledge source for automatic
verification of factual claims. Nevertheless, the majority of existing research
into this task has focused on textual data, and the few recent inquiries into
structured data have been for the closed-domain setting where appropriate
evidence for each claim is assumed to have already been retrieved. In this
paper, we investigate verification over structured data in the open-domain
setting, introducing a joint reranking-and-verification model which fuses
evidence documents in the verification component. Our open-domain model
achieves performance comparable to the closed-domain state-of-the-art on the
TabFact dataset, and demonstrates performance gains from the inclusion of
multiple tables as well as a significant improvement over a heuristic retrieval
baseline.",1,1,0,0,1,0,0.697498,6.0,0.761544,47
http://arxiv.org/abs/2007.13916v2,"Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases",198,0.777012,0.817593,"Self-supervised representation learning approaches have recently surpassed
their supervised learning counterparts on downstream tasks like object
detection and image classification. Somewhat mysteriously the recent gains in
performance come from training instance classification models, treating each
image and it's augmented versions as samples of a single class. In this work,
we first present quantitative experiments to demystify these gains. We
demonstrate that approaches like MOCO and PIRL learn occlusion-invariant
representations. However, they fail to capture viewpoint and category instance
invariance which are crucial components for object recognition. Second, we
demonstrate that these approaches obtain further gains from access to a clean
object-centric training dataset like Imagenet. Finally, we propose an approach
to leverage unstructured videos to learn representations that possess higher
viewpoint invariance. Our results show that the learned representations
outperform MOCOv2 trained on the same data in terms of invariances encoded and
the performance on downstream image classification and semantic segmentation
tasks.",0,0,0,0,0,0,0.945959,8.0,0.932683,47
http://arxiv.org/abs/2007.15280v2,Photon: A Robust Cross-Domain Text-to-SQL System,49,0.812871,0.834864,"Natural language interfaces to databases (NLIDB) democratize end user access
to relational data. Due to fundamental differences between natural language
communication and programming, it is common for end users to issue questions
that are ambiguous to the system or fall outside the semantic scope of its
underlying query language. We present Photon, a robust, modular, cross-domain
NLIDB that can flag natural language input to which a SQL mapping cannot be
immediately determined. Photon consists of a strong neural semantic parser
(63.2\% structure accuracy on the Spider dev benchmark), a human-in-the-loop
question corrector, a SQL executor and a response generator. The question
corrector is a discriminative neural sequence editor which detects confusion
span(s) in the input question and suggests rephrasing until a translatable
input is given by the user or a maximum number of iterations are conducted.
Experiments on simulated data show that the proposed method effectively
improves the robustness of text-to-SQL system against untranslatable user
input. The live demo of our system is available at http://naturalsql.com.",0,1,0,0,0,0,0.937526,5.0,0.882099,52
http://arxiv.org/abs/2005.09674v1,Tensor completion via nonconvex tensor ring rank minimization with guaranteed convergence,18,0.422578,0.387715,"In recent studies, the tensor ring (TR) rank has shown high effectiveness in
tensor completion due to its ability of capturing the intrinsic structure
within high-order tensors. A recently proposed TR rank minimization method is
based on the convex relaxation by penalizing the weighted sum of nuclear norm
of TR unfolding matrices. However, this method treats each singular value
equally and neglects their physical meanings, which usually leads to suboptimal
solutions in practice. In this paper, we propose to use the logdet-based
function as a nonconvex smooth relaxation of the TR rank for tensor completion,
which can more accurately approximate the TR rank and better promote the
low-rankness of the solution. To solve the proposed nonconvex model
efficiently, we develop an alternating direction method of multipliers
algorithm and theoretically prove that, under some mild assumptions, our
algorithm converges to a stationary point. Extensive experiments on color
images, multispectral images, and color videos demonstrate that the proposed
method outperforms several state-of-the-art competitors in both visual and
quantitative comparison. Key words: nonconvex optimization, tensor ring rank,
logdet function, tensor completion, alternating direction method of
multipliers.",0,0,0,0,1,0,0.877569,5.0,0.82652,72
http://arxiv.org/abs/2003.14132v1,Will we ever have Conscious Machines?,22,0.0388103,0.358279,"The question of whether artificial beings or machines could become self-aware
or consciousness has been a philosophical question for centuries. The main
problem is that self-awareness cannot be observed from an outside perspective
and the distinction of whether something is really self-aware or merely a
clever program that pretends to do so cannot be answered without access to
accurate knowledge about the mechanism's inner workings. We review the current
state-of-the-art regarding these developments and investigate common machine
learning approaches with respect to their potential ability to become
self-aware. We realise that many important algorithmic steps towards machines
with a core consciousness have already been devised. For human-level
intelligence, however, many additional techniques have to be discovered.",0,0,0,0,0,0,0.00541231,13.0,0.474938,158
http://arxiv.org/abs/2002.05878v2,An LSTM-Based Autonomous Driving Model Using Waymo Open Dataset,32,0.146516,0.417296,"The Waymo Open Dataset has been released recently, providing a platform to
crowdsource some fundamental challenges for automated vehicles (AVs), such as
3D detection and tracking. While~the dataset provides a large amount of
high-quality and multi-source driving information, people in academia are more
interested in the underlying driving policy programmed in Waymo self-driving
cars, which is inaccessible due to AV manufacturers' proprietary protection.
Accordingly, academic researchers have to make various assumptions to implement
AV components in their models or simulations, which may not represent the
realistic interactions in real-world traffic. Thus, this paper introduces an
approach to learn a long short-term memory (LSTM)-based model for imitating the
behavior of Waymo's self-driving model. The proposed model has been evaluated
based on Mean Absolute Error (MAE). The experimental results show that our
model outperforms several baseline models in driving action prediction. In
addition, a visualization tool is presented for verifying the performance of
the model.",0,1,0,0,0,0,0.667355,9.0,0.831832,22
http://arxiv.org/abs/2003.09163v2,"Detection in Crowded Scenes: One Proposal, Multiple Predictions",138,0.479979,0.996098,"We propose a simple yet effective proposal-based object detector, aiming at
detecting highly-overlapped instances in crowded scenes. The key of our
approach is to let each proposal predict a set of correlated instances rather
than a single one in previous proposal-based frameworks. Equipped with new
techniques such as EMD Loss and Set NMS, our detector can effectively handle
the difficulty of detecting highly overlapped objects. On a FPN-Res50 baseline,
our detector can obtain 4.9\% AP gains on challenging CrowdHuman dataset and
1.0\% $\text{MR}^{-2}$ improvements on CityPersons dataset, without bells and
whistles. Moreover, on less crowed datasets like COCO, our approach can still
achieve moderate improvement, suggesting the proposed method is robust to
crowdedness. Code and pre-trained models will be released at
https://github.com/megvii-model/CrowdDetection.",1,1,0,0,1,0,0.819503,7.0,0.846893,46
http://arxiv.org/abs/2008.09747v1,Towards Improved Human Action Recognition Using Convolutional Neural Networks and Multimodal Fusion of Depth and Inertial Sensor Data,16,0.0706063,0.364723,"This paper attempts at improving the accuracy of Human Action Recognition
(HAR) by fusion of depth and inertial sensor data. Firstly, we transform the
depth data into Sequential Front view Images(SFI) and fine-tune the pre-trained
AlexNet on these images. Then, inertial data is converted into Signal Images
(SI) and another convolutional neural network (CNN) is trained on these images.
Finally, learned features are extracted from both CNN, fused together to make a
shared feature layer, and these features are fed to the classifier. We
experiment with two classifiers, namely Support Vector Machines (SVM) and
softmax classifier and compare their performances. The recognition accuracies
of each modality, depth data alone and sensor data alone are also calculated
and compared with fusion based accuracies to highlight the fact that fusion of
modalities yields better results than individual modalities. Experimental
results on UTD-MHAD and Kinect 2D datasets show that proposed method achieves
state of the art results when compared to other recently proposed
visual-inertial action recognition methods.",0,1,0,0,1,0,0.238926,7.0,0.584624,42
http://arxiv.org/abs/2001.00735v2,Trajectory Forecasts in Unknown Environments Conditioned on Grid-Based Plans,126,0.929998,0.838553,"We address the problem of forecasting pedestrian and vehicle trajectories in
unknown environments, conditioned on their past motion and scene structure.
Trajectory forecasting is a challenging problem due to the large variation in
scene structure and the multimodal distribution of future trajectories. Unlike
prior approaches that directly learn one-to-many mappings from observed context
to multiple future trajectories, we propose to condition trajectory forecasts
on plans sampled from a grid based policy learned using maximum entropy inverse
reinforcement learning (MaxEnt IRL). We reformulate MaxEnt IRL to allow the
policy to jointly infer plausible agent goals, and paths to those goals on a
coarse 2-D grid defined over the scene. We propose an attention based
trajectory generator that generates continuous valued future trajectories
conditioned on state sequences sampled from the MaxEnt policy. Quantitative and
qualitative evaluation on the publicly available Stanford drone and NuScenes
datasets shows that our model generates trajectories that are diverse,
representing the multimodal predictive distribution, and precise, conforming to
the underlying scene structure over long prediction horizons.",1,1,0,0,0,0,0.971302,3.0,0.885922,47
http://arxiv.org/abs/2004.12873v1,Maximum Entropy Multi-Task Inverse RL,4,0.0465328,0.109086,"Multi-task IRL allows for the possibility that the expert could be switching
between multiple ways of solving the same problem, or interleaving
demonstrations of multiple tasks. The learner aims to learn the multiple reward
functions that guide these ways of solving the problem. We present a new method
for multi-task IRL that generalizes the well-known maximum entropy approach to
IRL by combining it with the Dirichlet process based clustering of the observed
input. This yields a single nonlinear optimization problem, called MaxEnt
Multi-task IRL, which can be solved using the Lagrangian relaxation and
gradient descent methods. We evaluate MaxEnt Multi-task IRL in simulation on
the robotic task of sorting onions on a processing line where the expert
utilizes multiple ways of detecting and removing blemished onions. The method
is able to learn the underlying reward functions to a high level of accuracy
and it improves on the previous approaches to multi-task IRL.",0,0,0,0,0,0,0.120912,13.0,0.718586,33
http://arxiv.org/abs/2006.07778v3,Cascaded deep monocular 3D human pose estimation with evolutionary training data,135,0.72125,0.972867,"End-to-end deep representation learning has achieved remarkable accuracy for
monocular 3D human pose estimation, yet these models may fail for unseen poses
with limited and fixed training data. This paper proposes a novel data
augmentation method that: (1) is scalable for synthesizing massive amount of
training data (over 8 million valid 3D human poses with corresponding 2D
projections) for training 2D-to-3D networks, (2) can effectively reduce dataset
bias. Our method evolves a limited dataset to synthesize unseen 3D human
skeletons based on a hierarchical human representation and heuristics inspired
by prior knowledge. Extensive experiments show that our approach not only
achieves state-of-the-art accuracy on the largest public benchmark, but also
generalizes significantly better to unseen and rare poses. Code, pre-trained
models and tools are available at this HTTPS URL.",0,1,0,1,1,0,0.916185,6.0,0.88308,77
http://arxiv.org/abs/2011.13265v1,CYPUR-NN: Crop Yield Prediction Using Regression and Neural Networks,1,0.0267908,0.0246682,"Our recent study using historic data of paddy yield and associated conditions
include humidity, luminescence, and temperature. By incorporating regression
models and neural networks (NN), one can produce highly satisfactory
forecasting of paddy yield. Simulations indicate that our model can predict
paddy yield with high accuracy while concurrently detecting diseases that may
exist and are oblivious to the human eye. Crop Yield Prediction Using
Regression and Neural Networks (CYPUR-NN) is developed here as a system that
will facilitate agriculturists and farmers to predict yield from a picture or
by entering values via a web interface. CYPUR-NN has been tested on stock
images and the experimental results are promising.",0,1,0,0,0,1,0.119424,29.0,0.873393,11
http://arxiv.org/abs/2003.01866v2,Region adaptive graph fourier transform for 3d point clouds,22,0.187215,0.369167,"We introduce the Region Adaptive Graph Fourier Transform (RA-GFT) for
compression of 3D point cloud attributes. The RA-GFT is a multiresolution
transform, formed by combining spatially localized block transforms. We assume
the points are organized by a family of nested partitions represented by a
rooted tree. At each resolution level, attributes are processed in clusters
using block transforms. Each block transform produces a single approximation
(DC) coefficient, and various detail (AC) coefficients. The DC coefficients are
promoted up the tree to the next (lower resolution) level, where the process
can be repeated until reaching the root. Since clusters may have a different
numbers of points, each block transform must incorporate the relative
importance of each coefficient. For this, we introduce the
$\mathbf{Q}$-normalized graph Laplacian, and propose using its eigenvectors as
the block transform. The RA-GFT achieves better complexity-performance
trade-offs than previous approaches. In particular, it outperforms the Region
Adaptive Haar Transform (RAHT) by up to 2.5 dB, with a small complexity
overhead.",1,0,0,0,0,0,0.175381,10.0,0.674464,20
http://arxiv.org/abs/2005.10899v2,Extracting Daily Dosage from Medication Instructions in EHRs: An Automated Approach and Lessons Learned,7,0.274789,0.559382,"Medication timelines have been shown to be effective in helping physicians
visualize complex patient medication information. A key feature in many such
designs is a longitudinal representation of a medication's daily dosage and its
changes over time. However, daily dosage as a discrete value is generally not
provided and needs to be derived from free text instructions (Sig). Existing
works in daily dosage extraction are narrow in scope, targeting dosage
extraction for a single drug from clinical notes. Here, we present an automated
approach to calculate daily dosage for all medications, combining deep
learning-based named entity extractor with lexicon dictionaries and regular
expressions, achieving 0.98 precision and 0.95 recall on an expert-generated
dataset of 1,000 Sigs. We also analyze our expert-generated dataset, discuss
the challenges in understanding the complex information contained in Sigs, and
provide insights to guide future work in the general-purpose daily dosage
calculation task.",0,1,0,0,0,0,0.98291,3.0,0.931342,21
http://arxiv.org/abs/2009.08553v4,Generation-Augmented Retrieval for Open-domain Question Answering,172,0.927664,0.935454,"We propose Generation-Augmented Retrieval (GAR) for answering open-domain
questions, which augments a query through text generation of heuristically
discovered relevant contexts without external resources as supervision. We
demonstrate that the generated contexts substantially enrich the semantics of
the queries and GAR with sparse representations (BM25) achieves comparable or
better performance than state-of-the-art dense retrieval methods such as DPR.
We show that generating diverse contexts for a query is beneficial as fusing
their results consistently yields better retrieval accuracy. Moreover, as
sparse and dense representations are often complementary, GAR can be easily
combined with DPR to achieve even better performance. GAR achieves
state-of-the-art performance on Natural Questions and TriviaQA datasets under
the extractive QA setup when equipped with an extractive reader, and
consistently outperforms other retrieval methods when the same generative
reader is used.",1,1,1,0,1,1,0.980288,2.0,0.879156,43
http://arxiv.org/abs/2001.09403v1,Sentiment and Knowledge Based Algorithmic Trading with Deep Reinforcement Learning,23,0.0750243,0.470208,"Algorithmic trading, due to its inherent nature, is a difficult problem to
tackle; there are too many variables involved in the real world which make it
almost impossible to have reliable algorithms for automated stock trading. The
lack of reliable labelled data that considers physical and physiological
factors that dictate the ups and downs of the market, has hindered the
supervised learning attempts for dependable predictions. To learn a good policy
for trading, we formulate an approach using reinforcement learning which uses
traditional time series stock price data and combines it with news headline
sentiments, while leveraging knowledge graphs for exploiting news about
implicit relationships.",0,1,0,0,0,0,0.0020221,18.0,0.565997,29
http://arxiv.org/abs/2010.00810v1,Public Announcement Logic in HOL,2,0.0143738,0.0601245,"A shallow semantical embedding for public announcement logic with relativized
common knowledge is presented. This embedding enables the first-time automation
of this logic with off-the-shelf theorem provers for classical higher-order
logic. It is demonstrated (i) how meta-theoretical studies can be automated
this way, and (ii) how non-trivial reasoning in the target logic (public
announcement logic), required e.g. to obtain a convincing encoding and
automation of the wise men puzzle, can be realized. Key to the presented
semantical embedding -- in contrast, e.g., to related work on the semantical
embedding of normal modal logics -- is that evaluation domains are modeled
explicitly and treated as additional parameter in the encodings of the
constituents of the embedded target logic, while they were previously
implicitly shared between meta logic and target logic.",0,0,0,0,0,0,3.76915e-05,27.0,0.56313,27
http://arxiv.org/abs/2006.03340v2,MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction,94,0.504275,0.975036,"Autonomous vehicles are expected to drive in complex scenarios with several
independent non cooperating agents. Path planning for safely navigating in such
environments can not just rely on perceiving present location and motion of
other agents. It requires instead to predict such variables in a far enough
future. In this paper we address the problem of multimodal trajectory
prediction exploiting a Memory Augmented Neural Network. Our method learns past
and future trajectory embeddings using recurrent neural networks and exploits
an associative external memory to store and retrieve such embeddings.
Trajectory prediction is then performed by decoding in-memory future encodings
conditioned with the observed past. We incorporate scene knowledge in the
decoding state by learning a CNN on top of semantic scene maps. Memory growth
is limited by learning a writing controller based on the predictive capability
of existing embeddings. We show that our method is able to natively perform
multi-modal trajectory prediction obtaining state-of-the art results on three
datasets. Moreover, thanks to the non-parametric nature of the memory module,
we show how once trained our system can continuously improve by ingesting novel
patterns.",0,0,0,0,1,0,0.786846,7.0,0.832295,55
http://arxiv.org/abs/2011.15000v1,"Fast, Self Supervised, Fully Convolutional Color Normalization of H&E Stained Images",12,0.226273,0.39489,"Performance of deep learning algorithms decreases drastically if the data
distributions of the training and testing sets are different. Due to variations
in staining protocols, reagent brands, and habits of technicians, color
variation in digital histopathology images is quite common. Color variation
causes problems for the deployment of deep learning-based solutions for
automatic diagnosis system in histopathology. Previously proposed color
normalization methods consider a small patch as a reference for normalization,
which creates artifacts on out-of-distribution source images. These methods are
also slow as most of the computation is performed on CPUs instead of the GPUs.
We propose a color normalization technique, which is fast during its
self-supervised training as well as inference. Our method is based on a
lightweight fully-convolutional neural network and can be easily attached to a
deep learning-based pipeline as a pre-processing block. For classification and
segmentation tasks on CAMELYON17 and MoNuSeg datasets respectively, the
proposed method is faster and gives a greater increase in accuracy than the
state of the art methods.",0,1,0,0,1,0,0.923974,6.0,0.88951,24
http://arxiv.org/abs/2001.10953v3,Human Action Performance using Deep Neuro-Fuzzy Recurrent Attention Model,22,0.294745,0.725297,"A great number of computer vision publications have focused on distinguishing
between human action recognition and classification rather than the intensity
of actions performed. Indexing the intensity which determines the performance
of human actions is a challenging task due to the uncertainty and information
deficiency that exists in the video inputs. To remedy this uncertainty, in this
paper we coupled fuzzy logic rules with the neural-based action recognition
model to rate the intensity of a human action as intense or mild. In our
approach, we used a Spatio-Temporal LSTM to generate the weights of the
fuzzy-logic model, and then demonstrate through experiments that indexing of
the action intensity is possible. We analyzed the integrated model by applying
it to videos of human actions with different action intensities and were able
to achieve an accuracy of 89.16% on our intensity indexing generated dataset.
The integrated model demonstrates the ability of a neuro-fuzzy inference module
to effectively estimate the intensity index of human actions.",0,1,0,0,0,0,0.70706,7.0,0.799397,71
http://arxiv.org/abs/2004.13188v1,Multi-Task Image-Based Dietary Assessment for Food Recognition and Portion Size Estimation,41,0.745544,0.59054,"Deep learning based methods have achieved impressive results in many
applications for image-based diet assessment such as food classification and
food portion size estimation. However, existing methods only focus on one task
at a time, making it difficult to apply in real life when multiple tasks need
to be processed together. In this work, we propose an end-to-end multi-task
framework that can achieve both food classification and food portion size
estimation. We introduce a food image dataset collected from a nutrition study
where the groundtruth food portion is provided by registered dietitians. The
multi-task learning uses L2-norm based soft parameter sharing to train the
classification and regression tasks simultaneously. We also propose the use of
cross-domain feature adaptation together with normalization to further improve
the performance of food portion size estimation. Our results outperforms the
baseline methods for both classification accuracy and mean absolute error for
portion estimation, which shows great potential for advancing the field of
image-based dietary assessment.",0,1,0,1,0,0,0.960868,9.0,0.95182,28
http://arxiv.org/abs/2008.04556v4,Text as Neural Operator: Image Manipulation by Text Instruction,36,0.273325,0.824153,"In recent years, text-guided image manipulation has gained increasing
attention in the multimedia and computer vision community. The input to
conditional image generation has evolved from image-only to multimodality. In
this paper, we study a setting that allows users to edit an image with multiple
objects using complex text instructions to add, remove, or change the objects.
The inputs of the task are multimodal including (1) a reference image and (2)
an instruction in natural language that describes desired modifications to the
image. We propose a GAN-based method to tackle this problem. The key idea is to
treat text as neural operators to locally modify the image feature. We show
that the proposed model performs favorably against recent strong baselines on
three public datasets. Specifically, it generates images of greater fidelity
and semantic relevance, and when used as a image query, leads to better
retrieval performance.",1,0,0,0,0,0,0.693648,5.0,0.711727,87
http://arxiv.org/abs/2002.12819v2,Indoor Scene Recognition in 3D,16,0.140101,0.37221,"Recognising in what type of environment one is located is an important
perception task. For instance, for a robot operating in indoors it is helpful
to be aware whether it is in a kitchen, a hallway or a bedroom. Existing
approaches attempt to classify the scene based on 2D images or 2.5D range
images. Here, we study scene recognition from 3D point cloud (or voxel) data,
and show that it greatly outperforms methods based on 2D birds-eye views.
Moreover, we advocate multi-task learning as a way of improving scene
recognition, building on the fact that the scene type is highly correlated with
the objects in the scene, and therefore with its semantic segmentation into
different object classes. In a series of ablation studies, we show that
successful scene recognition is not just the recognition of individual objects
unique to some scene type (such as a bathtub), but depends on several different
cues, including coarse 3D geometry, colour, and the (implicit) distribution of
object categories. Moreover, we demonstrate that surprisingly sparse 3D data is
sufficient to classify indoor scenes with good accuracy.",0,1,0,0,1,0,0.803078,8.0,0.859505,46
http://arxiv.org/abs/2006.15731v1,Unsupervised Learning of Video Representations via Dense Trajectory Clustering,22,0.077912,0.405748,"This paper addresses the task of unsupervised learning of representations for
action recognition in videos. Previous works proposed to utilize future
prediction, or other domain-specific objectives to train a network, but
achieved only limited success. In contrast, in the relevant field of image
representation learning, simpler, discrimination-based methods have recently
bridged the gap to fully-supervised performance. We first propose to adapt two
top performing objectives in this class - instance recognition and local
aggregation, to the video domain. In particular, the latter approach iterates
between clustering the videos in the feature space of a network and updating it
to respect the cluster with a non-parametric classification loss. We observe
promising performance, but qualitative analysis shows that the learned
representations fail to capture motion patterns, grouping the videos based on
appearance. To mitigate this issue, we turn to the heuristic-based IDT
descriptors, that were manually designed to encode motion patterns in videos.
We form the clusters in the IDT space, using these descriptors as a an
unsupervised prior in the iterative local aggregation algorithm. Our
experiments demonstrates that this approach outperform prior work on UCF101 and
HMDB51 action recognition benchmarks. We also qualitatively analyze the learned
representations and show that they successfully capture video dynamics.",1,1,0,0,0,0,0.820039,8.0,0.866248,50
http://arxiv.org/abs/2009.09359v2,"Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation",56,0.508308,0.973417,"Despite being the seventh most widely spoken language in the world, Bengali
has received much less attention in machine translation literature due to being
low in resources. Most publicly available parallel corpora for Bengali are not
large enough; and have rather poor quality, mostly because of incorrect
sentence alignments resulting from erroneous sentence segmentation, and also
because of a high volume of noise present in them. In this work, we build a
customized sentence segmenter for Bengali and propose two novel methods for
parallel corpus creation on low-resource setups: aligner ensembling and batch
filtering. With the segmenter and the two methods combined, we compile a
high-quality Bengali-English parallel corpus comprising of 2.75 million
sentence pairs, more than 2 million of which were not available before.
Training on neural models, we achieve an improvement of more than 9 BLEU score
over previous approaches to Bengali-English machine translation. We also
evaluate on a new test set of 1000 pairs made with extensive quality control.
We release the segmenter, parallel corpus, and the evaluation set, thus
elevating Bengali from its low-resource status. To the best of our knowledge,
this is the first ever large scale study on Bengali-English machine
translation. We believe our study will pave the way for future research on
Bengali-English machine translation as well as other low-resource languages.
Our data and code are available at https://github.com/csebuetnlp/banglanmt.",1,1,0,1,1,0,0.433617,8.0,0.728223,57
http://arxiv.org/abs/2008.05110v1,Facial Expression Retargeting from Human to Avatar Made Easy,33,0.17758,0.729505,"Facial expression retargeting from humans to virtual characters is a useful
technique in computer graphics and animation. Traditional methods use markers
or blendshapes to construct a mapping between the human and avatar faces.
However, these approaches require a tedious 3D modeling process, and the
performance relies on the modelers' experience. In this paper, we propose a
brand-new solution to this cross-domain expression transfer problem via
nonlinear expression embedding and expression domain translation. We first
build low-dimensional latent spaces for the human and avatar facial expressions
with variational autoencoder. Then we construct correspondences between the two
latent spaces guided by geometric and perceptual constraints. Specifically, we
design geometric correspondences to reflect geometric matching and utilize a
triplet data structure to express users' perceptual preference of avatar
expressions. A user-friendly method is proposed to automatically generate
triplets for a system allowing users to easily and efficiently annotate the
correspondences. Using both geometric and perceptual correspondences, we
trained a network for expression domain translation from human to avatar.
Extensive experimental results and user studies demonstrate that even
nonprofessional users can apply our method to generate high-quality facial
expression retargeting results with less time and effort.",0,1,0,0,0,0,0.0362037,13.0,0.622334,53
http://arxiv.org/abs/2008.03154v2,Decomposition of Longitudinal Deformations via Beltrami Descriptors,1,0.00854506,0.0468823,"We present a mathematical model to decompose a longitudinal deformation into
normal and abnormal components. The goal is to detect and extract subtle
quivers from periodic motions in a video sequence. It has important
applications in medical image analysis. To achieve this goal, we consider a
representation of the longitudinal deformation, called the Beltrami descriptor,
based on quasiconformal theories. The Beltrami descriptor is a complex-valued
matrix. Each longitudinal deformation is associated to a Beltrami descriptor
and vice versa. To decompose the longitudinal deformation, we propose to carry
out the low rank and sparse decomposition of the Beltrami descriptor. The low
rank component corresponds to the periodic motions, whereas the sparse part
corresponds to the abnormal motions of a longitudinal deformation. Experiments
have been carried out on both synthetic and real video sequences. Results
demonstrate the efficacy of our proposed model to decompose a longitudinal
deformation into regular and irregular components.",0,0,1,0,0,0,0.00281805,17.0,0.560016,65
http://arxiv.org/abs/2001.04735v3,NODIS: Neural Ordinary Differential Scene Understanding,16,0.0505959,0.320222,"Semantic image understanding is a challenging topic in computer vision. It
requires to detect all objects in an image, but also to identify all the
relations between them. Detected objects, their labels and the discovered
relations can be used to construct a scene graph which provides an abstract
semantic interpretation of an image. In previous works, relations were
identified by solving an assignment problem formulated as Mixed-Integer Linear
Programs. In this work, we interpret that formulation as Ordinary Differential
Equation (ODE). The proposed architecture performs scene graph inference by
solving a neural variant of an ODE by end-to-end learning. It achieves
state-of-the-art results on all three benchmark tasks: scene graph generation
(SGGen), classification (SGCls) and visual relationship detection (PredCls) on
Visual Genome benchmark.",0,0,0,0,1,0,0.509187,5.0,0.61009,55
http://arxiv.org/abs/2005.04166v1,Time Efficiency in Optimization with a Bayesian-Evolutionary Algorithm,59,0.0371481,0.421062,"Not all generate-and-test search algorithms are created equal. Bayesian
Optimization (BO) invests a lot of computation time to generate the candidate
solution that best balances the predicted value and the uncertainty given all
previous data, taking increasingly more time as the number of evaluations
performed grows. Evolutionary Algorithms (EA) on the other hand rely on search
heuristics that typically do not depend on all previous data and can be done in
constant time. Both the BO and EA community typically assess their performance
as a function of the number of evaluations. However, this is unfair once we
start to compare the efficiency of these classes of algorithms, as the overhead
times to generate candidate solutions are significantly different. We suggest
to measure the efficiency of generate-and-test search algorithms as the
expected gain in the objective value per unit of computation time spent. We
observe that the preference of an algorithm to be used can change after a
number of function evaluations. We therefore propose a new algorithm, a
combination of Bayesian optimization and an Evolutionary Algorithm, BEA for
short, that starts with BO, then transfers knowledge to an EA, and subsequently
runs the EA. We compare the BEA with BO and the EA. The results show that BEA
outperforms both BO and the EA in terms of time efficiency, and ultimately
leads to better performance on well-known benchmark objective functions with
many local optima. Moreover, we test the three algorithms on nine test cases of
robot learning problems and here again we find that BEA outperforms the other
algorithms.",0,1,0,0,0,0,0.0229797,7.0,0.232717,51
http://arxiv.org/abs/2006.13979v2,Unsupervised Cross-lingual Representation Learning for Speech Recognition,593,0.63364,0.999979,"This paper presents XLSR which learns cross-lingual speech representations by
pretraining a single model from the raw waveform of speech in multiple
languages. We build on wav2vec 2.0 which is trained by solving a contrastive
task over masked latent speech representations and jointly learns a
quantization of the latents shared across languages. The resulting model is
fine-tuned on labeled data and experiments show that cross-lingual pretraining
significantly outperforms monolingual pretraining. On the CommonVoice
benchmark, XLSR shows a relative phoneme error rate reduction of 72% compared
to the best known results. On BABEL, our approach improves word error rate by
16% relative compared to a comparable system. Our approach enables a single
multilingual speech recognition model which is competitive to strong individual
models. Analysis shows that the latent discrete speech representations are
shared across languages with increased sharing for related languages. We hope
to catalyze research in low-resource speech understanding by releasing XLSR-53,
a large model pretrained in 53 languages.",0,1,0,0,1,0,0.471276,4.0,0.485008,53
http://arxiv.org/abs/2003.02301v2,"Real-time, Universal, and Robust Adversarial Attacks Against Speaker Recognition Systems",85,0.335458,0.854982,"As the popularity of voice user interface (VUI) exploded in recent years,
speaker recognition system has emerged as an important medium of identifying a
speaker in many security-required applications and services. In this paper, we
propose the first real-time, universal, and robust adversarial attack against
the state-of-the-art deep neural network (DNN) based speaker recognition
system. Through adding an audio-agnostic universal perturbation on arbitrary
enrolled speaker's voice input, the DNN-based speaker recognition system would
identify the speaker as any target (i.e., adversary-desired) speaker label. In
addition, we improve the robustness of our attack by modeling the sound
distortions caused by the physical over-the-air propagation through estimating
room impulse response (RIR). Experiment using a public dataset of 109 English
speakers demonstrates the effectiveness and robustness of our proposed attack
with a high attack success rate of over 90%. The attack launching time also
achieves a 100X speedup over contemporary non-universal attacks.",0,1,0,0,1,0,0.818396,5.0,0.784934,18
http://arxiv.org/abs/2007.08547v1,Talking-head Generation with Rhythmic Head Motion,145,0.608622,0.997218,"When people deliver a speech, they naturally move heads, and this rhythmic
head motion conveys prosodic information. However, generating a lip-synced
video while moving head naturally is challenging. While remarkably successful,
existing works either generate still talkingface videos or rely on
landmark/video frames as sparse/dense mapping guidance to generate head
movements, which leads to unrealistic or uncontrollable video synthesis. To
overcome the limitations, we propose a 3D-aware generative network along with a
hybrid embedding module and a non-linear composition module. Through modeling
the head motion and facial expressions1 explicitly, manipulating 3D animation
carefully, and embedding reference images dynamically, our approach achieves
controllable, photo-realistic, and temporally coherent talking-head videos with
natural head movements. Thoughtful experiments on several standard benchmarks
demonstrate that our method achieves significantly better results than the
state-of-the-art methods in both quantitative and qualitative comparisons. The
code is available on https://github.com/
lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion.",1,1,0,0,1,0,0.905928,5.0,0.850157,43
http://arxiv.org/abs/2001.03210v1,A Probabilistic Simulator of Spatial Demand for Product Allocation,6,0.0881614,0.119556,"Connecting consumers with relevant products is a very important problem in
both online and offline commerce. In physical retail, product placement is an
effective way to connect consumers with products. However, selecting product
locations within a store can be a tedious process. Moreover, learning important
spatial patterns in offline retail is challenging due to the scarcity of data
and the high cost of exploration and experimentation in the physical world. To
address these challenges, we propose a stochastic model of spatial demand in
physical retail. We show that the proposed model is more predictive of demand
than existing baselines. We also perform a preliminary study into different
automation techniques and show that an optimal product allocation policy can be
learned through Deep Q-Learning.",0,1,0,0,0,0,0.894062,9.0,0.911025,24
http://arxiv.org/abs/2008.04852v1,GeLaTO: Generative Latent Textured Objects,12,0.0166911,0.102224,"Accurate modeling of 3D objects exhibiting transparency, reflections and thin
structures is an extremely challenging problem. Inspired by billboards and
geometric proxies used in computer graphics, this paper proposes Generative
Latent Textured Objects (GeLaTO), a compact representation that combines a set
of coarse shape proxies defining low frequency geometry with learned neural
textures, to encode both medium and fine scale geometry as well as
view-dependent appearance. To generate the proxies' textures, we learn a joint
latent space allowing category-level appearance and geometry interpolation. The
proxies are independently rasterized with their corresponding neural texture
and composited using a U-Net, which generates an output photorealistic image
including an alpha map. We demonstrate the effectiveness of our approach by
reconstructing complex objects from a sparse set of views. We show results on a
dataset of real images of eyeglasses frames, which are particularly challenging
to reconstruct using classical methods. We also demonstrate that these coarse
proxies can be handcrafted when the underlying object geometry is easy to
model, like eyeglasses, or generated using a neural network for more complex
categories, such as cars.",0,0,0,0,0,0,0.407751,5.0,0.548794,51
http://arxiv.org/abs/2003.07493v2,Deep Relational Reasoning Graph Network for Arbitrary Shape Text Detection,154,0.882143,0.996142,"Arbitrary shape text detection is a challenging task due to the high variety
and complexity of scenes texts. In this paper, we propose a novel unified
relational reasoning graph network for arbitrary shape text detection. In our
method, an innovative local graph bridges a text proposal model via
Convolutional Neural Network (CNN) and a deep relational reasoning network via
Graph Convolutional Network (GCN), making our network end-to-end trainable. To
be concrete, every text instance will be divided into a series of small
rectangular components, and the geometry attributes (e.g., height, width, and
orientation) of the small components will be estimated by our text proposal
model. Given the geometry attributes, the local graph construction model can
roughly establish linkages between different text components. For further
reasoning and deducing the likelihood of linkages between the component and its
neighbors, we adopt a graph-based network to perform deep relational reasoning
on local graphs. Experiments on public available datasets demonstrate the
state-of-the-art performance of our method.",1,1,0,0,1,0,0.965413,5.0,0.920755,44
http://arxiv.org/abs/2007.06995v2,Improving Face Recognition by Clustering Unlabeled Faces in the Wild,15,0.0287589,0.341923,"While deep face recognition has benefited significantly from large-scale
labeled data, current research is focused on leveraging unlabeled data to
further boost performance, reducing the cost of human annotation. Prior work
has mostly been in controlled settings, where the labeled and unlabeled data
sets have no overlapping identities by construction. This is not realistic in
large-scale face recognition, where one must contend with such overlaps, the
frequency of which increases with the volume of data. Ignoring identity overlap
leads to significant labeling noise, as data from the same identity is split
into multiple clusters. To address this, we propose a novel identity separation
method based on extreme value theory. It is formulated as an
out-of-distribution detection algorithm, and greatly reduces the problems
caused by overlapping-identity label noise. Considering cluster assignments as
pseudo-labels, we must also overcome the labeling noise from clustering errors.
We propose a modulation of the cosine loss, where the modulation weights
correspond to an estimate of clustering uncertainty. Extensive experiments on
both controlled and real settings demonstrate our method's consistent
improvements over supervised baselines, e.g., 11.6% improvement on IJB-A
verification.",0,1,1,0,0,0,0.303215,8.0,0.671557,47
http://arxiv.org/abs/2012.02189v2,Learned Initializations for Optimizing Coordinate-Based Neural Representations,227,0.625881,0.984219,"Coordinate-based neural representations have shown significant promise as an
alternative to discrete, array-based representations for complex low
dimensional signals. However, optimizing a coordinate-based network from
randomly initialized weights for each new signal is inefficient. We propose
applying standard meta-learning algorithms to learn the initial weight
parameters for these fully-connected networks based on the underlying class of
signals being represented (e.g., images of faces or 3D models of chairs).
Despite requiring only a minor change in implementation, using these learned
initial weights enables faster convergence during optimization and can serve as
a strong prior over the signal class being modeled, resulting in better
generalization when only partial observations of a given signal are available.
We explore these benefits across a variety of tasks, including representing 2D
images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D
image observations.",0,1,0,0,0,0,0.956266,4.0,0.882869,39
http://arxiv.org/abs/2007.03204v2,Learning Branching Heuristics for Propositional Model Counting,12,0.0526514,0.290274,"Propositional model counting, or #SAT, is the problem of computing the number
of satisfying assignments of a Boolean formula. Many problems from different
application areas, including many discrete probabilistic inference problems,
can be translated into model counting problems to be solved by #SAT solvers.
Exact #SAT solvers, however, are often not scalable to industrial size
instances. In this paper, we present Neuro#, an approach for learning branching
heuristics to improve the performance of exact #SAT solvers on instances from a
given family of problems. We experimentally show that our method reduces the
step count on similarly distributed held-out instances and generalizes to much
larger instances from the same problem family. It is able to achieve these
results on a number of different problem families having very different
structures. In addition to step count improvements, Neuro# can also achieve
orders of magnitude wall-clock speedups over the vanilla solver on larger
instances in some problem families, despite the runtime overhead of querying
the model.",1,0,0,0,0,0,0.0132216,13.0,0.543947,52
http://arxiv.org/abs/2003.12307v1,Lightweight Photometric Stereo for Facial Details Recovery,23,0.36753,0.567482,"Recently, 3D face reconstruction from a single image has achieved great
success with the help of deep learning and shape prior knowledge, but they
often fail to produce accurate geometry details. On the other hand, photometric
stereo methods can recover reliable geometry details, but require dense inputs
and need to solve a complex optimization problem. In this paper, we present a
lightweight strategy that only requires sparse inputs or even a single image to
recover high-fidelity face shapes with images captured under near-field lights.
To this end, we construct a dataset containing 84 different subjects with 29
expressions under 3 different lights. Data augmentation is applied to enrich
the data in terms of diversity in identity, lighting, expression, etc. With
this constructed dataset, we propose a novel neural network specially designed
for photometric stereo based 3D face reconstruction. Extensive experiments and
comparisons demonstrate that our method can generate high-quality
reconstruction results with one to three facial images captured under
near-field lights. Our full framework is available at
https://github.com/Juyong/FacePSNet.",1,1,0,1,0,0,0.846672,6.0,0.836544,49
http://arxiv.org/abs/2003.04991v2,Unsupervised and Interpretable Domain Adaptation to Rapidly Filter Tweets for Emergency Services,5,0.0529983,0.233507,"During the onset of a disaster event, filtering relevant information from the
social web data is challenging due to its sparse availability and practical
limitations in labeling datasets of an ongoing crisis. In this paper, we
hypothesize that unsupervised domain adaptation through multi-task learning can
be a useful framework to leverage data from past crisis events for training
efficient information filtering models during the sudden onset of a new crisis.
We present a novel method to classify relevant tweets during an ongoing crisis
without seeing any new examples, using the publicly available dataset of TREC
incident streams. Specifically, we construct a customized multi-task
architecture with a multi-domain discriminator for crisis analytics: multi-task
domain adversarial attention network. This model consists of dedicated
attention layers for each task to provide model interpretability; critical for
real-word applications. As deep networks struggle with sparse datasets, we show
that this can be improved by sharing a base layer for multi-task learning and
domain adversarial training. Evaluation of domain adaptation for crisis events
is performed by choosing a target event as the test set and training on the
rest. Our results show that the multi-task model outperformed its single task
counterpart. For the qualitative evaluation of interpretability, we show that
the attention layer can be used as a guide to explain the model predictions and
empower emergency services for exploring accountability of the model, by
showcasing the words in a tweet that are deemed important in the classification
process. Finally, we show a practical implication of our work by providing a
use-case for the COVID-19 pandemic.",1,1,0,0,0,0,0.396821,11.0,0.791676,41
http://arxiv.org/abs/2012.11727v1,Cross-Domain Latent Modulation for Variational Transfer Learning,1,0.0178245,0.0159603,"We propose a cross-domain latent modulation mechanism within a variational
autoencoders (VAE) framework to enable improved transfer learning. Our key idea
is to procure deep representations from one data domain and use it as
perturbation to the reparameterization of the latent variable in another
domain. Specifically, deep representations of the source and target domains are
first extracted by a unified inference model and aligned by employing gradient
reversal. Second, the learned deep representations are cross-modulated to the
latent encoding of the alternate domain. The consistency between the
reconstruction from the modulated latent encoding and the generation using deep
representation samples is then enforced in order to produce inter-class
alignment in the latent space. We apply the proposed model to a number of
transfer learning tasks including unsupervised domain adaptation and
image-toimage translation. Experimental results show that our model gives
competitive performance.",0,0,0,0,0,0,0.95473,8.0,0.940048,47
http://arxiv.org/abs/2005.07979v1,Unsupervised Embedding-based Detection of Lexical Semantic Changes,7,0.122407,0.387789,"This paper describes EmbLexChange, a system introduced by the ""Life-Language""
team for SemEval-2020 Task 1, on unsupervised detection of lexical-semantic
changes. EmbLexChange is defined as the divergence between the embedding based
profiles of word w (calculated with respect to a set of reference words) in the
source and the target domains (source and target domains can be simply two time
frames t1 and t2). The underlying assumption is that the lexical-semantic
change of word w would affect its co-occurring words and subsequently alters
the neighborhoods in the embedding spaces. We show that using a resampling
framework for the selection of reference words, we can reliably detect
lexical-semantic changes in English, German, Swedish, and Latin. EmbLexChange
achieved second place in the binary detection of semantic changes in the
SemEval-2020.",0,1,0,0,0,0,0.304956,9.0,0.708817,19
http://arxiv.org/abs/2004.12684v1,Age-Aware Status Update Control for Energy Harvesting IoT Sensors via Reinforcement Learning,29,0.57897,0.725182,"We consider an IoT sensing network with multiple users, multiple energy
harvesting sensors, and a wireless edge node acting as a gateway between the
users and sensors. The users request for updates about the value of physical
processes, each of which is measured by one sensor. The edge node has a cache
storage that stores the most recently received measurements from each sensor.
Upon receiving a request, the edge node can either command the corresponding
sensor to send a status update, or use the data in the cache. We aim to find
the best action of the edge node to minimize the average long-term cost which
trade-offs between the age of information and energy consumption. We propose a
practical reinforcement learning approach that finds an optimal policy without
knowing the exact battery levels of the sensors.",0,1,0,0,0,0,0.960199,6.0,0.926857,20
http://arxiv.org/abs/2009.05289v1,UPB at SemEval-2020 Task 11: Propaganda Detection with Domain-Specific Trained BERT,12,0.242,0.0571448,"Manipulative and misleading news have become a commodity for some online news
outlets and these news have gained a significant impact on the global mindset
of people. Propaganda is a frequently employed manipulation method having as
goal to influence readers by spreading ideas meant to distort or manipulate
their opinions. This paper describes our participation in the SemEval-2020,
Task 11: Detection of Propaganda Techniques in News Articles competition. Our
approach considers specializing a pre-trained BERT model on propagandistic and
hyperpartisan news articles, enabling it to create more adequate
representations for the two subtasks, namely propaganda Span Identification
(SI) and propaganda Technique Classification (TC). Our proposed system achieved
a F1-score of 46.060% in subtask SI, ranking 5th in the leaderboard from 36
teams and a micro-averaged F1 score of 54.302% for subtask TC, ranking 19th
from 32 teams.",0,1,0,0,0,0,0.904414,4.0,0.811002,17
http://arxiv.org/abs/2010.09240v2,Multi-hop Question Generation with Graph Convolutional Network,34,0.157079,0.746293,"Multi-hop Question Generation (QG) aims to generate answer-related questions
by aggregating and reasoning over multiple scattered evidence from different
paragraphs. It is a more challenging yet under-explored task compared to
conventional single-hop QG, where the questions are generated from the sentence
containing the answer or nearby sentences in the same paragraph without complex
reasoning. To address the additional challenges in multi-hop QG, we propose
Multi-Hop Encoding Fusion Network for Question Generation (MulQG), which does
context encoding in multiple hops with Graph Convolutional Network and encoding
fusion via an Encoder Reasoning Gate. To the best of our knowledge, we are the
first to tackle the challenge of multi-hop reasoning over paragraphs without
any sentence-level information. Empirical results on HotpotQA dataset
demonstrate the effectiveness of our method, in comparison with baselines on
automatic evaluation metrics. Moreover, from the human evaluation, our proposed
model is able to generate fluent questions with high completeness and
outperforms the strongest baseline by 20.8% in the multi-hop evaluation. The
code is publicly available at
https://github.com/HLTCHKUST/MulQG}{https://github.com/HLTCHKUST/MulQG .",1,0,1,0,0,0,0.477823,7.0,0.708484,38
http://arxiv.org/abs/2006.13882v1,Automatic Estimation of Self-Reported Pain by Interpretable Representations of Motion Dynamics,8,0.0821767,0.537351,"We propose an automatic method for pain intensity measurement from video. For
each video, pain intensity was measured using the dynamics of facial movement
using 66 facial points. Gram matrices formulation was used for facial points
trajectory representations on the Riemannian manifold of symmetric positive
semi-definite matrices of fixed rank. Curve fitting and temporal alignment were
then used to smooth the extracted trajectories. A Support Vector Regression
model was then trained to encode the extracted trajectories into ten pain
intensity levels consistent with the Visual Analogue Scale for pain intensity
measurement. The proposed approach was evaluated using the UNBC McMaster
Shoulder Pain Archive and was compared to the state-of-the-art on the same
data. Using both 5-fold cross-validation and leave-one-subject-out
cross-validation, our results are competitive with respect to state-of-the-art
methods.",0,0,0,0,0,0,0.00930376,19.0,0.669363,33
http://arxiv.org/abs/2011.05671v1,VStreamDRLS: Dynamic Graph Representation Learning with Self-Attention for Enterprise Distributed Video Streaming Solutions,5,0.0964762,0.230278,"Live video streaming has become a mainstay as a standard communication
solution for several enterprises worldwide. To efficiently stream high-quality
live video content to a large amount of offices, companies employ distributed
video streaming solutions which rely on prior knowledge of the underlying
evolving enterprise network. However, such networks are highly complex and
dynamic. Hence, to optimally coordinate the live video distribution, the
available network capacity between viewers has to be accurately predicted. In
this paper we propose a graph representation learning technique on weighted and
dynamic graphs to predict the network capacity, that is the weights of
connections/links between viewers/nodes. We propose VStreamDRLS, a graph neural
network architecture with a self-attention mechanism to capture the evolution
of the graph structure of live video streaming events. VStreamDRLS employs the
graph convolutional network (GCN) model over the duration of a live video
streaming event and introduces a self-attention mechanism to evolve the GCN
parameters. In doing so, our model focuses on the GCN weights that are relevant
to the evolution of the graph and generate the node representation,
accordingly. We evaluate our proposed approach on the link prediction task on
two real-world datasets, generated by enterprise live video streaming events.
The duration of each event lasted an hour. The experimental results demonstrate
the effectiveness of VStreamDRLS when compared with state-of-the-art
strategies. Our evaluation datasets and implementation are publicly available
at https://github.com/stefanosantaris/vstreamdrls",1,1,0,0,1,0,0.458505,7.0,0.700266,32
http://arxiv.org/abs/2006.12769v1,Long-Term Prediction of Lane Change Maneuver Through a Multilayer Perceptron,19,0.0693786,0.326768,"Behavior prediction plays an essential role in both autonomous driving
systems and Advanced Driver Assistance Systems (ADAS), since it enhances
vehicle's awareness of the imminent hazards in the surrounding environment.
Many existing lane change prediction models take as input lateral or angle
information and make short-term (< 5 seconds) maneuver predictions. In this
study, we propose a longer-term (5~10 seconds) prediction model without any
lateral or angle information. Three prediction models are introduced, including
a logistic regression model, a multilayer perceptron (MLP) model, and a
recurrent neural network (RNN) model, and their performances are compared by
using the real-world NGSIM dataset. To properly label the trajectory data, this
study proposes a new time-window labeling scheme by adding a time gap between
positive and negative samples. Two approaches are also proposed to address the
unstable prediction issue, where the aggressive approach propagates each
positive prediction for certain seconds, while the conservative approach adopts
a roll-window average to smooth the prediction. Evaluation results show that
the developed prediction model is able to capture 75% of real lane change
maneuvers with an average advanced prediction time of 8.05 seconds.",0,0,0,0,0,0,0.0022287,15.0,0.485689,21
http://arxiv.org/abs/2003.03570v2,CPM R-CNN: Calibrating Point-guided Misalignment in Object Detection,15,0.0130803,0.0993806,"In object detection, offset-guided and point-guided regression dominate
anchor-based and anchor-free method separately. Recently, point-guided approach
is introduced to anchor-based method. However, we observe points predicted by
this way are misaligned with matched region of proposals and score of
localization, causing a notable gap in performance. In this paper, we propose
CPM R-CNN which contains three efficient modules to optimize anchor-based
point-guided method. According to sufficient evaluations on the COCO dataset,
CPM R-CNN is demonstrated efficient to improve the localization accuracy by
calibrating mentioned misalignment. Compared with Faster R-CNN and Grid R-CNN
based on ResNet-101 with FPN, our approach can substantially improve detection
mAP by 3.3% and 1.5% respectively without whistles and bells. Moreover, our
best model achieves improvement by a large margin to 49.9% on COCO test-dev.
Code and models will be publicly available.",1,1,0,0,1,0,0.553524,6.0,0.695891,36
http://arxiv.org/abs/2011.12184v1,Neural Text Classification by Jointly Learning to Cluster and Align,1,0.00495254,0.0352896,"Distributional text clustering delivers semantically informative
representations and captures the relevance between each word and semantic
clustering centroids. We extend the neural text clustering approach to text
classification tasks by inducing cluster centers via a latent variable model
and interacting with distributional word embeddings, to enrich the
representation of tokens and measure the relatedness between tokens and each
learnable cluster centroid. The proposed method jointly learns word clustering
centroids and clustering-token alignments, achieving the state of the art
results on multiple benchmark datasets and proving that the proposed
cluster-token alignment mechanism is indeed favorable to text classification.
Notably, our qualitative analysis has conspicuously illustrated that text
representations learned by the proposed model are in accord well with our
intuition.",0,0,0,0,1,1,0.275176,9.0,0.695202,50
http://arxiv.org/abs/2004.10521v3,Efficient adjustment sets in causal graphical models with hidden variables,26,0.31909,0.467123,"We study the selection of covariate adjustment sets for estimating the value
of point exposure dynamic policies, also known as dynamic treatment regimes,
assuming a non-parametric causal graphical model with hidden variables, in
which at least one adjustment set is fully observable. We show that recently
developed criteria, for graphs without hidden variables, to compare the
asymptotic variance of non-parametric estimators of static policy values that
control for certain adjustment sets, are also valid under dynamic policies and
graphs with hidden variables. We show that there exist adjustment sets that are
optimal minimal (minimum), in the sense of yielding estimators with the
smallest variance among those that control for adjustment sets that are minimal
(of minimum cardinality). Moreover, we show that if either no variables are
hidden or if all the observable variables are ancestors of either treatment,
outcome, or the variables that are used to decide treatment, a globally optimal
adjustment set exists. We provide polynomial time algorithms to compute the
globally optimal (when it exists), optimal minimal, and optimal minimum
adjustment sets. Our results are based on the construction of an undirected
graph in which vertex cuts between the treatment and outcome variables
correspond to adjustment sets. In this undirected graph, a partial order
between minimal vertex cuts can be defined that makes the set of minimal cuts a
lattice. This partial order corresponds directly to the ordering of the
asymptotic variances of the corresponding non-parametrically adjusted
estimators.",0,0,0,0,0,0,0.143743,16.0,0.782964,43
http://arxiv.org/abs/2009.07936v3,How to marry a star: probabilistic constraints for meaning in context,7,0.0476225,0.13007,"In this paper, we derive a notion of 'word meaning in context' that
characterizes meaning as both intensional and conceptual. We introduce a
framework for specifying local as well as global constraints on word meaning in
context, together with their interactions, thus modelling the wide range of
lexical shifts and ambiguities observed in utterance interpretation. We
represent sentence meaning as a 'situation description system', a probabilistic
model which takes utterance understanding to be the mental process of
describing to oneself one or more situations that would account for an observed
utterance. We show how the system can be implemented in practice, and apply it
to examples containing various contextualisation phenomena.",0,0,0,0,0,0,0.00610663,14.0,0.521089,98
http://arxiv.org/abs/2004.01820v1,"Aggressive, Repetitive, Intentional, Visible, and Imbalanced: Refining Representations for Cyberbullying Classification",27,0.467574,0.115056,"Cyberbullying is a pervasive problem in online communities. To identify
cyberbullying cases in large-scale social networks, content moderators depend
on machine learning classifiers for automatic cyberbullying detection. However,
existing models remain unfit for real-world applications, largely due to a
shortage of publicly available training data and a lack of standard criteria
for assigning ground truth labels. In this study, we address the need for
reliable data using an original annotation framework. Inspired by social
sciences research into bullying behavior, we characterize the nuanced problem
of cyberbullying using five explicit factors to represent its social and
linguistic aspects. We model this behavior using social network and
language-based features, which improve classifier performance. These results
demonstrate the importance of representing and modeling cyberbullying as a
social phenomenon.",0,1,0,1,0,0,0.823561,11.0,0.903768,42
http://arxiv.org/abs/2001.11757v2,Statistical stability indices for LIME: obtaining reliable explanations for Machine Learning models,116,0.397787,0.863747,"Nowadays we are witnessing a transformation of the business processes towards
a more computation driven approach. The ever increasing usage of Machine
Learning techniques is the clearest example of such trend.
  This sort of revolution is often providing advantages, such as an increase in
prediction accuracy and a reduced time to obtain the results. However, these
methods present a major drawback: it is very difficult to understand on what
grounds the algorithm took the decision.
  To address this issue we consider the LIME method. We give a general
background on LIME then, we focus on the stability issue: employing the method
repeated times, under the same conditions, may yield to different explanations.
  Two complementary indices are proposed, to measure LIME stability. It is
important for the practitioner to be aware of the issue, as well as to have a
tool for spotting it. Stability guarantees LIME explanations to be reliable,
therefore a stability assessment, made through the proposed indices, is
crucial.
  As a case study, we apply both Machine Learning and classical statistical
techniques to Credit Risk data. We test LIME on the Machine Learning algorithm
and check its stability. Eventually, we examine the goodness of the
explanations returned.",1,1,0,0,0,0,0.462123,7.0,0.701818,38
http://arxiv.org/abs/2009.09680v5,Profile Consistency Identification for Open-domain Dialogue Agents,25,0.164029,0.282343,"Maintaining a consistent attribute profile is crucial for dialogue agents to
naturally converse with humans. Existing studies on improving attribute
consistency mainly explored how to incorporate attribute information in the
responses, but few efforts have been made to identify the consistency relations
between response and attribute profile. To facilitate the study of profile
consistency identification, we create a large-scale human-annotated dataset
with over 110K single-turn conversations and their key-value attribute
profiles. Explicit relation between response and profile is manually labeled.
We also propose a key-value structure information enriched BERT model to
identify the profile consistency, and it gained improvements over strong
baselines. Further evaluations on downstream tasks demonstrate that the profile
consistency identification model is conducive for improving dialogue
consistency.",1,1,1,1,0,0,0.782437,5.0,0.762546,30
http://arxiv.org/abs/2007.06290v1,Paranoid Transformer: Reading Narrative of Madness as Computational Approach to Creativity,14,0.297398,0.410642,"This papers revisits the receptive theory in context of computational
creativity. It presents a case study of a Paranoid Transformer - a fully
autonomous text generation engine with raw output that could be read as the
narrative of a mad digital persona without any additional human post-filtering.
We describe technical details of the generative system, provide examples of
output and discuss the impact of receptive theory, chance discovery and
simulation of fringe mental state on the understanding of computational
creativity.",0,0,0,0,0,0,0.374874,8.0,0.70439,52
http://arxiv.org/abs/2002.10640v1,Differentiable Reasoning over a Virtual Knowledge Base,81,0.295512,0.966386,"We consider the task of answering complex multi-hop questions using a corpus
as a virtual knowledge base (KB). In particular, we describe a neural module,
DrKIT, that traverses textual data like a KB, softly following paths of
relations between mentions of entities in the corpus. At each step the module
uses a combination of sparse-matrix TFIDF indices and a maximum inner product
search (MIPS) on a special index of contextual representations of the mentions.
This module is differentiable, so the full system can be trained end-to-end
using gradient based methods, starting from natural language inputs. We also
describe a pretraining scheme for the contextual representation encoder by
generating hard negative examples using existing knowledge bases. We show that
DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset,
cutting the gap between text-based and KB-based state-of-the-art by 70%. On
HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking
approach to retrieving the relevant passages required to answer a question.
DrKIT is also very efficient, processing 10-100x more queries per second than
existing multi-hop systems.",0,0,0,0,1,0,0.761868,4.0,0.68792,49
http://arxiv.org/abs/2006.06649v2,"Closed Loop Neural-Symbolic Learning via Integrating Neural Perception, Grammar Parsing, and Symbolic Reasoning",67,0.248353,0.568394,"The goal of neural-symbolic computation is to integrate the connectionist and
symbolist paradigms. Prior methods learn the neural-symbolic models using
reinforcement learning (RL) approaches, which ignore the error propagation in
the symbolic reasoning module and thus converge slowly with sparse rewards. In
this paper, we address these issues and close the loop of neural-symbolic
learning by (1) introducing the \textbf{grammar} model as a \textit{symbolic
prior} to bridge neural perception and symbolic reasoning, and (2) proposing a
novel \textbf{back-search} algorithm which mimics the top-down human-like
learning procedure to propagate the error through the symbolic reasoning module
efficiently. We further interpret the proposed learning framework as maximum
likelihood estimation using Markov chain Monte Carlo sampling and the
back-search algorithm as a Metropolis-Hastings sampler. The experiments are
conducted on two weakly-supervised neural-symbolic tasks: (1) handwritten
formula recognition on the newly introduced HWF dataset; (2) visual question
answering on the CLEVR dataset. The results show that our approach
significantly outperforms the RL methods in terms of performance, converging
speed, and data efficiency. Our code and data are released at
\url{https://liqing-ustc.github.io/NGS}.",0,0,0,0,0,0,0.421662,6.0,0.631391,69
http://arxiv.org/abs/2011.03088v2,HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification,102,0.587858,0.840338,"We introduce HoVer (HOppy VERification), a dataset for many-hop evidence
extraction and fact verification. It challenges models to extract facts from
several Wikipedia articles that are relevant to a claim and classify whether
the claim is Supported or Not-Supported by the facts. In HoVer, the claims
require evidence to be extracted from as many as four English Wikipedia
articles and embody reasoning graphs of diverse shapes. Moreover, most of the
3/4-hop claims are written in multiple sentences, which adds to the complexity
of understanding long-range dependency relations such as coreference. We show
that the performance of an existing state-of-the-art semantic-matching model
degrades significantly on our dataset as the number of reasoning hops
increases, hence demonstrating the necessity of many-hop reasoning to achieve
strong results. We hope that the introduction of this challenging dataset and
the accompanying evaluation task will encourage research in many-hop fact
retrieval and information verification. We make the HoVer dataset publicly
available at https://hover-nlp.github.io",1,1,1,1,0,0,0.906442,3.0,0.751034,56
http://arxiv.org/abs/2010.03155v1,A Self-Refinement Strategy for Noise Reduction in Grammatical Error Correction,13,0.408155,0.440592,"Existing approaches for grammatical error correction (GEC) largely rely on
supervised learning with manually created GEC datasets. However, there has been
little focus on verifying and ensuring the quality of the datasets, and on how
lower-quality data might affect GEC performance. We indeed found that there is
a non-negligible amount of ""noise"" where errors were inappropriately edited or
left uncorrected. To address this, we designed a self-refinement method where
the key idea is to denoise these datasets by leveraging the prediction
consistency of existing models, and outperformed strong denoising baseline
methods. We further applied task-specific techniques and achieved
state-of-the-art performance on the CoNLL-2014, JFLEG, and BEA-2019 benchmarks.
We then analyzed the effect of the proposed denoising method, and found that
our approach leads to improved coverage of corrections and facilitated fluency
edits which are reflected in higher recall and overall performance.",0,1,0,0,1,0,0.963157,6.0,0.930803,57
http://arxiv.org/abs/2010.02586v2,Knowing What You Know: Calibrating Dialogue Belief State Distributions via Ensembles,6,0.0981601,0.270096,"The ability to accurately track what happens during a conversation is
essential for the performance of a dialogue system. Current state-of-the-art
multi-domain dialogue state trackers achieve just over 55% accuracy on the
current go-to benchmark, which means that in almost every second dialogue turn
they place full confidence in an incorrect dialogue state. Belief trackers, on
the other hand, maintain a distribution over possible dialogue states. However,
they lack in performance compared to dialogue state trackers, and do not
produce well calibrated distributions. In this work we present state-of-the-art
performance in calibration for multi-domain dialogue belief trackers using a
calibrated ensemble of models. Our resulting dialogue belief tracker also
outperforms previous dialogue belief tracking models in terms of accuracy.",0,1,0,0,1,0,0.962112,4.0,0.894076,26
http://arxiv.org/abs/2009.02711v2,Efficient Pedestrian Detection in Top-View Fisheye Images Using Compositions of Perspective View Patches,24,0.123932,0.574033,"Pedestrian detection in images is a topic that has been studied extensively,
but existing detectors designed for perspective images do not perform as
successfully on images taken with top-view fisheye cameras, mainly due to the
orientation variation of people in such images. In our proposed approach,
several perspective views are generated from a fisheye image and then
concatenated to form a composite image. As pedestrians in this composite image
are more likely to be upright, existing detectors designed and trained for
perspective images can be applied directly without additional training. We also
describe a new method of mapping detection bounding boxes from the perspective
views to the fisheye frame. The detection performance on several public
datasets compare favorably with state-of-the-art results.",1,1,0,0,1,0,0.016969,11.0,0.483886,35
http://arxiv.org/abs/2011.07868v1,Evaluating Sentence Segmentation and Word Tokenization Systems on Estonian Web Texts,4,0.00574989,0.0332029,"Texts obtained from web are noisy and do not necessarily follow the
orthographic sentence and word boundary rules. Thus, sentence segmentation and
word tokenization systems that have been developed on well-formed texts might
not perform so well on unedited web texts. In this paper, we first describe the
manual annotation of sentence boundaries of an Estonian web dataset and then
present the evaluation results of three existing sentence segmentation and word
tokenization systems on this corpus: EstNLTK, Stanza and UDPipe. While EstNLTK
obtains the highest performance compared to other systems on sentence
segmentation on this dataset, the sentence segmentation performance of Stanza
and UDPipe remains well below the results obtained on the more well-formed
Estonian UD test set.",0,1,0,1,0,0,0.00541868,9.0,0.241708,16
http://arxiv.org/abs/2010.08437v1,Deep Learning based Automated Forest Health Diagnosis from Aerial Images,44,0.789285,0.588939,"Global climate change has had a drastic impact on our environment. Previous
study showed that pest disaster occured from global climate change may cause a
tremendous number of trees died and they inevitably became a factor of forest
fire. An important portent of the forest fire is the condition of forests.
Aerial image-based forest analysis can give an early detection of dead trees
and living trees. In this paper, we applied a synthetic method to enlarge
imagery dataset and present a new framework for automated dead tree detection
from aerial images using a re-trained Mask RCNN (Mask Region-based
Convolutional Neural Network) approach, with a transfer learning scheme. We
apply our framework to our aerial imagery datasets,and compare eight fine-tuned
models. The mean average precision score (mAP) for the best of these models
reaches 54%. Following the automated detection, we are able to automatically
produce and calculate number of dead tree masks to label the dead trees in an
image, as an indicator of forest health that could be linked to the causal
analysis of environmental changes and the predictive likelihood of forest fire.",0,1,0,0,0,0,0.810126,8.0,0.862278,59
http://arxiv.org/abs/2002.08348v1,Extracting Semantic Indoor Maps from Occupancy Grids,36,0.348504,0.410829,"The primary challenge for any autonomous system operating in realistic,
rather unconstrained scenarios is to manage the complexity and uncertainty of
the real world. While it is unclear how exactly humans and other higher animals
master these problems, it seems evident, that abstraction plays an important
role. The use of abstract concepts allows to define the system behavior on
higher levels. In this paper we focus on the semantic mapping of indoor
environments. We propose a method to extract an abstracted floor plan from
typical grid maps using Bayesian reasoning. The result of this procedure is a
probabilistic generative model of the environment defined over abstract
concepts. It is well suited for higher-level reasoning and communication
purposes. We demonstrate the effectiveness of the approach using real-world
data.",0,0,0,0,0,0,0.0124087,15.0,0.600496,36
http://arxiv.org/abs/2004.14356v1,AxCell: Automatic Extraction of Results from Machine Learning Papers,52,0.118084,0.540522,"Tracking progress in machine learning has become increasingly difficult with
the recent explosion in the number of papers. In this paper, we present AxCell,
an automatic machine learning pipeline for extracting results from papers.
AxCell uses several novel components, including a table segmentation subtask,
to learn relevant structural knowledge that aids extraction. When compared with
existing methods, our approach significantly improves the state of the art for
results extraction. We also release a structured, annotated dataset for
training models for results extraction, and a dataset for evaluating the
performance of models on this task. Lastly, we show the viability of our
approach enables it to be used for semi-automated results extraction in
production, suggesting our improvements make this task practically viable for
the first time. Code is available on GitHub.",0,1,0,1,1,0,0.483766,5.0,0.595371,15
http://arxiv.org/abs/2011.10369v3,ONION: A Simple and Effective Defense Against Textual Backdoor Attacks,165,0.997685,0.909749,"Backdoor attacks are a kind of emergent training-time threat to deep neural
networks (DNNs). They can manipulate the output of DNNs and possess high
insidiousness. In the field of natural language processing, some attack methods
have been proposed and achieve very high attack success rates on multiple
popular models. Nevertheless, there are few studies on defending against
textual backdoor attacks. In this paper, we propose a simple and effective
textual backdoor defense named ONION, which is based on outlier word detection
and, to the best of our knowledge, is the first method that can handle all the
textual backdoor attack situations. Experiments demonstrate the effectiveness
of our model in defending BiLSTM and BERT against five different backdoor
attacks. All the code and data of this paper can be obtained at
https://github.com/thunlp/ONION.",1,1,0,0,0,0,0.992792,4.0,0.996602,30
http://arxiv.org/abs/2010.09600v2,Drug Repurposing for COVID-19 via Knowledge Graph Completion,113,0.86341,0.935665,"Objective: To discover candidate drugs to repurpose for COVID-19 using
literature-derived knowledge and knowledge graph completion methods. Methods:
We propose a novel, integrative, and neural network-based literature-based
discovery (LBD) approach to identify drug candidates from both PubMed and
COVID-19-focused research literature. Our approach relies on semantic triples
extracted using SemRep (via SemMedDB). We identified an informative subset of
semantic triples using filtering rules and an accuracy classifier developed on
a BERT variant, and used this subset to construct a knowledge graph. Five SOTA,
neural knowledge graph completion algorithms were used to predict drug
repurposing candidates. The models were trained and assessed using a time
slicing approach and the predicted drugs were compared with a list of drugs
reported in the literature and evaluated in clinical trials. These models were
complemented by a discovery pattern-based approach. Results: Accuracy
classifier based on PubMedBERT achieved the best performance (F1= 0.854) in
classifying semantic predications. Among five knowledge graph completion
models, TransE outperformed others (MR = 0.923, Hits@1=0.417). Some known drugs
linked to COVID-19 in the literature were identified, as well as some candidate
drugs that have not yet been studied. Discovery patterns enabled generation of
plausible hypotheses regarding the relationships between the candidate drugs
and COVID-19. Among them, five highly ranked and novel drugs (paclitaxel, SB
203580, alpha 2-antiplasmin, pyrrolidine dithiocarbamate, and butylated
hydroxytoluene) with their mechanistic explanations were further discussed.
Conclusion: We show that an LBD approach can be feasible for discovering drug
candidates for COVID-19, and for generating mechanistic explanations. Our
approach can be generalized to other diseases as well as to other clinical
questions.",1,1,0,0,0,0,0.748847,6.0,0.785645,130
http://arxiv.org/abs/2010.12919v5,Causal Effects of Linguistic Properties,33,0.137643,0.517155,"We consider the problem of using observational data to estimate the causal
effects of linguistic properties. For example, does writing a complaint
politely lead to a faster response time? How much will a positive product
review increase sales? This paper addresses two technical challenges related to
the problem before developing a practical method. First, we formalize the
causal quantity of interest as the effect of a writer's intent, and establish
the assumptions necessary to identify this from observational data. Second, in
practice, we only have access to noisy proxies for the linguistic properties of
interest -- e.g., predictions from classifiers and lexicons. We propose an
estimator for this setting and prove that its bias is bounded when we perform
an adjustment for the text. Based on these results, we introduce TextCause, an
algorithm for estimating causal effects of linguistic properties. The method
leverages (1) distant supervision to improve the quality of noisy proxies, and
(2) a pre-trained language model (BERT) to adjust for the text. We show that
the proposed method outperforms related approaches when estimating the effect
of Amazon review sentiment on semi-simulated sales figures. Finally, we present
an applied case study investigating the effects of complaint politeness on
bureaucratic response times.",1,0,0,0,0,0,0.108589,9.0,0.580811,63
http://arxiv.org/abs/2011.03020v1,Quantifying Intimacy in Language,46,0.227882,0.78107,"Intimacy is a fundamental aspect of how we relate to others in social
settings. Language encodes the social information of intimacy through both
topics and other more subtle cues (such as linguistic hedging and swearing).
Here, we introduce a new computational framework for studying expressions of
the intimacy in language with an accompanying dataset and deep learning model
for accurately predicting the intimacy level of questions (Pearson's r=0.87).
Through analyzing a dataset of 80.5M questions across social media, books, and
films, we show that individuals employ interpersonal pragmatic moves in their
language to align their intimacy with social settings. Then, in three studies,
we further demonstrate how individuals modulate their intimacy to match social
norms around gender, social distance, and audience, each validating key
findings from studies in social psychology. Our work demonstrates that intimacy
is a pervasive and impactful social dimension of language.",1,0,1,1,0,0,0.00420978,20.0,0.646116,134
http://arxiv.org/abs/2010.12512v1,Generating Plausible Counterfactual Explanations for Deep Transformers in Financial Text Classification,54,0.400709,0.819124,"Corporate mergers and acquisitions (M&A) account for billions of dollars of
investment globally every year, and offer an interesting and challenging domain
for artificial intelligence. However, in these highly sensitive domains, it is
crucial to not only have a highly robust and accurate model, but be able to
generate useful explanations to garner a user's trust in the automated system.
Regrettably, the recent research regarding eXplainable AI (XAI) in financial
text classification has received little to no attention, and many current
methods for generating textual-based explanations result in highly implausible
explanations, which damage a user's trust in the system. To address these
issues, this paper proposes a novel methodology for producing plausible
counterfactual explanations, whilst exploring the regularization benefits of
adversarial training on language models in the domain of FinTech. Exhaustive
quantitative experiments demonstrate that not only does this approach improve
the model accuracy when compared to the current state-of-the-art and human
performance, but it also generates counterfactual explanations which are
significantly more plausible based on human trials.",0,1,0,0,1,0,0.72311,5.0,0.72813,37
http://arxiv.org/abs/2003.04857v2,Image Restoration for Under-Display Camera,51,0.155207,0.817296,"The new trend of full-screen devices encourages us to position a camera
behind a screen. Removing the bezel and centralizing the camera under the
screen brings larger display-to-body ratio and enhances eye contact in video
chat, but also causes image degradation. In this paper, we focus on a
newly-defined Under-Display Camera (UDC), as a novel real-world single image
restoration problem. First, we take a 4k Transparent OLED (T-OLED) and a phone
Pentile OLED (P-OLED) and analyze their optical systems to understand the
degradation. Second, we design a Monitor-Camera Imaging System (MCIS) for
easier real pair data acquisition, and a model-based data synthesizing pipeline
to generate Point Spread Function (PSF) and UDC data only from display pattern
and camera measurements. Finally, we resolve the complicated degradation using
deconvolution-based pipeline and learning-based methods. Our model demonstrates
a real-time high-quality restoration. The presented methods and results reveal
the promising research values and directions of UDC.",0,1,1,1,0,0,0.550838,4.0,0.541971,52
http://arxiv.org/abs/2004.03327v3,Cascaded Refinement Network for Point Cloud Completion,196,0.82831,0.960048,"Point clouds are often sparse and incomplete. Existing shape completion
methods are incapable of generating details of objects or learning the complex
point distributions. To this end, we propose a cascaded refinement network
together with a coarse-to-fine strategy to synthesize the detailed object
shapes. Considering the local details of partial input with the global shape
information together, we can preserve the existing details in the incomplete
point set and generate the missing parts with high fidelity. We also design a
patch discriminator that guarantees every local area has the same pattern with
the ground truth to learn the complicated point distribution. Quantitative and
qualitative experiments on different datasets show that our method achieves
superior results compared to existing state-of-the-art approaches on the 3D
point cloud completion task. Our source code is available at
https://github.com/xiaogangw/cascaded-point-completion.git.",1,1,0,0,1,0,0.960663,5.0,0.912955,54
http://arxiv.org/abs/2011.00259v2,Rumor Detection on Twitter Using Multiloss Hierarchical BiLSTM with an Attenuation Factor,9,0.146982,0.057654,"Social media platforms such as Twitter have become a breeding ground for
unverified information or rumors. These rumors can threaten people's health,
endanger the economy, and affect the stability of a country. Many researchers
have developed models to classify rumors using traditional machine learning or
vanilla deep learning models. However, previous studies on rumor detection have
achieved low precision and are time consuming. Inspired by the hierarchical
model and multitask learning, a multiloss hierarchical BiLSTM model with an
attenuation factor is proposed in this paper. The model is divided into two
BiLSTM modules: post level and event level. By means of this hierarchical
structure, the model can extract deep in-formation from limited quantities of
text. Each module has a loss function that helps to learn bilateral features
and reduce the training time. An attenuation fac-tor is added at the post level
to increase the accuracy. The results on two rumor datasets demonstrate that
our model achieves better performance than that of state-of-the-art machine
learning and vanilla deep learning models.",0,1,0,0,1,0,0.706054,8.0,0.824123,32
http://arxiv.org/abs/2003.13032v1,Named Entities in Medical Case Reports: Corpus and Experiments,9,0.12622,0.292478,"We present a new corpus comprising annotations of medical entities in case
reports, originating from PubMed Central's open access library. In the case
reports, we annotate cases, conditions, findings, factors and negation
modifiers. Moreover, where applicable, we annotate relations between these
entities. As such, this is the first corpus of this kind made available to the
scientific community in English. It enables the initial investigation of
automatic information extraction from case reports through tasks like Named
Entity Recognition, Relation Extraction and (sentence/paragraph) relevance
detection. Additionally, we present four strong baseline systems for the
detection of medical entities made available through the annotated dataset.",0,1,1,1,0,0,0.801217,6.0,0.811705,30
http://arxiv.org/abs/2010.10474v2,Towards Maximizing the Representation Gap between In-Domain & Out-of-Distribution Examples,47,0.165506,0.799453,"Among existing uncertainty estimation approaches, Dirichlet Prior Network
(DPN) distinctly models different predictive uncertainty types. However, for
in-domain examples with high data uncertainties among multiple classes, even a
DPN model often produces indistinguishable representations from the
out-of-distribution (OOD) examples, compromising their OOD detection
performance. We address this shortcoming by proposing a novel loss function for
DPN to maximize the \textit{representation gap} between in-domain and OOD
examples. Experimental results demonstrate that our proposed approach
consistently improves OOD detection performance.",1,1,0,0,0,0,0.745391,8.0,0.837991,40
http://arxiv.org/abs/2007.05515v3,AViD Dataset: Anonymized Videos from Diverse Countries,30,0.0868772,0.546596,"We introduce a new public video dataset for action recognition: Anonymized
Videos from Diverse countries (AViD). Unlike existing public video datasets,
AViD is a collection of action videos from many different countries. The
motivation is to create a public dataset that would benefit training and
pretraining of action recognition models for everybody, rather than making it
useful for limited countries. Further, all the face identities in the AViD
videos are properly anonymized to protect their privacy. It also is a static
dataset where each video is licensed with the creative commons license. We
confirm that most of the existing video datasets are statistically biased to
only capture action videos from a limited number of countries. We
experimentally illustrate that models trained with such biased datasets do not
transfer perfectly to action videos from the other countries, and show that
AViD addresses such problem. We also confirm that the new AViD dataset could
serve as a good dataset for pretraining the models, performing comparably or
better than prior datasets.",1,1,1,1,0,0,0.28267,7.0,0.612658,32
http://arxiv.org/abs/2005.06128v1,Response-Anticipated Memory for On-Demand Knowledge Integration in Response Generation,25,0.138374,0.556525,"Neural conversation models are known to generate appropriate but
non-informative responses in general. A scenario where informativeness can be
significantly enhanced is Conversing by Reading (CbR), where conversations take
place with respect to a given external document. In previous work, the external
document is utilized by (1) creating a context-aware document memory that
integrates information from the document and the conversational context, and
then (2) generating responses referring to the memory. In this paper, we
propose to create the document memory with some anticipated responses in mind.
This is achieved using a teacher-student framework. The teacher is given the
external document, the context, and the ground-truth response, and learns how
to build a response-aware document memory from three sources of information.
The student learns to construct a response-anticipated document memory from the
first two sources, and the teacher's insight on memory creation. Empirical
results show that our model outperforms the previous state-of-the-art for the
CbR task.",1,1,0,0,1,0,0.623499,7.0,0.766732,39
http://arxiv.org/abs/2006.05210v1,Neural Network Activation Quantization with Bitwise Information Bottlenecks,1,0.00933918,0.0178465,"Recent researches on information bottleneck shed new light on the continuous
attempts to open the black box of neural signal encoding. Inspired by the
problem of lossy signal compression for wireless communication, this paper
presents a Bitwise Information Bottleneck approach for quantizing and encoding
neural network activations. Based on the rate-distortion theory, the Bitwise
Information Bottleneck attempts to determine the most significant bits in
activation representation by assigning and approximating the sparse coefficient
associated with each bit. Given the constraint of a limited average code rate,
the information bottleneck minimizes the rate-distortion for optimal activation
quantization in a flexible layer-by-layer manner. Experiments over ImageNet and
other datasets show that, by minimizing the quantization rate-distortion of
each layer, the neural network with information bottlenecks achieves the
state-of-the-art accuracy with low-precision activation. Meanwhile, by reducing
the code rate, the proposed method can improve the memory and computational
efficiency by over six times compared with the deep neural network with
standard single-precision representation. Codes will be available on GitHub
when the paper is accepted \url{https://github.com/BitBottleneck/PublicCode}.",1,0,1,0,1,0,0.673812,8.0,0.813018,37
http://arxiv.org/abs/2010.12949v1,Advancing Non-Contact Vital Sign Measurement using Synthetic Avatars,22,0.774149,0.652317,"Non-contact physiological measurement has the potential to provide low-cost,
non-invasive health monitoring. However, machine vision approaches are often
limited by the availability and diversity of annotated video datasets resulting
in poor generalization to complex real-life conditions. To address these
challenges, this work proposes the use of synthetic avatars that display facial
blood flow changes and allow for systematic generation of samples under a wide
variety of conditions. Our results show that training on both simulated and
real video data can lead to performance gains under challenging conditions. We
show state-of-the-art performance on three large benchmark datasets and
improved robustness to skin type and motion.",0,1,0,1,1,0,0.927479,10.0,0.935522,56
http://arxiv.org/abs/2012.09421v4,Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning,33,0.251042,0.706868,"We consider the problem of learning fair policies in (deep) cooperative
multi-agent reinforcement learning (MARL). We formalize it in a principled way
as the problem of optimizing a welfare function that explicitly encodes two
important aspects of fairness: efficiency and equity. As a solution method, we
propose a novel neural network architecture, which is composed of two
sub-networks specifically designed for taking into account the two aspects of
fairness. In experiments, we demonstrate the importance of the two sub-networks
for fair optimization. Our overall approach is general as it can accommodate
any (sub)differentiable welfare function. Therefore, it is compatible with
various notions of fairness that have been proposed in the literature (e.g.,
lexicographic maximin, generalized Gini social welfare function, proportional
fairness). Our solution method is generic and can be implemented in various
MARL settings: centralized training and decentralized execution, or fully
decentralized. Finally, we experimentally validate our approach in various
domains and show that it can perform much better than previous methods.",1,0,0,0,1,0,0.394933,8.0,0.71278,61
http://arxiv.org/abs/2009.04202v1,Impact of News on the Commodity Market: Dataset and Results,42,0.808069,0.851451,"Over the last few years, machine learning based methods have been applied to
extract information from news flow in the financial domain. However, this
information has mostly been in the form of the financial sentiments contained
in the news headlines, primarily for the stock prices. In our current work, we
propose that various other dimensions of information can be extracted from news
headlines, which will be of interest to investors, policy-makers and other
practitioners. We propose a framework that extracts information such as past
movements and expected directionality in prices, asset comparison and other
general information that the news is referring to. We apply this framework to
the commodity ""Gold"" and train the machine learning models using a dataset of
11,412 human-annotated news headlines (released with this study), collected
from the period 2000-2019. We experiment to validate the causal effect of news
flow on gold prices and observe that the information produced from our
framework significantly impacts the future gold price.",0,1,0,1,0,0,0.216124,18.0,0.832108,32
http://arxiv.org/abs/2006.02786v3,"Multi-talker ASR for an unknown number of sources: Joint training of source counting, separation and ASR",37,0.600701,0.857828,"Most approaches to multi-talker overlapped speech separation and recognition
assume that the number of simultaneously active speakers is given, but in
realistic situations, it is typically unknown. To cope with this, we extend an
iterative speech extraction system with mechanisms to count the number of
sources and combine it with a single-talker speech recognizer to form the first
end-to-end multi-talker automatic speech recognition system for an unknown
number of active speakers. Our experiments show very promising performance in
counting accuracy, source separation and speech recognition on simulated clean
mixtures from WSJ0-2mix and WSJ0-3mix. Among others, we set a new
state-of-the-art word error rate on the WSJ0-2mix database. Furthermore, our
system generalizes well to a larger number of speakers than it ever saw during
training, as shown in experiments with the WSJ0-4mix database.",0,1,0,0,1,0,0.940395,5.0,0.885461,32
http://arxiv.org/abs/2006.05724v1,Real-time single image depth perception in the wild with handheld devices,35,0.39738,0.664138,"Depth perception is paramount to tackle real-world problems, ranging from
autonomous driving to consumer applications. For the latter, depth estimation
from a single image represents the most versatile solution, since a standard
camera is available on almost any handheld device. Nonetheless, two main issues
limit its practical deployment: i) the low reliability when deployed
in-the-wild and ii) the demanding resource requirements to achieve real-time
performance, often not compatible with such devices. Therefore, in this paper,
we deeply investigate these issues showing how they are both addressable
adopting appropriate network design and training strategies -- also outlining
how to map the resulting networks on handheld devices to achieve real-time
performance. Our thorough evaluation highlights the ability of such fast
networks to generalize well to new environments, a crucial feature required to
tackle the extremely varied contexts faced in real applications. Indeed, to
further support this evidence, we report experimental results concerning
real-time depth-aware augmented reality and image blurring with smartphones
in-the-wild.",1,1,0,0,0,0,0.94306,5.0,0.888679,56
http://arxiv.org/abs/2001.00583v1,On the Mutual Information between Source and Filter Contributions for Voice Pathology Detection,26,0.364242,0.798819,"This paper addresses the problem of automatic detection of voice pathologies
directly from the speech signal. For this, we investigate the use of the
glottal source estimation as a means to detect voice disorders. Three sets of
features are proposed, depending on whether they are related to the speech or
the glottal signal, or to prosody. The relevancy of these features is assessed
through mutual information-based measures. This allows an intuitive
interpretation in terms of discrimation power and redundancy between the
features, independently of any subsequent classifier. It is discussed which
characteristics are interestingly informative or complementary for detecting
voice pathologies.",0,1,0,0,0,0,0.0351529,42.0,0.882389,21
http://arxiv.org/abs/2009.07602v1,UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation,59,0.422438,0.925626,"Despite the success of existing referenced metrics (e.g., BLEU and
MoverScore), they correlate poorly with human judgments for open-ended text
generation including story or dialog generation because of the notorious
one-to-many issue: there are many plausible outputs for the same input, which
may differ substantially in literal or semantics from the limited number of
given references. To alleviate this issue, we propose UNION, a learnable
unreferenced metric for evaluating open-ended story generation, which measures
the quality of a generated story without any reference. Built on top of BERT,
UNION is trained to distinguish human-written stories from negative samples and
recover the perturbation in negative stories. We propose an approach of
constructing negative samples by mimicking the errors commonly observed in
existing NLG models, including repeated plots, conflicting logic, and
long-range incoherence. Experiments on two story datasets demonstrate that
UNION is a reliable measure for evaluating the quality of generated stories,
which correlates better with human judgments and is more generalizable than
existing state-of-the-art metrics.",1,0,0,0,1,0,0.892152,5.0,0.838247,38
http://arxiv.org/abs/2003.00393v1,Deep Active Learning for Biased Datasets via Fisher Kernel Self-Supervision,51,0.114692,0.608671,"Active learning (AL) aims to minimize labeling efforts for data-demanding
deep neural networks (DNNs) by selecting the most representative data points
for annotation. However, currently used methods are ill-equipped to deal with
biased data. The main motivation of this paper is to consider a realistic
setting for pool-based semi-supervised AL, where the unlabeled collection of
train data is biased. We theoretically derive an optimal acquisition function
for AL in this setting. It can be formulated as distribution shift minimization
between unlabeled train data and weakly-labeled validation dataset. To
implement such acquisition function, we propose a low-complexity method for
feature density matching using self-supervised Fisher kernel (FK) as well as
several novel pseudo-label estimators. Our FK-based method outperforms
state-of-the-art methods on MNIST, SVHN, and ImageNet classification while
requiring only 1/10th of processing. The conducted experiments show at least
40% drop in labeling efforts for the biased class-imbalanced data compared to
existing methods.",1,1,0,0,1,0,0.845019,6.0,0.835588,29
http://arxiv.org/abs/2008.02496v3,ConvBERT: Improving BERT with Span-based Dynamic Convolution,134,0.262933,0.951924,"Pre-trained language models like BERT and its variants have recently achieved
impressive performance in various natural language understanding tasks.
However, BERT heavily relies on the global self-attention block and thus
suffers large memory footprint and computation cost. Although all its attention
heads query on the whole input sequence for generating the attention map from a
global perspective, we observe some heads only need to learn local
dependencies, which means the existence of computation redundancy. We therefore
propose a novel span-based dynamic convolution to replace these self-attention
heads to directly model local dependencies. The novel convolution heads,
together with the rest self-attention heads, form a new mixed attention block
that is more efficient at both global and local context learning. We equip BERT
with this mixed attention design and build a ConvBERT model. Experiments have
shown that ConvBERT significantly outperforms BERT and its variants in various
downstream tasks, with lower training cost and fewer model parameters.
Remarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than
ELECTRAbase, while using less than 1/4 training cost. Code and pre-trained
models will be released.",1,1,0,0,1,0,0.92495,4.0,0.835517,78
http://arxiv.org/abs/2010.06307v1,How important are faces for person re-identification?,21,0.114492,0.559468,"This paper investigates the dependence of existing state-of-the-art person
re-identification models on the presence and visibility of human faces. We
apply a face detection and blurring algorithm to create anonymized versions of
several popular person re-identification datasets including Market1501,
DukeMTMC-reID, CUHK03, Viper, and Airport. Using a cross-section of existing
state-of-the-art models that range in accuracy and computational efficiency, we
evaluate the effect of this anonymization on re-identification performance
using standard metrics. Perhaps surprisingly, the effect on mAP is very small,
and accuracy is recovered by simply training on the anonymized versions of the
data rather than the original data. These findings are consistent across
multiple models and datasets. These results indicate that datasets can be
safely anonymized by blurring faces without significantly impacting the
performance of person reidentification systems, and may allow for the release
of new richer re-identification datasets where previously there were privacy or
data protection concerns.",1,1,0,0,0,0,0.477943,6.0,0.659958,44
http://arxiv.org/abs/2010.11062v1,Deep Q-Network-based Adaptive Alert Threshold Selection Policy for Payment Fraud Systems in Retail Banking,17,0.412952,0.757271,"Machine learning models have widely been used in fraud detection systems.
Most of the research and development efforts have been concentrated on
improving the performance of the fraud scoring models. Yet, the downstream
fraud alert systems still have limited to no model adoption and rely on manual
steps. Alert systems are pervasively used across all payment channels in retail
banking and play an important role in the overall fraud detection process.
Current fraud detection systems end up with large numbers of dropped alerts due
to their inability to account for the alert processing capacity. Ideally, alert
threshold selection enables the system to maximize the fraud detection while
balancing the upstream fraud scores and the available bandwidth of the alert
processing teams. However, in practice, fixed thresholds that are used for
their simplicity do not have this ability. In this paper, we propose an
enhanced threshold selection policy for fraud alert systems. The proposed
approach formulates the threshold selection as a sequential decision making
problem and uses Deep Q-Network based reinforcement learning. Experimental
results show that this adaptive approach outperforms the current static
solutions by reducing the fraud losses as well as improving the operational
efficiency of the alert system.",0,1,0,0,0,0,0.821078,10.0,0.893335,37
http://arxiv.org/abs/2009.08978v3,Modeling Online Behavior in Recommender Systems: The Importance of Temporal Context,8,0.0265655,0.171463,"Recommender systems research tends to evaluate model performance offline and
on randomly sampled targets, yet the same systems are later used to predict
user behavior sequentially from a fixed point in time. Simulating online
recommender system performance is notoriously difficult and the discrepancy
between online and offline behaviors is typically not accounted for in offline
evaluations. This disparity permits weaknesses to go unnoticed until the model
is deployed in a production setting. In this paper, we first demonstrate how
omitting temporal context when evaluating recommender system performance leads
to false confidence. To overcome this, we postulate that offline evaluation
protocols can only model real-life use-cases if they account for temporal
context. Next, we propose a training procedure to further embed the temporal
context in existing models. We use a multi-objective approach to introduce
temporal context into traditionally time-unaware recommender systems and
confirm its advantage via the proposed evaluation protocol. Finally, we
validate that the Pareto Fronts obtained with the added objective dominate
those produced by state-of-the-art models that are only optimized for accuracy
on three real-world publicly available datasets. The results show that
including our temporal objective can improve recall@20 by up to 20%.",1,0,0,0,0,0,0.252514,8.0,0.644533,28
http://arxiv.org/abs/2008.09982v1,Spending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection,8,0.134114,0.44591,"Online electronic coupon (e-coupon) is becoming a primary tool for e-commerce
platforms to attract users to place orders. E-coupons are the digital
equivalent of traditional paper coupons which provide customers with discounts
or gifts. One of the fundamental problems related is how to deliver e-coupons
with minimal cost while users' willingness to place an order is maximized. We
call this problem the coupon allocation problem. This is a non-trivial problem
since the number of regular users on a mature e-platform often reaches hundreds
of millions and the types of e-coupons to be allocated are often multiple. The
policy space is extremely large and the online allocation has to satisfy a
budget constraint. Besides, one can never observe the responses of one user
under different policies which increases the uncertainty of the policy making
process. Previous work fails to deal with these challenges. In this paper, we
decompose the coupon allocation task into two subtasks: the user intent
detection task and the allocation task. Accordingly, we propose a two-stage
solution: at the first stage (detection stage), we put forward a novel
Instantaneous Intent Detection Network (IIDN) which takes the user-coupon
features as input and predicts user real-time intents; at the second stage
(allocation stage), we model the allocation problem as a Multiple-Choice
Knapsack Problem (MCKP) and provide a computational efficient allocation method
using the intents predicted at the detection stage. We conduct extensive online
and offline experiments and the results show the superiority of our proposed
framework, which has brought great profits to the platform and continues to
function online.",0,1,0,0,0,0,0.423982,8.0,0.724458,37
http://arxiv.org/abs/2012.08919v2,Multilingual Evidence Retrieval and Fact Verification to Combat Global Disinformation: The Power of Polyglotism,3,0.0060287,0.0946884,"This article investigates multilingual evidence retrieval and fact
verification as a step to combat global disinformation, a first effort of this
kind, to the best of our knowledge. The goal is building multilingual systems
that retrieve in evidence-rich languages to verify claims in evidence-poor
languages that are more commonly targeted by disinformation. To this end, our
EnmBERT fact verification system shows evidence of transfer learning ability
and 400 example mixed English-Romanian dataset is made available for
cross-lingual transfer learning evaluation.",0,1,0,1,0,0,0.440431,5.0,0.56937,44
http://arxiv.org/abs/2011.03363v1,Domain Adaptive Person Re-Identification via Coupling Optimization,35,0.183441,0.76179,"Domain adaptive person Re-Identification (ReID) is challenging owing to the
domain gap and shortage of annotations on target scenarios. To handle those two
challenges, this paper proposes a coupling optimization method including the
Domain-Invariant Mapping (DIM) method and the Global-Local distance
Optimization (GLO), respectively. Different from previous methods that transfer
knowledge in two stages, the DIM achieves a more efficient one-stage knowledge
transfer by mapping images in labeled and unlabeled datasets to a shared
feature space. GLO is designed to train the ReID model with unsupervised
setting on the target domain. Instead of relying on existing optimization
strategies designed for supervised training, GLO involves more images in
distance optimization, and achieves better robustness to noisy label
prediction. GLO also integrates distance optimizations in both the global
dataset and local training batch, thus exhibits better training efficiency.
Extensive experiments on three large-scale datasets, i.e., Market-1501,
DukeMTMC-reID, and MSMT17, show that our coupling optimization outperforms
state-of-the-art methods by a large margin. Our method also works well in
unsupervised training, and even outperforms several recent domain adaptive
methods.",0,1,0,0,1,0,0.656563,5.0,0.691411,63
http://arxiv.org/abs/2011.12715v1,Resonance: Replacing Software Constants with Context-Aware Models in Real-time Communication,1,0.00540545,0.0326107,"Large software systems tune hundreds of 'constants' to optimize their runtime
performance. These values are commonly derived through intuition, lab tests, or
A/B tests. A 'one-size-fits-all' approach is often sub-optimal as the best
value depends on runtime context. In this paper, we provide an experimental
approach to replace constants with learned contextual functions for Skype - a
widely used real-time communication (RTC) application. We present Resonance, a
system based on contextual bandits (CB). We describe experiences from three
real-world experiments: applying it to the audio, video, and transport
components in Skype. We surface a unique and practical challenge of performing
machine learning (ML) inference in large software systems written using
encapsulation principles. Finally, we open-source FeatureBroker, a library to
reduce the friction in adopting ML models in such development environments",0,1,0,0,0,0,0.393275,5.0,0.539355,20
http://arxiv.org/abs/2010.02686v1,"BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking Scalar Adjectives with Contextualised Representations",17,0.0891718,0.689057,"Adjectives like pretty, beautiful and gorgeous describe positive properties
of the nouns they modify but with different intensity. These differences are
important for natural language understanding and reasoning. We propose a novel
BERT-based approach to intensity detection for scalar adjectives. We model
intensity by vectors directly derived from contextualised representations and
show they can successfully rank scalar adjectives. We evaluate our models both
intrinsically, on gold standard datasets, and on an Indirect Question Answering
task. Our results demonstrate that BERT encodes rich knowledge about the
semantics of scalar adjectives, and is able to provide better quality intensity
rankings than static embeddings and previous models with access to dedicated
resources.",1,0,0,0,0,0,0.187698,9.0,0.646643,56
http://arxiv.org/abs/2003.11631v2,Choice functions based on sets of strict partial orders: an axiomatic characterisation,4,0.00982571,0.154822,"Methods for choosing from a set of options are often based on a strict
partial order on these options, or on a set of such partial orders. I here
provide a very general axiomatic characterisation for choice functions of this
form. It includes as special cases axiomatic characterisations for choice
functions based on (sets of) total orders, (sets of) weak orders, (sets of)
coherent lower previsions and (sets of) probability measures.",0,0,0,0,0,0,0.0490929,6.0,0.233597,13
http://arxiv.org/abs/2009.12812v3,TernaryBERT: Distillation-aware Ultra-low Bit BERT,172,0.219608,0.765891,"Transformer-based pre-training models like BERT have achieved remarkable
performance in many natural language processing tasks.However, these models are
both computation and memory expensive, hindering their deployment to
resource-constrained devices. In this work, we propose TernaryBERT, which
ternarizes the weights in a fine-tuned BERT model. Specifically, we use both
approximation-based and loss-aware ternarization methods and empirically
investigate the ternarization granularity of different parts of BERT. Moreover,
to reduce the accuracy degradation caused by the lower capacity of low bits, we
leverage the knowledge distillation technique in the training process.
Experiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT
outperforms the other BERT quantization methods, and even achieves comparable
performance as the full-precision model while being 14.9x smaller.",1,1,0,0,1,0,0.7545,3.0,0.576738,40
http://arxiv.org/abs/2009.12562v1,Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach,67,0.84327,0.833365,"A critical concern in data-driven decision making is to build models whose
outcomes do not discriminate against some demographic groups, including gender,
ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of
the sensitive attributes is essential, while, in practice, these attributes may
not be available due to legal and ethical requirements. To address this
challenge, this paper studies a model that protects the privacy of the
individuals sensitive information while also allowing it to learn
non-discriminatory predictors. The method relies on the notion of differential
privacy and the use of Lagrangian duality to design neural networks that can
accommodate fairness constraints while guaranteeing the privacy of sensitive
attributes. The paper analyses the tension between accuracy, privacy, and
fairness and the experimental evaluation illustrates the benefits of the
proposed model on several prediction tasks.",0,0,0,0,0,0,0.960232,6.0,0.926899,47
http://arxiv.org/abs/2001.06684v3,"How do Data Science Workers Collaborate? Roles, Workflows, and Tools",210,0.888646,0.99772,"Today, the prominence of data science within organizations has given rise to
teams of data science workers collaborating on extracting insights from data,
as opposed to individual data scientists working alone. However, we still lack
a deep understanding of how data science workers collaborate in practice. In
this work, we conducted an online survey with 183 participants who work in
various aspects of data science. We focused on their reported interactions with
each other (e.g., managers with engineers) and with different tools (e.g.,
Jupyter Notebook). We found that data science teams are extremely collaborative
and work with a variety of stakeholders and tools during the six common steps
of a data science workflow (e.g., clean data and train model). We also found
that the collaborative practices workers employ, such as documentation, vary
according to the kinds of tools they use. Based on these findings, we discuss
design implications for supporting data science team collaborations and future
research directions.",0,1,0,0,0,1,0.200836,8.0,0.611912,105
http://arxiv.org/abs/2012.02366v4,DenserNet: Weakly Supervised Visual Localization Using Multi-scale Feature Aggregation,87,0.517796,0.721516,"In this work, we introduce a Denser Feature Network (DenserNet) for visual
localization. Our work provides three principal contributions. First, we
develop a convolutional neural network (CNN) architecture which aggregates
feature maps at different semantic levels for image representations. Using
denser feature maps, our method can produce more keypoint features and increase
image retrieval accuracy. Second, our model is trained end-to-end without
pixel-level annotation other than positive and negative GPS-tagged image pairs.
We use a weakly supervised triplet ranking loss to learn discriminative
features and encourage keypoint feature repeatability for image representation.
Finally, our method is computationally efficient as our architecture has shared
features and parameters during computation. Our method can perform accurate
large-scale localization under challenging conditions while remaining the
computational constraint. Extensive experiment results indicate that our method
sets a new state-of-the-art on four challenging large-scale localization
benchmarks and three image retrieval benchmarks.",1,1,0,0,1,0,0.436389,8.0,0.729297,38
http://arxiv.org/abs/2009.12576v2,Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics,30,0.52498,0.841924,"A fundamental question in neuroscience is how the brain creates an internal
model of the world to guide actions using sequences of ambiguous sensory
information. This is naturally formulated as a reinforcement learning problem
under partial observations, where an agent must estimate relevant latent
variables in the world from its evidence, anticipate possible future states,
and choose actions that optimize total expected reward. This problem can be
solved by control theory, which allows us to find the optimal actions for a
given system dynamics and objective function. However, animals often appear to
behave suboptimally. Why? We hypothesize that animals have their own flawed
internal model of the world, and choose actions with the highest expected
subjective reward according to that flawed model. We describe this behavior as
rational but not optimal. The problem of Inverse Rational Control (IRC) aims to
identify which internal model would best explain an agent's actions. Our
contribution here generalizes past work on Inverse Rational Control which
solved this problem for discrete control in partially observable Markov
decision processes. Here we accommodate continuous nonlinear dynamics and
continuous actions, and impute sensory observations corrupted by unknown noise
that is private to the animal. We first build an optimal Bayesian agent that
learns an optimal policy generalized over the entire model space of dynamics
and subjective rewards using deep reinforcement learning. Crucially, this
allows us to compute a likelihood over models for experimentally observable
action trajectories acquired from a suboptimal agent. We then find the model
parameters that maximize the likelihood using gradient ascent.",0,0,1,0,0,0,0.539716,12.0,0.844737,70
http://arxiv.org/abs/2002.06170v1,Transformer on a Diet,6,0.142647,0.0329993,"Transformer has been widely used thanks to its ability to capture sequence
information in an efficient way. However, recent developments, such as BERT and
GPT-2, deliver only heavy architectures with a focus on effectiveness. In this
paper, we explore three carefully-designed light Transformer architectures to
figure out whether the Transformer with less computations could produce
competitive results. Experimental results on language model benchmark datasets
hint that such trade-off is promising, and the light Transformer reduces 70%
parameters at best, while obtains competitive perplexity compared to standard
Transformer. The source code is publicly available.",0,1,0,0,0,0,0.987278,6.0,0.97734,29
http://arxiv.org/abs/2001.11207v3,Weakly Supervised Instance Segmentation by Deep Community Learning,19,0.17752,0.348786,"We present a weakly supervised instance segmentation algorithm based on deep
community learning with multiple tasks. This task is formulated as a
combination of weakly supervised object detection and semantic segmentation,
where individual objects of the same class are identified and segmented
separately. We address this problem by designing a unified deep neural network
architecture, which has a positive feedback loop of object detection with
bounding box regression, instance mask generation, instance segmentation, and
feature extraction. Each component of the network makes active interactions
with others to improve accuracy, and the end-to-end trainability of our model
makes our results more robust and reproducible. The proposed algorithm achieves
state-of-the-art performance in the weakly supervised setting without any
additional training such as Fast R-CNN and Mask R-CNN on the standard benchmark
dataset. The implementation of our algorithm is available on the project
webpage: https://cv.snu.ac.kr/research/WSIS_CL.",0,1,0,0,1,0,0.920352,7.0,0.902691,54
http://arxiv.org/abs/2003.08743v1,Generative Multi-Stream Architecture For American Sign Language Recognition,3,0.0717933,0.15794,"With advancements in deep model architectures, tasks in computer vision can
reach optimal convergence provided proper data preprocessing and model
parameter initialization. However, training on datasets with low
feature-richness for complex applications limit and detriment optimal
convergence below human performance. In past works, researchers have provided
external sources of complementary data at the cost of supplementary hardware,
which are fed in streams to counteract this limitation and boost performance.
We propose a generative multi-stream architecture, eliminating the need for
additional hardware with the intent to improve feature richness without risking
impracticability. We also introduce the compact spatio-temporal residual block
to the standard 3-dimensional convolutional model, C3D. Our rC3D model performs
comparatively to the top C3D residual variant architecture, the pseudo-3D
model, on the FASL-RGB dataset. Our methods have achieved 95.62% validation
accuracy with a variance of 1.42% from training, outperforming past models by
0.45% in validation accuracy and 5.53% in variance.",0,1,0,0,0,0,0.969915,10.0,0.964439,14
http://arxiv.org/abs/2003.06434v1,A Neural Architecture for Detecting Confusion in Eye-tracking Data,2,0.0236194,0.142566,"Encouraged by the success of deep learning in a variety of domains, we
investigate a novel application of its methods on the effectiveness of
detecting user confusion in eye-tracking data. We introduce an architecture
that uses RNN and CNN sub-models in parallel to take advantage of the temporal
and visuospatial aspects of our data. Experiments with a dataset of user
interactions with the ValueChart visualization tool show that our model
outperforms an existing model based on Random Forests resulting in a 22%
improvement in combined sensitivity & specificity.",0,1,0,0,1,0,0.360676,11.0,0.780558,31
http://arxiv.org/abs/2011.09315v2,End-to-End Object Detection with Adaptive Clustering Transformer,162,0.132551,0.730349,"End-to-end Object Detection with Transformer (DETR)proposes to perform object
detection with Transformer and achieve comparable performance with two-stage
object detection like Faster-RCNN. However, DETR needs huge computational
resources for training and inference due to the high-resolution spatial input.
In this paper, a novel variant of transformer named Adaptive Clustering
Transformer(ACT) has been proposed to reduce the computation cost for
high-resolution input. ACT cluster the query features adaptively using Locality
Sensitive Hashing (LSH) and ap-proximate the query-key interaction using the
prototype-key interaction. ACT can reduce the quadratic O(N2) complexity inside
self-attention into O(NK) where K is the number of prototypes in each layer.
ACT can be a drop-in module replacing the original self-attention module
without any training. ACT achieves a good balance between accuracy and
computation cost (FLOPs). The code is available as supplementary for the ease
of experiment replication and verification. Code is released at
\url{https://github.com/gaopengcuhk/SMCA-DETR/}",1,1,0,0,0,0,0.501485,7.0,0.718333,48
http://arxiv.org/abs/2005.00295v1,Hitachi at SemEval-2020 Task 12: Offensive Language Identification with Noisy Labels using Statistical Sampling and Post-Processing,7,0.16003,0.296054,"In this paper, we present our participation in SemEval-2020 Task-12 Subtask-A
(English Language) which focuses on offensive language identification from
noisy labels. To this end, we developed a hybrid system with the BERT
classifier trained with tweets selected using Statistical Sampling Algorithm
(SA) and Post-Processed (PP) using an offensive wordlist. Our developed system
achieved 34 th position with Macro-averaged F1-score (Macro-F1) of 0.90913 over
both offensive and non-offensive classes. We further show comprehensive results
and error analysis to assist future research in offensive language
identification with noisy labels.",0,1,0,0,0,1,0.929098,5.0,0.872756,33
http://arxiv.org/abs/2006.12246v1,Pain Intensity Estimation from Mobile Video Using 2D and 3D Facial Keypoints,4,0.0405163,0.330549,"Managing post-surgical pain is critical for successful surgical outcomes. One
of the challenges of pain management is accurately assessing the pain level of
patients. Self-reported numeric pain ratings are limited because they are
subjective, can be affected by mood, and can influence the patient's perception
of pain when making comparisons. In this paper, we introduce an approach that
analyzes 2D and 3D facial keypoints of post-surgical patients to estimate their
pain intensity level. Our approach leverages the previously unexplored
capabilities of a smartphone to capture a dense 3D representation of a person's
face as input for pain intensity level estimation. Our contributions are adata
collection study with post-surgical patients to collect ground-truth labeled
sequences of 2D and 3D facial keypoints for developing a pain estimation
algorithm, a pain estimation model that uses multiple instance learning to
overcome inherent limitations in facial keypoint sequences, and the preliminary
results of the pain estimation model using 2D and 3D features with comparisons
of alternate approaches.",0,1,0,1,0,0,0.108652,14.0,0.730565,43
http://arxiv.org/abs/2001.00804v1,Towards Intelligent Robotic Process Automation for BPMers,23,0.743396,0.801093,"Robotic Process Automation (RPA) is a fast-emerging automation technology
that sits between the fields of Business Process Management (BPM) and
Artificial Intelligence (AI), and allows organizations to automate high volume
routines. RPA tools are able to capture the execution of such routines
previously performed by a human users on the interface of a computer system,
and then emulate their enactment in place of the user by means of a software
robot. Nowadays, in the BPM domain, only simple, predictable business processes
involving routine work can be automated by RPA tools in situations where there
is no room for interpretation, while more sophisticated work is still left to
human experts. In this paper, starting from an in-depth experimentation of the
RPA tools available on the market, we provide a classification framework to
categorize them on the basis of some key dimensions. Then, based on this
analysis, we derive four research challenges and discuss prospective approaches
necessary to inject intelligence into current RPA technology, in order to
achieve more widespread adoption of RPA in the BPM domain.",0,1,0,0,0,0,0.964502,8.0,0.949502,40
http://arxiv.org/abs/2009.11023v2,The Struggles of Feature-Based Explanations: Shapley Values vs. Minimal Sufficient Subsets,23,0.0580845,0.429833,"For neural models to garner widespread public trust and ensure fairness, we
must have human-intelligible explanations for their predictions. Recently, an
increasing number of works focus on explaining the predictions of neural models
in terms of the relevance of the input features. In this work, we show that
feature-based explanations pose problems even for explaining trivial models. We
show that, in certain cases, there exist at least two ground-truth
feature-based explanations, and that, sometimes, neither of them is enough to
provide a complete view of the decision-making process of the model. Moreover,
we show that two popular classes of explainers, Shapley explainers and minimal
sufficient subsets explainers, target fundamentally different types of
ground-truth explanations, despite the apparently implicit assumption that
explainers should look for one specific feature-based explanation. These
findings bring an additional dimension to consider in both developing and
choosing explainers.",0,0,0,0,0,0,0.664205,6.0,0.746315,16
http://arxiv.org/abs/2002.04678v1,Adjusting Image Attributes of Localized Regions with Low-level Dialogue,2,0.00851584,0.0704462,"Natural Language Image Editing (NLIE) aims to use natural language
instructions to edit images. Since novices are inexperienced with image editing
techniques, their instructions are often ambiguous and contain high-level
abstractions that tend to correspond to complex editing steps to accomplish.
Motivated by this inexperience aspect, we aim to smooth the learning curve by
teaching the novices to edit images using low-level commanding terminologies.
Towards this end, we develop a task-oriented dialogue system to investigate
low-level instructions for NLIE. Our system grounds language on the level of
edit operations, and suggests options for a user to choose from. Though
compelled to express in low-level terms, a user evaluation shows that 25% of
users found our system easy-to-use, resonating with our motivation. An analysis
shows that users generally adapt to utilizing the proposed low-level language
interface. In this study, we identify that object segmentation as the key
factor to the user satisfaction. Our work demonstrates the advantages of the
low-level, direct language-action mapping approach that can be applied to other
problem domains beyond image editing such as audio editing or industrial
design.",0,1,0,0,0,0,0.45106,5.0,0.575869,32
http://arxiv.org/abs/2009.10315v1,PodSumm -- Podcast Audio Summarization,9,0.193984,0.504155,"The diverse nature, scale, and specificity of podcasts present a unique
challenge to content discovery systems. Listeners often rely on text
descriptions of episodes provided by the podcast creators to discover new
content. Some factors like the presentation style of the narrator and
production quality are significant indicators of subjective user preference but
are difficult to quantify and not reflected in the text descriptions provided
by the podcast creators. We propose the automated creation of podcast audio
summaries to aid in content discovery and help listeners to quickly preview
podcast content before investing time in listening to an entire episode. In
this paper, we present a method to automatically construct a podcast summary
via guidance from the text-domain. Our method performs two key steps, namely,
audio to text transcription and text summary generation. Motivated by a lack of
datasets for this task, we curate an internal dataset, find an effective scheme
for data augmentation, and design a protocol to gather summaries from
annotators. We fine-tune a PreSumm[10] model with our augmented dataset and
perform an ablation study. Our method achieves ROUGE-F(1/2/L) scores of
0.63/0.53/0.63 on our dataset. We hope these results may inspire future
research in this direction.",0,1,0,1,0,0,0.747839,7.0,0.815853,18
http://arxiv.org/abs/2002.04758v3,Salvaging Federated Learning by Local Adaptation,221,0.659416,0.743505,"Federated learning (FL) is a heavily promoted approach for training ML models
on sensitive data, e.g., text typed by users on their smartphones. FL is
expressly designed for training on data that are unbalanced and non-iid across
the participants. To ensure privacy and integrity of the fedeated model, latest
FL approaches use differential privacy or robust aggregation.
  We look at FL from the \emph{local} viewpoint of an individual participant
and ask: (1) do participants have an incentive to participate in FL? (2) how
can participants \emph{individually} improve the quality of their local models,
without re-designing the FL framework and/or involving other participants?
  First, we show that on standard tasks such as next-word prediction, many
participants gain no benefit from FL because the federated model is less
accurate on their data than the models they can train locally on their own.
Second, we show that differential privacy and robust aggregation make this
problem worse by further destroying the accuracy of the federated model for
many participants.
  Then, we evaluate three techniques for local adaptation of federated models:
fine-tuning, multi-task learning, and knowledge distillation. We analyze where
each is applicable and demonstrate that all participants benefit from local
adaptation. Participants whose local models are poor obtain big accuracy
improvements over conventional FL. Participants whose local models are better
than the federated model\textemdash and who have no incentive to participate in
FL today\textemdash improve less, but sufficiently to make the adapted
federated model better than their local models.",0,1,0,0,0,0,0.8606,4.0,0.767201,48
http://arxiv.org/abs/2012.00483v2,ClimaText: A Dataset for Climate Change Topic Detection,28,0.335641,0.887574,"Climate change communication in the mass media and other textual sources may
affect and shape public perception. Extracting climate change information from
these sources is an important task, e.g., for filtering content and
e-discovery, sentiment analysis, automatic summarization, question-answering,
and fact-checking. However, automating this process is a challenge, as climate
change is a complex, fast-moving, and often ambiguous topic with scarce
resources for popular text-based AI tasks. In this paper, we introduce
\textsc{ClimaText}, a dataset for sentence-based climate change topic
detection, which we make publicly available. We explore different approaches to
identify the climate change topic in various text sources. We find that popular
keyword-based models are not adequate for such a complex and evolving task.
Context-based algorithms like BERT \cite{devlin2018bert} can detect, in
addition to many trivial cases, a variety of complex and implicit topic
patterns. Nevertheless, our analysis reveals a great potential for improvement
in several directions, such as, e.g., capturing the discussion on indirect
effects of climate change. Hence, we hope this work can serve as a good
starting point for further research on this topic.",0,1,1,1,0,0,0.163857,17.0,0.804114,20
http://arxiv.org/abs/2011.12950v2,Space-time Neural Irradiance Fields for Free-Viewpoint Video,370,1.0,1.0,"We present a method that learns a spatiotemporal neural irradiance field for
dynamic scenes from a single video. Our learned representation enables
free-viewpoint rendering of the input video. Our method builds upon recent
advances in implicit representations. Learning a spatiotemporal irradiance
field from a single video poses significant challenges because the video
contains only one observation of the scene at any point in time. The 3D
geometry of a scene can be legitimately represented in numerous ways since
varying geometry (motion) can be explained with varying appearance and vice
versa. We address this ambiguity by constraining the time-varying geometry of
our dynamic scene representation using the scene depth estimated from video
depth estimation methods, aggregating contents from individual frames into a
single global representation. We provide an extensive quantitative evaluation
and demonstrate compelling free-viewpoint rendering results.",1,0,0,0,0,0,0.989374,4.0,0.976117,84
http://arxiv.org/abs/2009.13827v1,SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and Synonym Discovery,19,0.117311,0.568483,"Entity set expansion and synonym discovery are two critical NLP tasks.
Previous studies accomplish them separately, without exploring their
interdependencies. In this work, we hypothesize that these two tasks are
tightly coupled because two synonymous entities tend to have similar
likelihoods of belonging to various semantic classes. This motivates us to
design SynSetExpan, a novel framework that enables two tasks to mutually
enhance each other. SynSetExpan uses a synonym discovery model to include
popular entities' infrequent synonyms into the set, which boosts the set
expansion recall. Meanwhile, the set expansion model, being able to determine
whether an entity belongs to a semantic class, can generate pseudo training
data to fine-tune the synonym discovery model towards better accuracy. To
facilitate the research on studying the interplays of these two tasks, we
create the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via
crowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks
demonstrate the effectiveness of SynSetExpan for both entity set expansion and
synonym discovery tasks.",0,1,0,1,0,0,0.0707395,7.0,0.396896,45
http://arxiv.org/abs/2007.08661v2,Least squares surface reconstruction on arbitrary domains,10,0.0445831,0.434105,"Almost universally in computer vision, when surface derivatives are required,
they are computed using only first order accurate finite difference
approximations. We propose a new method for computing numerical derivatives
based on 2D Savitzky-Golay filters and K-nearest neighbour kernels. The
resulting derivative matrices can be used for least squares surface
reconstruction over arbitrary (even disconnected) domains in the presence of
large noise and allowing for higher order polynomial local surface
approximations. They are useful for a range of tasks including
normal-from-depth (i.e. surface differentiation), height-from-normals (i.e.
surface integration) and shape-from-x. We show how to write both orthographic
or perspective height-from-normals as a linear least squares problem using the
same formulation and avoiding a nonlinear change of variables in the
perspective case. We demonstrate improved performance relative to
state-of-the-art across these tasks on both synthetic and real data and make
available an open source implementation of our method.",0,1,0,0,1,0,0.000141114,23.0,0.544552,31
http://arxiv.org/abs/2009.13299v1,Learning to Match Jobs with Resumes from Sparse Interaction Data using Multi-View Co-Teaching Network,36,0.619527,0.988453,"With the ever-increasing growth of online recruitment data, job-resume
matching has become an important task to automatically match jobs with suitable
resumes. This task is typically casted as a supervised text matching problem.
Supervised learning is powerful when the labeled data is sufficient. However,
on online recruitment platforms, job-resume interaction data is sparse and
noisy, which affects the performance of job-resume match algorithms. To
alleviate these problems, in this paper, we propose a novel multi-view
co-teaching network from sparse interaction data for job-resume matching. Our
network consists of two major components, namely text-based matching model and
relation-based matching model. The two parts capture semantic compatibility in
two different views, and complement each other. In order to address the
challenges from sparse and noisy data, we design two specific strategies to
combine the two components. First, two components share the learned parameters
or representations, so that the original representations of each component can
be enhanced. More importantly, we adopt a co-teaching mechanism to reduce the
influence of noise in training data. The core idea is to let the two components
help each other by selecting more reliable training instances. The two
strategies focus on representation enhancement and data enhancement,
respectively. Compared with pure text-based matching models, the proposed
approach is able to learn better data representations from limited or even
sparse interaction data, which is more resistible to noise in training data.
Experiment results have demonstrated that our model is able to outperform
state-of-the-art methods for job-resume matching.",1,1,0,0,1,0,0.819288,7.0,0.846793,32
http://arxiv.org/abs/2004.11886v1,Lite Transformer with Long-Short Range Attention,251,0.974021,0.86532,"Transformer has become ubiquitous in natural language processing (e.g.,
machine translation, question answering); however, it requires enormous amount
of computations to achieve high performance, which makes it not suitable for
mobile applications that are tightly constrained by the hardware resources and
battery. In this paper, we present an efficient mobile NLP architecture, Lite
Transformer to facilitate deploying mobile NLP applications on edge devices.
The key primitive is the Long-Short Range Attention (LSRA), where one group of
heads specializes in the local context modeling (by convolution) while another
group specializes in the long-distance relationship modeling (by attention).
Such specialization brings consistent improvement over the vanilla transformer
on three well-established language tasks: machine translation, abstractive
summarization, and language modeling. Under constrained resources (500M/100M
MACs), Lite Transformer outperforms transformer on WMT'14 English-French by
1.2/1.7 BLEU, respectively. Lite Transformer reduces the computation of
transformer base model by 2.5x with 0.3 BLEU score degradation. Combining with
pruning and quantization, we further compressed the model size of Lite
Transformer by 18.2x. For language modeling, Lite Transformer achieves 1.8
lower perplexity than the transformer at around 500M MACs. Notably, Lite
Transformer outperforms the AutoML-based Evolved Transformer by 0.5 higher BLEU
for the mobile NLP setting without the costly architecture search that requires
more than 250 GPU years. Code has been made available at
https://github.com/mit-han-lab/lite-transformer.",1,1,0,0,1,0,0.988656,5.0,0.977997,57
http://arxiv.org/abs/2004.00384v1,Interpretable Deep Learning Model for Online Multi-touch Attribution,7,0.484214,0.514621,"In online advertising, users may be exposed to a range of different
advertising campaigns, such as natural search or referral or organic search,
before leading to a final transaction. Estimating the contribution of
advertising campaigns on the user's journey is very meaningful and crucial. A
marketer could observe each customer's interaction with different marketing
channels and modify their investment strategies accordingly. Existing methods
including both traditional last-clicking methods and recent data-driven
approaches for the multi-touch attribution (MTA) problem lack enough
interpretation on why the methods work. In this paper, we propose a novel model
called DeepMTA, which combines deep learning model and additive feature
explanation model for interpretable online multi-touch attribution. DeepMTA
mainly contains two parts, the phased-LSTMs based conversion prediction model
to catch different time intervals, and the additive feature attribution model
combined with shaley values. Additive feature attribution is explanatory that
contains a linear function of binary variables. As the first interpretable deep
learning model for MTA, DeepMTA considers three important features in the
customer journey: event sequence order, event frequency and time-decay effect
of the event. Evaluation on a real dataset shows the proposed conversion
prediction model achieves 91\% accuracy.",1,1,0,0,0,0,0.967538,12.0,0.968537,48
http://arxiv.org/abs/2011.08067v3,Hierarchical Transformer for Task Oriented Dialog Systems,25,0.404972,0.829824,"Generative models for dialog systems have gained much interest because of the
recent success of RNN and Transformer based models in tasks like question
answering and summarization. Although the task of dialog response generation is
generally seen as a sequence-to-sequence (Seq2Seq) problem, researchers in the
past have found it challenging to train dialog systems using the standard
Seq2Seq models. Therefore, to help the model learn meaningful utterance and
conversation level features, Sordoni et al. (2015b); Serban et al. (2016)
proposed Hierarchical RNN architecture, which was later adopted by several
other RNN based dialog systems. With the transformer-based models dominating
the seq2seq problems lately, the natural question to ask is the applicability
of the notion of hierarchy in transformer based dialog systems. In this paper,
we propose a generalized framework for Hierarchical Transformer Encoders and
show how a standard transformer can be morphed into any hierarchical encoder,
including HRED and HIBERT like models, by using specially designed attention
masks and positional encodings. We demonstrate that Hierarchical Encoding helps
achieve better natural language understanding of the contexts in
transformer-based models for task-oriented dialog systems through a wide range
of experiments.",1,0,0,0,0,0,0.962484,4.0,0.89483,29
http://arxiv.org/abs/2007.07768v2,Opening the Software Engineering Toolbox for the Assessment of Trustworthy AI,7,0.228392,0.106379,"Trustworthiness is a central requirement for the acceptance and success of
human-centered artificial intelligence (AI). To deem an AI system as
trustworthy, it is crucial to assess its behaviour and characteristics against
a gold standard of Trustworthy AI, consisting of guidelines, requirements, or
only expectations. While AI systems are highly complex, their implementations
are still based on software. The software engineering community has a
long-established toolbox for the assessment of software systems, especially in
the context of software testing. In this paper, we argue for the application of
software engineering and testing practices for the assessment of trustworthy
AI. We make the connection between the seven key requirements as defined by the
European Commission's AI high-level expert group and established procedures
from software engineering and raise questions for future work.",0,0,0,0,0,0,0.881018,5.0,0.829223,31
http://arxiv.org/abs/2005.03361v1,JASS: Japanese-specific Sequence to Sequence Pre-training for Neural Machine Translation,4,0.00988325,0.1281,"Neural machine translation (NMT) needs large parallel corpora for
state-of-the-art translation quality. Low-resource NMT is typically addressed
by transfer learning which leverages large monolingual or parallel corpora for
pre-training. Monolingual pre-training approaches such as MASS (MAsked Sequence
to Sequence) are extremely effective in boosting NMT quality for languages with
small parallel corpora. However, they do not account for linguistic information
obtained using syntactic analyzers which is known to be invaluable for several
Natural Language Processing (NLP) tasks. To this end, we propose JASS,
Japanese-specific Sequence to Sequence, as a novel pre-training alternative to
MASS for NMT involving Japanese as the source or target language. JASS is joint
BMASS (Bunsetsu MASS) and BRSS (Bunsetsu Reordering Sequence to Sequence)
pre-training which focuses on Japanese linguistic units called bunsetsus. In
our experiments on ASPEC Japanese--English and News Commentary
Japanese--Russian translation we show that JASS can give results that are
competitive with if not better than those given by MASS. Furthermore, we show
for the first time that joint MASS and JASS pre-training gives results that
significantly surpass the individual methods indicating their complementary
nature. We will release our code, pre-trained models and bunsetsu annotated
data as resources for researchers to use in their own NLP tasks.",0,1,0,0,1,0,0.348366,6.0,0.590428,38
http://arxiv.org/abs/2010.09531v1,Learning Locomotion Skills in Evolvable Robots,26,0.248238,0.45199,"The challenge of robotic reproduction -- making of new robots by recombining
two existing ones -- has been recently cracked and physically evolving robot
systems have come within reach. Here we address the next big hurdle: producing
an adequate brain for a newborn robot. In particular, we address the task of
targeted locomotion which is arguably a fundamental skill in any practical
implementation. We introduce a controller architecture and a generic learning
method to allow a modular robot with an arbitrary shape to learn to walk
towards a target and follow this target if it moves. Our approach is validated
on three robots, a spider, a gecko, and their offspring, in three real-world
scenarios.",0,0,0,0,0,0,0.0201311,14.0,0.606802,53
http://arxiv.org/abs/2010.08021v1,MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention,30,0.270901,0.683642,"This paper presents MAST, a new model for Multimodal Abstractive Text
Summarization that utilizes information from all three modalities -- text,
audio and video -- in a multimodal video. Prior work on multimodal abstractive
text summarization only utilized information from the text and video
modalities. We examine the usefulness and challenges of deriving information
from the audio modality and present a sequence-to-sequence trimodal
hierarchical attention-based model that overcomes these challenges by letting
the model pay more attention to the text modality. MAST outperforms the current
state of the art model (video-text) by 2.51 points in terms of Content F1 score
and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal
language understanding.",0,1,0,0,1,0,0.461268,10.0,0.791017,32
http://arxiv.org/abs/2001.04377v1,When Humans Aren't Optimal: Robots that Collaborate with Risk-Aware Humans,74,0.351682,0.905316,"In order to collaborate safely and efficiently, robots need to anticipate how
their human partners will behave. Some of today's robots model humans as if
they were also robots, and assume users are always optimal. Other robots
account for human limitations, and relax this assumption so that the human is
noisily rational. Both of these models make sense when the human receives
deterministic rewards: i.e., gaining either $100 or $130 with certainty. But in
real world scenarios, rewards are rarely deterministic. Instead, we must make
choices subject to risk and uncertainty--and in these settings, humans exhibit
a cognitive bias towards suboptimal behavior. For example, when deciding
between gaining $100 with certainty or $130 only 80% of the time, people tend
to make the risk-averse choice--even though it leads to a lower expected gain!
In this paper, we adopt a well-known Risk-Aware human model from behavioral
economics called Cumulative Prospect Theory and enable robots to leverage this
model during human-robot interaction (HRI). In our user studies, we offer
supporting evidence that the Risk-Aware model more accurately predicts
suboptimal human behavior. We find that this increased modeling accuracy
results in safer and more efficient human-robot collaboration. Overall, we
extend existing rational human models so that collaborative robots can
anticipate and plan around suboptimal human behavior during HRI.",0,0,0,0,0,0,0.0440881,11.0,0.571951,51
http://arxiv.org/abs/2006.06606v2,What makes instance discrimination good for transfer learning?,156,0.985664,0.876161,"Contrastive visual pretraining based on the instance discrimination pretext
task has made significant progress. Notably, recent work on unsupervised
pretraining has shown to surpass the supervised counterpart for finetuning
downstream applications such as object detection and segmentation. It comes as
a surprise that image annotations would be better left unused for transfer
learning. In this work, we investigate the following problems: What makes
instance discrimination pretraining good for transfer learning? What knowledge
is actually learned and transferred from these models? From this understanding
of instance discrimination, how can we better exploit human annotation labels
for pretraining? Our findings are threefold. First, what truly matters for the
transfer is low-level and mid-level representations, not high-level
representations. Second, the intra-category invariance enforced by the
traditional supervised model weakens transferability by increasing task
misalignment. Finally, supervised pretraining can be strengthened by following
an exemplar-based approach without explicit constraints among the instances
within the same category.",1,0,0,0,0,1,0.989956,6.0,0.986131,55
http://arxiv.org/abs/2004.13992v1,Retinal vessel segmentation by probing adaptive to lighting variations,3,0.0477234,0.18066,"We introduce a novel method to extract the vessels in eye fun-dus images
which is adaptive to lighting variations. In the Logarithmic Image Processing
framework, a 3-segment probe detects the vessels by probing the topographic
surface of an image from below. A map of contrasts between the probe and the
image allows to detect the vessels by a threshold. In a lowly contrasted image,
results show that our method better extract the vessels than another state-of
the-art method. In a highly contrasted image database (DRIVE) with a reference
, ours has an accuracy of 0.9454 which is similar or better than three
state-of-the-art methods and below three others. The three best methods have a
higher accuracy than a manual segmentation by another expert. Importantly, our
method automatically adapts to the lighting conditions of the image
acquisition.",0,1,0,0,1,0,0.778665,11.0,0.891036,9
http://arxiv.org/abs/2008.10312v2,Self-Supervised Learning for Large-Scale Unsupervised Image Clustering,8,0.0568234,0.130454,"Unsupervised learning has always been appealing to machine learning
researchers and practitioners, allowing them to avoid an expensive and
complicated process of labeling the data. However, unsupervised learning of
complex data is challenging, and even the best approaches show much weaker
performance than their supervised counterparts. Self-supervised deep learning
has become a strong instrument for representation learning in computer vision.
However, those methods have not been evaluated in a fully unsupervised setting.
In this paper, we propose a simple scheme for unsupervised classification based
on self-supervised representations. We evaluate the proposed approach with
several recent self-supervised methods showing that it achieves competitive
results for ImageNet classification (39% accuracy on ImageNet with 1000
clusters and 46% with overclustering). We suggest adding the unsupervised
evaluation to a set of standard benchmarks for self-supervised learning. The
code is available at https://github.com/Randl/kmeans_selfsuper",0,1,0,0,0,0,0.98605,3.0,0.947571,42
http://arxiv.org/abs/2010.09270v1,Global Attention for Name Tagging,17,0.147522,0.335933,"Many name tagging approaches use local contextual information with much
success, but fail when the local context is ambiguous or limited. We present a
new framework to improve name tagging by utilizing local, document-level, and
corpus-level contextual information. We retrieve document-level context from
other sentences within the same document and corpus-level context from
sentences in other topically related documents. We propose a model that learns
to incorporate document-level and corpus-level contextual information alongside
local contextual information via global attentions, which dynamically weight
their respective contextual information, and gating mechanisms, which determine
the influence of this information. Extensive experiments on benchmark datasets
show the effectiveness of our approach, which achieves state-of-the-art results
for Dutch, German, and Spanish on the CoNLL-2002 and CoNLL-2003 datasets.",1,1,0,0,1,0,0.362759,10.0,0.75934,42
http://arxiv.org/abs/2010.12547v2,Multilingual BERT Post-Pretraining Alignment,32,0.389821,0.723774,"We propose a simple method to align multilingual contextual embeddings as a
post-pretraining step for improved zero-shot cross-lingual transferability of
the pretrained models. Using parallel data, our method aligns embeddings on the
word level through the recently proposed Translation Language Modeling
objective as well as on the sentence level via contrastive learning and random
input shuffling. We also perform sentence-level code-switching with English
when finetuning on downstream tasks. On XNLI, our best model (initialized from
mBERT) improves over mBERT by 4.7% in the zero-shot setting and achieves
comparable result to XLM for translate-train while using less than 18% of the
same parallel data and 31% less model parameters. On MLQA, our model
outperforms XLM-R_Base that has 57% more parameters than ours.",0,1,0,0,1,0,0.989293,3.0,0.9676,30
http://arxiv.org/abs/2006.13913v2,Generative causal explanations of black-box classifiers,61,0.523336,0.656132,"We develop a method for generating causal post-hoc explanations of black-box
classifiers based on a learned low-dimensional representation of the data. The
explanation is causal in the sense that changing learned latent factors
produces a change in the classifier output statistics. To construct these
explanations, we design a learning framework that leverages a generative model
and information-theoretic measures of causal influence. Our objective function
encourages both the generative model to faithfully represent the data
distribution and the latent factors to have a large causal influence on the
classifier output. Our method learns both global and local explanations, is
compatible with any classifier that admits class probabilities and a gradient,
and does not require labeled attributes or knowledge of causal structure. Using
carefully controlled test cases, we provide intuition that illuminates the
function of our objective. We then demonstrate the practical utility of our
method on image recognition tasks.",0,0,0,0,0,0,0.897922,5.0,0.843124,84
http://arxiv.org/abs/2011.10219v2,Certified Monotonic Neural Networks,60,0.406812,0.542376,"Learning monotonic models with respect to a subset of the inputs is a
desirable feature to effectively address the fairness, interpretability, and
generalization issues in practice. Existing methods for learning monotonic
neural networks either require specifically designed model structures to ensure
monotonicity, which can be too restrictive/complicated, or enforce monotonicity
by adjusting the learning process, which cannot provably guarantee the learned
model is monotonic on selected features. In this work, we propose to certify
the monotonicity of the general piece-wise linear neural networks by solving a
mixed integer linear programming problem.This provides a new general approach
for learning monotonic neural networks with arbitrary model structures. Our
method allows us to train neural networks with heuristic monotonicity
regularizations, and we can gradually increase the regularization magnitude
until the learned network is certified monotonic. Compared to prior works, our
approach does not require human-designed constraints on the weight space and
also yields more accurate approximation. Empirical studies on various datasets
demonstrate the efficiency of our approach over the state-of-the-art methods,
such as Deep Lattice Networks.",0,0,0,0,1,0,0.377518,6.0,0.60735,40
http://arxiv.org/abs/2007.02244v1,Unsupervised Paraphrasing via Deep Reinforcement Learning,52,0.147887,0.433811,"Paraphrasing is expressing the meaning of an input sentence in different
wording while maintaining fluency (i.e., grammatical and syntactical
correctness). Most existing work on paraphrasing use supervised models that are
limited to specific domains (e.g., image captions). Such models can neither be
straightforwardly transferred to other domains nor generalize well, and
creating labeled training data for new domains is expensive and laborious. The
need for paraphrasing across different domains and the scarcity of labeled
training data in many such domains call for exploring unsupervised paraphrase
generation methods. We propose Progressive Unsupervised Paraphrasing (PUP): a
novel unsupervised paraphrase generation method based on deep reinforcement
learning (DRL). PUP uses a variational autoencoder (trained using a
non-parallel corpus) to generate a seed paraphrase that warm-starts the DRL
model. Then, PUP progressively tunes the seed paraphrase guided by our novel
reward function which combines semantic adequacy, language fluency, and
expression diversity measures to quantify the quality of the generated
paraphrases in each iteration without needing parallel sentences. Our extensive
experimental evaluation shows that PUP outperforms unsupervised
state-of-the-art paraphrasing techniques in terms of both automatic metrics and
user studies on four real datasets. We also show that PUP outperforms
domain-adapted supervised algorithms on several datasets. Our evaluation also
shows that PUP achieves a great trade-off between semantic similarity and
diversity of expression.",0,0,0,0,1,1,0.0287571,17.0,0.697426,53
http://arxiv.org/abs/2008.04403v1,Comparison of Model Predictive and Reinforcement Learning Methods for Fault Tolerant Control,17,0.139262,0.632467,"A desirable property in fault-tolerant controllers is adaptability to system
changes as they evolve during systems operations. An adaptive controller does
not require optimal control policies to be enumerated for possible faults.
Instead it can approximate one in real-time. We present two adaptive
fault-tolerant control schemes for a discrete time system based on hierarchical
reinforcement learning. We compare their performance against a model predictive
controller in presence of sensor noise and persistent faults. The controllers
are tested on a fuel tank model of a C-130 plane. Our experiments demonstrate
that reinforcement learning-based controllers perform more robustly than model
predictive controllers under faults, partially observable system models, and
varying sensor noise levels.",0,1,0,0,0,0,0.00142199,41.0,0.800868,17
http://arxiv.org/abs/2009.11321v1,Improving Dialog Evaluation with a Multi-reference Adversarial Dataset and Large Scale Pretraining,67,0.700683,0.874897,"There is an increasing focus on model-based dialog evaluation metrics such as
ADEM, RUBER, and the more recent BERT-based metrics. These models aim to assign
a high score to all relevant responses and a low score to all irrelevant
responses. Ideally, such models should be trained using multiple relevant and
irrelevant responses for any given context. However, no such data is publicly
available, and hence existing models are usually trained using a single
relevant response and multiple randomly selected responses from other contexts
(random negatives). To allow for better training and robust evaluation of
model-based metrics, we introduce the DailyDialog++ dataset, consisting of (i)
five relevant responses for each context and (ii) five adversarially crafted
irrelevant responses for each context. Using this dataset, we first show that
even in the presence of multiple correct references, n-gram based metrics and
embedding based metrics do not perform well at separating relevant responses
from even random negatives. While model-based metrics perform better than
n-gram and embedding based metrics on random negatives, their performance drops
substantially when evaluated on adversarial examples. To check if large scale
pretraining could help, we propose a new BERT-based evaluation metric called
DEB, which is pretrained on 727M Reddit conversations and then finetuned on our
dataset. DEB significantly outperforms existing models, showing better
correlation with human judgements and better performance on random negatives
(88.27% accuracy). However, its performance again drops substantially, when
evaluated on adversarial responses, thereby highlighting that even large-scale
pretrained evaluation models are not robust to the adversarial examples in our
dataset. The dataset and code are publicly available.",1,1,1,1,1,0,0.931927,8.0,0.922382,43
http://arxiv.org/abs/2001.02462v1,From Natural Language Instructions to Complex Processes: Issues in Chaining Trigger Action Rules,7,0.193902,0.462124,"Automation services for complex business processes usually require a high
level of information technology literacy. There is a strong demand for a
smartly assisted process automation (IPA: intelligent process automation)
service that enables even general users to easily use advanced automation. A
natural language interface for such automation is expected as an elemental
technology for the IPA realization. The workflow targeted by IPA is generally
composed of a combination of multiple tasks. However, semantic parsing, one of
the natural language processing methods, for such complex workflows has not yet
been fully studied. The reasons are that (1) the formal expression and grammar
of the workflow required for semantic analysis have not been sufficiently
examined and (2) the dataset of the workflow formal expression with its
corresponding natural language description required for learning workflow
semantics did not exist. This paper defines a new grammar for complex workflows
with chaining machine-executable meaning representations for semantic parsing.
The representations are at a high abstraction level. Additionally, an approach
to creating datasets is proposed based on this grammar.",0,0,1,1,0,0,0.875774,5.0,0.825129,14
http://arxiv.org/abs/2010.04762v1,Counterfactually-Augmented SNLI Training Data Does Not Yield Better Generalization Than Unaugmented Data,36,0.0786918,0.569028,"A growing body of work shows that models exploit annotation artifacts to
achieve state-of-the-art performance on standard crowdsourced
benchmarks---datasets collected from crowdworkers to create an evaluation
task---while still failing on out-of-domain examples for the same task. Recent
work has explored the use of counterfactually-augmented data---data built by
minimally editing a set of seed examples to yield counterfactual labels---to
augment training data associated with these benchmarks and build more robust
classifiers that generalize better. However, Khashabi et al. (2020) find that
this type of augmentation yields little benefit on reading comprehension tasks
when controlling for dataset size and cost of collection. We build upon this
work by using English natural language inference data to test model
generalization and robustness and find that models trained on a
counterfactually-augmented SNLI dataset do not generalize better than
unaugmented datasets of similar size and that counterfactual augmentation can
hurt performance, yielding models that are less robust to challenge examples.
Counterfactual augmentation of natural language understanding data through
standard crowdsourcing techniques does not appear to be an effective way of
collecting training data and further innovation is required to make this
general line of work viable.",0,0,0,0,0,0,0.580328,5.0,0.649865,17
http://arxiv.org/abs/2004.05274v1,Improved Speech Representations with Multi-Target Autoregressive Predictive Coding,54,0.201688,0.753774,"Training objectives based on predictive coding have recently been shown to be
very effective at learning meaningful representations from unlabeled speech.
One example is Autoregressive Predictive Coding (Chung et al., 2019), which
trains an autoregressive RNN to generate an unseen future frame given a context
such as recent past frames. The basic hypothesis of these approaches is that
hidden states that can accurately predict future frames are a useful
representation for many downstream tasks. In this paper we extend this
hypothesis and aim to enrich the information encoded in the hidden states by
training the model to make more accurate future predictions. We propose an
auxiliary objective that serves as a regularization to improve generalization
of the future frame prediction task. Experimental results on phonetic
classification, speech recognition, and speech translation not only support the
hypothesis, but also demonstrate the effectiveness of our approach in learning
representations that contain richer phonetic content.",0,0,0,0,0,0,0.693264,5.0,0.711515,31
http://arxiv.org/abs/2005.00820v2,Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing,50,0.496609,0.644007,"Prior work has explored directly regularizing the output distributions of
probabilistic models to alleviate peaky (i.e. over-confident) predictions, a
common sign of overfitting. This class of techniques, of which label smoothing
is one, has a connection to entropy regularization. Despite the consistent
success of label smoothing across architectures and data sets in language
generation tasks, two problems remain open: (1) there is little understanding
of the underlying effects entropy regularizers have on models, and (2) the full
space of entropy regularization techniques is largely unexplored. We introduce
a parametric family of entropy regularizers, which includes label smoothing as
a special case, and use it to gain a better understanding of the relationship
between the entropy of a model and its performance on language generation
tasks. We also find that variance in model performance can be explained largely
by the resulting entropy of the model. Lastly, we find that label smoothing
provably does not allow for sparsity in an output distribution, an undesirable
property for language generation models, and therefore advise the use of other
entropy regularization methods in its place.",1,0,0,0,0,0,0.907059,9.0,0.917321,45
http://arxiv.org/abs/2009.13282v1,Graph-based Multi-hop Reasoning for Long Text Generation,9,0.146982,0.131298,"Long text generation is an important but challenging task.The main problem
lies in learning sentence-level semantic dependencies which traditional
generative models often suffer from. To address this problem, we propose a
Multi-hop Reasoning Generation (MRG) approach that incorporates multi-hop
reasoning over a knowledge graph to learn semantic dependencies among
sentences. MRG consists of twoparts, a graph-based multi-hop reasoning module
and a path-aware sentence realization module. The reasoning module is
responsible for searching skeleton paths from a knowledge graph to imitate the
imagination process in the human writing for semantic transfer. Based on the
inferred paths, the sentence realization module then generates a complete
sentence. Unlike previous black-box models, MRG explicitly infers the skeleton
path, which provides explanatory views tounderstand how the proposed model
works. We conduct experiments on three representative tasks, including story
generation, review generation, and product description generation. Automatic
and manual evaluation show that our proposed method can generate more
informative and coherentlong text than strong baselines, such as pre-trained
models(e.g. GPT-2) and knowledge-enhanced models.",0,0,0,0,1,1,0.948805,5.0,0.895968,50
http://arxiv.org/abs/2003.03444v3,NYTWIT: A Dataset of Novel Words in the New York Times,13,0.183992,0.300231,"We present the New York Times Word Innovation Types dataset, or NYTWIT, a
collection of over 2,500 novel English words published in the New York Times
between November 2017 and March 2019, manually annotated for their class of
novelty (such as lexical derivation, dialectal variation, blending, or
compounding). We present baseline results for both uncontextual and contextual
prediction of novelty class, showing that there is room for improvement even
for state-of-the-art NLP systems. We hope this resource will prove useful for
linguists and NLP practitioners by providing a real-world environment of novel
word appearance.",1,0,1,1,0,0,0.208937,8.0,0.617468,25
http://arxiv.org/abs/2010.11533v2,Exponential Negation of a Probability Distribution,30,0.0466716,0.668975,"Negation operation is important in intelligent information processing.
Different with existing arithmetic negation, an exponential negation is
presented in this paper. The new negation can be seen as a kind of geometry
negation. Some basic properties of the proposed negation is investigated, we
find that the fix point is the uniform probability distribution. The negation
is an entropy increase operation and all the probability distributions will
converge to the uniform distribution after multiple negation iterations. The
number of iterations of convergence is inversely proportional to the number of
elements in the distribution. Some numerical examples are used to illustrate
the efficiency of the proposed negation.",0,0,0,0,0,0,0.638687,2.0,0.204206,75
http://arxiv.org/abs/2008.05396v1,Full Reference Screen Content Image Quality Assessment by Fusing Multi-level Structure Similarity,13,0.0559228,0.512232,"The screen content images (SCIs) usually comprise various content types with
sharp edges, in which the artifacts or distortions can be well sensed by the
vanilla structure similarity measurement in a full reference manner.
Nonetheless, almost all of the current SOTA structure similarity metrics are
""locally"" formulated in a single-level manner, while the true human visual
system (HVS) follows the multi-level manner, and such mismatch could eventually
prevent these metrics from achieving trustworthy quality assessment. To
ameliorate, this paper advocates a novel solution to measure structure
similarity ""globally"" from the perspective of sparse representation. To perform
multi-level quality assessment in accordance with the real HVS, the
above-mentioned global metric will be integrated with the conventional local
ones by resorting to the newly devised selective deep fusion network. To
validate its efficacy and effectiveness, we have compared our method with 12
SOTA methods over two widely-used large-scale public SCI datasets, and the
quantitative results indicate that our method yields significantly higher
consistency with subjective quality score than the currently leading works.
Both the source code and data are also publicly available to gain widespread
acceptance and facilitate new advancement and its validation.",1,0,0,0,1,0,0.060418,7.0,0.373585,65
http://arxiv.org/abs/2007.02527v1,Jump Operator Planning: Goal-Conditioned Policy Ensembles and Zero-Shot Transfer,2,0.0081097,0.0772577,"In Hierarchical Control, compositionality, abstraction, and task-transfer are
crucial for designing versatile algorithms which can solve a variety of
problems with maximal representational reuse. We propose a novel hierarchical
and compositional framework called Jump-Operator Dynamic Programming for
quickly computing solutions within a super-exponential space of sequential
sub-goal tasks with ordering constraints, while also providing a fast
linearly-solvable algorithm as an implementation. This approach involves
controlling over an ensemble of reusable goal-conditioned polices functioning
as temporally extended actions, and utilizes transition operators called
feasibility functions, which are used to summarize initial-to-final state
dynamics of the polices. Consequently, the added complexity of grounding a
high-level task space onto a larger ambient state-space can be mitigated by
optimizing in a lower-dimensional subspace defined by the grounding,
substantially improving the scalability of the algorithm while effecting
transferable solutions. We then identify classes of objective functions on this
subspace whose solutions are invariant to the grounding, resulting in optimal
zero-shot transfer.",0,0,0,0,0,0,0.3522,5.0,0.51125,29
http://arxiv.org/abs/2012.04778v2,Fact-Enhanced Synthetic News Generation,25,0.0914071,0.433533,"The advanced text generation methods have witnessed great success in text
summarization, language translation, and synthetic news generation. However,
these techniques can be abused to generate disinformation and fake news. To
better understand the potential threats of synthetic news, we develop a new
generation method FactGen to generate high-quality news content. The existing
text generation methods either afford limited supplementary information or lose
consistency between the input and output which makes the synthetic news less
trustworthy. To address these issues, FactGen retrieves external facts to
enrich the output and reconstructs the input claim from the generated content
to improve the consistency among the input and the output. Experiment results
on real-world datasets show that the generated news contents of FactGen are
consistent and contain rich facts. We also discuss the possible defending
method to identify these synthetic news pieces if FactGen is used to generate
synthetic news.",1,1,0,0,0,0,0.658325,5.0,0.692371,44
http://arxiv.org/abs/2012.08987v7,Discovering New Intents with Deep Aligned Clustering,91,0.479074,0.870442,"Discovering new intents is a crucial task in dialogue systems. Most existing
methods are limited in transferring the prior knowledge from known intents to
new intents. They also have difficulties in providing high-quality supervised
signals to learn clustering-friendly features for grouping unlabeled intents.
In this work, we propose an effective method, Deep Aligned Clustering, to
discover new intents with the aid of the limited known intent data. Firstly, we
leverage a few labeled known intent samples as prior knowledge to pre-train the
model. Then, we perform k-means to produce cluster assignments as
pseudo-labels. Moreover, we propose an alignment strategy to tackle the label
inconsistency problem during clustering assignments. Finally, we learn the
intent representations under the supervision of the aligned pseudo-labels. With
an unknown number of new intents, we predict the number of intent categories by
eliminating low-confidence intent-wise clusters. Extensive experiments on two
benchmark datasets show that our method is more robust and achieves substantial
improvements over the state-of-the-art methods. The codes are released at
https://github.com/thuiar/DeepAligned-Clustering.",1,1,0,0,1,0,0.594186,6.0,0.714544,41
http://arxiv.org/abs/2007.07843v1,Few-shot Scene-adaptive Anomaly Detection,103,0.321923,0.87242,"We address the problem of anomaly detection in videos. The goal is to
identify unusual behaviours automatically by learning exclusively from normal
videos. Most existing approaches are usually data-hungry and have limited
generalization abilities. They usually need to be trained on a large number of
videos from a target scene to achieve good results in that scene. In this
paper, we propose a novel few-shot scene-adaptive anomaly detection problem to
address the limitations of previous approaches. Our goal is to learn to detect
anomalies in a previously unseen scene with only a few frames. A reliable
solution for this new problem will have huge potential in real-world
applications since it is expensive to collect a massive amount of data for each
target scene. We propose a meta-learning based approach for solving this new
problem; extensive experimental results demonstrate the effectiveness of our
proposed method.",1,1,1,0,0,0,0.724354,8.0,0.830518,40
http://arxiv.org/abs/2007.03669v2,"See, Hear, Explore: Curiosity via Audio-Visual Association",57,0.708068,0.961137,"Exploration is one of the core challenges in reinforcement learning. A common
formulation of curiosity-driven exploration uses the difference between the
real future and the future predicted by a learned model. However, predicting
the future is an inherently difficult task which can be ill-posed in the face
of stochasticity. In this paper, we introduce an alternative form of curiosity
that rewards novel associations between different senses. Our approach exploits
multiple modalities to provide a stronger signal for more efficient
exploration. Our method is inspired by the fact that, for humans, both sight
and sound play a critical role in exploration. We present results on several
Atari environments and Habitat (a photorealistic navigation simulator), showing
the benefits of using an audio-visual association model for intrinsically
guiding learning agents in the absence of external rewards. For videos and
code, see https://vdean.github.io/audio-curiosity.html.",1,0,0,0,0,0,0.970346,5.0,0.9297,45
http://arxiv.org/abs/2101.09392v1,Fixed Viewpoint Mirror Surface Reconstruction under an Uncalibrated Camera,2,0.0134142,0.104732,"This paper addresses the problem of mirror surface reconstruction, and
proposes a solution based on observing the reflections of a moving reference
plane on the mirror surface. Unlike previous approaches which require tedious
calibration, our method can recover the camera intrinsics, the poses of the
reference plane, as well as the mirror surface from the observed reflections of
the reference plane under at least three unknown distinct poses. We first show
that the 3D poses of the reference plane can be estimated from the reflection
correspondences established between the images and the reference plane. We then
form a bunch of 3D lines from the reflection correspondences, and derive an
analytical solution to recover the line projection matrix. We transform the
line projection matrix to its equivalent camera projection matrix, and propose
a cross-ratio based formulation to optimize the camera projection matrix by
minimizing reprojection errors. The mirror surface is then reconstructed based
on the optimized cross-ratio constraint. Experimental results on both synthetic
and real data are presented, which demonstrate the feasibility and accuracy of
our method.",1,0,0,0,0,0,2.71779e-05,22.0,0.448976,38
http://arxiv.org/abs/2105.01727v1,GANs for Urban Design,3,0.0210703,0.187688,"Development and diffusion of machine learning and big data tools provide a
new tool for architects and urban planners that could be used as analytical or
design instruments. The topic investigated in this paper is the application of
Generative Adversarial Networks to the design of an urban block. The research
presents a flexible model able to adapt to the morphological characteristics of
a city. This method does not define explicitly any of the parameters of an
urban block typical for a city, the algorithm learns them from the existing
urban context. This approach has been applied to the cities with different
morphology: Milan, Amsterdam, Tallinn, Turin, and Bengaluru in order to see the
performance of the model and the possibility of style translation between
different cities. The data are gathered from Openstreetmap and Open Data
portals of the cities. This research presents the results of the experiments
and their quantitative and qualitative evaluation.",0,1,0,0,0,0,0.122682,7.0,0.47959,21
http://arxiv.org/abs/2109.00181v1,CTAL: Pre-training Cross-modal Transformer for Audio-and-Language Representations,11,0.0682476,0.265372,"Existing audio-language task-specific predictive approaches focus on building
complicated late-fusion mechanisms. However, these models are facing challenges
of overfitting with limited labels and low model generalization abilities. In
this paper, we present a Cross-modal Transformer for Audio-and-Language, i.e.,
CTAL, which aims to learn the intra-modality and inter-modality connections
between audio and language through two proxy tasks on a large amount of
audio-and-language pairs: masked language modeling and masked cross-modal
acoustic modeling. After fine-tuning our pre-trained model on multiple
downstream audio-and-language tasks, we observe significant improvements across
various tasks, such as, emotion classification, sentiment analysis, and speaker
verification. On this basis, we further propose a specially-designed fusion
mechanism that can be used in fine-tuning phase, which allows our pre-trained
model to achieve better performance. Lastly, we demonstrate detailed ablation
studies to prove that both our novel cross-modality fusion component and
audio-language pre-training methods significantly contribute to the promising
results.",1,0,1,0,0,0,0.853963,6.0,0.840819,47
http://arxiv.org/abs/2106.00517v3,Cooperative Multi-Agent Transfer Learning with Level-Adaptive Credit Assignment,13,0.216896,0.56647,"Extending transfer learning to cooperative multi-agent reinforcement learning
(MARL) has recently received much attention. In contrast to the single-agent
setting, the coordination indispensable in cooperative MARL constrains each
agent's policy. However, existing transfer methods focus exclusively on agent
policy and ignores coordination knowledge. We propose a new architecture that
realizes robust coordination knowledge transfer through appropriate
decomposition of the overall coordination into several coordination patterns.
We use a novel mixing network named level-adaptive QTransformer
(LA-QTransformer) to realize agent coordination that considers credit
assignment, with appropriate coordination patterns for different agents
realized by a novel level-adaptive Transformer (LA-Transformer) dedicated to
the transfer of coordination knowledge. In addition, we use a novel agent
network named Population Invariant agent with Transformer (PIT) to realize the
coordination transfer in more varieties of scenarios. Extensive experiments in
StarCraft II micro-management show that LA-QTransformer together with PIT
achieves superior performance compared with state-of-the-art baselines.",0,0,0,0,1,0,0.947331,6.0,0.911706,35
http://arxiv.org/abs/2102.13326v1,Zero-Shot Learning Based on Knowledge Sharing,1,0.00528856,0.013663,"Zero-Shot Learning (ZSL) is an emerging research that aims to solve the
classification problems with very few training data. The present works on ZSL
mainly focus on the mapping of learning semantic space to visual space. It
encounters many challenges that obstruct the progress of ZSL research. First,
the representation of the semantic feature is inadequate to represent all
features of the categories. Second, the domain drift problem still exists
during the transfer from semantic space to visual space. In this paper, we
introduce knowledge sharing (KS) to enrich the representation of semantic
features. Based on KS, we apply a generative adversarial network to generate
pseudo visual features from semantic features that are very close to the real
visual features. Abundant experimental results from two benchmark datasets of
ZSL show that the proposed approach has a consistent improvement.",0,1,0,0,0,0,0.145307,12.0,0.711595,34
http://arxiv.org/abs/2104.08110v1,LU-BZU at SemEval-2021 Task 2: Word2Vec and Lemma2Vec performance in Arabic Word-in-Context disambiguation,11,0.491822,0.664089,"This paper presents a set of experiments to evaluate and compare between the
performance of using CBOW Word2Vec and Lemma2Vec models for Arabic
Word-in-Context (WiC) disambiguation without using sense inventories or sense
embeddings. As part of the SemEval-2021 Shared Task 2 on WiC disambiguation, we
used the dev.ar-ar dataset (2k sentence pairs) to decide whether two words in a
given sentence pair carry the same meaning. We used two Word2Vec models:
Wiki-CBOW, a pre-trained model on Arabic Wikipedia, and another model we
trained on large Arabic corpora of about 3 billion tokens. Two Lemma2Vec models
was also constructed based on the two Word2Vec models. Each of the four models
was then used in the WiC disambiguation task, and then evaluated on the
SemEval-2021 test.ar-ar dataset. At the end, we reported the performance of
different models and compared between using lemma-based and word-based models.",0,1,0,0,0,0,0.851231,7.0,0.862176,37
http://arxiv.org/abs/2103.04133v1,Learning Statistical Texture for Semantic Segmentation,95,0.168851,0.674201,"Existing semantic segmentation works mainly focus on learning the contextual
information in high-level semantic features with CNNs. In order to maintain a
precise boundary, low-level texture features are directly skip-connected into
the deeper layers. Nevertheless, texture features are not only about local
structure, but also include global statistical knowledge of the input image. In
this paper, we fully take advantages of the low-level texture features and
propose a novel Statistical Texture Learning Network (STLNet) for semantic
segmentation. For the first time, STLNet analyzes the distribution of low level
information and efficiently utilizes them for the task. Specifically, a novel
Quantization and Counting Operator (QCO) is designed to describe the texture
information in a statistical manner. Based on QCO, two modules are introduced:
(1) Texture Enhance Module (TEM), to capture texture-related information and
enhance the texture details; (2) Pyramid Texture Feature Extraction Module
(PTFEM), to effectively extract the statistical texture features from multiple
scales. Through extensive experiments, we show that the proposed STLNet
achieves state-of-the-art performance on three semantic segmentation
benchmarks: Cityscapes, PASCAL Context and ADE20K.",0,1,1,0,1,0,0.327515,6.0,0.577696,39
http://arxiv.org/abs/2109.01703v1,Will bots take over the supply chain? Revisiting Agent-based supply chain automation,24,0.443791,0.874585,"Agent-based systems have the capability to fuse information from many
distributed sources and create better plans faster. This feature makes
agent-based systems naturally suitable to address the challenges in Supply
Chain Management (SCM). Although agent-based supply chains systems have been
proposed since early 2000; industrial uptake of them has been lagging. The
reasons quoted include the immaturity of the technology, a lack of
interoperability with supply chain information systems, and a lack of trust in
Artificial Intelligence (AI). In this paper, we revisit the agent-based supply
chain and review the state of the art. We find that agent-based technology has
matured, and other supporting technologies that are penetrating supply chains;
are filling in gaps, leaving the concept applicable to a wider range of
functions. For example, the ubiquity of IoT technology helps agents ""sense"" the
state of affairs in a supply chain and opens up new possibilities for
automation. Digital ledgers help securely transfer data between third parties,
making agent-based information sharing possible, without the need to integrate
Enterprise Resource Planning (ERP) systems. Learning functionality in agents
enables agents to move beyond automation and towards autonomy. We note this
convergence effect through conceptualising an agent-based supply chain
framework, reviewing its components, and highlighting research challenges that
need to be addressed in moving forward.",0,1,0,0,0,0,0.0053926,28.0,0.756091,161
http://arxiv.org/abs/2108.11101v1,Detecting Small Objects in Thermal Images Using Single-Shot Detector,10,0.00873929,0.0785974,"SSD (Single Shot Multibox Detector) is one of the most successful object
detectors for its high accuracy and fast speed. However, the features from
shallow layer (mainly Conv4_3) of SSD lack semantic information, resulting in
poor performance in small objects. In this paper, we proposed DDSSD (Dilation
and Deconvolution Single Shot Multibox Detector), an enhanced SSD with a novel
feature fusion module which can improve the performance over SSD for small
object detection. In the feature fusion module, dilation convolution module is
utilized to enlarge the receptive field of features from shallow layer and
deconvolution module is adopted to increase the size of feature maps from high
layer. Our network achieves 79.7% mAP on PASCAL VOC2007 test and 28.3% mmAP on
MS COCO test-dev at 41 FPS with only 300x300 input using a single Nvidia 1080
GPU. Especially, for small objects, DDSSD achieves 10.5% on MS COCO and 22.8%
on FLIR thermal dataset, outperforming a lot of state-of-the-art object
detection algorithms in both aspects of accuracy and speed.",0,1,0,0,1,0,0.171944,11.0,0.702075,34
http://arxiv.org/abs/2109.11442v1,Corpus and Models for Lemmatisation and POS-tagging of Old French,5,0.320866,0.674518,"Old French is a typical example of an under-resourced historic languages,
that furtherly displays animportant amount of linguistic variation. In this
paper, we present the current results of a long going project (2015-...) and
describe how we broached the difficult question of providing lemmatisation
andPOS models for Old French with the help of neural taggers and the
progressive constitution of dedicated corpora.",1,1,0,0,0,0,0.0806461,11.0,0.628602,46
http://arxiv.org/abs/2110.06997v1,Bandits Don't Follow Rules: Balancing Multi-Facet Machine Translation with Multi-Armed Bandits,13,0.021682,0.398572,"Training data for machine translation (MT) is often sourced from a multitude
of large corpora that are multi-faceted in nature, e.g. containing contents
from multiple domains or different levels of quality or complexity. Naturally,
these facets do not occur with equal frequency, nor are they equally important
for the test scenario at hand. In this work, we propose to optimize this
balance jointly with MT model parameters to relieve system developers from
manual schedule design. A multi-armed bandit is trained to dynamically choose
between facets in a way that is most beneficial for the MT system. We evaluate
it on three different multi-facet applications: balancing translationese and
natural training data, or data from multiple domains or multiple language
pairs. We find that bandit learning leads to competitive MT systems across
tasks, and our analysis provides insights into its learned strategies and the
underlying data sets.",0,1,0,0,0,0,0.083891,7.0,0.422259,66
http://arxiv.org/abs/2110.01938v1,Sicilian Translator: A Recipe for Low-Resource NMT,1,0.0292001,0.0841914,"With 17,000 pairs of Sicilian-English translated sentences, Arba Sicula
developed the first neural machine translator for the Sicilian language. Using
small subword vocabularies, we trained small Transformer models with high
dropout parameters and achieved BLEU scores in the upper 20s. Then we
supplemented our dataset with backtranslation and multilingual translation and
pushed our scores into the mid 30s. We also attribute our success to
incorporating theoretical information in our dataset. Prior to training, we
biased the subword vocabulary towards the desinences one finds in a textbook.
And we included textbook exercises in our dataset.",0,1,0,1,0,0,0.992306,9.0,0.997013,15
http://arxiv.org/abs/2109.01135v7,Sequence-to-Sequence Learning with Latent Neural Grammars,36,0.0577572,0.339736,"Sequence-to-sequence learning with neural networks has become the de facto
standard for sequence prediction tasks. This approach typically models the
local distribution over the next word with a powerful neural network that can
condition on arbitrary context. While flexible and performant, these models
often require large datasets for training and can fail spectacularly on
benchmarks designed to test for compositional generalization. This work
explores an alternative, hierarchical approach to sequence-to-sequence learning
with quasi-synchronous grammars, where each node in the target tree is
transduced by a node in the source tree. Both the source and target trees are
treated as latent and induced during training. We develop a neural
parameterization of the grammar which enables parameter sharing over the
combinatorial space of derivation rules without the need for manual feature
engineering. We apply this latent neural grammar to various domains -- a
diagnostic language navigation task designed to test for compositional
generalization (SCAN), style transfer, and small-scale machine translation --
and find that it performs respectably compared to standard baselines.",1,0,0,0,0,0,0.00785838,9.0,0.283148,134
http://arxiv.org/abs/2104.09962v3,Text-Aware Predictive Monitoring of Business Processes,9,0.110674,0.560974,"The real-time prediction of business processes using historical event data is
an important capability of modern business process monitoring systems. Existing
process prediction methods are able to also exploit the data perspective of
recorded events, in addition to the control-flow perspective. However, while
well-structured numerical or categorical attributes are considered in many
prediction techniques, almost no technique is able to utilize text documents
written in natural language, which can hold information critical to the
prediction task. In this paper, we illustrate the design, implementation, and
evaluation of a novel text-aware process prediction model based on Long
Short-Term Memory (LSTM) neural networks and natural language models. The
proposed model can take categorical, numerical and textual attributes in event
data into account to predict the activity and timestamp of the next event, the
outcome, and the cycle time of a running process instance. Experiments show
that the text-aware model is able to outperform state-of-the-art process
prediction methods on simulated and real-world event logs containing textual
data.",0,1,0,0,1,0,0.434739,10.0,0.782926,18
http://arxiv.org/abs/2109.01518v1,Biomedical Data-to-Text Generation via Fine-Tuning Transformers,9,0.415365,0.819908,"Data-to-text (D2T) generation in the biomedical domain is a promising - yet
mostly unexplored - field of research. Here, we apply neural models for D2T
generation to a real-world dataset consisting of package leaflets of European
medicines. We show that fine-tuned transformers are able to generate realistic,
multisentence text from data in the biomedical domain, yet have important
limitations. We also release a new dataset (BioLeaflets) for benchmarking D2T
generation models in the biomedical domain.",1,1,0,1,0,0,0.988301,7.0,0.983297,28
http://arxiv.org/abs/2111.04193v2,Machine-in-the-Loop Rewriting for Creative Image Captioning,11,0.0389833,0.225719,"Machine-in-the-loop writing aims to enable humans to collaborate with models
to complete their writing tasks more effectively. Prior work has found that
providing humans a machine-written draft or sentence-level continuations has
limited success since the generated text tends to deviate from humans'
intention. To allow the user to retain control over the content, we train a
rewriting model that, when prompted, modifies specified spans of text within
the user's original draft to introduce descriptive and figurative elements
locally in the text. We evaluate the model on its ability to collaborate with
humans on the task of creative image captioning. On a user study through Amazon
Mechanical Turk, our model is rated to be more helpful than a baseline
infilling language model. In addition, third-party evaluation shows that users
write more descriptive and figurative captions when collaborating with our
model compared to completing the task alone.",0,1,0,0,0,0,0.119111,6.0,0.387601,34
http://arxiv.org/abs/2106.08367v1,What Context Features Can Transformer Language Models Use?,62,0.134251,0.557388,"Transformer-based language models benefit from conditioning on contexts of
hundreds to thousands of previous tokens. What aspects of these contexts
contribute to accurate model prediction? We describe a series of experiments
that measure usable information by selectively ablating lexical and structural
information in transformer language models trained on English Wikipedia. In
both mid- and long-range contexts, we find that several extremely destructive
context manipulations -- including shuffling word order within sentences and
deleting all words other than nouns -- remove less than 15% of the usable
information. Our results suggest that long contexts, but not their detailed
syntactic and propositional content, are important for the low perplexity of
current transformer language models.",1,0,0,0,0,1,0.653386,5.0,0.68968,40
http://arxiv.org/abs/2103.01116v1,Blockchain-Based Federated Learning in Mobile Edge Networks with Application in Internet of Vehicles,9,0.1109,0.213211,"The rapid increase of the data scale in Internet of Vehicles (IoV) system
paradigm, hews out new possibilities in boosting the service quality for the
emerging applications through data sharing. Nevertheless, privacy concerns are
major bottlenecks for data providers to share private data in traditional IoV
networks. To this end, federated learning (FL) as an emerging learning
paradigm, where data providers only send local model updates trained on their
local raw data rather than upload any raw data, has been recently proposed to
build a privacy-preserving data sharing models. Unfortunately, by analyzing on
the differences of uploaded local model updates from data providers, private
information can still be divulged, and performance of the system cannot be
guaranteed when partial federated nodes executes malicious behavior.
Additionally, traditional cloud-based FL poses challenges to the communication
overhead with the rapid increase of terminal equipment in IoV system. All these
issues inspire us to propose an autonomous blockchain empowered
privacy-preserving FL framework in this paper, where the mobile edge computing
(MEC) technology was naturally integrated in IoV system.",0,1,0,0,0,0,0.938945,6.0,0.903124,31
http://arxiv.org/abs/2110.03786v2,Efficient large-scale image retrieval with deep feature orthogonality and Hybrid-Swin-Transformers,12,0.030004,0.375123,"We present an efficient end-to-end pipeline for largescale landmark
recognition and retrieval. We show how to combine and enhance concepts from
recent research in image retrieval and introduce two architectures especially
suited for large-scale landmark identification. A model with deep orthogonal
fusion of local and global features (DOLG) using an EfficientNet backbone as
well as a novel Hybrid-Swin-Transformer is discussed and details how to train
both architectures efficiently using a step-wise approach and a sub-center
arcface loss with dynamic margins are provided. Furthermore, we elaborate a
novel discriminative re-ranking methodology for image retrieval. The
superiority of our approach was demonstrated by winning the recognition and
retrieval track of the Google Landmark Competition 2021.",1,1,0,0,0,0,0.300691,5.0,0.472479,18
http://arxiv.org/abs/2109.06387v2,Rationales for Sequential Predictions,20,0.0582698,0.534854,"Sequence models are a critical component of modern NLP systems, but their
predictions are difficult to explain. We consider model explanations though
rationales, subsets of context that can explain individual model predictions.
We find sequential rationales by solving a combinatorial optimization: the best
rationale is the smallest subset of input tokens that would predict the same
output as the full sequence. Enumerating all subsets is intractable, so we
propose an efficient greedy algorithm to approximate this objective. The
algorithm, which is called greedy rationalization, applies to any model. For
this approach to be effective, the model should form compatible conditional
distributions when making predictions on incomplete subsets of the context.
This condition can be enforced with a short fine-tuning step. We study greedy
rationalization on language modeling and machine translation. Compared to
existing baselines, greedy rationalization is best at optimizing the
combinatorial objective and provides the most faithful rationales. On a new
dataset of annotated sequential rationales, greedy rationales are most similar
to human rationales.",0,0,0,0,0,1,0.379529,8.0,0.706363,54
http://arxiv.org/abs/2106.05969v3,Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation,57,0.24901,0.879749,"We propose a method for object-aware 3D egocentric pose estimation that
tightly integrates kinematics modeling, dynamics modeling, and scene object
information. Unlike prior kinematics or dynamics-based approaches where the two
components are used disjointly, we synergize the two approaches via
dynamics-regulated training. At each timestep, a kinematic model is used to
provide a target pose using video evidence and simulation state. Then, a
prelearned dynamics model attempts to mimic the kinematic pose in a physics
simulator. By comparing the pose instructed by the kinematic model against the
pose generated by the dynamics model, we can use their misalignment to further
improve the kinematic model. By factoring in the 6DoF pose of objects (e.g.,
chairs, boxes) in the scene, we demonstrate for the first time, the ability to
estimate physically-plausible 3D human-object interactions using a single
wearable camera. We evaluate our egocentric pose estimation method in both
controlled laboratory settings and real-world scenarios.",0,1,0,0,0,0,0.503002,5.0,0.60654,68
http://arxiv.org/abs/2110.04955v1,BuildingNet: Learning to Label 3D Buildings,25,0.490091,0.629788,"We introduce BuildingNet: (a) a large-scale dataset of 3D building models
whose exteriors are consistently labeled, (b) a graph neural network that
labels building meshes by analyzing spatial and structural relations of their
geometric primitives. To create our dataset, we used crowdsourcing combined
with expert guidance, resulting in 513K annotated mesh primitives, grouped into
292K semantic part components across 2K building models. The dataset covers
several building categories, such as houses, churches, skyscrapers, town halls,
libraries, and castles. We include a benchmark for evaluating mesh and point
cloud labeling. Buildings have more challenging structural complexity compared
to objects in existing benchmarks (e.g., ShapeNet, PartNet), thus, we hope that
our dataset can nurture the development of algorithms that are able to cope
with such large-scale geometric data for both vision and graphics tasks e.g.,
3D semantic segmentation, part-based generative models, correspondences,
texturing, and analysis of point cloud data acquired from real-world buildings.
Finally, we show that our mesh-based graph neural network significantly
improves performance over several baselines for labeling 3D meshes.",1,1,1,1,0,0,0.801437,9.0,0.874546,69
http://arxiv.org/abs/2104.06751v2,Is Multi-Hop Reasoning Really Explainable? Towards Benchmarking Reasoning Interpretability,12,0.161617,0.395769,"Multi-hop reasoning has been widely studied in recent years to obtain more
interpretable link prediction. However, we find in experiments that many paths
given by these models are actually unreasonable, while little works have been
done on interpretability evaluation for them. In this paper, we propose a
unified framework to quantitatively evaluate the interpretability of multi-hop
reasoning models so as to advance their development. In specific, we define
three metrics including path recall, local interpretability, and global
interpretability for evaluation, and design an approximate strategy to
calculate them using the interpretability scores of rules. Furthermore, we
manually annotate all possible rules and establish a Benchmark to detect the
Interpretability of Multi-hop Reasoning (BIMR). In experiments, we run nine
baselines on our benchmark. The experimental results show that the
interpretability of current multi-hop reasoning models is less satisfactory and
is still far from the upper bound given by our benchmark. Moreover, the
rule-based models outperform the multi-hop reasoning models in terms of
performance and interpretability, which points to a direction for future
research, i.e., we should investigate how to better incorporate rule
information into the multi-hop reasoning model. Our codes and datasets can be
obtained from https://github.com/THU-KEG/BIMR.",1,0,0,0,0,0,0.655879,6.0,0.742532,27
http://arxiv.org/abs/2108.11645v2,Robust Model-based Reinforcement Learning for Autonomous Greenhouse Control,10,0.135688,0.402269,"Due to the high efficiency and less weather dependency, autonomous
greenhouses provide an ideal solution to meet the increasing demand for fresh
food. However, managers are faced with some challenges in finding appropriate
control strategies for crop growth, since the decision space of the greenhouse
control problem is an astronomical number. Therefore, an intelligent
closed-loop control framework is highly desired to generate an automatic
control policy. As a powerful tool for optimal control, reinforcement learning
(RL) algorithms can surpass human beings' decision-making and can also be
seamlessly integrated into the closed-loop control framework. However, in
complex real-world scenarios such as agricultural automation control, where the
interaction with the environment is time-consuming and expensive, the
application of RL algorithms encounters two main challenges, i.e., sample
efficiency and safety. Although model-based RL methods can greatly mitigate the
efficiency problem of greenhouse control, the safety problem has not got too
much attention. In this paper, we present a model-based robust RL framework for
autonomous greenhouse control to meet the sample efficiency and safety
challenges. Specifically, our framework introduces an ensemble of environment
models to work as a simulator and assist in policy optimization, thereby
addressing the low sample efficiency problem. As for the safety concern, we
propose a sample dropout module to focus more on worst-case samples, which can
help improve the adaptability of the greenhouse planting policy in extreme
cases. Experimental results demonstrate that our approach can learn a more
effective greenhouse planting policy with better robustness than existing
methods.",0,1,0,0,0,0,0.376144,10.0,0.763944,37
http://arxiv.org/abs/2109.07298v1,FFAVOD: Feature Fusion Architecture for Video Object Detection,15,0.0699811,0.568029,"A significant amount of redundancy exists between consecutive frames of a
video. Object detectors typically produce detections for one image at a time,
without any capabilities for taking advantage of this redundancy. Meanwhile,
many applications for object detection work with videos, including intelligent
transportation systems, advanced driver assistance systems and video
surveillance. Our work aims at taking advantage of the similarity between video
frames to produce better detections. We propose FFAVOD, standing for feature
fusion architecture for video object detection. We first introduce a novel
video object detection architecture that allows a network to share feature maps
between nearby frames. Second, we propose a feature fusion module that learns
to merge feature maps to enhance them. We show that using the proposed
architecture and the fusion module can improve the performance of three base
object detectors on two object detection benchmarks containing sequences of
moving road users. Additionally, to further increase performance, we propose an
improvement to the SpotNet attention module. Using our architecture on the
improved SpotNet detector, we obtain the state-of-the-art performance on the
UA-DETRAC public benchmark as well as on the UAVDT dataset. Code is available
at https://github.com/hu64/FFAVOD.",1,1,0,0,1,0,0.220588,8.0,0.625141,46
http://arxiv.org/abs/2106.08226v1,Consistency Regularization for Cross-Lingual Fine-Tuning,49,0.620055,0.899287,"Fine-tuning pre-trained cross-lingual language models can transfer
task-specific supervision from one language to the others. In this work, we
propose to improve cross-lingual fine-tuning with consistency regularization.
Specifically, we use example consistency regularization to penalize the
prediction sensitivity to four types of data augmentations, i.e., subword
sampling, Gaussian noise, code-switch substitution, and machine translation. In
addition, we employ model consistency to regularize the models trained with two
augmented versions of the same training set. Experimental results on the XTREME
benchmark show that our method significantly improves cross-lingual fine-tuning
across various tasks, including text classification, question answering, and
sequence labeling.",0,1,0,0,0,0,0.977599,4.0,0.931302,43
http://arxiv.org/abs/2103.12169v1,A Pilot Study For Fragment Identification Using 2D NMR and Deep Learning,10,0.352289,0.602329,"This paper presents a method to identify substructures in NMR spectra of
mixtures, specifically 2D spectra, using a bespoke image-based Convolutional
Neural Network application. This is done using HSQC and HMBC spectra separately
and in combination. The application can reliably detect substructures in pure
compounds, using a simple network. It can work for mixtures when trained on
pure compounds only. HMBC data and the combination of HMBC and HSQC show better
results than HSQC alone.",1,1,0,0,0,0,0.896502,4.0,0.802387,47
http://arxiv.org/abs/2110.07379v1,Towards Safer Transportation: a self-supervised learning approach for traffic video deraining,1,0.0100605,0.140064,"Video monitoring of traffic is useful for traffic management and control,
traffic counting, and traffic law enforcement. However, traffic monitoring
during inclement weather such as rain is a challenging task because video
quality is corrupted by streaks of falling rain on the video image, and this
hinders reliable characterization not only of the road environment but also of
road-user behavior during such adverse weather events. This study proposes a
two-stage self-supervised learning method to remove rain streaks in traffic
videos. The first and second stages address intra- and inter-frame noise,
respectively. The results indicated that the model exhibits satisfactory
performance in terms of the image visual quality and the Peak Signal-Noise
Ratio value.",0,1,0,0,0,0,0.47899,11.0,0.814803,46
http://arxiv.org/abs/2104.06059v1,First and Second Order Dynamics in a Hierarchical SOM system for Action Recognition,23,0.0673063,0.223632,"Human recognition of the actions of other humans is very efficient and is
based on patterns of movements. Our theoretical starting point is that the
dynamics of the joint movements is important to action categorization. On the
basis of this theory, we present a novel action recognition system that employs
a hierarchy of Self-Organizing Maps together with a custom supervised neural
network that learns to categorize actions. The system preprocesses the input
from a Kinect like 3D camera to exploit the information not only about joint
positions, but also their first and second order dynamics. We evaluate our
system in two experiments with publicly available data sets, and compare its
performance to the performance with less sophisticated preprocessing of the
input. The results show that including the dynamics of the actions improves the
performance. We also apply an attention mechanism that focuses on the parts of
the body that are the most involved in performing the actions.",0,0,0,0,0,0,0.000466586,16.0,0.420045,44
http://arxiv.org/abs/2109.00162v4,Eyes Tell All: Irregular Pupil Shapes Reveal GAN-generated Faces,50,0.482364,0.984628,"Generative adversary network (GAN) generated high-realistic human faces have
been used as profile images for fake social media accounts and are visually
challenging to discern from real ones. In this work, we show that GAN-generated
faces can be exposed via irregular pupil shapes. This phenomenon is caused by
the lack of physiological constraints in the GAN models. We demonstrate that
such artifacts exist widely in high-quality GAN-generated faces and further
describe an automatic method to extract the pupils from two eyes and analysis
their shapes for exposing the GAN-generated faces. Qualitative and quantitative
evaluations of our method suggest its simplicity and effectiveness in
distinguishing GAN-generated faces.",1,1,0,0,0,0,0.770561,4.0,0.694316,40
http://arxiv.org/abs/2104.01454v4,Few-Shot Keyword Spotting in Any Language,30,0.850231,0.840963,"We introduce a few-shot transfer learning method for keyword spotting in any
language. Leveraging open speech corpora in nine languages, we automate the
extraction of a large multilingual keyword bank and use it to train an
embedding model. With just five training examples, we fine-tune the embedding
model for keyword spotting and achieve an average F1 score of 0.75 on keyword
classification for 180 new keywords unseen by the embedding model in these nine
languages. This embedding model also generalizes to new languages. We achieve
an average F1 score of 0.65 on 5-shot models for 260 keywords sampled across 13
new languages unseen by the embedding model. We investigate streaming accuracy
for our 5-shot models in two contexts: keyword spotting and keyword search.
Across 440 keywords in 22 languages, we achieve an average streaming keyword
spotting accuracy of 87.4% with a false acceptance rate of 4.3%, and observe
promising initial results on keyword search.",0,1,1,0,0,0,0.918721,6.0,0.885132,23
http://arxiv.org/abs/2110.13414v1,Semantic Host-free Trojan Attack,1,0.023218,0.0302,"In this paper, we propose a novel host-free Trojan attack with triggers that
are fixed in the semantic space but not necessarily in the pixel space. In
contrast to existing Trojan attacks which use clean input images as hosts to
carry small, meaningless trigger patterns, our attack considers triggers as
full-sized images belonging to a semantically meaningful object class. Since in
our attack, the backdoored classifier is encouraged to memorize the abstract
semantics of the trigger images than any specific fixed pattern, it can be
later triggered by semantically similar but different looking images. This
makes our attack more practical to be applied in the real-world and harder to
defend against. Extensive experimental results demonstrate that with only a
small number of Trojan patterns for training, our attack can generalize well to
new patterns of the same Trojan class and can bypass state-of-the-art defense
methods.",0,0,0,0,1,0,0.980435,6.0,0.960037,16
http://arxiv.org/abs/2110.02871v1,ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods,10,0.28183,0.441261,"Climate change is a major threat to humanity, and the actions required to
prevent its catastrophic consequences include changes in both policy-making and
individual behaviour. However, taking action requires understanding the effects
of climate change, even though they may seem abstract and distant. Projecting
the potential consequences of extreme climate events such as flooding in
familiar places can help make the abstract impacts of climate change more
concrete and encourage action. As part of a larger initiative to build a
website that projects extreme climate events onto user-chosen photos, we
present our solution to simulate photo-realistic floods on authentic images. To
address this complex task in the absence of suitable training data, we propose
ClimateGAN, a model that leverages both simulated and real data for
unsupervised domain adaptation and conditional image generation. In this paper,
we describe the details of our framework, thoroughly evaluate components of our
architecture and demonstrate that our model is capable of robustly generating
photo-realistic flooding.",0,1,0,1,0,0,0.960346,8.0,0.945286,65
http://arxiv.org/abs/2105.14088v1,Cloud Collectives: Towards Cloud-aware Collectives forML Workloads with Rank Reordering,1,0.00277225,0.0347006,"ML workloads are becoming increasingly popular in the cloud. Good cloud
training performance is contingent on efficient parameter exchange among VMs.
We find that Collectives, the widely used distributed communication algorithms,
cannot perform optimally out of the box due to the hierarchical topology of
datacenter networks and multi-tenancy nature of the cloudenvironment.In this
paper, we present Cloud Collectives , a prototype that accelerates collectives
by reordering theranks of participating VMs such that the communication pattern
dictated by the selected collectives operation best exploits the locality in
the network.Collectives is non-intrusive, requires no code changes nor rebuild
of an existing application, and runs without support from cloud providers. Our
preliminary application of Cloud Collectives on allreduce operations in public
clouds results in a speedup of up to 3.7x in multiple microbenchmarks and 1.3x
in real-world workloads of distributed training of deep neural networks and
gradient boosted decision trees using state-of-the-art frameworks.",0,1,0,0,0,0,1.3496e-05,24.0,0.465727,48
http://arxiv.org/abs/2104.01666v1,Improving Pretrained Models for Zero-shot Multi-label Text Classification through Reinforced Label Hierarchy Reasoning,18,0.14349,0.209979,"Exploiting label hierarchies has become a promising approach to tackling the
zero-shot multi-label text classification (ZS-MTC) problem. Conventional
methods aim to learn a matching model between text and labels, using a graph
encoder to incorporate label hierarchies to obtain effective label
representations \cite{rios2018few}. More recently, pretrained models like BERT
\cite{devlin2018bert} have been used to convert classification tasks into a
textual entailment task \cite{yin-etal-2019-benchmarking}. This approach is
naturally suitable for the ZS-MTC task. However, pretrained models are
underexplored in the existing work because they do not generate individual
vector representations for text or labels, making it unintuitive to combine
them with conventional graph encoding methods. In this paper, we explore to
improve pretrained models with label hierarchies on the ZS-MTC task. We propose
a Reinforced Label Hierarchy Reasoning (RLHR) approach to encourage
interdependence among labels in the hierarchies during training. Meanwhile, to
overcome the weakness of flat predictions, we design a rollback algorithm that
can remove logical errors from predictions during inference. Experimental
results on three real-life datasets show that our approach achieves better
performance and outperforms previous non-pretrained methods on the ZS-MTC task.",1,1,0,0,0,0,0.824682,4.0,0.736278,31
http://arxiv.org/abs/2106.14361v2,Word2Box: Capturing Set-Theoretic Semantics of Words using Box Embeddings,15,0.0730849,0.573927,"Learning representations of words in a continuous space is perhaps the most
fundamental task in NLP, however words interact in ways much richer than vector
dot product similarity can provide. Many relationships between words can be
expressed set-theoretically, for example, adjective-noun compounds (eg. ""red
cars""$\subseteq$""cars"") and homographs (eg. ""tongue""$\cap$""body"" should be
similar to ""mouth"", while ""tongue""$\cap$""language"" should be similar to
""dialect"") have natural set-theoretic interpretations. Box embeddings are a
novel region-based representation which provide the capability to perform these
set-theoretic operations. In this work, we provide a fuzzy-set interpretation
of box embeddings, and learn box representations of words using a set-theoretic
training objective. We demonstrate improved performance on various word
similarity tasks, particularly on less common words, and perform a quantitative
and qualitative analysis exploring the additional unique expressivity provided
by Word2Box.",1,0,0,0,0,0,0.165834,9.0,0.631454,54
http://arxiv.org/abs/2110.07240v1,"Causal Transformers Perform Below Chance on Recursive Nested Constructions, Unlike Humans",10,0.0431107,0.239898,"Recursive processing is considered a hallmark of human linguistic abilities.
A recent study evaluated recursive processing in recurrent neural language
models (RNN-LMs) and showed that such models perform below chance level on
embedded dependencies within nested constructions -- a prototypical example of
recursion in natural language. Here, we study if state-of-the-art Transformer
LMs do any better. We test four different Transformer LMs on two different
types of nested constructions, which differ in whether the embedded (inner)
dependency is short or long range. We find that Transformers achieve
near-perfect performance on short-range embedded dependencies, significantly
better than previous results reported for RNN-LMs and humans. However, on
long-range embedded dependencies, Transformers' performance sharply drops below
chance level. Remarkably, the addition of only three words to the embedded
dependency caused Transformers to fall from near-perfect to below-chance
performance. Taken together, our results reveal Transformers' shortcoming when
it comes to recursive, structure-based, processing.",0,0,0,0,0,0,0.219208,7.0,0.570572,36
http://arxiv.org/abs/2109.00182v2,You Only Hypothesize Once: Point Cloud Registration with Rotation-equivariant Descriptors,85,0.7739,0.925922,"In this paper, we propose a novel local descriptor-based framework, called
You Only Hypothesize Once (YOHO), for the registration of two unaligned point
clouds. In contrast to most existing local descriptors which rely on a fragile
local reference frame to gain rotation invariance, the proposed descriptor
achieves the rotation invariance by recent technologies of group equivariant
feature learning, which brings more robustness to point density and noise.
Meanwhile, the descriptor in YOHO also has a rotation equivariant part, which
enables us to estimate the registration from just one correspondence
hypothesis. Such property reduces the searching space for feasible
transformations, thus greatly improves both the accuracy and the efficiency of
YOHO. Extensive experiments show that YOHO achieves superior performances with
much fewer needed RANSAC iterations on four widely-used datasets, the
3DMatch/3DLoMatch datasets, the ETH dataset and the WHU-TLS dataset. More
details are shown in our project page: https://hpwang-whu.github.io/YOHO/.",1,0,0,0,0,0,0.785563,5.0,0.764435,99
http://arxiv.org/abs/2103.13019v1,Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama,67,0.0858894,0.587794,"The concept of literary genre is a highly complex one: not only are different
genres frequently defined on several, but not necessarily the same levels of
description, but consideration of genres as cognitive, social, or scholarly
constructs with a rich history further complicate the matter. This contribution
focuses on thematic aspects of genre with a quantitative approach, namely Topic
Modeling. Topic Modeling has proven to be useful to discover thematic patterns
and trends in large collections of texts, with a view to class or browse them
on the basis of their dominant themes. It has rarely if ever, however, been
applied to collections of dramatic texts.
  In this contribution, Topic Modeling is used to analyze a collection of
French Drama of the Classical Age and the Enlightenment. The general aim of
this contribution is to discover what semantic types of topics are found in
this collection, whether different dramatic subgenres have distinctive dominant
topics and plot-related topic patterns, and inversely, to what extent
clustering methods based on topic scores per play produce groupings of texts
which agree with more conventional genre distinctions. This contribution shows
that interesting topic patterns can be detected which provide new insights into
the thematic, subgenre-related structure of French drama as well as into the
history of French drama of the Classical Age and the Enlightenment.",0,0,0,0,0,0,0.0372369,8.0,0.389877,44
http://arxiv.org/abs/2109.07401v1,Matching with Transformers in MELT,9,0.123705,0.292145,"One of the strongest signals for automated matching of ontologies and
knowledge graphs are the textual descriptions of the concepts. The methods that
are typically applied (such as character- or token-based comparisons) are
relatively simple, and therefore do not capture the actual meaning of the
texts. With the rise of transformer-based language models, text comparison
based on meaning (rather than lexical features) is possible. In this paper, we
model the ontology matching task as classification problem and present
approaches based on transformer models. We further provide an easy to use
implementation in the MELT framework which is suited for ontology and knowledge
graph matching. We show that a transformer-based filter helps to choose the
correct correspondences given a high-recall alignment and already achieves a
good result with simple alignment post-processing methods.",0,1,0,0,0,0,0.733703,5.0,0.734115,20
http://arxiv.org/abs/2101.00603v1,A Switched View of Retinex: Deep Self-Regularized Low-Light Image Enhancement,42,0.600456,0.714199,"Self-regularized low-light image enhancement does not require any
normal-light image in training, thereby freeing from the chains on paired or
unpaired low-/normal-images. However, existing methods suffer color deviation
and fail to generalize to various lighting conditions. This paper presents a
novel self-regularized method based on Retinex, which, inspired by HSV,
preserves all colors (Hue, Saturation) and only integrates Retinex theory into
brightness (Value). We build a reflectance estimation network by restricting
the consistency of reflectances embedded in both the original and a novel
random disturbed form of the brightness of the same scene. The generated
reflectance, which is assumed to be irrelevant of illumination by Retinex, is
treated as enhanced brightness. Our method is efficient as a low-light image is
decoupled into two subspaces, color and brightness, for better preservation and
enhancement. Extensive experiments demonstrate that our method outperforms
multiple state-of-the-art algorithms qualitatively and quantitatively and
adapts to more lighting conditions.",0,1,0,0,1,0,0.986566,12.0,0.987624,26
http://arxiv.org/abs/2101.07172v2,HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network that Achieves over 0.9 Mean Dice and 86 FPS,146,0.997067,0.780394,"We propose a new convolution neural network called HarDNet-MSEG for polyp
segmentation. It achieves SOTA in both accuracy and inference speed on five
popular datasets. For Kvasir-SEG, HarDNet-MSEG delivers 0.904 mean Dice running
at 86.7 FPS on a GeForce RTX 2080 Ti GPU. It consists of a backbone and a
decoder. The backbone is a low memory traffic CNN called HarDNet68, which has
been successfully applied to various CV tasks including image classification,
object detection, multi-object tracking and semantic segmentation, etc. The
decoder part is inspired by the Cascaded Partial Decoder, known for fast and
accurate salient object detection. We have evaluated HarDNet-MSEG using those
five popular datasets. The code and all experiment details are available at
Github. https://github.com/james128333/HarDNet-MSEG",1,1,0,0,1,0,0.959099,8.0,0.944081,36
http://arxiv.org/abs/2106.05438v1,Cross-Modal Discrete Representation Learning,34,0.55657,0.576736,"Recent advances in representation learning have demonstrated an ability to
represent information from different modalities such as video, text, and audio
in a single high-level embedding vector. In this work we present a
self-supervised learning framework that is able to learn a representation that
captures finer levels of granularity across different modalities such as
concepts or events represented by visual objects or spoken words. Our framework
relies on a discretized embedding space created via vector quantization that is
shared across different modalities. Beyond the shared embedding space, we
propose a Cross-Modal Code Matching objective that forces the representations
from different views (modalities) to have a similar distribution over the
discrete embedding space such that cross-modal objects/actions localization can
be performed without direct supervision. In our experiments we show that the
proposed discretized multi-modal fine-grained representation (e.g.,
pixel/word/frame) can complement high-level summary representations (e.g.,
video/sentence/waveform) for improved performance on cross-modal retrieval
tasks. We also observe that the discretized representation uses individual
clusters to represent the same semantic concept across modalities.",0,0,0,0,0,0,0.935657,5.0,0.879961,47
http://arxiv.org/abs/2106.00952v3,End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net,16,0.0445459,0.35022,"Information extraction from document images has received a lot of attention
recently, due to the need for digitizing a large volume of unstructured
documents such as invoices, receipts, bank transfers, etc. In this paper, we
propose a novel deep learning architecture for end-to-end information
extraction on the 2D character-grid embedding of the document, namely the
\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and
spatial relations between 2D elements, our model leverages a specialized
multi-stage encoder-decoders design, in conjunction with efficient uses of the
self-attention mechanism and the box convolution. Experimental results on
different datasets show that our model outperforms the baseline U-Net
architecture by a large margin while using 40\% fewer parameters. Moreover, it
also significantly improved the baseline in erroneous OCR and limited training
data scenario, thus becomes practical for real-world applications.",1,1,0,0,1,0,0.00401398,13.0,0.451892,33
http://arxiv.org/abs/2101.06184v3,Temporal-Relational CrossTransformers for Few-Shot Action Recognition,112,0.72797,0.799717,"We propose a novel approach to few-shot action recognition, finding
temporally-corresponding frame tuples between the query and videos in the
support set. Distinct from previous few-shot works, we construct class
prototypes using the CrossTransformer attention mechanism to observe relevant
sub-sequences of all support videos, rather than using class averages or single
best matches. Video representations are formed from ordered tuples of varying
numbers of frames, which allows sub-sequences of actions at different speeds
and temporal offsets to be compared.
  Our proposed Temporal-Relational CrossTransformers (TRX) achieve
state-of-the-art results on few-shot splits of Kinetics, Something-Something V2
(SSv2), HMDB51 and UCF101. Importantly, our method outperforms prior work on
SSv2 by a wide margin (12%) due to the its ability to model temporal relations.
A detailed ablation showcases the importance of matching to multiple support
set videos and learning higher-order relational CrossTransformers.",1,1,0,0,1,0,0.906846,6.0,0.875821,36
http://arxiv.org/abs/2108.10272v1,Vogtareuth Rehab Depth Datasets: Benchmark for Marker-less Posture Estimation in Rehabilitation,1,0.0445628,0.116204,"Posture estimation using a single depth camera has become a useful tool for
analyzing movements in rehabilitation. Recent advances in posture estimation in
computer vision research have been possible due to the availability of
large-scale pose datasets. However, the complex postures involved in
rehabilitation exercises are not represented in the existing benchmark depth
datasets. To address this limitation, we propose two rehabilitation-specific
pose datasets containing depth images and 2D pose information of patients, both
adult and children, performing rehab exercises. We use a state-of-the-art
marker-less posture estimation model which is trained on a non-rehab benchmark
dataset. We evaluate it on our rehab datasets, and observe that the performance
degrades significantly from non-rehab to rehab, highlighting the need for these
datasets. We show that our dataset can be used to train pose models to detect
rehab-specific complex postures. The datasets will be released for the benefit
of the research community.",0,1,1,1,0,0,0.512298,11.0,0.823577,18
http://arxiv.org/abs/2110.00558v1,Natural language understanding for logical games,1,0.0022741,0.0271744,"We developed a system able to automatically solve logical puzzles in natural
language. Our solution is composed by a parser and an inference module. The
parser translates the text into first order logic (FOL), while the MACE4 model
finder is used to compute the models of the given FOL theory. We also empower
our software agent with the capability to provide Yes/No answers to natural
language questions related to each puzzle. Moreover, in line with Explainalbe
Artificial Intelligence (XAI), the agent can back its answer, providing a
graphical representation of the proof. The advantage of using reasoning for
Natural Language Understanding (NLU) instead of Machine learning is that the
user can obtain an explanation of the reasoning chain. We illustrate how the
system performs on various types of natural language puzzles, including 382
knights and knaves puzzles. These features together with the overall
performance rate of 80.89\% makes the proposed solution an improvement upon
similar solvers for natural language understanding in the puzzles domain.",0,0,0,0,0,0,0.00275477,10.0,0.249752,18
http://arxiv.org/abs/2106.11575v1,Learn to Resolve Conversational Dependency: A Consistency Training Framework for Conversational Question Answering,32,0.611826,0.563072,"One of the main challenges in conversational question answering (CQA) is to
resolve the conversational dependency, such as anaphora and ellipsis. However,
existing approaches do not explicitly train QA models on how to resolve the
dependency, and thus these models are limited in understanding human dialogues.
In this paper, we propose a novel framework, ExCorD (Explicit guidance on how
to resolve Conversational Dependency) to enhance the abilities of QA models in
comprehending conversational context. ExCorD first generates self-contained
questions that can be understood without the conversation history, then trains
a QA model with the pairs of original and self-contained questions using a
consistency-based regularizer. In our experiments, we demonstrate that ExCorD
significantly improves the QA models' performance by up to 1.2 F1 on QuAC, and
5.2 F1 on CANARD, while addressing the limitations of the existing approaches.",1,1,0,0,1,0,0.956566,5.0,0.906734,41
http://arxiv.org/abs/2108.09376v2,BlockCopy: High-Resolution Video Processing with Block-Sparse Feature Propagation and Online Policies,11,0.0332314,0.284982,"In this paper we propose BlockCopy, a scheme that accelerates pretrained
frame-based CNNs to process video more efficiently, compared to standard
frame-by-frame processing. To this end, a lightweight policy network determines
important regions in an image, and operations are applied on selected regions
only, using custom block-sparse convolutions. Features of non-selected regions
are simply copied from the preceding frame, reducing the number of computations
and latency. The execution policy is trained using reinforcement learning in an
online fashion without requiring ground truth annotations. Our universal
framework is demonstrated on dense prediction tasks such as pedestrian
detection, instance segmentation and semantic segmentation, using both state of
the art (Center and Scale Predictor, MGAN, SwiftNet) and standard baseline
networks (Mask-RCNN, DeepLabV3+). BlockCopy achieves significant FLOPS savings
and inference speedup with minimal impact on accuracy.",0,1,0,0,0,0,0.183677,8.0,0.599468,50
http://arxiv.org/abs/2111.09056v1,Improving Person Re-Identification with Temporal Constraints,4,0.0228946,0.254956,"In this paper we introduce an image-based person re-identification dataset
collected across five non-overlapping camera views in the large and busy
airport in Dublin, Ireland. Unlike all publicly available image-based datasets,
our dataset contains timestamp information in addition to frame number, and
camera and person IDs. Also our dataset has been fully anonymized to comply
with modern data privacy regulations. We apply state-of-the-art person
re-identification models to our dataset and show that by leveraging the
available timestamp information we are able to achieve a significant gain of
37.43% in mAP and a gain of 30.22% in Rank1 accuracy. We also propose a
Bayesian temporal re-ranking post-processing step, which further adds a 10.03%
gain in mAP and 9.95% gain in Rank1 accuracy metrics. This work on combining
visual and temporal information is not possible on other image-based person
re-identification datasets. We believe that the proposed new dataset will
enable further development of person re-identification research for challenging
real-world applications. DAA dataset can be downloaded from
https://bit.ly/3AtXTd6",1,1,1,1,1,0,0.272582,9.0,0.693962,33
http://arxiv.org/abs/2111.14911v1,Optimizing High-Dimensional Physics Simulations via Composite Bayesian Optimization,6,0.0789612,0.255858,"Physical simulation-based optimization is a common task in science and
engineering. Many such simulations produce image- or tensor-based outputs where
the desired objective is a function of those outputs, and optimization is
performed over a high-dimensional parameter space. We develop a Bayesian
optimization method leveraging tensor-based Gaussian process surrogates and
trust region Bayesian optimization to effectively model the image outputs and
to efficiently optimize these types of simulations, including a radio-frequency
tower configuration problem and an optical design problem.",0,1,0,0,0,0,0.741571,6.0,0.782164,21
http://arxiv.org/abs/2110.04902v1,Synthetic Data for Multi-Parameter Camera-Based Physiological Sensing,11,0.272115,0.671593,"Synthetic data is a powerful tool in training data hungry deep learning
algorithms. However, to date, camera-based physiological sensing has not taken
full advantage of these techniques. In this work, we leverage a high-fidelity
synthetics pipeline for generating videos of faces with faithful blood flow and
breathing patterns. We present systematic experiments showing how
physiologically-grounded synthetic data can be used in training camera-based
multi-parameter cardiopulmonary sensing. We provide empirical evidence that
heart and breathing rate measurement accuracy increases with the number of
synthetic avatars in the training set. Furthermore, training with avatars with
darker skin types leads to better overall performance than training with
avatars with lighter skin types. Finally, we discuss the opportunities that
synthetics present in the domain of camera-based physiological sensing and
limitations that need to be overcome.",0,1,0,1,0,0,0.498069,11.0,0.819861,42
http://arxiv.org/abs/2104.06924v1,Evaluation of Unsupervised Entity and Event Salience Estimation,4,0.0254082,0.0572601,"Salience Estimation aims to predict term importance in documents. Due to few
existing human-annotated datasets and the subjective notion of salience,
previous studies typically generate pseudo-ground truth for evaluation.
However, our investigation reveals that the evaluation protocol proposed by
prior work is difficult to replicate, thus leading to few follow-up studies
existing. Moreover, the evaluation process is problematic: the entity linking
tool used for entity matching is very noisy, while the ignorance of event
argument for event evaluation leads to boosted performance. In this work, we
propose a light yet practical entity and event salience estimation evaluation
protocol, which incorporates the more reliable syntactic dependency parser.
Furthermore, we conduct a comprehensive analysis among popular entity and event
definition standards, and present our own definition for the Salience
Estimation task to reduce noise during the pseudo-ground truth generation
process. Furthermore, we construct dependency-based heterogeneous graphs to
capture the interactions of entities and events. The empirical results show
that both baseline methods and the novel GNN method utilizing the heterogeneous
graph consistently outperform the previous SOTA model in all proposed metrics.",0,1,0,0,1,0,0.0374095,12.0,0.593645,24
http://arxiv.org/abs/2108.11458v1,Reducing Label Effort: Self-Supervised meets Active Learning,52,0.15183,0.494414,"Active learning is a paradigm aimed at reducing the annotation effort by
training the model on actively selected informative and/or representative
samples. Another paradigm to reduce the annotation effort is self-training that
learns from a large amount of unlabeled data in an unsupervised way and
fine-tunes on few labeled samples. Recent developments in self-training have
achieved very impressive results rivaling supervised learning on some datasets.
The current work focuses on whether the two paradigms can benefit from each
other. We studied object recognition datasets including CIFAR10, CIFAR100 and
Tiny ImageNet with several labeling budgets for the evaluations. Our
experiments reveal that self-training is remarkably more efficient than active
learning at reducing the labeling effort, that for a low labeling budget,
active learning offers no benefit to self-training, and finally that the
combination of active learning and self-training is fruitful when the labeling
budget is high. The performance gap between active learning trained either with
self-training or from scratch diminishes as we approach to the point where
almost half of the dataset is labeled.",0,1,0,0,0,1,0.380411,7.0,0.66484,56
http://arxiv.org/abs/2104.14346v1,Bridging the gap between streaming and non-streaming ASR systems bydistilling ensembles of CTC and RNN-T models,5,0.019895,0.219797,"Streaming end-to-end automatic speech recognition (ASR) systems are widely
used in everyday applications that require transcribing speech to text in
real-time. Their minimal latency makes them suitable for such tasks. Unlike
their non-streaming counterparts, streaming models are constrained to be causal
with no future context and suffer from higher word error rates (WER). To
improve streaming models, a recent study [1] proposed to distill a
non-streaming teacher model on unsupervised utterances, and then train a
streaming student using the teachers' predictions. However, the performance gap
between teacher and student WERs remains high. In this paper, we aim to close
this gap by using a diversified set of non-streaming teacher models and
combining them using Recognizer Output Voting Error Reduction (ROVER). In
particular, we show that, despite being weaker than RNN-T models, CTC models
are remarkable teachers. Further, by fusing RNN-T and CTC models together, we
build the strongest teachers. The resulting student models drastically improve
upon streaming models of previous work [1]: the WER decreases by 41% on
Spanish, 27% on Portuguese, and 13% on French.",0,1,0,0,0,0,0.567481,4.0,0.553495,29
http://arxiv.org/abs/2108.10052v1,Integrating LSTMs and GNNs for COVID-19 Forecasting,14,0.32696,0.730644,"The spread of COVID-19 has coincided with the rise of Graph Neural Networks
(GNNs), leading to several studies proposing their use to better forecast the
evolution of the pandemic. Many such models also include Long Short Term Memory
(LSTM) networks, a common tool for time series forecasting. In this work, we
further investigate the integration of these two methods by implementing GNNs
within the gates of an LSTM and exploiting spatial information. In addition, we
introduce a skip connection which proves critical to jointly capture the
spatial and temporal patterns in the data. We validate our daily COVID-19 new
cases forecast model on data of 37 European nations for the last 472 days and
show superior performance compared to state-of-the-art graph time series models
based on mean absolute scaled error (MASE). This area of research has important
applications to policy-making and we analyze its potential for pandemic
resource control.",1,1,0,0,1,0,0.988642,3.0,0.963232,33
http://arxiv.org/abs/2110.08955v1,Predicting Rebar Endpoints using Sin Exponential Regression Model,2,0.0735761,0.100937,"Currently, unmanned automation studies are underway to minimize the loss rate
of rebar production and the time and accuracy of calibration when producing
defective products in the cutting process of processing rebar factories. In
this paper, we propose a method to detect and track rebar endpoint images
entering the machine vision camera based on YOLO (You Only Look Once)v3, and to
predict rebar endpoint in advance with sin exponential regression of acquired
coordinates. The proposed method solves the problem of large prediction error
rates for frame locations where rebar endpoints are far away in OPPDet (Object
Position Prediction Detect) models, which prepredict rebar endpoints with
improved results showing 0.23 to 0.52% less error rates at sin exponential
regression prediction points.",0,1,0,0,0,0,0.115662,8.0,0.536788,4
http://arxiv.org/abs/2106.10715v3,CPM-2: Large-scale Cost-effective Pre-trained Language Models,76,0.170771,0.557109,"In recent years, the size of pre-trained language models (PLMs) has grown by
leaps and bounds. However, efficiency issues of these large-scale PLMs limit
their utilization in real-world scenarios. We present a suite of cost-effective
techniques for the use of PLMs to deal with the efficiency issues of
pre-training, fine-tuning, and inference. (1) We introduce knowledge
inheritance to accelerate the pre-training process by exploiting existing PLMs
instead of training models from scratch. (2) We explore the best practice of
prompt tuning with large-scale PLMs. Compared with conventional fine-tuning,
prompt tuning significantly reduces the number of task-specific parameters. (3)
We implement a new inference toolkit, namely InfMoE, for using large-scale PLMs
with limited computational resources. Based on our cost-effective pipeline, we
pre-train two models: an encoder-decoder bilingual model with 11 billion
parameters (CPM-2) and its corresponding MoE version with 198 billion
parameters. In our experiments, we compare CPM-2 with mT5 on downstream tasks.
Experimental results show that CPM-2 has excellent general language
intelligence. Moreover, we validate the efficiency of InfMoE when conducting
inference of large-scale models having tens of billions of parameters on a
single GPU. All source code and model parameters are available at
https://github.com/TsinghuaAI/CPM.",1,1,0,0,0,0,0.821396,3.0,0.644796,44
http://arxiv.org/abs/2106.02288v2,Tackling the Background Bias in Sparse Object Detection via Cropped Windows,7,0.0664786,0.0783247,"Object detection on Unmanned Aerial Vehicles (UAVs) is still a challenging
task. The recordings are mostly sparse and contain only small objects. In this
work, we propose a simple tiling method that improves the detection capability
in the remote sensing case without modifying the model itself. By reducing the
background bias and enabling the usage of higher image resolutions during
training, our method can improve the performance of models substantially. The
procedure was validated on three different data sets and outperformed similar
approaches in performance and speed.",1,1,0,0,1,0,0.832943,5.0,0.794491,33
http://arxiv.org/abs/2104.00568v2,LED2-Net: Monocular 360 Layout Estimation via Differentiable Depth Rendering,40,0.532364,0.987307,"Although significant progress has been made in room layout estimation, most
methods aim to reduce the loss in the 2D pixel coordinate rather than
exploiting the room structure in the 3D space. Towards reconstructing the room
layout in 3D, we formulate the task of 360 layout estimation as a problem of
predicting depth on the horizon line of a panorama. Specifically, we propose
the Differentiable Depth Rendering procedure to make the conversion from layout
to depth prediction differentiable, thus making our proposed model end-to-end
trainable while leveraging the 3D geometric information, without the need of
providing the ground truth depth. Our method achieves state-of-the-art
performance on numerous 360 layout benchmark datasets. Moreover, our
formulation enables a pre-training step on the depth dataset, which further
improves the generalizability of our layout estimation model.",1,1,0,0,1,0,0.857285,7.0,0.865258,30
http://arxiv.org/abs/2106.10684v1,Optimal personalised treatment computation through in silico clinical trials on patient digital twins,23,0.216207,0.554826,"In Silico Clinical Trials (ISTC), i.e., clinical experimental campaigns
carried out by means of computer simulations, hold the promise to decrease time
and cost for the safety and efficacy assessment of pharmacological treatments,
reduce the need for animal and human testing, and enable precision medicine. In
this paper we present methods and an algorithm that, by means of extensive
computer simulation--based experimental campaigns (ISTC) guided by intelligent
search, optimise a pharmacological treatment for an individual patient
(precision medicine). e show the effectiveness of our approach on a case study
involving a real pharmacological treatment, namely the downregulation phase of
a complex clinical protocol for assisted reproduction in humans.",0,0,0,0,0,0,0.00767146,13.0,0.501859,82
http://arxiv.org/abs/2104.07838v1,Investigating Failures of Automatic Translation in the Case of Unambiguous Gender,27,0.0648457,0.732185,"Transformer based models are the modern work horses for neural machine
translation (NMT), reaching state of the art across several benchmarks. Despite
their impressive accuracy, we observe a systemic and rudimentary class of
errors made by transformer based models with regards to translating from a
language that doesn't mark gender on nouns into others that do. We find that
even when the surrounding context provides unambiguous evidence of the
appropriate grammatical gender marking, no transformer based model we tested
was able to accurately gender occupation nouns systematically. We release an
evaluation scheme and dataset for measuring the ability of transformer based
NMT models to translate gender morphology correctly in unambiguous contexts
across syntactically diverse sentences. Our dataset translates from an English
source into 20 languages from several different language families. With the
availability of this dataset, our hope is that the NMT community can iterate on
solutions for this class of especially egregious errors.",0,1,1,1,0,0,0.241435,5.0,0.420878,64
http://arxiv.org/abs/2103.14431v3,Multimodal Knowledge Expansion,21,0.29268,0.820227,"The popularity of multimodal sensors and the accessibility of the Internet
have brought us a massive amount of unlabeled multimodal data. Since existing
datasets and well-trained models are primarily unimodal, the modality gap
between a unimodal network and unlabeled multimodal data poses an interesting
problem: how to transfer a pre-trained unimodal network to perform the same
task on unlabeled multimodal data? In this work, we propose multimodal
knowledge expansion (MKE), a knowledge distillation-based framework to
effectively utilize multimodal data without requiring labels. Opposite to
traditional knowledge distillation, where the student is designed to be
lightweight and inferior to the teacher, we observe that a multimodal student
model consistently denoises pseudo labels and generalizes better than its
teacher. Extensive experiments on four tasks and different modalities verify
this finding. Furthermore, we connect the mechanism of MKE to semi-supervised
learning and offer both empirical and theoretical explanations to understand
the denoising capability of a multimodal student.",1,0,0,0,0,0,0.975268,6.0,0.949801,53
http://arxiv.org/abs/2102.06045v1,Artificial Intelligence based Autonomous Molecular Design for Medical Therapeutic: A Perspective,2,0.0200998,0.0595837,"Domain-aware machine learning (ML) models have been increasingly adopted for
accelerating small molecule therapeutic design in the recent years. These
models have been enabled by significant advancement in state-of-the-art
artificial intelligence (AI) and computing infrastructures. Several ML
architectures are pre-dominantly and independently used either for predicting
the properties of small molecules, or for generating lead therapeutic
candidates. Synergetically using these individual components along with robust
representation and data generation techniques autonomously in closed loops
holds enormous promise for accelerated drug design which is a time consuming
and expensive task otherwise. In this perspective, we present the most recent
breakthrough achieved by each of the components, and how such autonomous AI and
ML workflow can be realized to radically accelerate the hit identification and
lead optimization. Taken together, this could significantly shorten the
timeline for end-to-end antiviral discovery and optimization times to weeks
upon the arrival of a novel zoonotic transmission event. Our perspective serves
as a guide for researchers to practice autonomous molecular design in
therapeutic discovery.",0,0,0,0,0,0,0.48516,7.0,0.711563,112
http://arxiv.org/abs/2103.05345v1,Detecting Inappropriate Messages on Sensitive Topics that Could Harm a Company's Reputation,9,0.074081,0.522717,"Not all topics are equally ""flammable"" in terms of toxicity: a calm
discussion of turtles or fishing less often fuels inappropriate toxic dialogues
than a discussion of politics or sexual minorities. We define a set of
sensitive topics that can yield inappropriate and toxic messages and describe
the methodology of collecting and labeling a dataset for appropriateness. While
toxicity in user-generated data is well-studied, we aim at defining a more
fine-grained notion of inappropriateness. The core of inappropriateness is that
it can harm the reputation of a speaker. This is different from toxicity in two
respects: (i) inappropriateness is topic-related, and (ii) inappropriate
message is not toxic but still unacceptable. We collect and release two
datasets for Russian: a topic-labeled dataset and an appropriateness-labeled
dataset. We also release pre-trained classification models trained on this
data.",0,1,0,1,0,0,0.794315,4.0,0.712219,23
http://arxiv.org/abs/2108.13004v1,X2Teeth: 3D Teeth Reconstruction from a Single Panoramic Radiograph,19,0.394469,0.412652,"3D teeth reconstruction from X-ray is important for dental diagnosis and many
clinical operations. However, no existing work has explored the reconstruction
of teeth for a whole cavity from a single panoramic radiograph. Different from
single object reconstruction from photos, this task has the unique challenge of
constructing multiple objects at high resolutions. To conquer this task, we
develop a novel ConvNet X2Teeth that decomposes the task into teeth
localization and single-shape estimation. We also introduce a patch-based
training strategy, such that X2Teeth can be end-to-end trained for optimal
performance. Extensive experiments show that our method can successfully
estimate the 3D structure of the cavity and reflect the details for each tooth.
Moreover, X2Teeth achieves a reconstruction IoU of 0.681, which significantly
outperforms the encoder-decoder method by $1.71X and the retrieval-based method
by $1.52X. Our method can also be promising for other multi-anatomy 3D
reconstruction tasks.",0,1,1,0,1,0,0.115383,15.0,0.752783,16
http://arxiv.org/abs/2105.06987v1,Scaling Ensemble Distribution Distillation to Many Classes with Proxy Targets,16,0.106723,0.648403,"Ensembles of machine learning models yield improved system performance as
well as robust and interpretable uncertainty estimates; however, their
inference costs may often be prohibitively high. \emph{Ensemble Distribution
Distillation} is an approach that allows a single model to efficiently capture
both the predictive performance and uncertainty estimates of an ensemble. For
classification, this is achieved by training a Dirichlet distribution over the
ensemble members' output distributions via the maximum likelihood criterion.
Although theoretically principled, this criterion exhibits poor convergence
when applied to large-scale tasks where the number of classes is very high. In
our work, we analyze this effect and show that the Dirichlet log-likelihood
criterion classes with low probability induce larger gradients than
high-probability classes. This forces the model to focus on the distribution of
the ensemble tail-class probabilities. We propose a new training objective that
minimizes the reverse KL-divergence to a \emph{Proxy-Dirichlet} target derived
from the ensemble. This loss resolves the gradient issues of Ensemble
Distribution Distillation, as we demonstrate both theoretically and empirically
on the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes,
respectively.",0,0,0,0,0,0,0.880067,6.0,0.857061,43
http://arxiv.org/abs/2102.00689v1,A NIR-to-VIS face recognition via part adaptive and relation attention module,3,0.114447,0.192882,"In the face recognition application scenario, we need to process facial
images captured in various conditions, such as at night by near-infrared (NIR)
surveillance cameras. The illumination difference between NIR and visible-light
(VIS) causes a domain gap between facial images, and the variations in pose and
emotion also make facial matching more difficult. Heterogeneous face
recognition (HFR) has difficulties in domain discrepancy, and many studies have
focused on extracting domain-invariant features, such as facial part relational
information. However, when pose variation occurs, the facial component position
changes, and a different part relation is extracted. In this paper, we propose
a part relation attention module that crops facial parts obtained through a
semantic mask and performs relational modeling using each of these
representative features. Furthermore, we suggest component adaptive triplet
loss function using adaptive weights for each part to reduce the intra-class
identity regardless of the domain as well as pose. Finally, our method exhibits
a performance improvement in the CASIA NIR-VIS 2.0 and achieves superior result
in the BUAA-VisNir with large pose and emotion variations.",0,1,0,0,0,0,0.84799,9.0,0.89154,21
http://arxiv.org/abs/2110.15156v1,Blending Anti-Aliasing into Vision Transformer,18,0.384839,0.704723,"The transformer architectures, based on self-attention mechanism and
convolution-free design, recently found superior performance and booming
applications in computer vision. However, the discontinuous patch-wise
tokenization process implicitly introduces jagged artifacts into attention
maps, arising the traditional problem of aliasing for vision transformers.
Aliasing effect occurs when discrete patterns are used to produce high
frequency or continuous information, resulting in the indistinguishable
distortions. Recent researches have found that modern convolution networks
still suffer from this phenomenon. In this work, we analyze the uncharted
problem of aliasing in vision transformer and explore to incorporate
anti-aliasing properties. Specifically, we propose a plug-and-play
Aliasing-Reduction Module(ARM) to alleviate the aforementioned issue. We
investigate the effectiveness and generalization of the proposed method across
multiple tasks and various vision transformer families. This lightweight design
consistently attains a clear boost over several famous structures. Furthermore,
our module also improves data efficiency and robustness of vision transformers.",0,1,0,0,0,0,0.986819,3.0,0.951966,69
http://arxiv.org/abs/2102.11000v1,"An open access NLP dataset for Arabic dialects : Data collection, labeling, and model construction",14,0.490535,0.663561,"Natural Language Processing (NLP) is today a very active field of research
and innovation. Many applications need however big sets of data for supervised
learning, suitably labelled for the training purpose. This includes
applications for the Arabic language and its national dialects. However, such
open access labeled data sets in Arabic and its dialects are lacking in the
Data Science ecosystem and this lack can be a burden to innovation and research
in this field. In this work, we present an open data set of social data content
in several Arabic dialects. This data was collected from the Twitter social
network and consists on +50K twits in five (5) national dialects. Furthermore,
this data was labeled for several applications, namely dialect detection, topic
detection and sentiment analysis. We publish this data as an open access data
to encourage innovation and encourage other works in the field of NLP for
Arabic dialects and social media. A selection of models were built using this
data set and are presented in this paper along with their performances.",0,1,1,1,0,0,0.427666,8.0,0.725903,20
http://arxiv.org/abs/2103.05636v1,A Gradient Estimator for Time-Varying Electrical Networks with Non-Linear Dissipation,6,0.0751775,0.700544,"We propose a method for extending the technique of equilibrium propagation
for estimating gradients in fixed-point neural networks to the more general
setting of directed, time-varying neural networks by modeling them as
electrical circuits. We use electrical circuit theory to construct a Lagrangian
capable of describing deep, directed neural networks modeled using nonlinear
capacitors and inductors, linear resistors and sources, and a special class of
nonlinear dissipative elements called fractional memristors. We then derive an
estimator for the gradient of the physical parameters of the network, such as
synapse conductances, with respect to an arbitrary loss function. This
estimator is entirely local, in that it only depends on information locally
available to each synapse. We conclude by suggesting methods for extending
these results to networks of biologically plausible neurons, e.g.
Hodgkin-Huxley neurons.",0,0,0,0,0,0,0.397643,18.0,0.872841,39
http://arxiv.org/abs/2110.02386v1,Analyzing the Effects of Reasoning Types on Cross-Lingual Transfer Performance,10,0.196598,0.422124,"Multilingual language models achieve impressive zero-shot accuracies in many
languages in complex tasks such as Natural Language Inference (NLI). Examples
in NLI (and equivalent complex tasks) often pertain to various types of
sub-tasks, requiring different kinds of reasoning. Certain types of reasoning
have proven to be more difficult to learn in a monolingual context, and in the
crosslingual context, similar observations may shed light on zero-shot transfer
efficiency and few-shot sample selection. Hence, to investigate the effects of
types of reasoning on transfer performance, we propose a category-annotated
multilingual NLI dataset and discuss the challenges to scale monolingual
annotations to multiple languages. We statistically observe interesting effects
that the confluence of reasoning types and language similarities have on
transfer performance.",0,0,0,0,0,0,0.969668,4.0,0.910513,22
http://arxiv.org/abs/2103.07371v1,PatchNet -- Short-range Template Matching for Efficient Video Processing,3,0.00917478,0.0709163,"Object recognition is a fundamental problem in many video processing tasks,
accurately locating seen objects at low computation cost paves the way for
on-device video recognition. We propose PatchNet, an efficient convolutional
neural network to match objects in adjacent video frames. It learns the
patchwise correlation features instead of pixel features. PatchNet is very
compact, running at just 58MFLOPs, $5\times$ simpler than MobileNetV2. We
demonstrate its application on two tasks, video object detection and visual
object tracking. On ImageNet VID, PatchNet reduces the flops of R-FCN
ResNet-101 by 5x and EfficientDet-D0 by 3.4x with less than 1% mAP loss. On
OTB2015, PatchNet reduces SiamFC and SiamRPN by 2.5x with no accuracy loss.
Experiments on Jetson Nano further demonstrate 2.8x to 4.3x speed-ups
associated with flops reduction. Code is open sourced at
https://github.com/RalphMao/PatchNet.",1,1,1,0,0,0,0.597807,6.0,0.716193,35
http://arxiv.org/abs/2106.01045v1,Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?,66,0.380733,0.952001,"Five years after the first published proofs of concept, direct approaches to
speech translation (ST) are now competing with traditional cascade solutions.
In light of this steady progress, can we claim that the performance gap between
the two is closed? Starting from this question, we present a systematic
comparison between state-of-the-art systems representative of the two
paradigms. Focusing on three language directions
(English-German/Italian/Spanish), we conduct automatic and manual evaluations,
exploiting high-quality professional post-edits and annotations. Our
multi-faceted analysis on one of the few publicly available ST benchmarks
attests for the first time that: i) the gap between the two paradigms is now
closed, and ii) the subtle differences observed in their behavior are not
sufficient for humans neither to distinguish them nor to prefer one over the
other.",0,1,0,0,0,0,0.200025,7.0,0.555823,72
http://arxiv.org/abs/2105.07220v1,String Theories involving Regular Membership Predicates: From Practice to Theory and Back,5,0.0615677,0.102018,"Widespread use of string solvers in formal analysis of string-heavy programs
has led to a growing demand for more efficient and reliable techniques which
can be applied in this context, especially for real-world cases. Designing an
algorithm for the (generally undecidable) satisfiability problem for systems of
string constraints requires a thorough understanding of the structure of
constraints present in the targeted cases. In this paper, we investigate
benchmarks presented in the literature containing regular expression membership
predicates, extract different first order logic theories, and prove their
decidability, resp. undecidability. Notably, the most common theories in
real-world benchmarks are PSPACE-complete and directly lead to the
implementation of a more efficient algorithm to solving string constraints.",0,0,0,0,0,0,0.0827956,9.0,0.54912,35
http://arxiv.org/abs/2104.06599v1,Learning How to Ask: Querying LMs with Mixtures of Soft Prompts,433,0.842759,0.999104,"Natural-language prompts have recently been used to coax pretrained language
models into performing other AI tasks, using a fill-in-the-blank paradigm
(Petroni et al., 2019) or a few-shot extrapolation paradigm (Brown et al.,
2020). For example, language models retain factual knowledge from their
training corpora that can be extracted by asking them to ""fill in the blank"" in
a sentential prompt. However, where does this prompt come from? We explore the
idea of learning prompts by gradient descent -- either fine-tuning prompts
taken from previous work, or starting from random initialization. Our prompts
consist of ""soft words,"" i.e., continuous vectors that are not necessarily word
type embeddings from the language model. Furthermore, for each task, we
optimize a mixture of prompts, learning which prompts are most effective and
how to ensemble them. Across multiple English LMs and tasks, our approach
hugely outperforms previous methods, showing that the implicit factual
knowledge in language models was previously underestimated. Moreover, this
knowledge is cheap to elicit: random initialization is nearly as good as
informed initialization.",1,1,0,0,1,0,0.883845,4.0,0.789337,40
http://arxiv.org/abs/2110.04260v3,Taming Sparsely Activated Transformer with Stochastic Experts,82,0.892785,0.792749,"Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can
easily scale to have outrageously large amounts of parameters without
significant increase in computational cost. However, SAMs are reported to be
parameter inefficient such that larger models do not always lead to better
performance. While most on-going research focuses on improving SAMs models by
exploring methods of routing inputs to experts, our analysis reveals that such
research might not lead to the solution we expect, i.e., the commonly-used
routing methods based on gating mechanisms do not work better than randomly
routing inputs to experts. In this paper, we propose a new expert-based model,
THOR (Transformer witH StOchastic ExpeRts). Unlike classic expert-based models,
such as the Switch Transformer, experts in THOR are randomly activated for each
input during training and inference. THOR models are trained using a
consistency regularized loss, where experts learn not only from training data
but also from other experts as teachers, such that all the experts make
consistent predictions. We validate the effectiveness of THOR on machine
translation tasks. Results show that THOR models are more parameter efficient
in that they significantly outperform the Transformer and MoE models across
various settings. For example, in multilingual translation, THOR outperforms
the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as
that of a state-of-the-art MoE model that is 18 times larger. Our code is
publicly available at:
https://github.com/microsoft/Stochastic-Mixture-of-Experts.",1,0,0,0,1,0,0.985523,5.0,0.966797,36
http://arxiv.org/abs/2105.04047v2,Analyzing Online Political Advertisements,10,0.133013,0.411675,"Online political advertising is a central aspect of modern election
campaigning for influencing public opinion. Computational analysis of political
ads is of utmost importance in political science to understand the
characteristics of digital campaigning. It is also important in computational
linguistics to study features of political discourse and communication on a
large scale. In this work, we present the first computational study on online
political ads with the aim to (1) infer the political ideology of an ad
sponsor; and (2) identify whether the sponsor is an official political party or
a third-party organization. We develop two new large datasets for the two tasks
consisting of ads from the U.S.. Evaluation results show that our approach that
combines textual and visual information from pre-trained neural models
outperforms a state-of-the-art method for generic commercial ad classification.
Finally, we provide an in-depth analysis of the limitations of our
best-performing models and linguistic analysis to study the characteristics of
political ads discourse.",0,1,1,1,1,0,0.144657,8.0,0.566785,73
http://arxiv.org/abs/2110.04111v1,"Discover, Hallucinate, and Adapt: Open Compound Domain Adaptation for Semantic Segmentation",31,0.0579737,0.341737,"Unsupervised domain adaptation (UDA) for semantic segmentation has been
attracting attention recently, as it could be beneficial for various
label-scarce real-world scenarios (e.g., robot control, autonomous driving,
medical imaging, etc.). Despite the significant progress in this field, current
works mainly focus on a single-source single-target setting, which cannot
handle more practical settings of multiple targets or even unseen targets. In
this paper, we investigate open compound domain adaptation (OCDA), which deals
with mixed and novel situations at the same time, for semantic segmentation. We
present a novel framework based on three main design principles: discover,
hallucinate, and adapt. The scheme first clusters compound target data based on
style, discovering multiple latent domains (discover). Then, it hallucinates
multiple latent target domains in source by using image-translation
(hallucinate). This step ensures the latent domains in the source and the
target to be paired. Finally, target-to-source alignment is learned separately
between domains (adapt). In high-level, our solution replaces a hard OCDA
problem with much easier multiple UDA problems. We evaluate our solution on
standard benchmark GTA to C-driving, and achieved new state-of-the-art results.",0,1,1,0,1,0,0.562206,7.0,0.742773,48
http://arxiv.org/abs/2111.06660v1,Frequency learning for structured CNN filters with Gaussian fractional derivatives,6,0.0274802,0.162687,"Frequency information lies at the base of discriminating between textures,
and therefore between different objects. Classical CNN architectures limit the
frequency learning through fixed filter sizes, and lack a way of explicitly
controlling it. Here, we build on the structured receptive field filters with
Gaussian derivative basis. Yet, rather than using predetermined derivative
orders, which typically result in fixed frequency responses for the basis
functions, we learn these. We show that by learning the order of the basis we
can accurately learn the frequency of the filters, and hence adapt to the
optimal frequencies for the underlying learning task. We investigate the
well-founded mathematical formulation of fractional derivatives to adapt the
filter frequencies during training. Our formulation leads to parameter savings
and data efficiency when compared to the standard CNNs and the Gaussian
derivative CNN filter networks that we build upon.",0,0,0,0,0,0,0.373326,9.0,0.736649,48
http://arxiv.org/abs/2110.08387v3,Generated Knowledge Prompting for Commonsense Reasoning,222,0.941038,0.993366,"It remains an open question whether incorporating external knowledge benefits
commonsense reasoning while maintaining the flexibility of pretrained sequence
models. To investigate this question, we develop generated knowledge prompting,
which consists of generating knowledge from a language model, then providing
the knowledge as additional input when answering a question. Our method does
not require task-specific supervision for knowledge integration, or access to a
structured knowledge base, yet it improves performance of large-scale,
state-of-the-art models on four commonsense reasoning tasks, achieving
state-of-the-art results on numerical commonsense (NumerSense), general
commonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks.
Generated knowledge prompting highlights large-scale language models as
flexible sources of external knowledge for improving commonsense reasoning. Our
code is available at https://github.com/liujch1998/GKP",1,1,0,0,1,0,0.878533,5.0,0.827271,47
http://arxiv.org/abs/2102.10336v2,Physical Reasoning Using Dynamics-Aware Models,3,0.0392711,0.0887804,"A common approach to solving physical reasoning tasks is to train a value
learner on example tasks. A limitation of such an approach is that it requires
learning about object dynamics solely from reward values assigned to the final
state of a rollout of the environment. This study aims to address this
limitation by augmenting the reward value with self-supervised signals about
object dynamics. Specifically, we train the model to characterize the
similarity of two environment rollouts, jointly with predicting the outcome of
the reasoning task. This similarity can be defined as a distance measure
between the trajectory of objects in the two rollouts, or learned directly from
pixels using a contrastive formulation. Empirically, we find that this approach
leads to substantial performance improvements on the PHYRE benchmark for
physical reasoning (Bakhtin et al., 2019), establishing a new state-of-the-art.",0,1,0,0,1,0,0.709087,6.0,0.766902,12
http://arxiv.org/abs/2107.11614v1,Automatic tempered posterior distributions for Bayesian inversion problems,12,0.29287,0.224777,"We propose a novel adaptive importance sampling scheme for Bayesian inversion
problems where the inference of the variables of interest and the power of the
data noise is split. More specifically, we consider a Bayesian analysis for the
variables of interest (i.e., the parameters of the model to invert), whereas we
employ a maximum likelihood approach for the estimation of the noise power. The
whole technique is implemented by means of an iterative procedure, alternating
sampling and optimization steps. Moreover, the noise power is also used as a
tempered parameter for the posterior distribution of the the variables of
interest. Therefore, a sequence of tempered posterior densities is generated,
where the tempered parameter is automatically selected according to the actual
estimation of the noise power. A complete Bayesian study over the model
parameters and the scale parameter can be also performed. Numerical experiments
show the benefits of the proposed approach.",0,0,0,0,0,0,0.239182,19.0,0.847031,26
http://arxiv.org/abs/2111.13284v1,Ensembling of Distilled Models from Multi-task Teachers for Constrained Resource Language Pairs,2,0.00336671,0.0814858,"This paper describes our submission to the constrained track of WMT21 shared
news translation task. We focus on the three relatively low resource language
pairs Bengali to and from Hindi, English to and from Hausa, and Xhosa to and
from Zulu. To overcome the limitation of relatively low parallel data we train
a multilingual model using a multitask objective employing both parallel and
monolingual data. In addition, we augment the data using back translation. We
also train a bilingual model incorporating back translation and knowledge
distillation then combine the two models using sequence-to-sequence mapping. We
see around 70% relative gain in BLEU point for English to and from Hausa, and
around 25% relative improvements for both Bengali to and from Hindi, and Xhosa
to and from Zulu compared to bilingual baselines.",0,1,0,0,0,0,0.0771072,10.0,0.586786,16
http://arxiv.org/abs/2105.01839v1,Encoder Fusion Network with Co-Attention Embedding for Referring Image Segmentation,127,0.927986,0.825604,"Recently, referring image segmentation has aroused widespread interest.
Previous methods perform the multi-modal fusion between language and vision at
the decoding side of the network. And, linguistic feature interacts with visual
feature of each scale separately, which ignores the continuous guidance of
language to multi-scale visual features. In this work, we propose an encoder
fusion network (EFN), which transforms the visual encoder into a multi-modal
feature learning network, and uses language to refine the multi-modal features
progressively. Moreover, a co-attention mechanism is embedded in the EFN to
realize the parallel update of multi-modal features, which can promote the
consistent of the cross-modal information representation in the semantic space.
Finally, we propose a boundary enhancement module (BEM) to make the network pay
more attention to the fine structure. The experiment results on four benchmark
datasets demonstrate that the proposed approach achieves the state-of-the-art
performance under different evaluation metrics without any post-processing.",0,1,0,0,1,0,0.974975,7.0,0.956516,45
http://arxiv.org/abs/2106.01269v1,More Identifiable yet Equally Performant Transformers for Text Classification,6,0.0106081,0.0938904,"Interpretability is an important aspect of the trustworthiness of a model's
predictions. Transformer's predictions are widely explained by the attention
weights, i.e., a probability distribution generated at its self-attention unit
(head). Current empirical studies provide shreds of evidence that attention
weights are not explanations by proving that they are not unique. A recent
study showed theoretical justifications to this observation by proving the
non-identifiability of attention weights. For a given input to a head and its
output, if the attention weights generated in it are unique, we call the
weights identifiable. In this work, we provide deeper theoretical analysis and
empirical observations on the identifiability of attention weights. Ignored in
the previous works, we find the attention weights are more identifiable than we
currently perceive by uncovering the hidden role of the key vector. However,
the weights are still prone to be non-unique attentions that make them unfit
for interpretation. To tackle this issue, we provide a variant of the encoder
layer that decouples the relationship between key and value vector and provides
identifiable weights up to the desired length of the input. We prove the
applicability of such variations by providing empirical justifications on
varied text classification tasks. The implementations are available at
https://github.com/declare-lab/identifiable-transformers.",1,0,0,0,0,0,0.502792,12.0,0.836008,15
http://arxiv.org/abs/2107.01905v1,Creating Unbiased Public Benchmark Datasets with Data Leakage Prevention for Predictive Process Monitoring,10,0.10858,0.571189,"Advances in AI, and especially machine learning, are increasingly drawing
research interest and efforts towards predictive process monitoring, the
subfield of process mining (PM) that concerns predicting next events, process
outcomes and remaining execution times. Unfortunately, researchers use a
variety of datasets and ways to split them into training and test sets. The
documentation of these preprocessing steps is not always complete.
Consequently, research results are hard or even impossible to reproduce and to
compare between papers. At times, the use of non-public domain knowledge
further hampers the fair competition of ideas. Often the training and test sets
are not completely separated, a data leakage problem particular to predictive
process monitoring. Moreover, test sets usually suffer from bias in terms of
both the mix of case durations and the number of running cases. These obstacles
pose a challenge to the field's progress. The contribution of this paper is to
identify and demonstrate the importance of these obstacles and to propose
preprocessing steps to arrive at unbiased benchmark datasets in a principled
way, thus creating representative test sets without data leakage with the aim
of levelling the playing field, promoting open science and contributing to more
rapid progress in predictive process monitoring.",0,1,0,0,0,0,0.579569,9.0,0.805249,8
http://arxiv.org/abs/2112.06199v1,Learning Nigerian accent embeddings from speech: preliminary results based on SautiDB-Naija corpus,3,0.0872174,0.0267002,"This paper describes foundational efforts with SautiDB-Naija, a novel corpus
of non-native (L2) Nigerian English speech. We describe how the corpus was
created and curated as well as preliminary experiments with accent
classification and learning Nigerian accent embeddings. The initial version of
the corpus includes over 900 recordings from L2 English speakers of Nigerian
languages, such as Yoruba, Igbo, Edo, Efik-Ibibio, and Igala. We further
demonstrate how fine-tuning on a pre-trained model like wav2vec can yield
representations suitable for related speech tasks such as accent
classification. SautiDB-Naija has been published to Zenodo for general use
under a flexible Creative Commons License.",0,1,1,1,0,0,0.530383,8.0,0.763829,24
http://arxiv.org/abs/2107.02282v1,Weakly Supervised Named Entity Tagging with Learnable Logical Rules,33,0.601554,0.923938,"We study the problem of building entity tagging systems by using a few rules
as weak supervision. Previous methods mostly focus on disambiguation entity
types based on contexts and expert-provided rules, while assuming entity spans
are given. In this work, we propose a novel method TALLOR that bootstraps
high-quality logical rules to train a neural tagger in a fully automated
manner. Specifically, we introduce compound rules that are composed from simple
rules to increase the precision of boundary detection and generate more diverse
pseudo labels. We further design a dynamic label selection strategy to ensure
pseudo label quality and therefore avoid overfitting the neural tagger.
Experiments on three datasets demonstrate that our method outperforms other
weakly supervised methods and even rivals a state-of-the-art distantly
supervised tagger with a lexicon of over 2,000 terms when starting from only 20
simple rules. Our method can serve as a tool for rapidly building taggers in
emerging domains and tasks. Case studies show that learned rules can
potentially explain the predicted entities.",0,1,0,0,1,0,0.905527,9.0,0.916554,27
http://arxiv.org/abs/2106.03084v2,Combining Static Word Embeddings and Contextual Representations for Bilingual Lexicon Induction,15,0.358213,0.892101,"Bilingual Lexicon Induction (BLI) aims to map words in one language to their
translations in another, and is typically through learning linear projections
to align monolingual word representation spaces. Two classes of word
representations have been explored for BLI: static word embeddings and
contextual representations, but there is no studies to combine both. In this
paper, we propose a simple yet effective mechanism to combine the static word
embeddings and the contextual representations to utilize the advantages of both
paradigms. We test the combination mechanism on various language pairs under
the supervised and unsupervised BLI benchmark settings. Experiments show that
our mechanism consistently improves performances over robust BLI baselines on
all language pairs by averagely improving 3.2 points in the supervised setting,
and 3.1 points in the unsupervised setting.",1,1,0,0,0,0,0.949306,8.0,0.935392,43
http://arxiv.org/abs/2108.00279v1,A Psychologically Informed Part-of-Speech Analysis of Depression in Social Media,11,0.0,0.483572,"In this work, we provide an extensive part-of-speech analysis of the
discourse of social media users with depression. Research in psychology
revealed that depressed users tend to be self-focused, more preoccupied with
themselves and ruminate more about their lives and emotions. Our work aims to
make use of large-scale datasets and computational methods for a quantitative
exploration of discourse. We use the publicly available depression dataset from
the Early Risk Prediction on the Internet Workshop (eRisk) 2018 and extract
part-of-speech features and several indices based on them. Our results reveal
statistically significant differences between the depressed and non-depressed
individuals confirming findings from the existing psychology literature. Our
work provides insights regarding the way in which depressed individuals are
expressing themselves on social media platforms, allowing for better-informed
computational models to help monitor and prevent mental illnesses.",0,1,0,0,0,0,0.00230838,11.0,0.301864,61
http://arxiv.org/abs/2103.12346v1,Co-Grounding Networks with Semantic Attention for Referring Expression Comprehension in Videos,15,0.210053,0.65283,"In this paper, we address the problem of referring expression comprehension
in videos, which is challenging due to complex expression and scene dynamics.
Unlike previous methods which solve the problem in multiple stages (i.e.,
tracking, proposal-based matching), we tackle the problem from a novel
perspective, \textbf{co-grounding}, with an elegant one-stage framework. We
enhance the single-frame grounding accuracy by semantic attention learning and
improve the cross-frame grounding consistency with co-grounding feature
learning. Semantic attention learning explicitly parses referring cues in
different attributes to reduce the ambiguity in the complex expression.
Co-grounding feature learning boosts visual feature representations by
integrating temporal correlation to reduce the ambiguity caused by scene
dynamics. Experiment results demonstrate the superiority of our framework on
the video grounding datasets VID and LiOTB in generating accurate and stable
results across frames. Our model is also applicable to referring expression
comprehension in images, illustrated by the improved performance on the RefCOCO
dataset. Our project is available at https://sijiesong.github.io/co-grounding.",1,1,0,0,1,0,0.948182,7.0,0.925108,43
http://arxiv.org/abs/2105.02099v1,Efficient Strategy Synthesis for MDPs with Resource Constraints,4,0.0798949,0.135732,"We consider qualitative strategy synthesis for the formalism called
consumption Markov decision processes. This formalism can model dynamics of an
agents that operates under resource constraints in a stochastic environment.
The presented algorithms work in time polynomial with respect to the
representation of the model and they synthesize strategies ensuring that a
given set of goal states will be reached (once or infinitely many times) with
probability 1 without resource exhaustion. In particular, when the amount of
resource becomes too low to safely continue in the mission, the strategy
changes course of the agent towards one of a designated set of reload states
where the agent replenishes the resource to full capacity; with sufficient
amount of resource, the agent attempts to fulfill the mission again.
  We also present two heuristics that attempt to reduce expected time that the
agent needs to fulfill the given mission, a parameter important in practical
planning. The presented algorithms were implemented and numerical examples
demonstrate (i) the effectiveness (in terms of computation time) of the
planning approach based on consumption Markov decision processes and (ii) the
positive impact of the two heuristics on planning in a realistic example.",0,1,0,0,0,0,0.0033695,19.0,0.61575,37
http://arxiv.org/abs/2110.04476v1,Label quality in AffectNet: results of crowd-based re-annotation,3,0.0,0.290427,"AffectNet is one of the most popular resources for facial expression
recognition (FER) on relatively unconstrained in-the-wild images. Given that
images were annotated by only one annotator with limited consistency checks on
the data, however, label quality and consistency may be limited. Here, we take
a similar approach to a study that re-labeled another, smaller dataset
(FER2013) with crowd-based annotations, and report results from a re-labeling
and re-annotation of a subset of difficult AffectNet faces with 13 people on
both expression label, and valence and arousal ratings. Our results show that
human labels overall have medium to good consistency, whereas human ratings
especially for valence are in excellent agreement. Importantly, however,
crowd-based labels are significantly shifting towards neutral and happy
categories and crowd-based affective ratings form a consistent pattern
different from the original ratings. ResNets fully trained on the original
AffectNet dataset do not predict human voting patterns, but when weakly-trained
do so much better, particularly for valence. Our results have important
ramifications for label quality in affective computing.",0,1,0,0,0,0,0.325854,9.0,0.717771,22
http://arxiv.org/abs/2106.07561v1,Direct Servo Control from In-Sensor CNN Inference with A Pixel Processor Array,6,0.175503,0.330397,"This work demonstrates direct visual sensory-motor control using high-speed
CNN inference via a SCAMP-5 Pixel Processor Array (PPA). We demonstrate how
PPAs are able to efficiently bridge the gap between perception and action. A
binary Convolutional Neural Network (CNN) is used for a classic rock, paper,
scissors classification problem at over 8000 FPS. Control instructions are
directly sent to a servo motor from the PPA according to the CNN's
classification result without any other intermediate hardware.",0,1,0,0,0,0,0.820651,4.0,0.732992,6
http://arxiv.org/abs/2105.01047v1,Act the Part: Learning Interaction Strategies for Articulated Object Part Discovery,38,0.61572,0.801336,"People often use physical intuition when manipulating articulated objects,
irrespective of object semantics. Motivated by this observation, we identify an
important embodied task where an agent must play with objects to recover their
parts. To this end, we introduce Act the Part (AtP) to learn how to interact
with articulated objects to discover and segment their pieces. By coupling
action selection and motion segmentation, AtP is able to isolate structures to
make perceptual part recovery possible without semantic labels. Our experiments
show AtP learns efficient strategies for part discovery, can generalize to
unseen categories, and is capable of conditional reasoning for the task.
Although trained in simulation, we show convincing transfer to real world data
with no fine-tuning.",1,1,1,0,0,0,0.536922,11.0,0.829911,56
http://arxiv.org/abs/2104.01978v2,Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition,7,0.14079,0.465035,"Key challenges in developing generalized automatic emotion recognition
systems include scarcity of labeled data and lack of gold-standard references.
Even for the cues that are labeled as the same emotion category, the
variability of associated expressions can be high depending on the elicitation
context e.g., emotion elicited during improvised conversations vs. acted
sessions with predefined scripts. In this work, we regard the emotion
elicitation approach as domain knowledge, and explore domain transfer learning
techniques on emotional utterances collected under different emotion
elicitation approaches, particularly with limited labeled target samples. Our
emotion recognition model combines the gradient reversal technique with an
entropy loss function as well as the softlabel loss, and the experiment results
show that domain transfer learning methods can be employed to alleviate the
domain mismatch between different elicitation approaches. Our work provides new
insights into emotion data collection, particularly the impact of its
elicitation strategies, and the importance of domain adaptation in emotion
recognition aiming for generalized systems.",0,1,0,0,0,0,0.59994,7.0,0.757568,33
http://arxiv.org/abs/2105.12172v1,IntelliCAT: Intelligent Machine Translation Post-Editing with Quality Estimation and Translation Suggestion,17,0.0282583,0.45279,"We present IntelliCAT, an interactive translation interface with neural
models that streamline the post-editing process on machine translation output.
We leverage two quality estimation (QE) models at different granularities:
sentence-level QE, to predict the quality of each machine-translated sentence,
and word-level QE, to locate the parts of the machine-translated sentence that
need correction. Additionally, we introduce a novel translation suggestion
model conditioned on both the left and right contexts, providing alternatives
for specific words or phrases for correction. Finally, with word alignments,
IntelliCAT automatically preserves the original document's styles in the
translated document. The experimental results show that post-editing based on
the proposed QE and translation suggestions can significantly improve
translation quality. Furthermore, a user study reveals that three features
provided in IntelliCAT significantly accelerate the post-editing task,
achieving a 52.9\% speedup in translation time compared to translating from
scratch. The interface is publicly available at
https://intellicat.beringlab.com/.",1,1,0,0,0,0,0.0222502,9.0,0.399599,38
http://arxiv.org/abs/2102.01013v1,End2End Acoustic to Semantic Transduction,15,0.0249967,0.338455,"In this paper, we propose a novel end-to-end sequence-to-sequence spoken
language understanding model using an attention mechanism. It reliably selects
contextual acoustic features in order to hypothesize semantic contents. An
initial architecture capable of extracting all pronounced words and concepts
from acoustic spans is designed and tested. With a shallow fusion language
model, this system reaches a 13.6 concept error rate (CER) and an 18.5 concept
value error rate (CVER) on the French MEDIA corpus, achieving an absolute 2.8
points reduction compared to the state-of-the-art. Then, an original model is
proposed for hypothesizing concepts and their values. This transduction reaches
a 15.4 CER and a 21.6 CVER without any new type of context.",0,1,0,0,1,0,0.0366385,7.0,0.300359,30
http://arxiv.org/abs/2111.06265v1,Dense Unsupervised Learning for Video Segmentation,21,0.0947772,0.660809,"We present a novel approach to unsupervised learning for video object
segmentation (VOS). Unlike previous work, our formulation allows to learn dense
feature representations directly in a fully convolutional regime. We rely on
uniform grid sampling to extract a set of anchors and train our model to
disambiguate between them on both inter- and intra-video levels. However, a
naive scheme to train such a model results in a degenerate solution. We propose
to prevent this with a simple regularisation scheme, accommodating the
equivariance property of the segmentation task to similarity transformations.
Our training objective admits efficient implementation and exhibits fast
training convergence. On established VOS benchmarks, our approach exceeds the
segmentation accuracy of previous work despite using significantly less
training data and compute power.",1,0,0,0,1,0,0.80219,6.0,0.812211,50
http://arxiv.org/abs/2106.03717v1,Diverse Pretrained Context Encodings Improve Document Translation,12,0.0890483,0.298245,"We propose a new architecture for adapting a sentence-level
sequence-to-sequence transformer by incorporating multiple pretrained document
context signals and assess the impact on translation performance of (1)
different pretraining approaches for generating these signals, (2) the quantity
of parallel data for which document context is available, and (3) conditioning
on source, target, or source and target contexts. Experiments on the NIST
Chinese-English, and IWSLT and WMT English-German tasks support four general
conclusions: that using pretrained context representations markedly improves
sample efficiency, that adequate parallel data resources are crucial for
learning to use document context, that jointly conditioning on multiple context
representations outperforms any single representation, and that source context
is more valuable for translation performance than target side context. Our best
multi-context model consistently outperforms the best existing context-aware
transformers.",0,0,0,0,0,0,0.759122,5.0,0.748731,44
http://arxiv.org/abs/2109.10115v3,StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose Estimation,38,0.539969,0.914673,"We present a large-scale stereo RGB image object pose estimation dataset
named the $\textbf{StereOBJ-1M}$ dataset. The dataset is designed to address
challenging cases such as object transparency, translucency, and specular
reflection, in addition to the common challenges of occlusion, symmetry, and
variations in illumination and environments. In order to collect data of
sufficient scale for modern deep learning models, we propose a novel method for
efficiently annotating pose data in a multi-view fashion that allows data
capturing in complex and flexible environments. Fully annotated with 6D object
poses, our dataset contains over 393K frames and over 1.5M annotations of 18
objects recorded in 182 scenes constructed in 11 different environments. The 18
objects include 8 symmetric objects, 7 transparent objects, and 8 reflective
objects. We benchmark two state-of-the-art pose estimation frameworks on
StereOBJ-1M as baselines for future work. We also propose a novel object-level
pose optimization method for computing 6D pose from keypoint predictions in
multiple images. Project website: https://sites.google.com/view/stereobj-1m.",0,1,0,1,0,0,0.896883,7.0,0.887311,43
http://arxiv.org/abs/2105.11921v1,Focus Attention: Promoting Faithfulness and Diversity in Summarization,40,0.0598429,0.393826,"Professional summaries are written with document-level information, such as
the theme of the document, in mind. This is in contrast with most seq2seq
decoders which simultaneously learn to focus on salient content, while deciding
what to generate, at each decoding step. With the motivation to narrow this
gap, we introduce Focus Attention Mechanism, a simple yet effective method to
encourage decoders to proactively generate tokens that are similar or topical
to the input document. Further, we propose a Focus Sampling method to enable
generation of diverse summaries, an area currently understudied in
summarization. When evaluated on the BBC extreme summarization task, two
state-of-the-art models augmented with Focus Attention generate summaries that
are closer to the target and more faithful to their input documents,
outperforming their vanilla counterparts on \rouge and multiple faithfulness
measures. We also empirically demonstrate that Focus Sampling is more effective
in generating diverse and faithful summaries than top-$k$ or nucleus
sampling-based decoding methods.",0,1,1,0,1,0,0.444947,5.0,0.572142,91
http://arxiv.org/abs/2105.06496v2,"Deepfake Detection by Human Crowds, Machines, and Machine-informed Crowds",101,0.980917,0.579951,"The recent emergence of machine-manipulated media raises an important
societal question: how can we know if a video that we watch is real or fake? In
two online studies with 15,016 participants, we present authentic videos and
deepfakes and ask participants to identify which is which. We compare the
performance of ordinary human observers against the leading computer vision
deepfake detection model and find them similarly accurate while making
different kinds of mistakes. Together, participants with access to the model's
prediction are more accurate than either alone, but inaccurate model
predictions often decrease participants' accuracy. To probe the relative
strengths and weaknesses of humans and machines as detectors of deepfakes, we
examine human and machine performance across video-level features, and we
evaluate the impact of pre-registered randomized interventions on deepfake
detection. We find that manipulations designed to disrupt visual processing of
faces hinder human participants' performance while mostly not affecting the
model's performance, suggesting a role for specialized cognitive capacities in
explaining human deepfake detection performance.",1,1,0,0,0,0,0.965363,5.0,0.920669,94
http://arxiv.org/abs/2102.09532v2,Clockwork Variational Autoencoders,42,0.228371,0.820291,"Deep learning has enabled algorithms to generate realistic images. However,
accurately predicting long video sequences requires understanding long-term
dependencies and remains an open challenge. While existing video prediction
models succeed at generating sharp images, they tend to fail at accurately
predicting far into the future. We introduce the Clockwork VAE (CW-VAE), a
video prediction model that leverages a hierarchy of latent sequences, where
higher levels tick at slower intervals. We demonstrate the benefits of both
hierarchical latents and temporal abstraction on 4 diverse video prediction
datasets with sequences of up to 1000 frames, where CW-VAE outperforms top
video prediction models. Additionally, we propose a Minecraft benchmark for
long-term video prediction. We conduct several experiments to gain insights
into CW-VAE and confirm that slower levels learn to represent objects that
change more slowly in the video, and faster levels learn to represent faster
objects.",0,1,0,0,1,0,0.682175,8.0,0.815883,61
http://arxiv.org/abs/2104.03663v1,Connecting Deep-Reinforcement-Learning-based Obstacle Avoidance with Conventional Global Planners using Waypoint Generators,22,0.161462,0.847903,"Deep Reinforcement Learning has emerged as an efficient dynamic obstacle
avoidance method in highly dynamic environments. It has the potential to
replace overly conservative or inefficient navigation approaches. However, the
integration of Deep Reinforcement Learning into existing navigation systems is
still an open frontier due to the myopic nature of
Deep-Reinforcement-Learning-based navigation, which hinders its widespread
integration into current navigation systems. In this paper, we propose the
concept of an intermediate planner to interconnect novel
Deep-Reinforcement-Learning-based obstacle avoidance with conventional global
planning methods using waypoint generation. Therefore, we integrate different
waypoint generators into existing navigation systems and compare the joint
system against traditional ones. We found an increased performance in terms of
safety, efficiency and path smoothness especially in highly dynamic
environments.",1,1,0,0,0,0,0.611312,6.0,0.722328,26
http://arxiv.org/abs/2102.07983v1,"FEWS: Large-Scale, Low-Shot Word Sense Disambiguation with the Dictionary",15,0.130471,0.817535,"Current models for Word Sense Disambiguation (WSD) struggle to disambiguate
rare senses, despite reaching human performance on global WSD metrics. This
stems from a lack of data for both modeling and evaluating rare senses in
existing WSD datasets. In this paper, we introduce FEWS (Few-shot Examples of
Word Senses), a new low-shot WSD dataset automatically extracted from example
sentences in Wiktionary. FEWS has high sense coverage across different natural
language domains and provides: (1) a large training set that covers many more
senses than previous datasets and (2) a comprehensive evaluation set containing
few- and zero-shot examples of a wide variety of senses. We establish baselines
on FEWS with knowledge-based and neural WSD approaches and present transfer
learning experiments demonstrating that models additionally trained with FEWS
better capture rare senses in existing WSD datasets. Finally, we find humans
outperform the best baseline models on FEWS, indicating that FEWS will support
significant future work on low-shot WSD.",1,1,1,1,0,0,0.0615025,16.0,0.727091,30
http://arxiv.org/abs/2105.01735v1,HerBERT: Efficiently Pretrained Transformer-based Language Model for Polish,65,0.269763,0.782381,"BERT-based models are currently used for solving nearly all Natural Language
Processing (NLP) tasks and most often achieve state-of-the-art results.
Therefore, the NLP community conducts extensive research on understanding these
models, but above all on designing effective and efficient training procedures.
Several ablation studies investigating how to train BERT-like models have been
carried out, but the vast majority of them concerned only the English language.
A training procedure designed for English does not have to be universal and
applicable to other especially typologically different languages. Therefore,
this paper presents the first ablation study focused on Polish, which, unlike
the isolating English language, is a fusional language. We design and
thoroughly evaluate a pretraining procedure of transferring knowledge from
multilingual to monolingual BERT-based models. In addition to multilingual
model initialization, other factors that possibly influence pretraining are
also explored, i.e. training objective, corpus size, BPE-Dropout, and
pretraining length. Based on the proposed procedure, a Polish BERT-based
language model -- HerBERT -- is trained. This model achieves state-of-the-art
results on multiple downstream tasks.",1,1,0,0,1,0,0.813317,4.0,0.727092,45
http://arxiv.org/abs/2104.05314v2,Machine learning and deep learning,685,0.28044,0.97804,"Today, intelligent systems that offer artificial intelligence capabilities
often rely on machine learning. Machine learning describes the capacity of
systems to learn from problem-specific training data to automate the process of
analytical model building and solve associated tasks. Deep learning is a
machine learning concept based on artificial neural networks. For many
applications, deep learning models outperform shallow machine learning models
and traditional data analysis approaches. In this article, we summarize the
fundamentals of machine learning and deep learning to generate a broader
understanding of the methodical underpinning of current intelligent systems. In
particular, we provide a conceptual distinction between relevant terms and
concepts, explain the process of automated analytical model building through
machine learning and deep learning, and discuss the challenges that arise when
implementing such intelligent systems in the field of electronic markets and
networked business. These naturally go beyond technological aspects and
highlight issues in human-machine interaction and artificial intelligence
servitization.",0,0,0,0,0,0,0.0419586,7.0,0.320121,64
http://arxiv.org/abs/2109.03009v1,Sequential Attention Module for Natural Language Processing,1,0.00144058,0.0143219,"Recently, large pre-trained neural language models have attained remarkable
performance on many downstream natural language processing (NLP) applications
via fine-tuning. In this paper, we target at how to further improve the token
representations on the language models. We, therefore, propose a simple yet
effective plug-and-play module, Sequential Attention Module (SAM), on the token
embeddings learned from a pre-trained language model. Our proposed SAM consists
of two main attention modules deployed sequentially: Feature-wise Attention
Module (FAM) and Token-wise Attention Module (TAM). More specifically, FAM can
effectively identify the importance of features at each dimension and promote
the effect via dot-product on the original token embeddings for downstream NLP
applications. Meanwhile, TAM can further re-weight the features at the
token-wise level. Moreover, we propose an adaptive filter on FAM to prevent
noise impact and increase information absorption. Finally, we conduct extensive
experiments to demonstrate the advantages and properties of our proposed SAM.
We first show how SAM plays a primary role in the champion solution of two
subtasks of SemEval'21 Task 7. After that, we apply SAM on sentiment analysis
and three popular NLP tasks and demonstrate that SAM consistently outperforms
the state-of-the-art baselines.",1,1,0,0,1,1,0.111678,9.0,0.584117,45
http://arxiv.org/abs/2104.09742v1,Mitigating Temporal-Drift: A Simple Approach to Keep NER Models Crisp,7,0.0426462,0.343362,"Performance of neural models for named entity recognition degrades over time,
becoming stale. This degradation is due to temporal drift, the change in our
target variables' statistical properties over time. This issue is especially
problematic for social media data, where topics change rapidly. In order to
mitigate the problem, data annotation and retraining of models is common.
Despite its usefulness, this process is expensive and time-consuming, which
motivates new research on efficient model updating. In this paper, we propose
an intuitive approach to measure the potential trendiness of tweets and use
this metric to select the most informative instances to use for training. We
conduct experiments on three state-of-the-art models on the Temporal Twitter
Dataset. Our approach shows larger increases in prediction accuracy with less
training data than the alternatives, making it an attractive, practical
solution.",1,1,0,0,0,0,0.20983,10.0,0.694455,18
http://arxiv.org/abs/2107.08262v1,Tea: Program Repair Using Neural Network Based on Program Information Attention Matrix,1,0.0125238,0.0225439,"The advance in machine learning (ML)-driven natural language process (NLP)
points a promising direction for automatic bug fixing for software programs, as
fixing a buggy program can be transformed to a translation task. While software
programs contain much richer information than one-dimensional natural language
documents, pioneering work on using ML-driven NLP techniques for automatic
program repair only considered a limited set of such information. We
hypothesize that more comprehensive information of software programs, if
appropriately utilized, can improve the effectiveness of ML-driven NLP
approaches in repairing software programs. As the first step towards proving
this hypothesis, we propose a unified representation to capture the syntax,
data flow, and control flow aspects of software programs, and devise a method
to use such a representation to guide the transformer model from NLP in better
understanding and fixing buggy programs. Our preliminary experiment confirms
that the more comprehensive information of software programs used, the better
ML-driven NLP techniques can perform in fixing bugs in these programs.",1,1,0,0,0,0,0.481169,9.0,0.77436,14
http://arxiv.org/abs/2104.00124v2,Misinformation detection in Luganda-English code-mixed social media text,1,0.0425322,0.0107255,"The increasing occurrence, forms, and negative effects of misinformation on
social media platforms has necessitated more misinformation detection tools.
Currently, work is being done addressing COVID-19 misinformation however, there
are no misinformation detection tools for any of the 40 distinct indigenous
Ugandan languages. This paper addresses this gap by presenting basic language
resources and a misinformation detection data set based on code-mixed
Luganda-English messages sourced from the Facebook and Twitter social media
platforms. Several machine learning methods are applied on the misinformation
detection data set to develop classification models for detecting whether a
code-mixed Luganda-English message contains misinformation or not. A 10-fold
cross validation evaluation of the classification methods in an experimental
misinformation detection task shows that a Discriminative Multinomial Naive
Bayes (DMNB) method achieves the highest accuracy and F-measure of 78.19% and
77.90% respectively. Also, Support Vector Machine and Bagging ensemble
classification models achieve comparable results. These results are promising
since the machine learning models are based on n-gram features from only the
misinformation detection dataset.",1,1,1,1,1,0,0.638279,10.0,0.84073,41
http://arxiv.org/abs/2102.07716v2,How RL Agents Behave When Their Actions Are Modified,13,0.0179148,0.150044,"Reinforcement learning in complex environments may require supervision to
prevent the agent from attempting dangerous actions. As a result of supervisor
intervention, the executed action may differ from the action specified by the
policy. How does this affect learning? We present the Modified-Action Markov
Decision Process, an extension of the MDP model that allows actions to differ
from the policy. We analyze the asymptotic behaviours of common reinforcement
learning algorithms in this setting and show that they adapt in different ways:
some completely ignore modifications while others go to various lengths in
trying to avoid action modifications that decrease reward. By choosing the
right algorithm, developers can prevent their agents from learning to
circumvent interruptions or constraints, and better control agent responses to
other kinds of action modification, like self-damage.",1,0,0,0,0,0,0.0658302,10.0,0.570374,34
http://arxiv.org/abs/2103.16324v1,"Automated Cleanup of the ImageNet Dataset by Model Consensus, Explainability and Confident Learning",21,0.180724,0.565229,"The convolutional neural networks (CNNs) trained on ILSVRC12 ImageNet were
the backbone of various applications as a generic classifier, a feature
extractor or a base model for transfer learning. This paper describes automated
heuristics based on model consensus, explainability and confident learning to
correct labeling mistakes and remove ambiguous images from this dataset. After
making these changes on the training and validation sets, the ImageNet-Clean
improves the model performance by 2-2.4 % for SqueezeNet and EfficientNet-B0
models. The results support the importance of larger image corpora and
semi-supervised learning, but the original datasets must be fixed to avoid
transmitting their mistakes and biases to the student learner. Further
contributions describe the training impacts of widescreen input resolutions in
portrait and landscape orientations. The trained models and scripts are
published on Github (https://github.com/kecsap/imagenet-clean) to clean up
ImageNet and ImageNetV2 datasets for reproducible research.",1,1,0,0,1,1,0.806233,5.0,0.777185,33
http://arxiv.org/abs/2110.07911v1,Learning to Infer Kinematic Hierarchies for Novel Object Instances,10,0.294945,0.198099,"Manipulating an articulated object requires perceiving itskinematic
hierarchy: its parts, how each can move, and howthose motions are coupled.
Previous work has explored per-ception for kinematics, but none infers a
complete kinematichierarchy on never-before-seen object instances, without
relyingon a schema or template. We present a novel perception systemthat
achieves this goal. Our system infers the moving parts ofan object and the
kinematic couplings that relate them. Toinfer parts, it uses a point cloud
instance segmentation neuralnetwork and to infer kinematic hierarchies, it uses
a graphneural network to predict the existence, direction, and typeof edges
(i.e. joints) that relate the inferred parts. We trainthese networks using
simulated scans of synthetic 3D models.We evaluate our system on simulated
scans of 3D objects, andwe demonstrate a proof-of-concept use of our system to
drivereal-world robotic manipulation.",0,1,1,0,0,0,0.637897,7.0,0.772323,37
http://arxiv.org/abs/2105.05996v3,Multilingual Offensive Language Identification for Low-resource Languages,57,0.758293,0.989234,"Offensive content is pervasive in social media and a reason for concern to
companies and government organizations. Several studies have been recently
published investigating methods to detect the various forms of such content
(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of
these studies deal with English partially because most annotated datasets
available contain English data. In this paper, we take advantage of available
English datasets by applying cross-lingual contextual word embeddings and
transfer learning to make predictions in low-resource languages. We project
predictions on comparable data in Arabic, Bengali, Danish, Greek, Hindi,
Spanish, and Turkish. We report results of 0.8415 F1 macro for Bengali in
TRAC-2 shared task, 0.8532 F1 macro for Danish and 0.8701 F1 macro for Greek in
OffensEval 2020, 0.8568 F1 macro for Hindi in HASOC 2019 shared task and 0.7513
F1 macro for Spanish in in SemEval-2019 Task 5 (HatEval) showing that our
approach compares favourably to the best systems submitted to recent shared
tasks on these three languages. Additionally, we report competitive performance
on Arabic, and Turkish using the training and development sets of OffensEval
2020 shared task. The results for all languages confirm the robustness of
cross-lingual contextual embeddings and transfer learning for this task.",0,1,0,0,1,0,0.876744,4.0,0.782349,61
http://arxiv.org/abs/2105.14424v1,Gaze Estimation using Transformer,54,0.737794,0.671259,"Recent work has proven the effectiveness of transformers in many computer
vision tasks. However, the performance of transformers in gaze estimation is
still unexplored. In this paper, we employ transformers and assess their
effectiveness for gaze estimation. We consider two forms of vision transformer
which are pure transformers and hybrid transformers. We first follow the
popular ViT and employ a pure transformer to estimate gaze from images. On the
other hand, we preserve the convolutional layers and integrate CNNs as well as
transformers. The transformer serves as a component to complement CNNs. We
compare the performance of the two transformers in gaze estimation. The Hybrid
transformer significantly outperforms the pure transformer in all evaluation
datasets with less parameters. We further conduct experiments to assess the
effectiveness of the hybrid transformer and explore the advantage of
self-attention mechanism. Experiments show the hybrid transformer can achieve
state-of-the-art performance in all benchmarks with pre-training.To facilitate
further research, we release codes and models in
https://github.com/yihuacheng/GazeTR.",1,0,0,0,1,0,0.975507,4.0,0.925355,46
http://arxiv.org/abs/2104.05433v1,Multilingual Language Models Predict Human Reading Behavior,37,0.0519424,0.296134,"We analyze if large language models are able to predict patterns of human
reading behavior. We compare the performance of language-specific and
multilingual pretrained transformer models to predict reading time measures
reflecting natural human sentence processing on Dutch, English, German, and
Russian texts. This results in accurate models of human reading behavior, which
indicates that transformer models implicitly encode relative importance in
language in a way that is comparable to human processing mechanisms. We find
that BERT and XLM models successfully predict a range of eye tracking features.
In a series of experiments, we analyze the cross-domain and cross-language
abilities of these models and show how they reflect human sentence processing.",0,0,0,0,0,0,0.155771,5.0,0.322933,67
http://arxiv.org/abs/2104.08200v3,IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural Language Generation,73,0.337703,0.745049,"Natural language generation (NLG) benchmarks provide an important avenue to
measure progress and develop better NLG systems. Unfortunately, the lack of
publicly available NLG benchmarks for low-resource languages poses a
challenging barrier for building NLG systems that work well for languages with
limited amounts of data. Here we introduce IndoNLG, the first benchmark to
measure natural language generation (NLG) progress in three low-resource -- yet
widely spoken -- languages of Indonesia: Indonesian, Javanese, and Sundanese.
Altogether, these languages are spoken by more than 100 million native
speakers, and hence constitute an important use case of NLG systems today.
Concretely, IndoNLG covers six tasks: summarization, question answering,
chit-chat, and three different pairs of machine translation (MT) tasks. We
collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese
datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and
IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on
all tasks -- despite using only one-fifth the parameters of a larger
multilingual model, mBART-LARGE (Liu et al., 2020). This finding emphasizes the
importance of pretraining on closely related, local languages to achieve more
efficient learning and faster inference for very low-resource languages like
Javanese and Sundanese.",1,1,0,1,0,0,0.842337,3.0,0.668095,73
http://arxiv.org/abs/2110.08544v2,Answering Open-Domain Multi-Answer Questions via a Recall-then-Verify Framework,8,0.0409346,0.277715,"Open-domain questions are likely to be open-ended and ambiguous, leading to
multiple valid answers. Existing approaches typically adopt the
rerank-then-read framework, where a reader reads top-ranking evidence to
predict answers. According to our empirical analysis, this framework faces
three problems: first, to leverage a large reader under a memory constraint,
the reranker should select only a few relevant passages to cover diverse
answers, while balancing relevance and diversity is non-trivial; second, the
small reading budget prevents the reader from accessing valuable retrieved
evidence filtered out by the reranker; third, when using a generative reader to
predict answers all at once based on all selected evidence, whether a valid
answer will be predicted also pathologically depends on the evidence of some
other valid answer(s). To address these issues, we propose to answer
open-domain multi-answer questions with a recall-then-verify framework, which
separates the reasoning process of each answer so that we can make better use
of retrieved evidence while also leveraging large models under the same memory
constraint. Our framework achieves state-of-the-art results on two multi-answer
datasets, and predicts significantly more gold answers than a rerank-then-read
system that uses an oracle reranker.",0,1,0,0,1,0,0.716093,4.0,0.655242,38
http://arxiv.org/abs/2103.07815v1,Dynamically Switching Human Prediction Models for Efficient Planning,5,0.0284782,0.177705,"As environments involving both robots and humans become increasingly common,
so does the need to account for people during planning. To plan effectively,
robots must be able to respond to and sometimes influence what humans do. This
requires a human model which predicts future human actions. A simple model may
assume the human will continue what they did previously; a more complex one
might predict that the human will act optimally, disregarding the robot;
whereas an even more complex one might capture the robot's ability to influence
the human. These models make different trade-offs between computational time
and performance of the resulting robot plan. Using only one model of the human
either wastes computational resources or is unable to handle critical
situations. In this work, we give the robot access to a suite of human models
and enable it to assess the performance-computation trade-off online. By
estimating how an alternate model could improve human prediction and how that
may translate to performance gain, the robot can dynamically switch human
models whenever the additional computation is justified. Our experiments in a
driving simulator showcase how the robot can achieve performance comparable to
always using the best human model, but with greatly reduced computation.",0,1,0,0,0,0,0.140638,10.0,0.650382,30
http://arxiv.org/abs/2104.05832v1,SpartQA: : A Textual Question Answering Benchmark for Spatial Reasoning,53,0.394284,0.574947,"This paper proposes a question-answering (QA) benchmark for spatial reasoning
on natural language text which contains more realistic spatial phenomena not
covered by prior work and is challenging for state-of-the-art language models
(LM). We propose a distant supervision method to improve on this task.
Specifically, we design grammar and reasoning rules to automatically generate a
spatial description of visual scenes and corresponding QA pairs. Experiments
show that further pretraining LMs on these automatically generated data
significantly improves LMs' capability on spatial understanding, which in turn
helps to better solve two external datasets, bAbI, and boolQ. We hope that this
work can foster investigations into more sophisticated models for spatial
reasoning over text.",1,1,1,1,0,0,0.7351,5.0,0.734908,56
http://arxiv.org/abs/2104.05507v1,BART based semantic correction for Mandarin automatic speech recognition system,21,0.0846241,0.724687,"Although automatic speech recognition (ASR) systems achieved significantly
improvements in recent years, spoken language recognition error occurs which
can be easily spotted by human beings. Various language modeling techniques
have been developed on post recognition tasks like semantic correction. In this
paper, we propose a Transformer based semantic correction method with
pretrained BART initialization, Experiments on 10000 hours Mandarin speech
dataset show that character error rate (CER) can be effectively reduced by
21.7% relatively compared to our baseline ASR system. Expert evaluation
demonstrates that actual improvement of our model surpasses what CER indicates.",0,1,0,0,1,0,0.653028,4.0,0.611856,23
http://arxiv.org/abs/2107.12544v1,"Human-Level Reinforcement Learning through Theory-Based Modeling, Exploration, and Planning",35,0.0475041,0.40863,"Reinforcement learning (RL) studies how an agent comes to achieve reward in
an environment through interactions over time. Recent advances in machine RL
have surpassed human expertise at the world's oldest board games and many
classic video games, but they require vast quantities of experience to learn
successfully -- none of today's algorithms account for the human ability to
learn so many different tasks, so quickly. Here we propose a new approach to
this challenge based on a particularly strong form of model-based RL which we
call Theory-Based Reinforcement Learning, because it uses human-like intuitive
theories -- rich, abstract, causal models of physical objects, intentional
agents, and their interactions -- to explore and model an environment, and plan
effectively to achieve task goals. We instantiate the approach in a video game
playing agent called EMPA (the Exploring, Modeling, and Planning Agent), which
performs Bayesian inference to learn probabilistic generative models expressed
as programs for a game-engine simulator, and runs internal simulations over
these models to support efficient object-based, relational exploration and
heuristic planning. EMPA closely matches human learning efficiency on a suite
of 90 challenging Atari-style video games, learning new games in just minutes
of game play and generalizing robustly to new game situations and new levels.
The model also captures fine-grained structure in people's exploration
trajectories and learning dynamics. Its design and behavior suggest a way
forward for building more general human-like AI systems.",0,0,0,0,0,0,0.011434,11.0,0.44774,88
http://arxiv.org/abs/2105.11120v1,A Fourier-based Framework for Domain Generalization,308,0.745048,0.999784,"Modern deep neural networks suffer from performance degradation when
evaluated on testing data under different distributions from training data.
Domain generalization aims at tackling this problem by learning transferable
knowledge from multiple source domains in order to generalize to unseen target
domains. This paper introduces a novel Fourier-based perspective for domain
generalization. The main assumption is that the Fourier phase information
contains high-level semantics and is not easily affected by domain shifts. To
force the model to capture phase information, we develop a novel Fourier-based
data augmentation strategy called amplitude mix which linearly interpolates
between the amplitude spectrums of two images. A dual-formed consistency loss
called co-teacher regularization is further introduced between the predictions
induced from original and augmented images. Extensive experiments on three
benchmarks have demonstrated that the proposed method is able to achieve
state-of-the-arts performance for domain generalization.",1,1,0,0,1,0,0.743871,7.0,0.814225,55
http://arxiv.org/abs/2110.07331v1,Plug-Tagger: A Pluggable Sequence Labeling Framework Using Language Models,5,0.0156719,0.255873,"Plug-and-play functionality allows deep learning models to adapt well to
different tasks without requiring any parameters modified. Recently,
prefix-tuning was shown to be a plug-and-play method on various text generation
tasks by simply inserting corresponding continuous vectors into the inputs.
However, sequence labeling tasks invalidate existing plug-and-play methods
since different label sets demand changes to the architecture of the model
classifier. In this work, we propose the use of label word prediction instead
of classification to totally reuse the architecture of pre-trained models for
sequence labeling tasks. Specifically, for each task, a label word set is first
constructed by selecting a high-frequency word for each class respectively, and
then, task-specific vectors are inserted into the inputs and optimized to
manipulate the model predictions towards the corresponding label words. As a
result, by simply switching the plugin vectors on the input, a frozen
pre-trained language model is allowed to perform different tasks. Experimental
results on three sequence labeling tasks show that the performance of the
proposed method can achieve comparable performance with standard fine-tuning
with only 0.1\% task-specific parameters. In addition, our method is up to 70
times faster than non-plug-and-play methods while switching different tasks
under the resource-constrained scenario.",0,1,0,0,0,0,0.757463,5.0,0.747765,44
http://arxiv.org/abs/2108.05280v1,Putting RDF2vec in Order,11,0.0984631,0.486044,"The RDF2vec method for creating node embeddings on knowledge graphs is based
on word2vec, which, in turn, is agnostic towards the position of context words.
In this paper, we argue that this might be a shortcoming when training RDF2vec,
and show that using a word2vec variant which respects order yields considerable
performance gains especially on tasks where entities of different classes are
involved.",0,0,0,0,0,0,0.276545,8.0,0.657835,15
http://arxiv.org/abs/2109.07445v1,Challenges in Detoxifying Language Models,140,0.110065,0.53595,"Large language models (LM) generate remarkably fluent text and can be
efficiently adapted across NLP tasks. Measuring and guaranteeing the quality of
generated text in terms of safety is imperative for deploying LMs in the real
world; to this end, prior work often relies on automatic evaluation of LM
toxicity. We critically discuss this approach, evaluate several toxicity
mitigation strategies with respect to both automatic and human evaluation, and
analyze consequences of toxicity mitigation in terms of model bias and LM
quality. We demonstrate that while basic intervention strategies can
effectively optimize previously established automatic metrics on the
RealToxicityPrompts dataset, this comes at the cost of reduced LM coverage for
both texts about, and dialects of, marginalized groups. Additionally, we find
that human raters often disagree with high automatic toxicity scores after
strong toxicity reduction interventions -- highlighting further the nuances
involved in careful evaluation of LM toxicity.",0,1,0,0,0,0,0.24999,5.0,0.428924,62
http://arxiv.org/abs/2105.13782v1,How to Split: the Effect of Word Segmentation on Gender Bias in Speech Translation,13,0.0900737,0.426533,"Having recognized gender bias as a major issue affecting current translation
technologies, researchers have primarily attempted to mitigate it by working on
the data front. However, whether algorithmic aspects concur to exacerbate
unwanted outputs remains so far under-investigated. In this work, we bring the
analysis on gender bias in automatic translation onto a seemingly neutral yet
critical component: word segmentation. Can segmenting methods influence the
ability to translate gender? Do certain segmentation approaches penalize the
representation of feminine linguistic markings? We address these questions by
comparing 5 existing segmentation strategies on the target side of speech
translation systems. Our results on two language pairs (English-Italian/French)
show that state-of-the-art sub-word splitting (BPE) comes at the cost of higher
gender bias. In light of this finding, we propose a combined approach that
preserves BPE overall translation quality, while leveraging the higher ability
of character-based segmentation to properly translate gender.",1,0,0,0,0,0,0.399738,5.0,0.543596,99
http://arxiv.org/abs/2102.08773v2,Predicting Lexical Complexity in English Texts: The Complex 2.0 Dataset,33,0.565597,0.685904,"Identifying words which may cause difficulty for a reader is an essential
step in most lexical text simplification systems prior to lexical substitution
and can also be used for assessing the readability of a text. This task is
commonly referred to as Complex Word Identification (CWI) and is often modelled
as a supervised classification problem. For training such systems, annotated
datasets in which words and sometimes multi-word expressions are labelled
regarding complexity are required. In this paper we analyze previous work
carried out in this task and investigate the properties of CWI datasets for
English. We develop a protocol for the annotation of lexical complexity and use
this to annotate a new dataset, CompLex 2.0. We present experiments using both
new and old datasets to investigate the nature of lexical complexity. We found
that a Likert-scale annotation protocol provides an objective setting that is
superior for identifying the complexity of words compared to a binary
annotation protocol. We release a new dataset using our new protocol to promote
the task of Lexical Complexity Prediction.",0,1,0,1,0,0,0.166065,10.0,0.668461,95
http://arxiv.org/abs/2110.08744v1,A model for full local image interpretation,8,0.0242729,0.346948,"We describe a computational model of humans' ability to provide a detailed
interpretation of components in a scene. Humans can identify in an image
meaningful components almost everywhere, and identifying these components is an
essential part of the visual process, and of understanding the surrounding
scene and its potential meaning to the viewer. Detailed interpretation is
beyond the scope of current models of visual recognition. Our model suggests
that this is a fundamental limitation, related to the fact that existing models
rely on feed-forward but limited top-down processing. In our model, a first
recognition stage leads to the initial activation of class candidates, which is
incomplete and with limited accuracy. This stage then triggers the application
of class-specific interpretation and validation processes, which recover richer
and more accurate interpretation of the visible scene. We discuss implications
of the model for visual interpretation by humans and by computer vision models.",0,0,0,0,0,0,0.0669387,21.0,0.796239,23
http://arxiv.org/abs/2112.07356v2,Technical Language Supervision for Intelligent Fault Diagnosis in Process Industry,4,0.0607876,0.229335,"In the process industry, condition monitoring systems with automated fault
diagnosis methods assist human experts and thereby improve maintenance
efficiency, process sustainability, and workplace safety. Improving the
automated fault diagnosis methods using data and machine learning-based models
is a central aspect of intelligent fault diagnosis (IFD). A major challenge in
IFD is to develop realistic datasets with accurate labels needed to train and
validate models, and to transfer models trained with labeled lab data to
heterogeneous process industry environments. However, fault descriptions and
work-orders written by domain experts are increasingly digitised in modern
condition monitoring systems, for example in the context of rotating equipment
monitoring. Thus, domain-specific knowledge about fault characteristics and
severities exists as technical language annotations in industrial datasets.
Furthermore, recent advances in natural language processing enable weakly
supervised model optimisation using natural language annotations, most notably
in the form of natural language supervision (NLS). This creates a timely
opportunity to develop technical language supervision (TLS) solutions for IFD
systems grounded in industrial data, for example as a complement to
pre-training with lab data to address problems like overfitting and inaccurate
out-of-sample generalisation. We surveyed the literature and identify a
considerable improvement in the maturity of NLS over the last two years,
facilitating applications beyond natural language; a rapid development of weak
supervision methods; and transfer learning as a current trend in IFD which can
benefit from these developments. Finally we describe a general framework for
TLS and implement a TLS case study based on SentenceBERT and contrastive
learning based zero-shot inference on annotated industry data.",0,0,0,0,0,0,0.887984,6.0,0.862343,173
http://arxiv.org/abs/2102.01301v2,Learning Crisp Boundaries Using Deep Refinement Network and Adaptive Weighting Loss,33,0.149046,0.863451,"Significant progress has been made in boundary detection with the help of
convolutional neural networks. Recent boundary detection models not only focus
on real object boundary detection but also ""crisp"" boundaries (precisely
localized along the object's contour). There are two methods to evaluate crisp
boundary performance. One uses more strict tolerance to measure the distance
between the ground truth and the detected contour. The other focuses on
evaluating the contour map without any postprocessing. In this study, we
analyze both methods and conclude that both methods are two aspects of crisp
contour evaluation. Accordingly, we propose a novel network named deep
refinement network (DRNet) that stacks multiple refinement modules to achieve
richer feature representation and a novel loss function, which combines
cross-entropy and dice loss through effective adaptive fusion. Experimental
results demonstrated that we achieve state-of-the-art performance for several
available datasets.",0,1,0,0,1,0,0.140204,12.0,0.708374,48
http://arxiv.org/abs/2101.04342v1,Mixup Without Hesitation,15,0.0423774,0.190909,"Mixup linearly interpolates pairs of examples to form new samples, which is
easy to implement and has been shown to be effective in image classification
tasks. However, there are two drawbacks in mixup: one is that more training
epochs are needed to obtain a well-trained model; the other is that mixup
requires tuning a hyper-parameter to gain appropriate capacity but that is a
difficult task. In this paper, we find that mixup constantly explores the
representation space, and inspired by the exploration-exploitation dilemma in
reinforcement learning, we propose mixup Without hesitation (mWh), a concise,
effective, and easy-to-use training algorithm. We show that mWh strikes a good
balance between exploration and exploitation by gradually replacing mixup with
basic data augmentation. It can achieve a strong baseline with less training
time than original mixup and without searching for optimal hyper-parameter,
i.e., mWh acts as mixup without hesitation. mWh can also transfer to CutMix,
and gain consistent improvement on other machine learning and computer vision
tasks such as object detection. Our code is open-source and available at
https://github.com/yuhao318/mwh",1,1,0,0,0,1,0.900753,5.0,0.845574,26
http://arxiv.org/abs/2104.08790v4,Misinfo Reaction Frames: Reasoning about Readers' Reactions to News Headlines,30,0.505541,0.947915,"Even to a simple and short news headline, readers react in a multitude of
ways: cognitively (e.g. inferring the writer's intent), emotionally (e.g.
feeling distrust), and behaviorally (e.g. sharing the news with their friends).
Such reactions are instantaneous and yet complex, as they rely on factors that
go beyond interpreting factual content of news. We propose Misinfo Reaction
Frames (MRF), a pragmatic formalism for modeling how readers might react to a
news headline. In contrast to categorical schema, our free-text dimensions
provide a more nuanced way of understanding intent beyond being benign or
malicious. We also introduce a Misinfo Reaction Frames corpus, a crowdsourced
dataset of reactions to over 25k news headlines focusing on global crises: the
Covid-19 pandemic, climate change, and cancer. Empirical results confirm that
it is indeed possible for neural models to predict the prominent patterns of
readers' reactions to previously unseen news headlines. Additionally, our user
study shows that displaying machine-generated MRF implications alongside news
headlines to readers can increase their trust in real news while decreasing
their trust in misinformation. Our work demonstrates the feasibility and
importance of pragmatic inferences on news headlines to help enhance AI-guided
misinformation detection and mitigation.",1,0,1,1,0,0,0.93941,5.0,0.884295,87
http://arxiv.org/abs/2110.03847v1,Machine Translation Verbosity Control for Automatic Dubbing,20,0.0331615,0.517966,"Automatic dubbing aims at seamlessly replacing the speech in a video document
with synthetic speech in a different language. The task implies many
challenges, one of which is generating translations that not only convey the
original content, but also match the duration of the corresponding utterances.
In this paper, we focus on the problem of controlling the verbosity of machine
translation output, so that subsequent steps of our automatic dubbing pipeline
can generate dubs of better quality. We propose new methods to control the
verbosity of MT output and compare them against the state of the art with both
intrinsic and extrinsic evaluations. For our experiments we use a public data
set to dub English speeches into French, Italian, German and Spanish. Finally,
we report extensive subjective tests that measure the impact of MT verbosity
control on the final quality of dubbed video clips.",0,1,0,0,0,0,0.0975155,6.0,0.35228,32
http://arxiv.org/abs/2112.01894v1,The Catalan Language CLUB,2,0.00454302,0.0558837,"The Catalan Language Understanding Benchmark (CLUB) encompasses various
datasets representative of different NLU tasks that enable accurate evaluations
of language models, following the General Language Understanding Evaluation
(GLUE) example. It is part of AINA and PlanTL, two public funding initiatives
to empower the Catalan language in the Artificial Intelligence era.",0,1,0,1,0,0,0.760691,7.0,0.821177,7
http://arxiv.org/abs/2110.12427v4,Image-Based CLIP-Guided Essence Transfer,42,0.0386072,0.399538,"We make the distinction between (i) style transfer, in which a source image
is manipulated to match the textures and colors of a target image, and (ii)
essence transfer, in which one edits the source image to include high-level
semantic attributes from the target. Crucially, the semantic attributes that
constitute the essence of an image may differ from image to image. Our blending
operator combines the powerful StyleGAN generator and the semantic encoder of
CLIP in a novel way that is simultaneously additive in both latent spaces,
resulting in a mechanism that guarantees both identity preservation and
high-level feature transfer without relying on a facial recognition network. We
present two variants of our method. The first is based on optimization, while
the second fine-tunes an existing inversion encoder to perform essence
extraction. Through extensive experiments, we demonstrate the superiority of
our methods for essence transfer over existing methods for style transfer,
domain adaptation, and text-based semantic editing. Our code is available at
https://github.com/hila-chefer/TargetCLIP.",1,0,1,0,0,0,0.431042,4.0,0.454443,55
http://arxiv.org/abs/2102.04110v1,Clinical Outcome Prediction from Admission Notes using Self-Supervised Knowledge Integration,55,0.452932,0.976738,"Outcome prediction from clinical text can prevent doctors from overlooking
possible risks and help hospitals to plan capacities. We simulate patients at
admission time, when decision support can be especially valuable, and
contribute a novel admission to discharge task with four common outcome
prediction targets: Diagnoses at discharge, procedures performed, in-hospital
mortality and length-of-stay prediction. The ideal system should infer outcomes
based on symptoms, pre-conditions and risk factors of a patient. We evaluate
the effectiveness of language models to handle this scenario and propose
clinical outcome pre-training to integrate knowledge about patient outcomes
from multiple public sources. We further present a simple method to incorporate
ICD code hierarchy into the models. We show that our approach improves
performance on the outcome tasks against several baselines. A detailed analysis
reveals further strengths of the model, including transferability, but also
weaknesses such as handling of vital values and inconsistencies in the
underlying data.",1,1,1,0,0,0,0.701697,4.0,0.645222,48
http://arxiv.org/abs/2103.00710v3,Towards Personalized Federated Learning,517,0.995964,0.999844,"In parallel with the rapid adoption of Artificial Intelligence (AI) empowered
by advances in AI research, there have been growing awareness and concerns of
data privacy. Recent significant developments in the data regulation landscape
have prompted a seismic shift in interest towards privacy-preserving AI. This
has contributed to the popularity of Federated Learning (FL), the leading
paradigm for the training of machine learning models on data silos in a
privacy-preserving manner. In this survey, we explore the domain of
Personalized FL (PFL) to address the fundamental challenges of FL on
heterogeneous data, a universal characteristic inherent in all real-world
datasets. We analyze the key motivations for PFL and present a unique taxonomy
of PFL techniques categorized according to the key challenges and
personalization strategies in PFL. We highlight their key ideas, challenges and
opportunities and envision promising future trajectories of research towards
new PFL architectural design, realistic PFL benchmarking, and trustworthy PFL
approaches.",0,0,1,0,0,0,0.952764,3.0,0.835519,138
http://arxiv.org/abs/2108.02740v2,WSDesc: Weakly Supervised 3D Local Descriptor Learning for Point Cloud Registration,10,0.153846,0.271623,"In this work, we present a novel method called WSDesc to learn 3D local
descriptors in a weakly supervised manner for robust point cloud registration.
Our work builds upon recent 3D CNN-based descriptor extractors, which leverage
a voxel-based representation to parameterize local geometry of 3D points.
Instead of using a predefined fixed-size local support in voxelization, we
propose to learn the optimal support in a data-driven manner. To this end, we
design a novel differentiable voxelization layer that can back-propagate the
gradient to the support size optimization. To train the extracted descriptors,
we propose a novel registration loss based on the deviation from rigidity of 3D
transformations, and the loss is weakly supervised by the prior knowledge that
the input point clouds have partial overlap, without requiring ground-truth
alignment information. Through extensive experiments, we show that our learned
descriptors yield superior performance on existing geometric registration
benchmarks.",1,1,0,0,1,0,0.930602,7.0,0.910264,79
http://arxiv.org/abs/2106.08495v1,Improving Entity Linking through Semantic Reinforced Entity Embeddings,36,0.229403,0.578892,"Entity embeddings, which represent different aspects of each entity with a
single vector like word embeddings, are a key component of neural entity
linking models. Existing entity embeddings are learned from canonical Wikipedia
articles and local contexts surrounding target entities. Such entity embeddings
are effective, but too distinctive for linking models to learn contextual
commonality. We propose a simple yet effective method, FGS2EE, to inject
fine-grained semantic information into entity embeddings to reduce the
distinctiveness and facilitate the learning of contextual commonality. FGS2EE
first uses the embeddings of semantic type words to generate semantic
embeddings, and then combines them with existing entity embeddings through
linear aggregation. Extensive experiments show the effectiveness of such
embeddings. Based on our entity embeddings, we achieved new sate-of-the-art
performance on entity linking.",1,1,0,0,1,0,0.219939,8.0,0.624722,25
http://arxiv.org/abs/2104.01409v1,Diff-TTS: A Denoising Diffusion Model for Text-to-Speech,148,0.408197,0.997963,"Although neural text-to-speech (TTS) models have attracted a lot of attention
and succeeded in generating human-like speech, there is still room for
improvements to its naturalness and architectural efficiency. In this work, we
propose a novel non-autoregressive TTS model, namely Diff-TTS, which achieves
highly natural and efficient speech synthesis. Given the text, Diff-TTS
exploits a denoising diffusion framework to transform the noise signal into a
mel-spectrogram via diffusion time steps. In order to learn the mel-spectrogram
distribution conditioned on the text, we present a likelihood-based
optimization method for TTS. Furthermore, to boost up the inference speed, we
leverage the accelerated sampling method that allows Diff-TTS to generate raw
waveforms much faster without significantly degrading perceptual quality.
Through experiments, we verified that Diff-TTS generates 28 times faster than
the real-time with a single NVIDIA 2080Ti GPU.",0,0,1,0,0,0,0.946829,2.0,0.733505,31
http://arxiv.org/abs/2108.06637v1,Deep Algorithm Unrolling for Biomedical Imaging,8,0.0258408,0.328185,"In this chapter, we review biomedical applications and breakthroughs via
leveraging algorithm unrolling, an important technique that bridges between
traditional iterative algorithms and modern deep learning techniques. To
provide context, we start by tracing the origin of algorithm unrolling and
providing a comprehensive tutorial on how to unroll iterative algorithms into
deep networks. We then extensively cover algorithm unrolling in a wide variety
of biomedical imaging modalities and delve into several representative recent
works in detail. Indeed, there is a rich history of iterative algorithms for
biomedical image synthesis, which makes the field ripe for unrolling
techniques. In addition, we put algorithm unrolling into a broad perspective,
in order to understand why it is particularly effective and discuss recent
trends. Finally, we conclude the chapter by discussing open challenges, and
suggesting future research directions.",0,0,0,0,0,0,0.063226,9.0,0.518,46
http://arxiv.org/abs/2110.09157v1,Disentangled Representation with Dual-stage Feature Learning for Face Anti-spoofing,14,0.318062,0.80734,"As face recognition is widely used in diverse security-critical applications,
the study of face anti-spoofing (FAS) has attracted more and more attention.
Several FAS methods have achieved promising performances if the attack types in
the testing data are the same as training data, while the performance
significantly degrades for unseen attack types. It is essential to learn more
generalized and discriminative features to prevent overfitting to pre-defined
spoof attack types. This paper proposes a novel dual-stage disentangled
representation learning method that can efficiently untangle spoof-related
features from irrelevant ones. Unlike previous FAS disentanglement works with
one-stage architecture, we found that the dual-stage training design can
improve the training stability and effectively encode the features to detect
unseen attack types. Our experiments show that the proposed method provides
superior accuracy than the state-of-the-art methods on several cross-type FAS
benchmarks.",0,1,0,0,1,0,0.965384,8.0,0.950441,37
http://arxiv.org/abs/2109.01156v3,Challenges in Generalization in Open Domain Question Answering,33,0.395121,0.822075,"Recent work on Open Domain Question Answering has shown that there is a large
discrepancy in model performance between novel test questions and those that
largely overlap with training questions. However, it is unclear which aspects
of novel questions make them challenging. Drawing upon studies on systematic
generalization, we introduce and annotate questions according to three
categories that measure different levels and kinds of generalization: training
set overlap, compositional generalization (comp-gen), and novel-entity
generalization (novel-entity). When evaluating six popular parametric and
non-parametric models, we find that for the established Natural Questions and
TriviaQA datasets, even the strongest model performance for
comp-gen/novel-entity is 13.1/5.4% and 9.6/1.5% lower compared to that for the
full test set -- indicating the challenge posed by these types of questions.
Furthermore, we show that whilst non-parametric models can handle questions
containing novel entities relatively well, they struggle with those requiring
compositional generalization. Lastly, we find that key question difficulty
factors are: cascading errors from the retrieval component, frequency of
question pattern, and frequency of the entity.",0,0,0,0,0,0,0.962085,4.0,0.894021,75
http://arxiv.org/abs/2104.05216v1,Contextualized Knowledge-aware Attentive Neural Network: Enhancing Answer Selection with Knowledge,18,0.127224,0.309064,"Answer selection, which is involved in many natural language processing
applications such as dialog systems and question answering (QA), is an
important yet challenging task in practice, since conventional methods
typically suffer from the issues of ignoring diverse real-world background
knowledge. In this paper, we extensively investigate approaches to enhancing
the answer selection model with external knowledge from knowledge graph (KG).
First, we present a context-knowledge interaction learning framework,
Knowledge-aware Neural Network (KNN), which learns the QA sentence
representations by considering a tight interaction with the external knowledge
from KG and the textual information. Then, we develop two kinds of
knowledge-aware attention mechanism to summarize both the context-based and
knowledge-based interactions between questions and answers. To handle the
diversity and complexity of KG information, we further propose a Contextualized
Knowledge-aware Attentive Neural Network (CKANN), which improves the knowledge
representation learning with structure information via a customized Graph
Convolutional Network (GCN) and comprehensively learns context-based and
knowledge-based sentence representation via the multi-view knowledge-aware
attention mechanism. We evaluate our method on four widely-used benchmark QA
datasets, including WikiQA, TREC QA, InsuranceQA and Yahoo QA. Results verify
the benefits of incorporating external knowledge from KG, and show the robust
superiority and extensive applicability of our method.",1,1,0,0,0,1,0.269035,8.0,0.653782,71
http://arxiv.org/abs/2106.05303v1,Explaining Time Series Predictions with Dynamic Masks,52,0.248776,0.872865,"How can we explain the predictions of a machine learning model? When the data
is structured as a multivariate time series, this question induces additional
difficulties such as the necessity for the explanation to embody the time
dependency and the large number of inputs. To address these challenges, we
propose dynamic masks (Dynamask). This method produces instance-wise importance
scores for each feature at each time step by fitting a perturbation mask to the
input sequence. In order to incorporate the time dependency of the data,
Dynamask studies the effects of dynamic perturbation operators. In order to
tackle the large number of inputs, we propose a scheme to make the feature
selection parsimonious (to select no more feature than necessary) and legible
(a notion that we detail by making a parallel with information theory). With
synthetic and real-world data, we demonstrate that the dynamic underpinning of
Dynamask, together with its parsimony, offer a neat improvement in the
identification of feature importance over time. The modularity of Dynamask
makes it ideal as a plug-in to increase the transparency of a wide range of
machine learning models in areas such as medicine and finance, where time
series are abundant.",1,1,0,0,0,0,0.642157,7.0,0.773978,49
http://arxiv.org/abs/2111.07367v2,"""Will You Find These Shortcuts?"" A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification",56,0.0963523,0.778857,"Feature attribution a.k.a. input salience methods which assign an importance
score to a feature are abundant but may produce surprisingly different results
for the same model on the same input. While differences are expected if
disparate definitions of importance are assumed, most methods claim to provide
faithful attributions and point at the features most relevant for a model's
prediction. Existing work on faithfulness evaluation is not conclusive and does
not provide a clear answer as to how different methods are to be compared.
Focusing on text classification and the model debugging scenario, our main
contribution is a protocol for faithfulness evaluation that makes use of
partially synthetic data to obtain ground truth for feature importance ranking.
Following the protocol, we do an in-depth analysis of four standard salience
method classes on a range of datasets and shortcuts for BERT and LSTM models
and demonstrate that some of the most popular method configurations provide
poor results even for simplest shortcuts. We recommend following the protocol
for each new task and model combination to find the best method for identifying
shortcuts.",1,1,0,0,0,0,0.236487,5.0,0.416116,65
http://arxiv.org/abs/2102.07736v3,Network of Tensor Time Series,29,0.429117,0.594217,"Co-evolving time series appears in a multitude of applications such as
environmental monitoring, financial analysis, and smart transportation. This
paper aims to address the following challenges, including (C1) how to
incorporate explicit relationship networks of the time series; (C2) how to
model the implicit relationship of the temporal dynamics. We propose a novel
model called Network of Tensor Time Series, which is comprised of two modules,
including Tensor Graph Convolutional Network (TGCN) and Tensor Recurrent Neural
Network (TRNN). TGCN tackles the first challenge by generalizing Graph
Convolutional Network (GCN) for flat graphs to tensor graphs, which captures
the synergy between multiple graphs associated with the tensors. TRNN leverages
tensor decomposition to model the implicit relationships among co-evolving time
series. The experimental results on five real-world datasets demonstrate the
efficacy of the proposed method.",0,0,0,0,0,0,0.729399,9.0,0.850931,46
http://arxiv.org/abs/2105.09428v1,Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder,5,0.0847454,0.293505,"In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an
Artificial Intelligence (AI) Health Outcomes Challenge seeking solutions to
predict risk in value-based care for incorporation into CMS Innovation Center
payment and service delivery models. Recently, modern language models have
played key roles in a number of health related tasks. This paper presents, to
the best of our knowledge, the first application of these models to patient
readmission prediction. To facilitate this, we create a dataset of 1.2 million
medical history samples derived from the Limited Dataset (LDS) issued by CMS.
Moreover, we propose a comprehensive modeling solution centered on a deep
learning framework for this data. To demonstrate the framework, we train an
attention-based Transformer to learn Medicare semantics in support of
performing downstream prediction tasks thereby achieving 0.91 AUC and 0.91
recall on readmission classification. We also introduce a novel data
pre-processing pipeline and discuss pertinent deployment considerations
surrounding model explainability and bias.",0,1,0,1,0,0,0.648734,8.0,0.804467,55
http://arxiv.org/abs/2108.03489v1,Impact of Aliasing on Generalization in Deep Convolutional Networks,30,0.0208298,0.345426,"We investigate the impact of aliasing on generalization in Deep Convolutional
Networks and show that data augmentation schemes alone are unable to prevent it
due to structural limitations in widely used architectures. Drawing insights
from frequency analysis theory, we take a closer look at ResNet and
EfficientNet architectures and review the trade-off between aliasing and
information loss in each of their major components. We show how to mitigate
aliasing by inserting non-trainable low-pass filters at key locations,
particularly where networks lack the capacity to learn them. These simple
architectural changes lead to substantial improvements in generalization on
i.i.d. and even more on out-of-distribution conditions, such as image
classification under natural corruptions on ImageNet-C [11] and few-shot
learning on Meta-Dataset [26]. State-of-the art results are achieved on both
datasets without introducing additional trainable parameters and using the
default hyper-parameters of open source codebases.",0,0,0,0,1,0,0.316114,5.0,0.484577,32
http://arxiv.org/abs/2109.15196v2,Multilingual AMR Parsing with Noisy Knowledge Distillation,14,0.344511,0.533867,"We study multilingual AMR parsing from the perspective of knowledge
distillation, where the aim is to learn and improve a multilingual AMR parser
by using an existing English parser as its teacher. We constrain our
exploration in a strict multilingual setting: there is but one model to parse
all different languages including English. We identify that noisy input and
precise output are the key to successful distillation. Together with extensive
pre-training, we obtain an AMR parser whose performances surpass all previously
published results on four different foreign languages, including German,
Spanish, Italian, and Chinese, by large margins (up to 18.8 \textsc{Smatch}
points on Chinese and on average 11.3 \textsc{Smatch} points). Our parser also
achieves comparable performance on English to the latest state-of-the-art
English-only parser.",1,1,0,0,1,0,0.907503,6.0,0.876318,58
http://arxiv.org/abs/2109.12702v2,Extracting and Inferring Personal Attributes from Dialogue,12,0.707781,0.691635,"Personal attributes represent structured information about a person, such as
their hobbies, pets, family, likes and dislikes. We introduce the tasks of
extracting and inferring personal attributes from human-human dialogue, and
analyze the linguistic demands of these tasks. To meet these challenges, we
introduce a simple and extensible model that combines an autoregressive
language model utilizing constrained attribute generation with a discriminative
reranker. Our model outperforms strong baselines on extracting personal
attributes as well as inferring personal attributes that are not contained
verbatim in utterances and instead requires commonsense reasoning and lexical
inferences, which occur frequently in everyday conversation. Finally, we
demonstrate the benefit of incorporating personal attributes in social
chit-chat and task-oriented dialogue settings.",0,0,0,0,0,0,0.987781,5.0,0.974648,50
http://arxiv.org/abs/2112.04803v1,Combining Textual Features for the Detection of Hateful and Offensive Language,4,0.156351,0.463869,"The detection of offensive, hateful and profane language has become a
critical challenge since many users in social networks are exposed to
cyberbullying activities on a daily basis. In this paper, we present an
analysis of combining different textual features for the detection of hateful
or offensive posts on Twitter. We provide a detailed experimental evaluation to
understand the impact of each building block in a neural network architecture.
The proposed architecture is evaluated on the English Subtask 1A: Identifying
Hate, offensive and profane content from the post datasets of HASOC-2021
dataset under the team name TIB-VA. We compared different variants of the
contextual word embeddings combined with the character level embeddings and the
encoding of collected hate terms.",0,1,0,0,0,0,0.989734,5.0,0.982405,16
http://arxiv.org/abs/2110.09240v1,Value alignment: a formal approach,28,0.133303,0.333147,"principles that should govern autonomous AI systems. It essentially states
that a system's goals and behaviour should be aligned with human values. But
how to ensure value alignment? In this paper we first provide a formal model to
represent values through preferences and ways to compute value aggregations;
i.e. preferences with respect to a group of agents and/or preferences with
respect to sets of values. Value alignment is then defined, and computed, for a
given norm with respect to a given value through the increase/decrease that it
results in the preferences of future states of the world. We focus on norms as
it is norms that govern behaviour, and as such, the alignment of a given system
with a given value will be dictated by the norms the system follows.",0,0,0,0,0,0,0.00958951,11.0,0.431663,26
http://arxiv.org/abs/2106.04275v1,Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition,6,0.0540848,0.379932,"End-to-end speech recognition generally uses hand-engineered acoustic
features as input and excludes the feature extraction module from its joint
optimization. To extract learnable and adaptive features and mitigate
information loss, we propose a new encoder that adopts globally attentive
locally recurrent (GALR) networks and directly takes raw waveform as input. We
observe improved ASR performance and robustness by applying GALR on different
window lengths to aggregate fine-grain temporal information into multi-scale
acoustic features. Experiments are conducted on a benchmark dataset AISHELL-2
and two large-scale Mandarin speech corpus of 5,000 hours and 21,000 hours.
With faster speed and comparable model size, our proposed multi-scale GALR
waveform encoder achieved consistent character error rate reductions (CERRs)
from 7.9% to 28.1% relative over strong baselines, including Conformer and
TDNN-Conformer. In particular, our approach demonstrated notable robustness
than the traditional handcrafted features and outperformed the baseline
MFCC-based TDNN-Conformer model by a 15.2% CERR on a music-mixed real-world
speech test set.",0,1,0,0,1,0,0.469201,6.0,0.655644,37
http://arxiv.org/abs/2103.10195v1,Let-Mi: An Arabic Levantine Twitter Dataset for Misogynistic Language,35,0.413139,0.208831,"Online misogyny has become an increasing worry for Arab women who experience
gender-based online abuse on a daily basis. Misogyny automatic detection
systems can assist in the prohibition of anti-women Arabic toxic content.
Developing such systems is hindered by the lack of the Arabic misogyny
benchmark datasets. In this paper, we introduce an Arabic Levantine Twitter
dataset for Misogynistic language (LeT-Mi) to be the first benchmark dataset
for Arabic misogyny. We further provide a detailed review of the dataset
creation and annotation phases. The consistency of the annotations for the
proposed dataset was emphasized through inter-rater agreement evaluation
measures. Moreover, Let-Mi was used as an evaluation dataset through
binary/multi-/target classification tasks conducted by several state-of-the-art
machine learning systems along with Multi-Task Learning (MTL) configuration.
The obtained results indicated that the performances achieved by the used
systems are consistent with state-of-the-art results for languages other than
Arabic, while employing MTL improved the performance of the misogyny/target
classification tasks.",0,1,1,1,1,0,0.750257,6.0,0.786323,30
http://arxiv.org/abs/2106.03269v3,Itihasa: A large-scale corpus for Sanskrit to English translation,6,0.763959,0.657481,"This work introduces Itihasa, a large-scale translation dataset containing
93,000 pairs of Sanskrit shlokas and their English translations. The shlokas
are extracted from two Indian epics viz., The Ramayana and The Mahabharata. We
first describe the motivation behind the curation of such a dataset and follow
up with empirical analysis to bring out its nuances. We then benchmark the
performance of standard translation models on this corpus and show that even
state-of-the-art transformer architectures perform poorly, emphasizing the
complexity of the dataset.",0,1,0,1,0,0,0.971571,7.0,0.951488,32
http://arxiv.org/abs/2104.13579v1,Multi-view Inference for Relation Extraction with Uncertain Knowledge,16,0.114858,0.437226,"Knowledge graphs (KGs) are widely used to facilitate relation extraction (RE)
tasks. While most previous RE methods focus on leveraging deterministic KGs,
uncertain KGs, which assign a confidence score for each relation instance, can
provide prior probability distributions of relational facts as valuable
external knowledge for RE models. This paper proposes to exploit uncertain
knowledge to improve relation extraction. Specifically, we introduce ProBase,
an uncertain KG that indicates to what extent a target entity belongs to a
concept, into our RE architecture. We then design a novel multi-view inference
framework to systematically integrate local context and global knowledge across
three views: mention-, entity- and concept-view. The experimental results show
that our model achieves competitive performances on both sentence- and
document-level relation extraction, which verifies the effectiveness of
introducing uncertain knowledge and the multi-view inference framework that we
design.",0,1,0,0,0,0,0.387839,6.0,0.613127,38
http://arxiv.org/abs/2107.11904v1,Transferable Dialogue Systems and User Simulators,46,0.28083,0.795008,"One of the difficulties in training dialogue systems is the lack of training
data. We explore the possibility of creating dialogue data through the
interaction between a dialogue system and a user simulator. Our goal is to
develop a modelling framework that can incorporate new dialogue scenarios
through self-play between the two agents. In this framework, we first pre-train
the two agents on a collection of source domain dialogues, which equips the
agents to converse with each other via natural language. With further
fine-tuning on a small amount of target domain data, the agents continue to
interact with the aim of improving their behaviors using reinforcement learning
with structured reward functions. In experiments on the MultiWOZ dataset, two
practical transfer learning problems are investigated: 1) domain adaptation and
2) single-to-multiple domain transfer. We demonstrate that the proposed
framework is highly effective in bootstrapping the performance of the two
agents in transfer learning. We also show that our method leads to improvements
in dialogue system performance on complete datasets.",1,1,0,0,0,0,0.221236,8.0,0.625557,40
http://arxiv.org/abs/2107.06015v2,A Classification of Artificial Intelligence Systems for Mathematics Education,5,0.0423847,0.409714,"This chapter provides an overview of the different Artificial Intelligence
(AI) systems that are being used in contemporary digital tools for Mathematics
Education (ME). It is aimed at researchers in AI and Machine Learning (ML), for
whom we shed some light on the specific technologies that are being used in
educational applications; and at researchers in ME, for whom we clarify: i)
what the possibilities of the current AI technologies are, ii) what is still
out of reach and iii) what is to be expected in the near future. We start our
analysis by establishing a high-level taxonomy of AI tools that are found as
components in digital ME applications. Then, we describe in detail how these AI
tools, and in particular ML, are being used in two key applications,
specifically AI-based calculators and intelligent tutoring systems. We finish
the chapter with a discussion about student modeling systems and their
relationship to artificial general intelligence.",0,0,0,0,0,0,0.12217,9.0,0.59474,63
http://arxiv.org/abs/2109.01693v1,Weakly Supervised Few-Shot Segmentation Via Meta-Learning,14,0.137743,0.304054,"Semantic segmentation is a classic computer vision task with multiple
applications, which includes medical and remote sensing image analysis. Despite
recent advances with deep-based approaches, labeling samples (pixels) for
training models is laborious and, in some cases, unfeasible. In this paper, we
present two novel meta learning methods, named WeaSeL and ProtoSeg, for the
few-shot semantic segmentation task with sparse annotations. We conducted
extensive evaluation of the proposed methods in different applications (12
datasets) in medical imaging and agricultural remote sensing, which are very
distinct fields of knowledge and usually subject to data scarcity. The results
demonstrated the potential of our method, achieving suitable results for
segmenting both coffee/orange crops and anatomical parts of the human body in
comparison with full dense annotation.",0,0,0,0,0,0,0.398066,8.0,0.714064,49
http://arxiv.org/abs/2105.09114v1,Explainable Tsetlin Machine framework for fake news detection with credibility score assessment,26,0.379891,0.733563,"The proliferation of fake news, i.e., news intentionally spread for
misinformation, poses a threat to individuals and society. Despite various
fact-checking websites such as PolitiFact, robust detection techniques are
required to deal with the increase in fake news. Several deep learning models
show promising results for fake news classification, however, their black-box
nature makes it difficult to explain their classification decisions and
quality-assure the models. We here address this problem by proposing a novel
interpretable fake news detection framework based on the recently introduced
Tsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to
capture lexical and semantic properties of both true and fake news text.
Further, we use the clause ensembles to calculate the credibility of fake news.
For evaluation, we conduct experiments on two publicly available datasets,
PolitiFact and GossipCop, and demonstrate that the TM framework significantly
outperforms previously published baselines by at least $5\%$ in terms of
accuracy, with the added benefit of an interpretable logic-based
representation. Further, our approach provides higher F1-score than BERT and
XLNet, however, we obtain slightly lower accuracy. We finally present a case
study on our model's explainability, demonstrating how it decomposes into
meaningful words and their negations.",0,1,0,0,1,0,0.844763,8.0,0.876581,43
http://arxiv.org/abs/2108.11098v1,Monocular Depth Estimation Primed by Salient Point Detection and Normalized Hessian Loss,4,0.0562388,0.163283,"Deep neural networks have recently thrived on single image depth estimation.
That being said, current developments on this topic highlight an apparent
compromise between accuracy and network size. This work proposes an accurate
and lightweight framework for monocular depth estimation based on a
self-attention mechanism stemming from salient point detection. Specifically,
we utilize a sparse set of keypoints to train a FuSaNet model that consists of
two major components: Fusion-Net and Saliency-Net. In addition, we introduce a
normalized Hessian loss term invariant to scaling and shear along the depth
direction, which is shown to substantially improve the accuracy. The proposed
method achieves state-of-the-art results on NYU-Depth-v2 and KITTI while using
3.1-38.4 times smaller model in terms of the number of parameters than baseline
approaches. Experiments on the SUN-RGBD further demonstrate the
generalizability of the proposed method.",0,1,0,0,1,0,0.816798,7.0,0.845646,71
http://arxiv.org/abs/2103.07461v1,Probabilistic two-stage detection,190,0.155096,0.858083,"We develop a probabilistic interpretation of two-stage object detection. We
show that this probabilistic interpretation motivates a number of common
empirical training practices. It also suggests changes to two-stage detection
pipelines. Specifically, the first stage should infer proper
object-vs-background likelihoods, which should then inform the overall score of
the detector. A standard region proposal network (RPN) cannot infer this
likelihood sufficiently well, but many one-stage detectors can. We show how to
build a probabilistic two-stage detector from any state-of-the-art one-stage
detector. The resulting detectors are faster and more accurate than both their
one- and two-stage precursors. Our detector achieves 56.4 mAP on COCO test-dev
with single-scale testing, outperforming all published results. Using a
lightweight backbone, our detector achieves 49.2 mAP on COCO at 33 fps on a
Titan Xp, outperforming the popular YOLOv4 model.",1,1,0,0,1,0,0.634613,4.0,0.599334,66
http://arxiv.org/abs/2101.00178v2,UnitedQA: A Hybrid Approach for Open Domain Question Answering,46,0.503797,0.811296,"To date, most of recent work under the retrieval-reader framework for
open-domain QA focuses on either extractive or generative reader exclusively.
In this paper, we study a hybrid approach for leveraging the strengths of both
models. We apply novel techniques to enhance both extractive and generative
readers built upon recent pretrained neural language models, and find that
proper training methods can provide large improvement over previous
state-of-the-art models. We demonstrate that a simple hybrid approach by
combining answers from both readers can efficiently take advantages of
extractive and generative answer inference strategies and outperforms single
models as well as homogeneous ensembles. Our approach outperforms previous
state-of-the-art models by 3.3 and 2.7 points in exact match on
NaturalQuestions and TriviaQA respectively.",0,1,0,0,1,1,0.973507,3.0,0.893344,35
http://arxiv.org/abs/2108.07344v2,IsoScore: Measuring the Uniformity of Embedding Space Utilization,20,0.295946,0.665718,"The recent success of distributed word representations has led to an
increased interest in analyzing the properties of their spatial distribution.
Several studies have suggested that contextualized word embedding models do not
isotropically project tokens into vector space. However, current methods
designed to measure isotropy, such as average random cosine similarity and the
partition score, have not been thoroughly analyzed and are not appropriate for
measuring isotropy. We propose IsoScore: a novel tool that quantifies the
degree to which a point cloud uniformly utilizes the ambient vector space.
Using rigorously designed tests, we demonstrate that IsoScore is the only tool
available in the literature that accurately measures how uniformly distributed
variance is across dimensions in vector space. Additionally, we use IsoScore to
challenge a number of recent conclusions in the NLP literature that have been
derived using brittle metrics of isotropy. We caution future studies from using
existing tools to measure isotropy in contextualized embedding space as
resulting conclusions will be misleading or altogether inaccurate.",1,0,0,0,0,0,0.741451,5.0,0.738529,30
http://arxiv.org/abs/2103.05683v1,Combining Context-Free and Contextualized Representations for Arabic Sarcasm Detection and Sentiment Identification,11,0.311969,0.616705,"Since their inception, transformer-based language models have led to
impressive performance gains across multiple natural language processing tasks.
For Arabic, the current state-of-the-art results on most datasets are achieved
by the AraBERT language model. Notwithstanding these recent advancements,
sarcasm and sentiment detection persist to be challenging tasks in Arabic,
given the language's rich morphology, linguistic disparity and dialectal
variations. This paper proffers team SPPU-AASM's submission for the WANLP
ArSarcasm shared-task 2021, which centers around the sarcasm and sentiment
polarity detection of Arabic tweets. The study proposes a hybrid model,
combining sentence representations from AraBERT with static word vectors
trained on Arabic social media corpora. The proposed system achieves a
F1-sarcastic score of 0.62 and a F-PN score of 0.715 for the sarcasm and
sentiment detection tasks, respectively. Simulation results show that the
proposed system outperforms multiple existing approaches for both the tasks,
suggesting that the amalgamation of context-free and context-dependent text
representations can help capture complementary facets of word meaning in
Arabic. The system ranked second and tenth in the respective sub-tasks of
sarcasm detection and sentiment identification.",1,1,0,0,0,0,0.953585,6.0,0.918713,31
http://arxiv.org/abs/2105.06136v1,Adaptive Warm-Start MCTS in AlphaZero-like Deep Reinforcement Learning,7,0.0166489,0.131903,"AlphaZero has achieved impressive performance in deep reinforcement learning
by utilizing an architecture that combines search and training of a neural
network in self-play. Many researchers are looking for ways to reproduce and
improve results for other games/tasks. However, the architecture is designed to
learn from scratch, tabula rasa, accepting a cold-start problem in self-play.
Recently, a warm-start enhancement method for Monte Carlo Tree Search was
proposed to improve the self-play starting phase. It employs a fixed parameter
$I^\prime$ to control the warm-start length. Improved performance was reported
in small board games. In this paper we present results with an adaptive switch
method. Experiments show that our approach works better than the fixed
$I^\prime$, especially for ""deep,"" tactical, games (Othello and Connect Four).
We conjecture that the adaptive value for $I^\prime$ is also influenced by the
size of the game, and that on average $I^\prime$ will increase with game size.
We conclude that AlphaZero-like deep reinforcement learning benefits from
adaptive rollout based warm-start, as Rapid Action Value Estimate did for
rollout-based reinforcement learning 15 years ago.",0,1,0,0,0,0,0.0321029,11.0,0.542548,34
http://arxiv.org/abs/2110.07986v2,On Generating Identifiable Virtual Faces,10,0.0950785,0.260693,"Face anonymization with generative models have become increasingly prevalent
since they sanitize private information by generating virtual face images,
ensuring both privacy and image utility. Such virtual face images are usually
not identifiable after the removal or protection of the original identity. In
this paper, we formalize and tackle the problem of generating identifiable
virtual face images. Our virtual face images are visually different from the
original ones for privacy protection. In addition, they are bound with new
virtual identities, which can be directly used for face recognition. We propose
an Identifiable Virtual Face Generator (IVFG) to generate the virtual face
images. The IVFG projects the latent vectors of the original face images into
virtual ones according to a user specific key, based on which the virtual face
images are generated. To make the virtual face images identifiable, we propose
a multi-task learning objective as well as a triplet styled training strategy
to learn the IVFG. We evaluate the performance of our virtual face images using
different face recognizers on diffident face image datasets, all of which
demonstrate the effectiveness of the IVFG for generate identifiable virtual
face images.",0,1,0,0,0,0,0.618966,9.0,0.8172,35
http://arxiv.org/abs/2109.12912v2,A User-Centred Framework for Explainable Artificial Intelligence in Human-Robot Interaction,10,0.058985,0.328579,"State of the art Artificial Intelligence (AI) techniques have reached an
impressive complexity. Consequently, researchers are discovering more and more
methods to use them in real-world applications. However, the complexity of such
systems requires the introduction of methods that make those transparent to the
human user. The AI community is trying to overcome the problem by introducing
the Explainable AI (XAI) field, which is tentative to make AI algorithms less
opaque. However, in recent years, it became clearer that XAI is much more than
a computer science problem: since it is about communication, XAI is also a
Human-Agent Interaction problem. Moreover, AI came out of the laboratories to
be used in real life. This implies the need for XAI solutions tailored to
non-expert users. Hence, we propose a user-centred framework for XAI that
focuses on its social-interactive aspect taking inspiration from cognitive and
social sciences' theories and findings. The framework aims to provide a
structure for interactive XAI solutions thought for non-expert users.",0,0,0,0,0,0,0.235408,10.0,0.707533,37
http://arxiv.org/abs/2106.15510v2,Fast and Accurate Road Crack Detection Based on Adaptive Cost-Sensitive Loss Function,31,0.610898,0.840711,"Numerous detection problems in computer vision, including road crack
detection, suffer from exceedingly foreground-background imbalance.
Fortunately, modification of loss function appears to solve this puzzle once
and for all. In this paper, we propose a pixel-based adaptive weighted
cross-entropy loss in conjunction with Jaccard distance to facilitate
high-quality pixel-level road crack detection. Our work profoundly demonstrates
the influence of loss functions on detection outcomes, and sheds light on the
sophisticated consecutive improvements in the realm of crack detection.
Specifically, to verify the effectiveness of the proposed loss, we conduct
extensive experiments on four public databases, i.e., CrackForest, AigleRN,
Crack360, and BJN260. Compared with the vanilla weighted cross-entropy, the
proposed loss significantly speeds up the training process while retaining the
test accuracy.",1,1,0,1,0,0,0.863328,9.0,0.897642,70
http://arxiv.org/abs/2109.06987v1,NOPE: A Corpus of Naturally-Occurring Presuppositions in English,18,0.266517,0.13758,"Understanding language requires grasping not only the overtly stated content,
but also making inferences about things that were left unsaid. These inferences
include presuppositions, a phenomenon by which a listener learns about new
information through reasoning about what a speaker takes as given.
Presuppositions require complex understanding of the lexical and syntactic
properties that trigger them as well as the broader conversational context. In
this work, we introduce the Naturally-Occurring Presuppositions in English
(NOPE) Corpus to investigate the context-sensitivity of 10 different types of
presupposition triggers and to evaluate machine learning models' ability to
predict human inferences. We find that most of the triggers we investigate
exhibit moderate variability. We further find that transformer-based models
draw correct inferences in simple cases involving presuppositions, but they
fail to capture the minority of exceptional cases in which human judgments
reveal complex interactions between context and triggers.",1,0,0,1,0,0,0.690554,7.0,0.792872,71
http://arxiv.org/abs/2104.08727v2,GooAQ: Open Question Answering with Diverse Answer Types,38,0.0635626,0.484032,"While day-to-day questions come with a variety of answer types, the current
question-answering (QA) literature has failed to adequately address the answer
diversity of questions. To this end, we present GooAQ, a large-scale dataset
with a variety of answer types. This dataset contains over 5 million questions
and 3 million answers collected from Google. GooAQ questions are collected
semi-automatically from the Google search engine using its autocomplete
feature. This results in naturalistic questions of practical interest that are
nonetheless short and expressed using simple language. GooAQ answers are mined
from Google's responses to our collected questions, specifically from the
answer boxes in the search results. This yields a rich space of answer types,
containing both textual answers (short and long) as well as more structured
ones such as collections. We benchmarkT5 models on GooAQ and observe that: (a)
in line with recent work, LM's strong performance on GooAQ's short-answer
questions heavily benefit from annotated data; however, (b) their quality in
generating coherent and accurate responses for questions requiring long
responses (such as 'how' and 'why' questions) is less reliant on observing
annotated data and mainly supported by their pre-training. We release GooAQ to
facilitate further research on improving QA with diverse response types.",0,1,1,1,0,0,0.570457,4.0,0.555546,24
http://arxiv.org/abs/2107.08685v1,Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images,17,0.409637,0.722077,"In multi-modal dialogue systems, it is important to allow the use of images
as part of a multi-turn conversation. Training such dialogue systems generally
requires a large-scale dataset consisting of multi-turn dialogues that involve
images, but such datasets rarely exist. In response, this paper proposes a 45k
multi-modal dialogue dataset created with minimal human intervention. Our
method to create such a dataset consists of (1) preparing and pre-processing
text dialogue datasets, (2) creating image-mixed dialogues by using a
text-to-image replacement technique, and (3) employing a
contextual-similarity-based filtering step to ensure the contextual coherence
of the dataset. To evaluate the validity of our dataset, we devise a simple
retrieval model for dialogue sentence prediction tasks. Automatic metrics and
human evaluation results on such tasks show that our dataset can be effectively
used as training data for multi-modal dialogue systems which require an
understanding of images and text in a context-aware manner. Our dataset and
generation code is available at
https://github.com/shh1574/multi-modal-dialogue-dataset.",0,1,0,1,0,0,0.987615,6.0,0.978362,18
http://arxiv.org/abs/2109.03857v1,Robust Optimal Classification Trees Against Adversarial Examples,18,0.07215,0.62594,"Decision trees are a popular choice of explainable model, but just like
neural networks, they suffer from adversarial examples. Existing algorithms for
fitting decision trees robust against adversarial examples are greedy
heuristics and lack approximation guarantees. In this paper we propose ROCT, a
collection of methods to train decision trees that are optimally robust against
user-specified attack models. We show that the min-max optimization problem
that arises in adversarial learning can be solved using a single minimization
formulation for decision trees with 0-1 loss. We propose such formulations in
Mixed-Integer Linear Programming and Maximum Satisfiability, which widely
available solvers can optimize. We also present a method that determines the
upper bound on adversarial accuracy for any model using bipartite matching. Our
experimental results demonstrate that the existing heuristics achieve close to
optimal scores while ROCT achieves state-of-the-art scores.",0,0,0,0,1,0,0.114815,7.0,0.469498,32
http://arxiv.org/abs/2108.07555v1,Revisiting State Augmentation methods for Reinforcement Learning with Stochastic Delays,15,0.0220032,0.209586,"Several real-world scenarios, such as remote control and sensing, are
comprised of action and observation delays. The presence of delays degrades the
performance of reinforcement learning (RL) algorithms, often to such an extent
that algorithms fail to learn anything substantial. This paper formally
describes the notion of Markov Decision Processes (MDPs) with stochastic delays
and shows that delayed MDPs can be transformed into equivalent standard MDPs
(without delays) with significantly simplified cost structure. We employ this
equivalence to derive a model-free Delay-Resolved RL framework and show that
even a simple RL algorithm built upon this framework achieves near-optimal
rewards in environments with stochastic delays in actions and observations. The
delay-resolved deep Q-network (DRDQN) algorithm is bench-marked on a variety of
environments comprising of multi-step and stochastic delays and results in
better performance, both in terms of achieving near-optimal rewards and
minimizing the computational overhead thereof, with respect to the currently
established algorithms.",0,1,0,0,0,0,3.60908e-07,22.0,0.252542,37
http://arxiv.org/abs/2103.14443v1,Incorporating Connections Beyond Knowledge Embeddings: A Plug-and-Play Module to Enhance Commonsense Reasoning in Machine Reading Comprehension,2,0.0249588,0.0520306,"Conventional Machine Reading Comprehension (MRC) has been well-addressed by
pattern matching, but the ability of commonsense reasoning remains a gap
between humans and machines. Previous methods tackle this problem by enriching
word representations via pre-trained Knowledge Graph Embeddings (KGE). However,
they make limited use of a large number of connections between nodes in
Knowledge Graphs (KG), which could be pivotal cues to build the commonsense
reasoning chains. In this paper, we propose a Plug-and-play module to
IncorporatE Connection information for commonsEnse Reasoning (PIECER). Beyond
enriching word representations with knowledge embeddings, PIECER constructs a
joint query-passage graph to explicitly guide commonsense reasoning by the
knowledge-oriented connections between words. Further, PIECER has high
generalizability since it can be plugged into suitable positions in any MRC
model. Experimental results on ReCoRD, a large-scale public MRC dataset
requiring commonsense reasoning, show that PIECER introduces stable performance
improvements for four representative base MRC models, especially in
low-resource settings.",0,1,0,0,0,0,0.940277,7.0,0.918087,45
http://arxiv.org/abs/2110.08470v3,Case-based Reasoning for Better Generalization in Textual Reinforcement Learning,8,0.210199,0.11679,"Text-based games (TBG) have emerged as promising environments for driving
research in grounded language understanding and studying problems like
generalization and sample efficiency. Several deep reinforcement learning (RL)
methods with varying architectures and learning schemes have been proposed for
TBGs. However, these methods fail to generalize efficiently, especially under
distributional shifts. In a departure from deep RL approaches, in this paper,
we propose a general method inspired by case-based reasoning to train agents
and generalize out of the training distribution. The case-based reasoner
collects instances of positive experiences from the agent's interaction with
the world in the past and later reuses the collected experiences to act
efficiently. The method can be applied in conjunction with any existing
on-policy neural agent in the literature for TBGs. Our experiments show that
the proposed approach consistently improves existing methods, obtains good
out-of-distribution generalization, and achieves new state-of-the-art results
on widely used environments.",0,1,0,0,1,0,0.720894,6.0,0.772404,45
http://arxiv.org/abs/2109.11635v1,Revisiting the Uniform Information Density Hypothesis,52,0.142231,0.892424,"The uniform information density (UID) hypothesis posits a preference among
language users for utterances structured such that information is distributed
uniformly across a signal. While its implications on language production have
been well explored, the hypothesis potentially makes predictions about language
comprehension and linguistic acceptability as well. Further, it is unclear how
uniformity in a linguistic signal -- or lack thereof -- should be measured, and
over which linguistic unit, e.g., the sentence or language level, this
uniformity should hold. Here we investigate these facets of the UID hypothesis
using reading time and acceptability data. While our reading time results are
generally consistent with previous work, they are also consistent with a weakly
super-linear effect of surprisal, which would be compatible with UID's
predictions. For acceptability judgments, we find clearer evidence that
non-uniformity in information density is predictive of lower acceptability. We
then explore multiple operationalizations of UID, motivated by different
interpretations of the original hypothesis, and analyze the scope over which
the pressure towards uniformity is exerted. The explanatory power of a subset
of the proposed operationalizations suggests that the strongest trend may be a
regression towards a mean surprisal across the language, rather than the
phrase, sentence, or document -- a finding that supports a typical
interpretation of UID, namely that it is the byproduct of language users
maximizing the use of a (hypothetical) communication channel.",0,0,0,0,0,0,0.00250882,14.0,0.45742,60
http://arxiv.org/abs/2101.04772v1,DuctTake: Spatiotemporal Video Compositing,25,0.437819,0.18854,"DuctTake is a system designed to enable practical compositing of multiple
takes of a scene into a single video. Current industry solutions are based
around object segmentation, a hard problem that requires extensive manual input
and cleanup, making compositing an expensive part of the film-making process.
Our method instead composites shots together by finding optimal spatiotemporal
seams using motion-compensated 3D graph cuts through the video volume. We
describe in detail the required components, decisions, and new techniques that
together make a usable, interactive tool for compositing HD video, paying
special attention to running time and performance of each section. We validate
our approach by presenting a wide variety of examples and by comparing result
quality and creation time to composites made by professional artists using
current state-of-the-art tools.",0,1,0,0,1,0,0.270032,16.0,0.827163,32
http://arxiv.org/abs/2109.05003v1,Distantly-Supervised Named Entity Recognition with Noise-Robust Learning and Language Model Augmented Self-Training,56,0.298745,0.98594,"We study the problem of training named entity recognition (NER) models using
only distantly-labeled data, which can be automatically obtained by matching
entity mentions in the raw text with entity types in a knowledge base. The
biggest challenge of distantly-supervised NER is that the distant supervision
may induce incomplete and noisy labels, rendering the straightforward
application of supervised learning ineffective. In this paper, we propose (1) a
noise-robust learning scheme comprised of a new loss function and a noisy label
removal step, for training NER models on distantly-labeled data, and (2) a
self-training method that uses contextualized augmentations created by
pre-trained language models to improve the generalization ability of the NER
model. On three benchmark datasets, our method achieves superior performance,
outperforming existing distantly-supervised NER models by significant margins.",1,1,0,0,1,1,0.551274,7.0,0.738442,51
http://arxiv.org/abs/2104.00059v2,Passive Inter-Photon Imaging,26,0.204451,0.754378,"Digital camera pixels measure image intensities by converting incident light
energy into an analog electrical current, and then digitizing it into a
fixed-width binary representation. This direct measurement method, while
conceptually simple, suffers from limited dynamic range and poor performance
under extreme illumination -- electronic noise dominates under low
illumination, and pixel full-well capacity results in saturation under bright
illumination. We propose a novel intensity cue based on measuring inter-photon
timing, defined as the time delay between detection of successive photons.
Based on the statistics of inter-photon times measured by a time-resolved
single-photon sensor, we develop theory and algorithms for a scene brightness
estimator which works over extreme dynamic range; we experimentally demonstrate
imaging scenes with a dynamic range of over ten million to one. The proposed
techniques, aided by the emergence of single-photon sensors such as
single-photon avalanche diodes (SPADs) with picosecond timing resolution, will
have implications for a wide range of imaging applications: robotics, consumer
photography, astronomy, microscopy and biomedical imaging.",0,0,1,0,0,0,0.292682,7.0,0.618577,58
http://arxiv.org/abs/2102.07943v1,Structured Graph Learning for Scalable Subspace Clustering: From Single-view to Multi-view,150,0.714005,0.994702,"Graph-based subspace clustering methods have exhibited promising performance.
However, they still suffer some of these drawbacks: encounter the expensive
time overhead, fail in exploring the explicit clusters, and cannot generalize
to unseen data points. In this work, we propose a scalable graph learning
framework, seeking to address the above three challenges simultaneously.
Specifically, it is based on the ideas of anchor points and bipartite graph.
Rather than building a $n\times n$ graph, where $n$ is the number of samples,
we construct a bipartite graph to depict the relationship between samples and
anchor points. Meanwhile, a connectivity constraint is employed to ensure that
the connected components indicate clusters directly. We further establish the
connection between our method and the K-means clustering. Moreover, a model to
process multi-view data is also proposed, which is linear scaled with respect
to $n$. Extensive experiments demonstrate the efficiency and effectiveness of
our approach with respect to many state-of-the-art clustering methods.",0,1,0,0,1,0,0.432532,6.0,0.637068,73
http://arxiv.org/abs/2104.01193v1,Learning Description Logic Ontologies. Five Approaches. Where Do They Stand?,29,0.308652,0.169208,"The quest for acquiring a formal representation of the knowledge of a domain
of interest has attracted researchers with various backgrounds into a diverse
field called ontology learning. We highlight classical machine learning and
data mining approaches that have been proposed for (semi-)automating the
creation of description logic (DL) ontologies. These are based on association
rule mining, formal concept analysis, inductive logic programming,
computational learning theory, and neural networks. We provide an overview of
each approach and how it has been adapted for dealing with DL ontologies.
Finally, we discuss the benefits and limitations of each of them for learning
DL ontologies.",0,0,0,0,0,0,0.00619601,16.0,0.581864,54
http://arxiv.org/abs/2106.04678v1,Incentivizing Efficient Equilibria in Traffic Networks with Mixed Autonomy,14,0.0265035,0.320791,"Traffic congestion has large economic and social costs. The introduction of
autonomous vehicles can potentially reduce this congestion by increasing road
capacity via vehicle platooning and by creating an avenue for influencing
people's choice of routes. We consider a network of parallel roads with two
modes of transportation: (i) human drivers, who will choose the quickest route
available to them, and (ii) a ride hailing service, which provides an array of
autonomous vehicle route options, each with different prices, to users. We
formalize a model of vehicle flow in mixed autonomy and a model of how
autonomous service users make choices between routes with different prices and
latencies. Developing an algorithm to learn the preferences of the users, we
formulate a planning optimization that chooses prices to maximize a social
objective. We demonstrate the benefit of the proposed scheme by comparing the
results to theoretical benchmarks which we show can be efficiently calculated.",0,0,0,0,0,0,0.000128073,18.0,0.412651,47
http://arxiv.org/abs/2106.02228v1,Addressing Inquiries about History: An Efficient and Practical Framework for Evaluating Open-domain Chatbot Consistency,13,0.406658,0.472708,"A good open-domain chatbot should avoid presenting contradictory responses
about facts or opinions in a conversational session, known as its consistency
capacity. However, evaluating the consistency capacity of a chatbot is still
challenging. Employing human judges to interact with chatbots on purpose to
check their capacities is costly and low-efficient, and difficult to get rid of
subjective bias. In this paper, we propose the Addressing Inquiries about
History (AIH), an efficient and practical framework for the consistency
evaluation. At the conversation stage, AIH attempts to address appropriate
inquiries about the dialogue history to induce the chatbot to redeclare the
historical facts or opinions. We carry out the conversation between chatbots,
which is more efficient than the human-bot interaction and can also alleviate
the subjective bias. In this way, we manage to rapidly obtain a dialog session
that contains responses with high contradiction possibilities. At the
contradiction recognition stage, we can either employ human judges or a natural
language inference (NLI) model to recognize whether the answers to the
inquiries are contradictory with history. Finally, we are able to rank chatbots
according to the contradiction statistics. Experiments on open-domain chatbots
show that our approach can efficiently and reliably assess the consistency
capacity of chatbots and achieve a high ranking correlation with the human
evaluation. We release the framework and hope to help improve the consistency
capacity of chatbots. \footnote{\url{https://github.com/ictnlp/AIH}}",0,1,0,0,0,1,0.976444,4.0,0.927971,31
http://arxiv.org/abs/2105.11696v1,Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation,21,0.480606,0.650246,"For a computer to naturally interact with a human, it needs to be human-like.
In this paper, we propose a neural response generation model with multi-task
learning of generation and classification, focusing on emotion. Our model based
on BART (Lewis et al., 2020), a pre-trained transformer encoder-decoder model,
is trained to generate responses and recognize emotions simultaneously.
Furthermore, we weight the losses for the tasks to control the update of
parameters. Automatic evaluations and crowdsourced manual evaluations show that
the proposed model makes generated responses more emotionally aware.",0,1,0,0,0,0,0.941943,6.0,0.906099,23
http://arxiv.org/abs/2109.12258v2,Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features,61,0.848266,0.843601,"We report two essential improvements in readability assessment: 1. three
novel features in advanced semantics and 2. the timely evidence that
traditional ML models (e.g. Random Forest, using handcrafted features) can
combine with transformers (e.g. RoBERTa) to augment model performance. First,
we explore suitable transformers and traditional ML models. Then, we extract
255 handcrafted linguistic features using self-developed extraction software.
Finally, we assemble those to create several hybrid models, achieving
state-of-the-art (SOTA) accuracy on popular datasets in readability assessment.
The use of handcrafted features help model performance on smaller datasets.
Notably, our RoBERTA-RF-T1 hybrid achieves the near-perfect classification
accuracy of 99%, a 20.3% increase from the previous SOTA.",1,1,0,0,1,0,0.185357,17.0,0.812109,107
http://arxiv.org/abs/2102.02723v1,Data-to-text Generation with Macro Planning,65,0.333476,0.904312,"Recent approaches to data-to-text generation have adopted the very successful
encoder-decoder architecture or variants thereof. These models generate text
which is fluent (but often imprecise) and perform quite poorly at selecting
appropriate content and ordering it coherently. To overcome some of these
issues, we propose a neural model with a macro planning stage followed by a
generation stage reminiscent of traditional methods which embrace separate
modules for planning and surface realization. Macro plans represent high level
organization of important content such as entities, events and their
interactions; they are learnt from data and given as input to the generator.
Extensive experiments on two data-to-text benchmarks (RotoWire and MLB) show
that our approach outperforms competitive baselines in terms of automatic and
human evaluation.",1,1,0,0,1,0,0.215881,10.0,0.697667,73
http://arxiv.org/abs/2110.06829v2,Towards a fully RL-based Market Simulator,14,0.37294,0.68154,"We present a new financial framework where two families of RL-based agents
representing the Liquidity Providers and Liquidity Takers learn simultaneously
to satisfy their objective. Thanks to a parametrized reward formulation and the
use of Deep RL, each group learns a shared policy able to generalize and
interpolate over a wide range of behaviors. This is a step towards a fully
RL-based market simulator replicating complex market conditions particularly
suited to study the dynamics of the financial market under various scenarios.",0,0,0,0,0,0,0.0936611,14.0,0.719376,21
http://arxiv.org/abs/2106.06588v1,Visualization Techniques to Enhance Automated Event Extraction,2,0.0204312,0.0947975,"Robust visualization of complex data is critical for the effective use of NLP
for event classification, as the volume of data is large and the
high-dimensional structure of text makes data challenging to summarize
succinctly. In event extraction tasks in particular, visualization can aid in
understanding and illustrating the textual relationships from which machine
learning tools produce insights. Through our case study which seeks to identify
potential triggers of state-led mass killings from news articles using NLP, we
demonstrate how visualizations can aid in each stage, from exploratory analysis
of raw data, to machine learning training analysis, and finally post-inference
validation.",1,1,0,0,0,0,0.0841414,10.0,0.595893,20
http://arxiv.org/abs/2105.14683v1,Know Your Surroundings: Panoramic Multi-Object Tracking by Multimodality Collaboration,9,0.0721905,0.187915,"In this paper, we focus on the multi-object tracking (MOT) problem of
automatic driving and robot navigation. Most existing MOT methods track
multiple objects using a singular RGB camera, which are prone to camera
field-of-view and suffer tracking failures in complex scenarios due to
background clutters and poor light conditions. To meet these challenges, we
propose a MultiModality PAnoramic multi-object Tracking framework (MMPAT),
which takes both 2D panorama images and 3D point clouds as input and then
infers target trajectories using the multimodality data. The proposed method
contains four major modules, a panorama image detection module, a multimodality
data fusion module, a data association module and a trajectory inference model.
We evaluate the proposed method on the JRDB dataset, where the MMPAT achieves
the top performance in both the detection and tracking tasks and significantly
outperforms state-of-the-art methods by a large margin (15.7 and 8.5
improvement in terms of AP and MOTA, respectively).",0,1,0,0,1,0,0.801238,7.0,0.838614,93
http://arxiv.org/abs/2106.00250v3,ViTA: Visual-Linguistic Translation by Aligning Object Tags,12,0.0944249,0.347626,"Multimodal Machine Translation (MMT) enriches the source text with visual
information for translation. It has gained popularity in recent years, and
several pipelines have been proposed in the same direction. Yet, the task lacks
quality datasets to illustrate the contribution of visual modality in the
translation systems. In this paper, we propose our system under the team name
Volta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We
also participate in the textual-only subtask of the same language pair for
which we use mBART, a pretrained multilingual sequence-to-sequence model. For
multimodal translation, we propose to enhance the textual input by bringing the
visual information to a textual domain by extracting object tags from the
image. We also explore the robustness of our system by systematically degrading
the source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test
set and challenge set of the multimodal task.",1,1,0,0,0,0,0.415957,9.0,0.752251,31
http://arxiv.org/abs/2110.08190v4,Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm,25,0.224977,0.452915,"Conventional wisdom in pruning Transformer-based language models is that
pruning reduces the model expressiveness and thus is more likely to underfit
rather than overfit. However, under the trending pretrain-and-finetune
paradigm, we postulate a counter-traditional hypothesis, that is: pruning
increases the risk of overfitting when performed at the fine-tuning phase. In
this paper, we aim to address the overfitting problem and improve pruning
performance via progressive knowledge distillation with error-bound properties.
We show for the first time that reducing the risk of overfitting can help the
effectiveness of pruning under the pretrain-and-finetune paradigm. Ablation
studies and experiments on the GLUE benchmark show that our method outperforms
the leading competitors across different tasks.",0,1,0,0,1,0,0.788372,4.0,0.707676,47
http://arxiv.org/abs/2109.10557v1,A Reinforcement Learning Benchmark for Autonomous Driving in Intersection Scenarios,8,0.038833,0.187528,"In recent years, control under urban intersection scenarios becomes an
emerging research topic. In such scenarios, the autonomous vehicle confronts
complicated situations since it must deal with the interaction with social
vehicles timely while obeying the traffic rules. Generally, the autonomous
vehicle is supposed to avoid collisions while pursuing better efficiency. The
existing work fails to provide a framework that emphasizes the integrity of the
scenarios while being able to deploy and test reinforcement learning(RL)
methods. Specifically, we propose a benchmark for training and testing RL-based
autonomous driving agents in complex intersection scenarios, which is called
RL-CIS. Then, a set of baselines are deployed consists of various algorithms.
The test benchmark and baselines are to provide a fair and comprehensive
training and testing platform for the study of RL for autonomous driving in the
intersection scenario, advancing the progress of RL-based methods for
intersection autonomous driving control. The code of our proposed framework can
be found at https://github.com/liuyuqi123/ComplexUrbanScenarios.",1,1,0,0,0,0,0.205124,6.0,0.486502,23
http://arxiv.org/abs/2110.06628v1,Oriented Feature Alignment for Fine-grained Object Recognition in High-Resolution Satellite Imagery,7,0.0472551,0.323998,"Oriented object detection in remote sensing images has made great progress in
recent years. However, most of the current methods only focus on detecting
targets, and cannot distinguish fine-grained objects well in complex scenes. In
this technical report, we analyzed the key issues of fine-grained object
recognition, and use an oriented feature alignment network (OFA-Net) to achieve
high-performance fine-grained oriented object recognition in optical remote
sensing images. OFA-Net achieves accurate object localization through a rotated
bounding boxes refinement module. On this basis, the boundary-constrained
rotation feature alignment module is applied to achieve local feature
extraction, which is beneficial to fine-grained object classification. The
single model of our method achieved mAP of 46.51\% in the GaoFen competition
and won 3rd place in the ISPRS benchmark with the mAP of 43.73\%.",1,1,0,0,0,0,0.951915,3.0,0.833567,15
http://arxiv.org/abs/2104.10791v1,Extracting Adverse Drug Events from Clinical Notes,21,0.279425,0.259112,"Adverse drug events (ADEs) are unexpected incidents caused by the
administration of a drug or medication. To identify and extract these events,
we require information about not just the drug itself but attributes describing
the drug (e.g., strength, dosage), the reason why the drug was initially
prescribed, and any adverse reaction to the drug. This paper explores the
relationship between a drug and its associated attributes using relation
extraction techniques. We explore three approaches: a rule-based approach, a
deep learning-based approach, and a contextualized language model-based
approach. We evaluate our system on the n2c2-2018 ADE extraction dataset. Our
experimental results demonstrate that the contextualized language model-based
approach outperformed other models overall and obtain the state-of-the-art
performance in ADE extraction with a Precision of 0.93, Recall of 0.96, and an
$F_1$ score of 0.94; however, for certain relation types, the rule-based
approach obtained a higher Precision and Recall than either learning approach.",0,1,0,0,1,0,0.480108,8.0,0.745765,24
http://arxiv.org/abs/2102.02531v1,ABCNet: Attentive Bilateral Contextual Network for Efficient Semantic Segmentation of Fine-Resolution Remote Sensing Images,116,0.203342,0.742538,"Semantic segmentation of remotely sensed images plays a crucial role in
precision agriculture, environmental protection, and economic assessment. In
recent years, substantial fine-resolution remote sensing images are available
for semantic segmentation. However, due to the complicated information caused
by the increased spatial resolution, state-of-the-art deep learning algorithms
normally utilize complex network architectures for segmentation, which usually
incurs high computational complexity. Specifically, the high-caliber
performance of the convolutional neural network (CNN) heavily relies on
fine-grained spatial details (fine resolution) and sufficient contextual
information (large receptive fields), both of which trigger high computational
costs. This crucially impedes their practicability and availability in
real-world scenarios that require real-time processing. In this paper, we
propose an Attentive Bilateral Contextual Network (ABCNet), a convolutional
neural network (CNN) with double branches, with prominently lower computational
consumptions compared to the cutting-edge algorithms, while maintaining a
competitive accuracy. Code is available at https://github.com/lironui/ABCNet.",1,1,0,0,0,0,0.509079,5.0,0.610029,85
http://arxiv.org/abs/2108.07524v1,Neural Photofit: Gaze-based Mental Image Reconstruction,8,0.127971,0.62977,"We propose a novel method that leverages human fixations to visually decode
the image a person has in mind into a photofit (facial composite). Our method
combines three neural networks: An encoder, a scoring network, and a decoder.
The encoder extracts image features and predicts a neural activation map for
each face looked at by a human observer. A neural scoring network compares the
human and neural attention and predicts a relevance score for each extracted
image feature. Finally, image features are aggregated into a single feature
vector as a linear combination of all features weighted by relevance which a
decoder decodes into the final photofit. We train the neural scoring network on
a novel dataset containing gaze data of 19 participants looking at collages of
synthetic faces. We show that our method significantly outperforms a mean
baseline predictor and report on a human study that shows that we can decode
photofits that are visually plausible and close to the observer's mental image.",1,0,0,1,0,0,0.0950538,11.0,0.644252,42
http://arxiv.org/abs/2105.01305v1,Large-scale Taxonomy Induction Using Entity and Word Embeddings,23,0.0521372,0.235691,"Taxonomies are an important ingredient of knowledge organization, and serve
as a backbone for more sophisticated knowledge representations in intelligent
systems, such as formal ontologies. However, building taxonomies manually is a
costly endeavor, and hence, automatic methods for taxonomy induction are a good
alternative to build large-scale taxonomies. In this paper, we propose TIEmb,
an approach for automatic unsupervised class subsumption axiom extraction from
knowledge bases using entity and text embeddings. We apply the approach on the
WebIsA database, a database of subsumption relations extracted from the large
portion of the World Wide Web, to extract class hierarchies in the Person and
Place domain.",0,0,0,0,0,0,0.283662,7.0,0.613251,33
http://arxiv.org/abs/2111.02086v1,Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task,41,0.505071,0.852894,"This report describes Microsoft's machine translation systems for the WMT21
shared task on large-scale multilingual machine translation. We participated in
all three evaluation tracks including Large Track and two Small Tracks where
the former one is unconstrained and the latter two are fully constrained. Our
model submissions to the shared task were initialized with
DeltaLM\footnote{\url{https://aka.ms/deltalm}}, a generic pre-trained
multilingual encoder-decoder model, and fine-tuned correspondingly with the
vast collected parallel data and allowed data sources according to track
settings, together with applying progressive learning and iterative
back-translation approaches to further improve the performance. Our final
submissions ranked first on three tracks in terms of the automatic evaluation
metric.",0,1,0,0,0,1,0.890922,5.0,0.837225,31
http://arxiv.org/abs/2111.05526v1,Space-Time Memory Network for Sounding Object Localization in Videos,5,0.0207047,0.319366,"Leveraging temporal synchronization and association within sight and sound is
an essential step towards robust localization of sounding objects. To this end,
we propose a space-time memory network for sounding object localization in
videos. It can simultaneously learn spatio-temporal attention over both
uni-modal and cross-modal representations from audio and visual modalities. We
show and analyze both quantitatively and qualitatively the effectiveness of
incorporating spatio-temporal learning in localizing audio-visual objects. We
demonstrate that our approach generalizes over various complex audio-visual
scenes and outperforms recent state-of-the-art methods.",1,0,0,0,1,0,0.284496,6.0,0.549374,35
http://arxiv.org/abs/2103.10957v2,Efficient Visual Pretraining with Contrastive Detection,137,0.679135,0.93382,"Self-supervised pretraining has been shown to yield powerful representations
for transfer learning. These performance gains come at a large computational
cost however, with state-of-the-art methods requiring an order of magnitude
more computation than supervised pretraining. We tackle this computational
bottleneck by introducing a new self-supervised objective, contrastive
detection, which tasks representations with identifying object-level features
across augmentations. This objective extracts a rich learning signal per image,
leading to state-of-the-art transfer accuracy on a variety of downstream tasks,
while requiring up to 10x less pretraining. In particular, our strongest
ImageNet-pretrained model performs on par with SEER, one of the largest
self-supervised systems to date, which uses 1000x more pretraining data.
Finally, our objective seamlessly handles pretraining on more complex images
such as those in COCO, closing the gap with supervised transfer learning from
COCO to PASCAL.",0,1,0,0,1,0,0.93697,8.0,0.925911,70
http://arxiv.org/abs/2111.11170v1,Human-Machine Interaction Speech Corpus from the ROBIN project,4,0.0308916,0.217407,"This paper introduces a new Romanian speech corpus from the ROBIN project,
called ROBIN Technical Acquisition Speech Corpus (ROBINTASC). Its main purpose
was to improve the behaviour of a conversational agent, allowing human-machine
interaction in the context of purchasing technical equipment. The paper
contains a detailed description of the acquisition process, corpus statistics
as well as an evaluation of the corpus influence on a low-latency ASR system as
well as a dialogue component.",0,1,1,1,0,0,0.197066,5.0,0.374816,28
http://arxiv.org/abs/2105.07299v1,Texture Generation with Neural Cellular Automata,6,0.0928359,0.106024,"Neural Cellular Automata (NCA) have shown a remarkable ability to learn the
required rules to ""grow"" images, classify morphologies, segment images, as well
as to do general computation such as path-finding. We believe the inductive
prior they introduce lends itself to the generation of textures. Textures in
the natural world are often generated by variants of locally interacting
reaction-diffusion systems. Human-made textures are likewise often generated in
a local manner (textile weaving, for instance) or using rules with local
dependencies (regular grids or geometric patterns). We demonstrate learning a
texture generator from a single template image, with the generation method
being embarrassingly parallel, exhibiting quick convergence and high fidelity
of output, and requiring only some minimal assumptions around the underlying
state manifold. Furthermore, we investigate properties of the learned models
that are both useful and interesting, such as non-stationary dynamics and an
inherent robustness to damage. Finally, we make qualitative claims that the
behaviour exhibited by the NCA model is a learned, distributed, local algorithm
to generate a texture, setting our method apart from existing work on texture
generation. We discuss the advantages of such a paradigm.",0,0,0,0,0,0,0.325494,12.0,0.788216,42
http://arxiv.org/abs/2110.14309v1,Inferring the Class Conditional Response Map for Weakly Supervised Semantic Segmentation,11,0.228403,0.278192,"Image-level weakly supervised semantic segmentation (WSSS) relies on class
activation maps (CAMs) for pseudo labels generation. As CAMs only highlight the
most discriminative regions of objects, the generated pseudo labels are usually
unsatisfactory to serve directly as supervision. To solve this, most existing
approaches follow a multi-training pipeline to refine CAMs for better
pseudo-labels, which includes: 1) re-training the classification model to
generate CAMs; 2) post-processing CAMs to obtain pseudo labels; and 3) training
a semantic segmentation model with the obtained pseudo labels. However, this
multi-training pipeline requires complicated adjustment and additional time. To
address this, we propose a class-conditional inference strategy and an
activation aware mask refinement loss function to generate better pseudo labels
without re-training the classifier. The class conditional inference-time
approach is presented to separately and iteratively reveal the classification
network's hidden object activation to generate more complete response maps.
Further, our activation aware mask refinement loss function introduces a novel
way to exploit saliency maps during segmentation training and refine the
foreground object masks without suppressing background objects. Our method
achieves superior WSSS results without requiring re-training of the classifier.",1,1,0,0,0,0,0.978278,7.0,0.961896,54
http://arxiv.org/abs/2110.09742v2,Learning Not to Reconstruct Anomalies,31,0.499832,0.632465,"Video anomaly detection is often seen as one-class classification (OCC)
problem due to the limited availability of anomaly examples. Typically, to
tackle this problem, an autoencoder (AE) is trained to reconstruct the input
with training set consisting only of normal data. At test time, the AE is then
expected to well reconstruct the normal data while poorly reconstructing the
anomalous data. However, several studies have shown that, even with only normal
data training, AEs can often start reconstructing anomalies as well which
depletes the anomaly detection performance. To mitigate this problem, we
propose a novel methodology to train AEs with the objective of reconstructing
only normal data, regardless of the input (i.e., normal or abnormal). Since no
real anomalies are available in the OCC settings, the training is assisted by
pseudo anomalies that are generated by manipulating normal data to simulate the
out-of-normal-data distribution. We additionally propose two ways to generate
pseudo anomalies: patch and skip frame based. Extensive experiments on three
challenging video anomaly datasets demonstrate the effectiveness of our method
in improving conventional AEs, achieving state-of-the-art performance.",1,1,0,0,1,0,0.902595,8.0,0.904494,61
http://arxiv.org/abs/2109.06232v2,The Emergence of the Shape Bias Results from Communicative Efficiency,15,0.0514709,0.349713,"By the age of two, children tend to assume that new word categories are based
on objects' shape, rather than their color or texture; this assumption is
called the shape bias. They are thought to learn this bias by observing that
their caregiver's language is biased towards shape based categories. This
presents a chicken and egg problem: if the shape bias must be present in the
language in order for children to learn it, how did it arise in language in the
first place? In this paper, we propose that communicative efficiency explains
both how the shape bias emerged and why it persists across generations. We
model this process with neural emergent language agents that learn to
communicate about raw pixelated images. First, we show that the shape bias
emerges as a result of efficient communication strategies employed by agents.
Second, we show that pressure brought on by communicative need is also
necessary for it to persist across generations; simply having a shape bias in
an agent's input language is insufficient. These results suggest that, over and
above the operation of other learning strategies, the shape bias in human
learners may emerge and be sustained by communicative pressures.",1,0,0,0,0,0,0.0377434,10.0,0.513279,62
http://arxiv.org/abs/2106.10102v1,hSMAL: Detailed Horse Shape and Pose Reconstruction for Motion Pattern Recognition,15,0.128141,0.368207,"In this paper we present our preliminary work on model-based behavioral
analysis of horse motion. Our approach is based on the SMAL model, a 3D
articulated statistical model of animal shape. We define a novel SMAL model for
horses based on a new template, skeleton and shape space learned from $37$
horse toys. We test the accuracy of our hSMAL model in reconstructing a horse
from 3D mocap data and images. We apply the hSMAL model to the problem of
lameness detection from video, where we fit the model to images to recover 3D
pose and train an ST-GCN network on pose data. A comparison with the same
network trained on mocap points illustrates the benefit of our approach.",0,1,0,0,0,0,0.349178,6.0,0.590912,21
http://arxiv.org/abs/2103.16435v1,EnergyVis: Interactively Tracking and Exploring Energy Consumption for ML Models,12,0.210938,0.483577,"The advent of larger machine learning (ML) models have improved
state-of-the-art (SOTA) performance in various modeling tasks, ranging from
computer vision to natural language. As ML models continue increasing in size,
so does their respective energy consumption and computational requirements.
However, the methods for tracking, reporting, and comparing energy consumption
remain limited. We presentEnergyVis, an interactive energy consumption tracker
for ML models. Consisting of multiple coordinated views, EnergyVis enables
researchers to interactively track, visualize and compare model energy
consumption across key energy consumption and carbon footprint metrics (kWh and
CO2), helping users explore alternative deployment locations and hardware that
may reduce carbon footprints. EnergyVis aims to raise awareness concerning
computational sustainability by interactively highlighting excessive energy
usage during model training; and by providing alternative training options to
reduce energy usage.",0,1,0,0,0,0,0.969409,4.0,0.909906,24
http://arxiv.org/abs/2104.10995v3,A learning gap between neuroscience and reinforcement learning,3,0.0,0.172619,"Historically, artificial intelligence has drawn much inspiration from
neuroscience to fuel advances in the field. However, current progress in
reinforcement learning is largely focused on benchmark problems that fail to
capture many of the aspects that are of interest in neuroscience today. We
illustrate this point by extending a T-maze task from neuroscience for use with
reinforcement learning algorithms, and show that state-of-the-art algorithms
are not capable of solving this problem. Finally, we point out where insights
from neuroscience could help explain some of the issues encountered.",0,0,0,0,0,0,0.743893,8.0,0.837454,38
http://arxiv.org/abs/2111.10293v1,A 3D 2D convolutional Neural Network Model for Hyperspectral Image Classification,1,0.00648325,0.065498,"In the proposed SEHybridSN model, a dense block was used to reuse shallow
feature and aimed at better exploiting hierarchical spatial spectral feature.
Subsequent depth separable convolutional layers were used to discriminate the
spatial information. Further refinement of spatial spectral features was
realized by the channel attention method, which were performed behind every 3D
convolutional layer and every 2D convolutional layer. Experiment results
indicate that our proposed model learn more discriminative spatial spectral
features using very few training data. SEHybridSN using only 0.05 and 0.01
labeled data for training, a very satisfactory performance is obtained.",0,1,0,0,0,0,0.374938,8.0,0.704417,32
http://arxiv.org/abs/2107.08212v1,On the Copying Behaviors of Pre-Training for Neural Machine Translation,21,0.0508089,0.768002,"Previous studies have shown that initializing neural machine translation
(NMT) models with the pre-trained language models (LM) can speed up the model
training and boost the model performance. In this work, we identify a critical
side-effect of pre-training for NMT, which is due to the discrepancy between
the training objectives of LM-based pre-training and NMT. Since the LM
objective learns to reconstruct a few source tokens and copy most of them, the
pre-training initialization would affect the copying behaviors of NMT models.
We provide a quantitative analysis of copying behaviors by introducing a metric
called copying ratio, which empirically shows that pre-training based NMT
models have a larger copying ratio than the standard one. In response to this
problem, we propose a simple and effective method named copying penalty to
control the copying behaviors in decoding. Extensive experiments on both
in-domain and out-of-domain benchmarks show that the copying penalty method
consistently improves translation performance by controlling copying behaviors
for pre-training based NMT models. Source code is freely available at
https://github.com/SunbowLiu/CopyingPenalty.",1,0,0,0,0,0,0.580109,5.0,0.649744,43
http://arxiv.org/abs/2105.08326v2,Actively Learning Concepts and Conjunctive Queries under ELr-Ontologies,6,0.0142295,0.15337,"We consider the problem to learn a concept or a query in the presence of an
ontology formulated in the description logic ELr, in Angluin's framework of
active learning that allows the learning algorithm to interactively query an
oracle (such as a domain expert). We show that the following can be learned in
polynomial time: (1) EL-concepts, (2) symmetry-free ELI-concepts, and (3)
conjunctive queries (CQs) that are chordal, symmetry-free, and of bounded
arity. In all cases, the learner can pose to the oracle membership queries
based on ABoxes and equivalence queries that ask whether a given concept/query
from the considered class is equivalent to the target. The restriction to
bounded arity in (3) can be removed when we admit unrestricted CQs in
equivalence queries. We also show that EL-concepts are not polynomial query
learnable in the presence of ELI-ontologies.",0,0,0,0,0,0,8.27567e-06,19.0,0.299388,45
http://arxiv.org/abs/2105.08440v1,CFR-MIX: Solving Imperfect Information Extensive-Form Games with Combinatorial Action Space,7,0.157256,0.554479,"In many real-world scenarios, a team of agents coordinate with each other to
compete against an opponent. The challenge of solving this type of game is that
the team's joint action space grows exponentially with the number of agents,
which results in the inefficiency of the existing algorithms, e.g.,
Counterfactual Regret Minimization (CFR). To address this problem, we propose a
new framework of CFR: CFR-MIX. Firstly, we propose a new strategy
representation that represents a joint action strategy using individual
strategies of all agents and a consistency relationship to maintain the
cooperation between agents. To compute the equilibrium with individual
strategies under the CFR framework, we transform the consistency relationship
between strategies to the consistency relationship between the cumulative
regret values. Furthermore, we propose a novel decomposition method over
cumulative regret values to guarantee the consistency relationship between the
cumulative regret values. Finally, we introduce our new algorithm CFR-MIX which
employs a mixing layer to estimate cumulative regret values of joint actions as
a non-linear combination of cumulative regret values of individual actions.
Experimental results show that CFR-MIX outperforms existing algorithms on
various games significantly.",0,0,0,0,1,0,0.369171,11.0,0.783236,35
http://arxiv.org/abs/2109.04901v1,Document-level Entity-based Extraction as Template Generation,48,0.633803,0.996677,"Document-level entity-based extraction (EE), aiming at extracting
entity-centric information such as entity roles and entity relations, is key to
automatic knowledge acquisition from text corpora for various domains. Most
document-level EE systems build extractive models, which struggle to model
long-term dependencies among entities at the document level. To address this
issue, we propose a generative framework for two document-level EE tasks:
role-filler entity extraction (REE) and relation extraction (RE). We first
formulate them as a template generation problem, allowing models to efficiently
capture cross-entity dependencies, exploit label semantics, and avoid the
exponential computation complexity of identifying N-ary relations. A novel
cross-attention guided copy mechanism, TopK Copy, is incorporated into a
pre-trained sequence-to-sequence model to enhance the capabilities of
identifying key information in the input document. Experiments done on the
MUC-4 and SciREX dataset show new state-of-the-art results on REE (+3.26%),
binary RE (+4.8%), and 4-ary RE (+2.7%) in F1 score.",1,1,0,0,1,0,0.918304,5.0,0.86175,29
http://arxiv.org/abs/2101.08661v1,Regularization via deep generative models: an analysis point of view,7,0.00624419,0.0497047,"This paper proposes a new way of regularizing an inverse problem in imaging
(e.g., deblurring or inpainting) by means of a deep generative neural network.
Compared to end-to-end models, such approaches seem particularly interesting
since the same network can be used for many different problems and experimental
conditions, as soon as the generative model is suited to the data. Previous
works proposed to use a synthesis framework, where the estimation is performed
on the latent vector, the solution being obtained afterwards via the decoder.
Instead, we propose an analysis formulation where we directly optimize the
image itself and penalize the latent vector. We illustrate the interest of such
a formulation by running experiments of inpainting, deblurring and
super-resolution. In many cases our technique achieves a clear improvement of
the performance and seems to be more robust, in particular with respect to
initialization.",0,0,0,0,0,0,0.153172,8.0,0.574543,29
http://arxiv.org/abs/2108.00194v1,Using Knowledge-Embedded Attention to Augment Pre-trained Language Models for Fine-Grained Emotion Recognition,14,0.0767842,0.440693,"Modern emotion recognition systems are trained to recognize only a small set
of emotions, and hence fail to capture the broad spectrum of emotions people
experience and express in daily life. In order to engage in more empathetic
interactions, future AI has to perform \textit{fine-grained} emotion
recognition, distinguishing between many more varied emotions. Here, we focus
on improving fine-grained emotion recognition by introducing external knowledge
into a pre-trained self-attention model. We propose Knowledge-Embedded
Attention (KEA) to use knowledge from emotion lexicons to augment the
contextual representations from pre-trained ELECTRA and BERT models. Our
results and error analyses outperform previous models on several datasets, and
is better able to differentiate closely-confusable emotions, such as afraid and
terrified.",0,1,0,0,0,0,0.553426,5.0,0.635016,49
http://arxiv.org/abs/2104.08478v1,Sentence Concatenation Approach to Data Augmentation for Neural Machine Translation,15,0.0365614,0.518381,"Neural machine translation (NMT) has recently gained widespread attention
because of its high translation accuracy. However, it shows poor performance in
the translation of long sentences, which is a major issue in low-resource
languages. It is assumed that this issue is caused by insufficient number of
long sentences in the training data. Therefore, this study proposes a simple
data augmentation method to handle long sentences. In this method, we use only
the given parallel corpora as the training data and generate long sentences by
concatenating two sentences. Based on the experimental results, we confirm
improvements in long sentence translation by the proposed data augmentation
method, despite its simplicity. Moreover, the translation quality is further
improved by the proposed method, when combined with back-translation.",0,1,0,0,0,0,0.325943,6.0,0.576712,15
http://arxiv.org/abs/2104.11530v2,Supervised Video Summarization via Multiple Feature Sets with Parallel Attention,34,0.239078,0.391578,"The assignment of importance scores to particular frames or (short) segments
in a video is crucial for summarization, but also a difficult task. Previous
work utilizes only one source of visual features. In this paper, we suggest a
novel model architecture that combines three feature sets for visual content
and motion to predict importance scores. The proposed architecture utilizes an
attention mechanism before fusing motion features and features representing the
(static) visual content, i.e., derived from an image classification model.
Comprehensive experimental evaluations are reported for two well-known
datasets, SumMe and TVSum. In this context, we identify methodological issues
on how previous work used these benchmark datasets, and present a fair
evaluation scheme with appropriate data splits that can be used in future work.
When using static and motion features with parallel attention mechanism, we
improve state-of-the-art results for SumMe, while being on par with the state
of the art for the other dataset.",1,1,0,0,1,0,0.514351,8.0,0.758151,17
http://arxiv.org/abs/2104.03483v3,Question-Driven Design Process for Explainable AI User Experiences,39,0.642683,0.749047,"A pervasive design issue of AI systems is their explainability--how to
provide appropriate information to help users understand the AI. The technical
field of explainable AI (XAI) has produced a rich toolbox of techniques.
Designers are now tasked with the challenges of how to select the most suitable
XAI techniques and translate them into UX solutions. Informed by our previous
work studying design challenges around XAI UX, this work proposes a design
process to tackle these challenges. We review our and related prior work to
identify requirements that the process should fulfill, and accordingly, propose
a Question-Driven Design Process that grounds the user needs, choices of XAI
techniques, design, and evaluation of XAI UX all in the user questions. We
provide a mapping guide between prototypical user questions and exemplars of
XAI techniques to reframe the technical space of XAI, also serving as boundary
objects to support collaboration between designers and AI engineers. We
demonstrate it with a use case of designing XAI for healthcare adverse events
prediction, and discuss lessons learned for tackling design challenges of AI
systems.",0,0,0,0,0,0,0.945686,5.0,0.891948,56
http://arxiv.org/abs/2104.08620v3,Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as a Target for NLP,13,0.31173,0.832245,"Cryptic crosswords, the dominant crossword variety in the UK, are a promising
target for advancing NLP systems that seek to process semantically complex,
highly compositional language. Cryptic clues read like fluent natural language
but are adversarially composed of two parts: a definition and a wordplay cipher
requiring character-level manipulations. Expert humans use creative
intelligence to solve cryptics, flexibly combining linguistic, world, and
domain knowledge. In this paper, we make two main contributions. First, we
present a dataset of cryptic clues as a challenging new benchmark for NLP
systems that seek to process compositional language in more creative,
human-like ways. After showing that three non-neural approaches and T5, a
state-of-the-art neural language model, do not achieve good performance, we
make our second main contribution: a novel curriculum approach, in which the
model is first fine-tuned on related tasks such as unscrambling words.We also
introduce a challenging data split, examine the meta-linguistic capabilities of
subword-tokenized models, and investigate model systematicity by perturbing the
wordplay part of clues, showing that T5 exhibits behavior partially consistent
with human solving strategies. Although our curricular approach considerably
improves on the T5 baseline, our best-performing model still fails to
generalize to the extent that humans can. Thus, cryptic crosswords remain an
unsolved challenge for NLP systems and a potential source of future innovation.",1,0,1,1,0,0,0.8693,4.0,0.775246,43
http://arxiv.org/abs/2110.09109v1,Patch-Based Deep Autoencoder for Point Cloud Geometry Compression,20,0.224624,0.726227,"The ever-increasing 3D application makes the point cloud compression
unprecedentedly important and needed. In this paper, we propose a patch-based
compression process using deep learning, focusing on the lossy point cloud
geometry compression. Unlike existing point cloud compression networks, which
apply feature extraction and reconstruction on the entire point cloud, we
divide the point cloud into patches and compress each patch independently. In
the decoding process, we finally assemble the decompressed patches into a
complete point cloud. In addition, we train our network by a patch-to-patch
criterion, i.e., use the local reconstruction loss for optimization, to
approximate the global reconstruction optimality. Our method outperforms the
state-of-the-art in terms of rate-distortion performance, especially at low
bitrates. Moreover, the compression process we proposed can guarantee to
generate the same number of points as the input. The network model of this
method can be easily applied to other point cloud reconstruction problems, such
as upsampling.",1,1,0,0,1,0,0.763709,8.0,0.844634,23
http://arxiv.org/abs/2105.13465v1,Verb Sense Clustering using Contextualized Word Representations for Semantic Frame Induction,6,0.0577652,0.41438,"Contextualized word representations have proven useful for various natural
language processing tasks. However, it remains unclear to what extent these
representations can cover hand-coded semantic information such as semantic
frames, which specify the semantic role of the arguments associated with a
predicate. In this paper, we focus on verbs that evoke different frames
depending on the context, and we investigate how well contextualized word
representations can recognize the difference of frames that the same verb
evokes. We also explore which types of representation are suitable for semantic
frame induction. In our experiments, we compare seven different contextualized
word representations for two English frame-semantic resources, FrameNet and
PropBank. We demonstrate that several contextualized word representations,
especially BERT and its variants, are considerably informative for semantic
frame induction. Furthermore, we examine the extent to which the contextualized
representation of a verb can estimate the number of frames that the verb can
evoke.",0,0,0,0,0,0,0.431579,7.0,0.688492,32
http://arxiv.org/abs/2107.07124v1,An Educational System for Personalized Teacher Recommendation in K-12 Online Classrooms,5,0.0238428,0.177084,"In this paper, we propose a simple yet effective solution to build practical
teacher recommender systems for online one-on-one classes. Our system consists
of (1) a pseudo matching score module that provides reliable training labels;
(2) a ranking model that scores every candidate teacher; (3) a novelty boosting
module that gives additional opportunities to new teachers; and (4) a diversity
metric that guardrails the recommended results to reduce the chance of
collision. Offline experimental results show that our approach outperforms a
wide range of baselines. Furthermore, we show that our approach is able to
reduce the number of student-teacher matching attempts from 7.22 to 3.09 in a
five-month observation on a third-party online education platform.",0,1,0,0,1,0,0.00215626,22.0,0.64783,13
http://arxiv.org/abs/2105.00447v1,Automatic Visual Inspection of Rare Defects: A Framework based on GP-WGAN and Enhanced Faster R-CNN,7,0.151461,0.258814,"A current trend in industries such as semiconductors and foundry is to shift
their visual inspection processes to Automatic Visual Inspection (AVI) systems,
to reduce their costs, mistakes, and dependency on human experts. This paper
proposes a two-staged fault diagnosis framework for AVI systems. In the first
stage, a generation model is designed to synthesize new samples based on real
samples. The proposed augmentation algorithm extracts objects from the real
samples and blends them randomly, to generate new samples and enhance the
performance of the image processor. In the second stage, an improved deep
learning architecture based on Faster R-CNN, Feature Pyramid Network (FPN), and
a Residual Network is proposed to perform object detection on the enhanced
dataset. The performance of the algorithm is validated and evaluated on two
multi-class datasets. The experimental results performed over a range of
imbalance severities demonstrate the superiority of the proposed framework
compared to other solutions.",0,1,0,0,0,0,0.653367,7.0,0.778335,31
http://arxiv.org/abs/2103.01328v1,ToxCCIn: Toxic Content Classification with Interpretability,12,0.0505698,0.411609,"Despite the recent successes of transformer-based models in terms of
effectiveness on a variety of tasks, their decisions often remain opaque to
humans. Explanations are particularly important for tasks like offensive
language or toxicity detection on social media because a manual appeal process
is often in place to dispute automatically flagged content. In this work, we
propose a technique to improve the interpretability of these models, based on a
simple and powerful assumption: a post is at least as toxic as its most toxic
span. We incorporate this assumption into transformer models by scoring a post
based on the maximum toxicity of its spans and augmenting the training process
to identify correct spans. We find this approach effective and can produce
explanations that exceed the quality of those provided by Logistic Regression
analysis (often regarded as a highly-interpretable model), according to a human
study.",0,1,0,0,0,0,0.823894,5.0,0.788506,48
http://arxiv.org/abs/2110.06679v2,EditVAE: Unsupervised Part-Aware Controllable 3D Point Cloud Shape Generation,17,0.201468,0.63985,"This paper tackles the problem of parts-aware point cloud generation. Unlike
existing works which require the point cloud to be segmented into parts a
priori, our parts-aware editing and generation are performed in an unsupervised
manner. We achieve this with a simple modification of the Variational
Auto-Encoder which yields a joint model of the point cloud itself along with a
schematic representation of it as a combination of shape primitives. In
particular, we introduce a latent representation of the point cloud which can
be decomposed into a disentangled representation for each part of the shape.
These parts are in turn disentangled into both a shape primitive and a point
cloud representation, along with a standardising transformation to a canonical
coordinate system. The dependencies between our standardising transformations
preserve the spatial dependencies between the parts in a manner that allows
meaningful parts-aware point cloud generation and shape editing. In addition to
the flexibility afforded by our disentangled representation, the inductive bias
introduced by our joint modeling approach yields state-of-the-art experimental
results on the ShapeNet dataset.",0,0,0,0,1,0,0.731267,6.0,0.777278,44
http://arxiv.org/abs/2106.11849v1,Algorithmic Recourse in Partially and Fully Confounded Settings Through Bounding Counterfactual Effects,2,0.0513785,0.0122902,"Algorithmic recourse aims to provide actionable recommendations to
individuals to obtain a more favourable outcome from an automated
decision-making system. As it involves reasoning about interventions performed
in the physical world, recourse is fundamentally a causal problem. Existing
methods compute the effect of recourse actions using a causal model learnt from
data under the assumption of no hidden confounding and modelling assumptions
such as additive noise. Building on the seminal work of Balke and Pearl (1994),
we propose an alternative approach for discrete random variables which relaxes
these assumptions and allows for unobserved confounding and arbitrary
structural equations. The proposed approach only requires specification of the
causal graph and confounding structure and bounds the expected counterfactual
effect of recourse actions. If the lower bound is above a certain threshold,
i.e., on the other side of the decision boundary, recourse is guaranteed in
expectation.",0,0,0,0,0,0,0.926041,4.0,0.836927,25
http://arxiv.org/abs/2106.15206v1,Domain-Class Correlation Decomposition for Generalizable Person Re-Identification,9,0.0562574,0.404423,"Domain generalization in person re-identification is a highly important
meaningful and practical task in which a model trained with data from several
source domains is expected to generalize well to unseen target domains. Domain
adversarial learning is a promising domain generalization method that aims to
remove domain information in the latent representation through adversarial
training. However, in person re-identification, the domain and class are
correlated, and we theoretically show that domain adversarial learning will
lose certain information about class due to this domain-class correlation.
Inspired by casual inference, we propose to perform interventions to the domain
factor $d$, aiming to decompose the domain-class correlation. To achieve this
goal, we proposed estimating the resulting representation $z^{*}$ caused by the
intervention through first- and second-order statistical characteristic
matching. Specifically, we build a memory bank to restore the statistical
characteristics of each domain. Then, we use the newly generated samples
$\{z^{*},y,d^{*}\}$ to compute the loss function. These samples are
domain-class correlation decomposed; thus, we can learn a domain-invariant
representation that can capture more class-related features. Extensive
experiments show that our model outperforms the state-of-the-art methods on the
large-scale domain generalization Re-ID benchmark.",0,0,0,0,1,0,0.59228,7.0,0.75458,82
http://arxiv.org/abs/2109.15271v2,TöRF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis,80,0.88306,0.889951,"Neural networks can represent and accurately reconstruct radiance fields for
static 3D scenes (e.g., NeRF). Several works extend these to dynamic scenes
captured with monocular video, with promising performance. However, the
monocular setting is known to be an under-constrained problem, and so methods
rely on data-driven priors for reconstructing dynamic content. We replace these
priors with measurements from a time-of-flight (ToF) camera, and introduce a
neural representation based on an image formation model for continuous-wave ToF
cameras. Instead of working with processed depth maps, we model the raw ToF
sensor measurements to improve reconstruction quality and avoid issues with low
reflectance regions, multi-path interference, and a sensor's limited
unambiguous depth range. We show that this approach improves robustness of
dynamic scene reconstruction to erroneous calibration and large motions, and
discuss the benefits and limitations of integrating RGB+ToF sensors that are
now available on modern smartphones.",0,0,0,0,0,0,0.969536,5.0,0.928162,57
http://arxiv.org/abs/2105.14804v1,Scene-aware Generative Network for Human Motion Synthesis,57,0.756315,0.837708,"We revisit human motion synthesis, a task useful in various real world
applications, in this paper. Whereas a number of methods have been developed
previously for this task, they are often limited in two aspects: focusing on
the poses while leaving the location movement behind, and ignoring the impact
of the environment on the human motion. In this paper, we propose a new
framework, with the interaction between the scene and the human motion taken
into account. Considering the uncertainty of human motion, we formulate this
task as a generative task, whose objective is to generate plausible human
motion conditioned on both the scene and the human initial position. This
framework factorizes the distribution of human motions into a distribution of
movement trajectories conditioned on scenes and that of body pose dynamics
conditioned on both scenes and trajectories. We further derive a GAN based
learning approach, with discriminators to enforce the compatibility between the
human motion and the contextual scene as well as the 3D to 2D projection
constraints. We assess the effectiveness of the proposed method on two
challenging datasets, which cover both synthetic and real world environments.",0,0,0,0,0,0,0.930465,6.0,0.895186,37
http://arxiv.org/abs/2109.10715v1,Simulated Annealing for Emotional Dialogue Systems,5,0.109523,0.284075,"Explicitly modeling emotions in dialogue generation has important
applications, such as building empathetic personal companions. In this study,
we consider the task of expressing a specific emotion for dialogue generation.
Previous approaches take the emotion as an input signal, which may be ignored
during inference. We instead propose a search-based emotional dialogue system
by simulated annealing (SA). Specifically, we first define a scoring function
that combines contextual coherence and emotional correctness. Then, SA
iteratively edits a general response and searches for a sentence with a higher
score, enforcing the presence of the desired emotion. We evaluate our system on
the NLPCC2017 dataset. Our proposed method shows 12% improvements in emotion
accuracy compared with the previous state-of-the-art method, without hurting
the generation quality (measured by BLEU).",1,1,0,0,1,0,0.903318,8.0,0.904893,28
http://arxiv.org/abs/2107.08045v2,Desiderata for Explainable AI in statistical production systems of the European Central Bank,9,0.0532466,0.277951,"Explainable AI constitutes a fundamental step towards establishing fairness
and addressing bias in algorithmic decision-making. Despite the large body of
work on the topic, the benefit of solutions is mostly evaluated from a
conceptual or theoretical point of view and the usefulness for real-world use
cases remains uncertain. In this work, we aim to state clear user-centric
desiderata for explainable AI reflecting common explainability needs
experienced in statistical production systems of the European Central Bank. We
link the desiderata to archetypical user roles and give examples of techniques
and methods which can be used to address the user's needs. To this end, we
provide two concrete use cases from the domain of statistical data production
in central banks: the detection of outliers in the Centralised Securities
Database and the data-driven identification of data quality checks for the
Supervisory Banking data system.",0,1,0,0,0,0,0.517678,7.0,0.724954,51
http://arxiv.org/abs/2106.05264v1,NeRF in detail: Learning to sample for view synthesis,33,0.180671,0.305378,"Neural radiance fields (NeRF) methods have demonstrated impressive novel view
synthesis performance. The core approach is to render individual rays by
querying a neural network at points sampled along the ray to obtain the density
and colour of the sampled points, and integrating this information using the
rendering equation. Since dense sampling is computationally prohibitive, a
common solution is to perform coarse-to-fine sampling.
  In this work we address a clear limitation of the vanilla coarse-to-fine
approach -- that it is based on a heuristic and not trained end-to-end for the
task at hand. We introduce a differentiable module that learns to propose
samples and their importance for the fine network, and consider and compare
multiple alternatives for its neural architecture. Training the proposal module
from scratch can be unstable due to lack of supervision, so an effective
pre-training strategy is also put forward. The approach, named `NeRF in detail'
(NeRF-ID), achieves superior view synthesis quality over NeRF and the
state-of-the-art on the synthetic Blender benchmark and on par or better
performance on the real LLFF-NeRF scenes. Furthermore, by leveraging the
predicted sample importance, a 25% saving in computation can be achieved
without significantly sacrificing the rendering quality.",0,0,0,0,1,0,0.939581,5.0,0.884497,70
http://arxiv.org/abs/2109.01330v1,Detecting Speaker Personas from Conversational Texts,15,0.2182,0.770481,"Personas are useful for dialogue response prediction. However, the personas
used in current studies are pre-defined and hard to obtain before a
conversation. To tackle this issue, we study a new task, named Speaker Persona
Detection (SPD), which aims to detect speaker personas based on the plain
conversational text. In this task, a best-matched persona is searched out from
candidates given the conversational text. This is a many-to-many semantic
matching task because both contexts and personas in SPD are composed of
multiple sentences. The long-term dependency and the dynamic redundancy among
these sentences increase the difficulty of this task. We build a dataset for
SPD, dubbed as Persona Match on Persona-Chat (PMPC). Furthermore, we evaluate
several baseline models and propose utterance-to-profile (U2P) matching
networks for this task. The U2P models operate at a fine granularity which
treat both contexts and personas as sets of multiple sequences. Then, each
sequence pair is scored and an interpretable overall score is obtained for a
context-persona pair through aggregation. Evaluation results show that the U2P
models outperform their baseline counterparts significantly.",1,0,1,1,0,0,0.781152,9.0,0.867651,32
http://arxiv.org/abs/2105.04505v1,Towards Benchmarking the Utility of Explanations for Model Debugging,15,0.0382742,0.435799,"Post-hoc explanation methods are an important class of approaches that help
understand the rationale underlying a trained model's decision. But how useful
are they for an end-user towards accomplishing a given task? In this vision
paper, we argue the need for a benchmark to facilitate evaluations of the
utility of post-hoc explanation methods. As a first step to this end, we
enumerate desirable properties that such a benchmark should possess for the
task of debugging text classifiers. Additionally, we highlight that such a
benchmark facilitates not only assessing the effectiveness of explanations but
also their efficiency.",0,0,0,0,0,0,0.779033,4.0,0.700625,18
http://arxiv.org/abs/2103.07208v1,In the light of feature distributions: moment matching for Neural Style Transfer,38,0.48097,0.543619,"Style transfer aims to render the content of a given image in the
graphical/artistic style of another image. The fundamental concept underlying
NeuralStyle Transfer (NST) is to interpret style as a distribution in the
feature space of a Convolutional Neural Network, such that a desired style can
be achieved by matching its feature distribution. We show that most current
implementations of that concept have important theoretical and practical
limitations, as they only partially align the feature distributions. We propose
a novel approach that matches the distributions more precisely, thus
reproducing the desired style more faithfully, while still being
computationally efficient. Specifically, we adapt the dual form of Central
Moment Discrepancy (CMD), as recently proposed for domain adaptation, to
minimize the difference between the target style and the feature distribution
of the output image. The dual interpretation of this metric explicitly matches
all higher-order centralized moments and is therefore a natural extension of
existing NST methods that only take into account the first and second moments.
Our experiments confirm that the strong theoretical properties also translate
to visually better style transfer, and better disentangle style from semantic
image content.",0,0,0,0,0,0,0.975264,9.0,0.966529,41
http://arxiv.org/abs/2106.01597v1,ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language Generation,30,0.0929213,0.450869,"Despite the recent advancement in NLP research, cross-lingual transfer for
natural language generation is relatively understudied. In this work, we
transfer supervision from high resource language (HRL) to multiple low-resource
languages (LRLs) for natural language generation (NLG). We consider four NLG
tasks (text summarization, question generation, news headline generation, and
distractor generation) and three syntactically diverse languages, i.e.,
English, Hindi, and Japanese. We propose an unsupervised cross-lingual language
generation framework (called ZmBART) that does not use any parallel or
pseudo-parallel/back-translated data. In this framework, we further pre-train
mBART sequence-to-sequence denoising auto-encoder model with an auxiliary task
using monolingual data of three languages. The objective function of the
auxiliary task is close to the target tasks which enriches the multi-lingual
latent representation of mBART and provides good initialization for target
tasks. Then, this model is fine-tuned with task-specific supervised English
data and directly evaluated with low-resource languages in the Zero-shot
setting. To overcome catastrophic forgetting and spurious correlation issues,
we applied freezing model component and data argumentation approaches
respectively. This simple modeling approach gave us promising results.We
experimented with few-shot training (with 1000 supervised data points) which
boosted the model performance further. We performed several ablations and
cross-lingual transferability analyses to demonstrate the robustness of ZmBART.",1,1,0,1,0,0,0.621971,4.0,0.590742,26
http://arxiv.org/abs/2111.07555v1,"Confucius, Cyberpunk and Mr. Science: Comparing AI ethics between China and the EU",1,0.0193811,0.0687525,"The exponential development and application of artificial intelligence
triggered an unprecedented global concern for potential social and ethical
issues. Stakeholders from different industries, international foundations,
governmental organisations and standards institutions quickly improvised and
created various codes of ethics attempting to regulate AI. A major concern is
the large homogeneity and presumed consensualism around these principles. While
it is true that some ethical doctrines, such as the famous Kantian deontology,
aspire to universalism, they are however not universal in practice. In fact,
ethical pluralism is more about differences in which relevant questions to ask
rather than different answers to a common question. When people abide by
different moral doctrines, they tend to disagree on the very approach to an
issue. Even when people from different cultures happen to agree on a set of
common principles, it does not necessarily mean that they share the same
understanding of these concepts and what they entail. In order to better
understand the philosophical roots and cultural context underlying ethical
principles in AI, we propose to analyse and compare the ethical principles
endorsed by the Chinese National New Generation Artificial Intelligence
Governance Professional Committee (CNNGAIGPC) and those elaborated by the
European High-level Expert Group on AI (HLEGAI). China and the EU have very
different political systems and diverge in their cultural heritages. In our
analysis, we wish to highlight that principles that seem similar a priori may
actually have different meanings, derived from different approaches and reflect
distinct goals.",0,0,0,0,0,0,0.332145,7.0,0.640491,26
http://arxiv.org/abs/2107.07844v1,Versatile modular neural locomotion control with fast learning,18,0.297134,0.702483,"Legged robots have significant potential to operate in highly unstructured
environments. The design of locomotion control is, however, still challenging.
Currently, controllers must be either manually designed for specific robots and
tasks, or automatically designed via machine learning methods that require long
training times and yield large opaque controllers. Drawing inspiration from
animal locomotion, we propose a simple yet versatile modular neural control
structure with fast learning. The key advantages of our approach are that
behavior-specific control modules can be added incrementally to obtain
increasingly complex emergent locomotion behaviors, and that neural connections
interfacing with existing modules can be quickly and automatically learned. In
a series of experiments, we show how eight modules can be quickly learned and
added to a base control module to obtain emergent adaptive behaviors allowing a
hexapod robot to navigate in complex environments. We also show that modules
can be added and removed during operation without affecting the functionality
of the remaining controller. Finally, the control approach was successfully
demonstrated on a physical hexapod robot. Taken together, our study reveals a
significant step towards fast automatic design of versatile neural locomotion
control for complex robotic systems.",1,0,0,0,0,0,0.0872214,12.0,0.666378,61
http://arxiv.org/abs/2101.09486v1,Neural Relational Inference with Efficient Message Passing Mechanisms,11,0.0772506,0.191028,"Many complex processes can be viewed as dynamical systems of interacting
agents. In many cases, only the state sequences of individual agents are
observed, while the interacting relations and the dynamical rules are unknown.
The neural relational inference (NRI) model adopts graph neural networks that
pass messages over a latent graph to jointly learn the relations and the
dynamics based on the observed data. However, NRI infers the relations
independently and suffers from error accumulation in multi-step prediction at
dynamics learning procedure. Besides, relation reconstruction without prior
knowledge becomes more difficult in more complex systems. This paper introduces
efficient message passing mechanisms to the graph neural networks with
structural prior knowledge to address these problems. A relation interaction
mechanism is proposed to capture the coexistence of all relations, and a
spatio-temporal message passing mechanism is proposed to use historical
information to alleviate error accumulation. Additionally, the structural prior
knowledge, symmetry as a special case, is introduced for better relation
prediction in more complex systems. The experimental results on simulated
physics systems show that the proposed method outperforms existing
state-of-the-art methods.",0,0,0,0,1,0,0.71085,5.0,0.721265,36
http://arxiv.org/abs/2106.03548v3,Auction-based and Distributed Optimization Approaches for Scheduling Observations in Satellite Constellations with Exclusive Orbit Portions,8,0.427045,0.498695,"We investigate the use of multi-agent allocation techniques on problems
related to Earth observation scenarios with multiple users and satellites. We
focus on the problem of coordinating users having reserved exclusive orbit
portions and one central planner having several requests that may use some
intervals of these exclusives. We define this problem as Earth Observation
Satellite Constellation Scheduling Problem (EOSCSP) and map it to a Mixed
Integer Linear Program. As to solve EOSCSP, we propose market-based techniques
and a distributed problem solving technique based on Distributed Constraint
Optimization (DCOP), where agents cooperate to allocate requests without
sharing their own schedules. These contributions are experimentally evaluated
on randomly generated EOSCSP instances based on real large-scale or highly
conflicting observation order books.",0,1,0,0,0,0,0.602928,25.0,0.932445,18
http://arxiv.org/abs/2103.13164v1,M3DSSD: Monocular 3D Single Stage Object Detector,64,0.41163,0.93178,"In this paper, we propose a Monocular 3D Single Stage object Detector
(M3DSSD) with feature alignment and asymmetric non-local attention. Current
anchor-based monocular 3D object detection methods suffer from feature
mismatching. To overcome this, we propose a two-step feature alignment
approach. In the first step, the shape alignment is performed to enable the
receptive field of the feature map to focus on the pre-defined anchors with
high confidence scores. In the second step, the center alignment is used to
align the features at 2D/3D centers. Further, it is often difficult to learn
global information and capture long-range relationships, which are important
for the depth prediction of objects. Therefore, we propose a novel asymmetric
non-local attention block with multi-scale sampling to extract depth-wise
features. The proposed M3DSSD achieves significantly better performance than
the monocular 3D object detection methods on the KITTI dataset, in both 3D
object detection and bird's eye view tasks.",1,1,0,0,1,0,0.880896,5.0,0.829126,47
http://arxiv.org/abs/2109.00892v1,KITTI-CARLA: a KITTI-like dataset generated by CARLA Simulator,36,0.126142,0.567125,"KITTI-CARLA is a dataset built from the CARLA v0.9.10 simulator using a
vehicle with sensors identical to the KITTI dataset. The vehicle thus has a
Velodyne HDL64 LiDAR positioned in the middle of the roof and two color cameras
similar to Point Grey Flea 2. The positions of the LiDAR and cameras are the
same as the setup used in KITTI. The objective of this dataset is to test
approaches of semantic segmentation LiDAR and/or images, odometry LiDAR and/or
image in synthetic data and to compare with the results obtained on real data
like KITTI. This dataset thus makes it possible to improve transfer learning
methods from a synthetic dataset to a real dataset. We created 7 sequences with
5000 frames in each sequence in the 7 maps of CARLA providing different
environments (city, suburban area, mountain, rural area, highway...). The
dataset is available at: http://npm3d.fr",0,1,0,1,0,0,0.993262,19.0,1.0,2
http://arxiv.org/abs/2105.10076v2,An Optical physics inspired CNN approach for intrinsic image decomposition,1,0.0573611,0.0280298,"Intrinsic Image Decomposition is an open problem of generating the
constituents of an image. Generating reflectance and shading from a single
image is a challenging task specifically when there is no ground truth. There
is a lack of unsupervised learning approaches for decomposing an image into
reflectance and shading using a single image. We propose a neural network
architecture capable of this decomposition using physics-based parameters
derived from the image. Through experimental results, we show that (a) the
proposed methodology outperforms the existing deep learning-based IID
techniques and (b) the derived parameters improve the efficacy significantly.
We conclude with a closer analysis of the results (numerical and example
images) showing several avenues for improvement.",0,1,0,0,1,0,0.890318,8.0,0.897954,19
http://arxiv.org/abs/2109.08597v1,Boosting Transformers for Job Expression Extraction and Classification in a Low-Resource Setting,4,0.0113275,0.119331,"In this paper, we explore possible improvements of transformer models in a
low-resource setting. In particular, we present our approaches to tackle the
first two of three subtasks of the MEDDOPROF competition, i.e., the extraction
and classification of job expressions in Spanish clinical texts. As neither
language nor domain experts, we experiment with the multilingual XLM-R
transformer model and tackle these low-resource information extraction tasks as
sequence-labeling problems. We explore domain- and language-adaptive
pretraining, transfer learning and strategic datasplits to boost the
transformer model. Our results show strong improvements using these methods by
up to 5.3 F1 points compared to a fine-tuned XLM-R model. Our best models
achieve 83.2 and 79.3 F1 for the first two tasks, respectively.",0,1,0,0,0,0,0.498153,3.0,0.339571,18
http://arxiv.org/abs/2108.04231v1,Adding Visibility to Visibility Graphs: Weighting Visibility Analysis with Attenuation Coefficients,1,0.0125332,0.0667122,"Evaluating the built environment based on visibility has been long used as a
tool for human-centric design. The origins of isovists and visibility graphs
are within interior spaces, while more recently, these evaluation techniques
have been applied in the urban context. One of the key differentiators of an
outside environment is the weather, which has largely been ignored in the
design computation and space-syntax research areas. While a visibility graph is
a straightforward metric for determining connectivity between regions of space
through a line of sight calculation, this approach largely ignores the actual
visibility of one point to another. This paper introduces a new method for
weighting a visibility graph based on weather conditions (i.e. rain, fog,
snow). These new factors are integrated into visibility graphs and applied to
sample environments to demonstrate the variance between assuming a straight
line of sight and reduced visibility.",0,0,1,0,0,0,0.0012902,17.0,0.514015,42
http://arxiv.org/abs/2106.05830v1,A Template-guided Hybrid Pointer Network for Knowledge-basedTask-oriented Dialogue Systems,11,0.331267,0.604856,"Most existing neural network based task-oriented dialogue systems follow
encoder-decoder paradigm, where the decoder purely depends on the source texts
to generate a sequence of words, usually suffering from instability and poor
readability. Inspired by the traditional template-based generation approaches,
we propose a template-guided hybrid pointer network for the knowledge-based
task-oriented dialogue system, which retrieves several potentially relevant
answers from a pre-constructed domain-specific conversational repository as
guidance answers, and incorporates the guidance answers into both the encoding
and decoding processes. Specifically, we design a memory pointer network model
with a gating mechanism to fully exploit the semantic correlation between the
retrieved answers and the ground-truth response. We evaluate our model on four
widely used task-oriented datasets, including one simulated and three manually
created datasets. The experimental results demonstrate that the proposed model
achieves significantly better performance than the state-of-the-art methods
over different automatic evaluation metrics.",1,1,0,0,1,0,0.952526,11.0,0.954991,39
http://arxiv.org/abs/2102.08866v3,IoTDevID: A Behavior-Based Device Identification Method for the IoT,22,0.46979,0.470557,"Device identification is one way to secure a network of IoT devices, whereby
devices identified as suspicious can subsequently be isolated from a network.
In this study, we present a machine learning-based method, IoTDevID, that
recognizes devices through characteristics of their network packets. As a
result of using a rigorous feature analysis and selection process, our study
offers a generalizable and realistic approach to modelling device behavior,
achieving high predictive accuracy across two public datasets. The model's
underlying feature set is shown to be more predictive than existing feature
sets used for device identification, and is shown to generalize to data unseen
during the feature selection process. Unlike most existing approaches to IoT
device identification, IoTDevID is able to detect devices using non-IP and
low-energy protocols.",1,1,0,0,0,0,0.986739,6.0,0.975749,19
http://arxiv.org/abs/2103.05677v1,SMIL: Multimodal Learning with Severely Missing Modality,169,0.635722,0.996147,"A common assumption in multimodal learning is the completeness of training
data, i.e., full modalities are available in all training examples. Although
there exists research endeavor in developing novel methods to tackle the
incompleteness of testing data, e.g., modalities are partially missing in
testing examples, few of them can handle incomplete training modalities. The
problem becomes even more challenging if considering the case of severely
missing, e.g., 90% training examples may have incomplete modalities. For the
first time in the literature, this paper formally studies multimodal learning
with missing modality in terms of flexibility (missing modalities in training,
testing, or both) and efficiency (most training data have incomplete modality).
Technically, we propose a new method named SMIL that leverages Bayesian
meta-learning in uniformly achieving both objectives. To validate our idea, we
conduct a series of experiments on three popular benchmarks: MM-IMDb, CMU-MOSI,
and avMNIST. The results prove the state-of-the-art performance of SMIL over
existing methods and generative baselines including autoencoders and generative
adversarial networks. Our code is available at
https://github.com/mengmenm/SMIL.",1,0,1,0,1,0,0.642414,8.0,0.802318,53
http://arxiv.org/abs/2105.02061v1,Proposal-free One-stage Referring Expression via Grid-Word Cross-Attention,13,0.184824,0.597972,"Referring Expression Comprehension (REC) has become one of the most important
tasks in visual reasoning, since it is an essential step for many
vision-and-language tasks such as visual question answering. However, it has
not been widely used in many downstream tasks because it suffers 1) two-stage
methods exist heavy computation cost and inevitable error accumulation, and 2)
one-stage methods have to depend on lots of hyper-parameters (such as anchors)
to generate bounding box. In this paper, we present a proposal-free one-stage
(PFOS) model that is able to regress the region-of-interest from the image,
based on a textual query, in an end-to-end manner. Instead of using the
dominant anchor proposal fashion, we directly take the dense-grid of an image
as input for a cross-attention transformer that learns grid-word
correspondences. The final bounding box is predicted directly from the image
without the time-consuming anchor selection process that previous methods
suffer. Our model achieves the state-of-the-art performance on four referring
expression datasets with higher efficiency, comparing to previous best
one-stage and two-stage methods.",0,1,0,0,1,0,0.95374,8.0,0.939171,27
http://arxiv.org/abs/2110.11589v1,Text Counterfactuals via Latent Optimization and Shapley-Guided Search,15,0.0558922,0.235287,"We study the problem of generating counterfactual text for a classifier as a
means for understanding and debugging classification. Given a textual input and
a classification model, we aim to minimally alter the text to change the
model's prediction. White-box approaches have been successfully applied to
similar problems in vision where one can directly optimize the continuous
input. Optimization-based approaches become difficult in the language domain
due to the discrete nature of text. We bypass this issue by directly optimizing
in the latent space and leveraging a language model to generate candidate
modifications from optimized latent representations. We additionally use
Shapley values to estimate the combinatoric effect of multiple changes. We then
use these estimates to guide a beam search for the final counterfactual text.
We achieve favorable performance compared to recent white-box and black-box
baselines using human and automatic evaluations. Ablation studies show that
both latent optimization and the use of Shapley values improve success rate and
the quality of the generated counterfactuals.",0,1,0,0,0,0,0.766519,5.0,0.753066,34
http://arxiv.org/abs/2104.13636v2,Point Cloud Learning with Transformer,26,0.162494,0.61741,"Remarkable performance from Transformer networks in Natural Language
Processing promote the development of these models in dealing with computer
vision tasks such as image recognition and segmentation. In this paper, we
introduce a novel framework, called Multi-level Multi-scale Point Transformer
(MLMSPT) that works directly on the irregular point clouds for representation
learning. Specifically, a point pyramid transformer is investigated to model
features with diverse resolutions or scales we defined, followed by a
multi-level transformer module to aggregate contextual information from
different levels of each scale and enhance their interactions. While a
multi-scale transformer module is designed to capture the dependencies among
representations across different scales. Extensive evaluation on public
benchmark datasets demonstrate the effectiveness and the competitive
performance of our methods on 3D shape classification, segmentation tasks.",0,0,1,0,0,0,0.833085,5.0,0.794586,62
http://arxiv.org/abs/2109.02753v1,End-to-end Neural Information Status Classification,6,0.145088,0.398122,"Most previous studies on information status (IS) classification and bridging
anaphora recognition assume that the gold mention or syntactic tree information
is given (Hou et al., 2013; Roesiger et al., 2018; Hou, 2020; Yu and Poesio,
2020). In this paper, we propose an end-to-end neural approach for information
status classification. Our approach consists of a mention extraction component
and an information status assignment component. During the inference time, our
system takes a raw text as the input and generates mentions together with their
information status. On the ISNotes corpus (Markert et al., 2012), we show that
our information status assignment component achieves new state-of-the-art
results on fine-grained IS classification based on gold mentions. Furthermore,
our system performs significantly better than other baselines for both mention
extraction and fine-grained IS classification in the end-to-end setting.
Finally, we apply our system on BASHI (Roesiger, 2018) and SciCorp (Roesiger,
2016) to recognize referential bridging anaphora. We find that our end-to-end
system trained on ISNotes achieves competitive results on bridging anaphora
recognition compared to the previous state-of-the-art system that relies on
syntactic information and is trained on the in-domain datasets (Yu and Poesio,
2020).",1,1,0,0,1,0,0.242105,11.0,0.737053,41
http://arxiv.org/abs/2104.07253v2,Integration of Pre-trained Networks with Continuous Token Interface for End-to-End Spoken Language Understanding,28,0.344152,0.493078,"Most End-to-End (E2E) SLU networks leverage the pre-trained ASR networks but
still lack the capability to understand the semantics of utterances, crucial
for the SLU task. To solve this, recently proposed studies use pre-trained NLU
networks. However, it is not trivial to fully utilize both pre-trained
networks; many solutions were proposed, such as Knowledge Distillation,
cross-modal shared embedding, and network integration with Interface. We
propose a simple and robust integration method for the E2E SLU network with
novel Interface, Continuous Token Interface (CTI), the junctional
representation of the ASR and NLU networks when both networks are pre-trained
with the same vocabulary. Because the only difference is the noise level, we
directly feed the ASR network's output to the NLU network. Thus, we can train
our SLU network in an E2E manner without additional modules, such as
Gumbel-Softmax. We evaluate our model using SLURP, a challenging SLU dataset
and achieve state-of-the-art scores on both intent classification and slot
filling tasks. We also verify the NLU network, pre-trained with Masked Language
Model, can utilize a noisy textual representation of CTI. Moreover, we show our
model can be trained with multi-task learning from heterogeneous data even
after integration with CTI.",0,1,0,0,1,0,0.78415,4.0,0.704475,35
http://arxiv.org/abs/2109.02229v3,Efficient Combinatorial Optimization for Word-level Adversarial Textual Attack,23,0.109638,0.592395,"Over the past few years, various word-level textual attack approaches have
been proposed to reveal the vulnerability of deep neural networks used in
natural language processing. Typically, these approaches involve an important
optimization step to determine which substitute to be used for each word in the
original input. However, current research on this step is still rather limited,
from the perspectives of both problem-understanding and problem-solving. In
this paper, we address these issues by uncovering the theoretical properties of
the problem and proposing an efficient local search algorithm (LS) to solve it.
We establish the first provable approximation guarantee on solving the problem
in general cases.Extensive experiments involving 5 NLP tasks, 8 datasets and 26
NLP models show that LS can largely reduce the number of queries usually by an
order of magnitude to achieve high attack success rates. Further experiments
show that the adversarial examples crafted by LS usually have higher quality,
exhibit better transferability, and can bring more robustness improvement to
victim models by adversarial training.",1,0,0,0,0,0,0.512577,7.0,0.722878,51
http://arxiv.org/abs/2106.04315v2,Learning Riemannian Manifolds for Geodesic Motion Skills,24,0.315117,0.953861,"For robots to work alongside humans and perform in unstructured environments,
they must learn new motion skills and adapt them to unseen situations on the
fly. This demands learning models that capture relevant motion patterns, while
offering enough flexibility to adapt the encoded skills to new requirements,
such as dynamic obstacle avoidance. We introduce a Riemannian manifold
perspective on this problem, and propose to learn a Riemannian manifold from
human demonstrations on which geodesics are natural motion skills. We realize
this with a variational autoencoder (VAE) over the space of position and
orientations of the robot end-effector. Geodesic motion skills let a robot plan
movements from and to arbitrary points on the data manifold. They also provide
a straightforward method to avoid obstacles by redefining the ambient metric in
an online fashion. Moreover, geodesics naturally exploit the manifold resulting
from multiple--mode tasks to design motions that were not explicitly
demonstrated previously. We test our learning framework using a 7-DoF robotic
manipulator, where the robot satisfactorily learns and reproduces realistic
skills featuring elaborated motion patterns, avoids previously unseen
obstacles, and generates novel movements in multiple-mode settings.",0,1,0,0,0,0,0.299445,8.0,0.669676,41
http://arxiv.org/abs/2102.11051v1,Improved Learning of Robot Manipulation Tasks via Tactile Intrinsic Motivation,16,0.0870131,0.513299,"In this paper we address the challenge of exploration in deep reinforcement
learning for robotic manipulation tasks. In sparse goal settings, an agent does
not receive any positive feedback until randomly achieving the goal, which
becomes infeasible for longer control sequences. Inspired by touch-based
exploration observed in children, we formulate an intrinsic reward based on the
sum of forces between a robot's force sensors and manipulation objects that
encourages physical interaction. Furthermore, we introduce contact-prioritized
experience replay, a sampling scheme that prioritizes contact rich episodes and
transitions. We show that our solution accelerates the exploration and
outperforms state-of-the-art methods on three fundamental robot manipulation
benchmarks.",0,1,0,0,1,0,0.485909,7.0,0.711875,32
http://arxiv.org/abs/2103.07785v1,Deep Discourse Analysis for Generating Personalized Feedback in Intelligent Tutor Systems,16,0.172252,0.583252,"We explore creating automated, personalized feedback in an intelligent
tutoring system (ITS). Our goal is to pinpoint correct and incorrect concepts
in student answers in order to achieve better student learning gains. Although
automatic methods for providing personalized feedback exist, they do not
explicitly inform students about which concepts in their answers are correct or
incorrect. Our approach involves decomposing students answers using neural
discourse segmentation and classification techniques. This decomposition yields
a relational graph over all discourse units covered by the reference solutions
and student answers. We use this inferred relational graph structure and a
neural classifier to match student answers with reference solutions and
generate personalized feedback. Although the process is completely automated
and data-driven, the personalized feedback generated is highly contextual,
domain-aware and effectively targets each student's misconceptions and
knowledge gaps. We test our method in a dialogue-based ITS and demonstrate that
our approach results in high-quality feedback and significantly improved
student learning gains.",0,1,0,0,0,0,0.19772,9.0,0.653088,52
http://arxiv.org/abs/2105.09383v1,Guaranteeing Maximin Shares: Some Agents Left Behind,14,0.252398,0.373928,"The maximin share (MMS) guarantee is a desirable fairness notion for
allocating indivisible goods. While MMS allocations do not always exist,
several approximation techniques have been developed to ensure that all agents
receive a fraction of their maximin share. We focus on an alternative
approximation notion, based on the population of agents, that seeks to
guarantee MMS for a fraction of agents. We show that no optimal approximation
algorithm can satisfy more than a constant number of agents, and discuss the
existence and computation of MMS for all but one agent and its relation to
approximate MMS guarantees. We then prove the existence of allocations that
guarantee MMS for $\frac{2}{3}$ of agents, and devise a polynomial time
algorithm that achieves this bound for up to nine agents. A key implication of
our result is the existence of allocations that guarantee
$\text{MMS}^{\lceil{3n/2}\rceil}$, i.e., the value that agents receive by
partitioning the goods into $\lceil{\frac{3}{2}n}\rceil$ bundles, improving the
best known guarantee of $\text{MMS}^{2n-2}$. Finally, we provide empirical
experiments using synthetic data.",0,0,0,0,0,0,0.209992,10.0,0.694542,52
http://arxiv.org/abs/2101.11431v2,SkillNER: Mining and Mapping Soft Skills from any Text,34,0.0925157,0.789621,"In today's digital world, there is an increasing focus on soft skills. On the
one hand, they facilitate innovation at companies, but on the other, they are
unlikely to be automated soon. Researchers struggle with accurately approaching
quantitatively the study of soft skills due to the lack of data-driven methods
to retrieve them. This limits the possibility for psychologists and HR managers
to understand the relation between humans and digitalisation. This paper
presents SkillNER, a novel data-driven method for automatically extracting soft
skills from text. It is a named entity recognition (NER) system trained with a
support vector machine (SVM) on a corpus of more than 5000 scientific papers.
We developed this system by measuring the performance of our approach against
different training models and validating the results together with a team of
psychologists. Finally, SkillNER was tested in a real-world case study using
the job descriptions of ESCO (European Skill/Competence Qualification and
Occupation) as textual source. The system enabled the detection of communities
of job profiles based on their shared soft skills and communities of soft
skills based on their shared job profiles. This case study demonstrates that
the tool can automatically retrieve soft skills from a large corpus in an
efficient way, proving useful for firms, institutions, and workers. The tool is
open and available online to foster quantitative methods for the study of soft
skills.",0,1,0,0,0,0,0.044993,8.0,0.414031,60
http://arxiv.org/abs/2107.04362v1,RGB Stream Is Enough for Temporal Action Detection,21,0.285781,0.397105,"State-of-the-art temporal action detectors to date are based on two-stream
input including RGB frames and optical flow. Although combining RGB frames and
optical flow boosts performance significantly, optical flow is a hand-designed
representation which not only requires heavy computation, but also makes it
methodologically unsatisfactory that two-stream methods are often not learned
end-to-end jointly with the flow. In this paper, we argue that optical flow is
dispensable in high-accuracy temporal action detection and image level data
augmentation (ILDA) is the key solution to avoid performance degradation when
optical flow is removed. To evaluate the effectiveness of ILDA, we design a
simple yet efficient one-stage temporal action detector based on single RGB
stream named DaoTAD. Our results show that when trained with ILDA, DaoTAD has
comparable accuracy with all existing state-of-the-art two-stream detectors
while surpassing the inference speed of previous methods by a large margin and
the inference speed is astounding 6668 fps on GeForce GTX 1080 Ti. Code is
available at \url{https://github.com/Media-Smart/vedatad}.",1,1,0,0,1,0,0.946799,7.0,0.923831,61
http://arxiv.org/abs/2109.04404v1,All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality,78,0.170307,0.668195,"Similarity measures are a vital tool for understanding how language models
represent and process language. Standard representational similarity measures
such as cosine similarity and Euclidean distance have been successfully used in
static word embedding models to understand how words cluster in semantic space.
Recently, these measures have been applied to embeddings from contextualized
models such as BERT and GPT-2. In this work, we call into question the
informativity of such measures for contextualized language models. We find that
a small number of rogue dimensions, often just 1-3, dominate these measures.
Moreover, we find a striking mismatch between the dimensions that dominate
similarity measures and those which are important to the behavior of the model.
We show that simple postprocessing techniques such as standardization are able
to correct for rogue dimensions and reveal underlying representational quality.
We argue that accounting for rogue dimensions is essential for any
similarity-based analysis of contextual language models.",1,0,0,0,0,0,0.350559,5.0,0.510081,47
http://arxiv.org/abs/2101.03553v1,"Summaformers @ LaySumm 20, LongSumm 20",13,0.0501242,0.466806,"Automatic text summarization has been widely studied as an important task in
natural language processing. Traditionally, various feature engineering and
machine learning based systems have been proposed for extractive as well as
abstractive text summarization. Recently, deep learning based, specifically
Transformer-based systems have been immensely popular. Summarization is a
cognitively challenging task - extracting summary worthy sentences is
laborious, and expressing semantics in brief when doing abstractive
summarization is complicated. In this paper, we specifically look at the
problem of summarizing scientific research papers from multiple domains. We
differentiate between two types of summaries, namely, (a) LaySumm: A very short
summary that captures the essence of the research paper in layman terms
restricting overtly specific technical jargon and (b) LongSumm: A much longer
detailed summary aimed at providing specific insights into various ideas
touched upon in the paper. While leveraging latest Transformer-based models,
our systems are simple, intuitive and based on how specific paper sections
contribute to human summaries of the two types described above. Evaluations
against gold standard summaries using ROUGE metrics prove the effectiveness of
our approach. On blind test corpora, our system ranks first and third for the
LongSumm and LaySumm tasks respectively.",0,1,0,0,0,0,0.499311,6.0,0.670344,28
http://arxiv.org/abs/2109.12093v2,SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction,32,0.440918,0.963388,"Stepping from sentence-level to document-level, the research on relation
extraction (RE) confronts increasing text length and more complicated entity
interactions. Consequently, it is more challenging to encode the key
information sources--relevant contexts and entity types. However, existing
methods only implicitly learn to model these critical information sources while
being trained for RE. As a result, they suffer the problems of ineffective
supervision and uninterpretable model predictions. In contrast, we propose to
explicitly teach the model to capture relevant contexts and entity types by
supervising and augmenting intermediate steps (SAIS) for RE. Based on a broad
spectrum of carefully designed tasks, our proposed SAIS method not only
extracts relations of better quality due to more effective supervision, but
also retrieves the corresponding supporting evidence more accurately so as to
enhance interpretability. By assessing model uncertainty, SAIS further boosts
the performance via evidence-based data augmentation and ensemble inference
while reducing the computational cost. Eventually, SAIS delivers
state-of-the-art RE results on three benchmarks (DocRED, CDR, and GDA) and
outperforms the runner-up by 5.04% relatively in F1 score in evidence retrieval
on DocRED.",0,1,0,0,1,0,0.923615,5.0,0.867047,54
http://arxiv.org/abs/2109.06671v2,High-Resolution Image Harmonization via Collaborative Dual Transformations,59,0.145924,0.886059,"Given a composite image, image harmonization aims to adjust the foreground to
make it compatible with the background. High-resolution image harmonization is
in high demand, but still remains unexplored. Conventional image harmonization
methods learn global RGB-to-RGB transformation which could effortlessly scale
to high resolution, but ignore diverse local context. Recent deep learning
methods learn the dense pixel-to-pixel transformation which could generate
harmonious outputs, but are highly constrained in low resolution. In this work,
we propose a high-resolution image harmonization network with Collaborative
Dual Transformation (CDTNet) to combine pixel-to-pixel transformation and
RGB-to-RGB transformation coherently in an end-to-end network. Our CDTNet
consists of a low-resolution generator for pixel-to-pixel transformation, a
color mapping module for RGB-to-RGB transformation, and a refinement module to
take advantage of both. Extensive experiments on high-resolution benchmark
dataset and our created high-resolution real composite images demonstrate that
our CDTNet strikes a good balance between efficiency and effectiveness. Our
used datasets can be found in
https://github.com/bcmi/CDTNet-High-Resolution-Image-Harmonization.",1,0,0,0,0,0,0.0522432,8.0,0.433178,46
http://arxiv.org/abs/2109.04715v1,AfroMT: Pretraining Strategies and Reproducible Benchmarks for Translation of 8 African Languages,25,0.0412787,0.613815,"Reproducible benchmarks are crucial in driving progress of machine
translation research. However, existing machine translation benchmarks have
been mostly limited to high-resource or well-represented languages. Despite an
increasing interest in low-resource machine translation, there are no
standardized reproducible benchmarks for many African languages, many of which
are used by millions of speakers but have less digitized textual data. To
tackle these challenges, we propose AfroMT, a standardized, clean, and
reproducible machine translation benchmark for eight widely spoken African
languages. We also develop a suite of analysis tools for system diagnosis
taking into account the unique properties of these languages. Furthermore, we
explore the newly considered case of low-resource focused pretraining and
develop two novel data augmentation-based strategies, leveraging word-level
alignment information and pseudo-monolingual data for pretraining multilingual
sequence-to-sequence models. We demonstrate significant improvements when
pretraining on 11 languages, with gains of up to 2 BLEU points over strong
baselines. We also show gains of up to 12 BLEU points over cross-lingual
transfer baselines in data-constrained scenarios. All code and pretrained
models will be released as further steps towards larger reproducible benchmarks
for African languages.",1,1,1,1,0,0,0.334124,6.0,0.581794,52
http://arxiv.org/abs/2110.08486v4,Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals,19,0.20153,0.647573,"The ability to sequence unordered events is an essential skill to comprehend
and reason about real world task procedures, which often requires thorough
understanding of temporal common sense and multimodal information, as these
procedures are often communicated through a combination of texts and images.
Such capability is essential for applications such as sequential task planning
and multi-source instruction summarization. While humans are capable of
reasoning about and sequencing unordered multimodal procedural instructions,
whether current machine learning models have such essential capability is still
an open question. In this work, we benchmark models' capability of reasoning
over and sequencing unordered multimodal instructions by curating datasets from
popular online instructional manuals and collecting comprehensive human
annotations. We find models not only perform significantly worse than humans
but also seem incapable of efficiently utilizing the multimodal information. To
improve machines' performance on multimodal event sequencing, we propose
sequentiality-aware pretraining techniques that exploit the sequential
alignment properties of both texts and images, resulting in > 5% significant
improvements.",0,0,0,1,0,0,0.700233,5.0,0.715367,56
http://arxiv.org/abs/2109.00475v2,Capturing Stance Dynamics in Social Media: Open Challenges and Research Directions,14,0.0794051,0.479146,"Social media platforms provide a goldmine for mining public opinion on issues
of wide societal interest and impact. Opinion mining is a problem that can be
operationalised by capturing and aggregating the stance of individual social
media posts as supporting, opposing or being neutral towards the issue at hand.
While most prior work in stance detection has investigated datasets that cover
short periods of time, interest in investigating longitudinal datasets has
recently increased. Evolving dynamics in linguistic and behavioural patterns
observed in new data require adapting stance detection systems to deal with the
changes. In this survey paper, we investigate the intersection between
computational linguistics and the temporal evolution of human communication in
digital media. We perform a critical review of emerging research considering
dynamics, exploring different semantic and pragmatic factors that impact
linguistic data in general, and stance in particular. We further discuss
current directions in capturing stance dynamics in social media. We discuss the
challenges encountered when dealing with stance dynamics, identify open
challenges and discuss future directions in three key dimensions: utterance,
context and influence.",0,0,0,0,0,0,0.0289301,9.0,0.429148,114
http://arxiv.org/abs/2103.08082v1,Exploring Genetic-histologic Relationships in Breast Cancer,5,0.132041,0.19175,"The advent of digital pathology presents opportunities for computer vision
for fast, accurate, and objective solutions for histopathological images and
aid in knowledge discovery. This work uses deep learning to predict genomic
biomarkers - TP53 mutation, PIK3CA mutation, ER status, PR status, HER2 status,
and intrinsic subtypes, from breast cancer histopathology images. Furthermore,
we attempt to understand the underlying morphology as to how these genomic
biomarkers manifest in images. Since gene sequencing is expensive, not always
available, or even feasible, predicting these biomarkers from images would help
in diagnosis, prognosis, and effective treatment planning. We outperform the
existing works with a minimum improvement of 0.02 and a maximum of 0.13 AUROC
scores across all tasks. We also gain insights that can serve as hypotheses for
further experimentations, including the presence of lymphocytes and
karyorrhexis. Moreover, our fully automated workflow can be extended to other
tasks across other cancer subtypes.",1,1,0,0,1,0,0.934877,6.0,0.899234,21
http://arxiv.org/abs/2104.09887v1,Comparing Representations in Tracking for Event Camera-based SLAM,24,0.548605,0.726099,"This paper investigates two typical image-type representations for event
camera-based tracking: time surface (TS) and event map (EM). Based on the
original TS-based tracker, we make use of these two representations'
complementary strengths to develop an enhanced version. The proposed tracker
consists of a general strategy to evaluate the optimization problem's
degeneracy online and then switch proper representations. Both TS and EM are
motion- and scene-dependent, and thus it is important to figure out their
limitations in tracking. We develop six tracker variations and conduct a
thorough comparison of them on sequences covering various scenarios and motion
complexities. We release our implementations and detailed results to benefit
the research community on event cameras: https:
//github.com/gogojjh/ESVO_extension.",1,1,0,0,0,0,0.90155,8.0,0.903919,34
http://arxiv.org/abs/2110.13495v1,Assessing the Sufficiency of Arguments through Conclusion Generation,21,0.361144,0.935684,"The premises of an argument give evidence or other reasons to support a
conclusion. However, the amount of support required depends on the generality
of a conclusion, the nature of the individual premises, and similar. An
argument whose premises make its conclusion rationally worthy to be drawn is
called sufficient in argument quality research. Previous work tackled
sufficiency assessment as a standard text classification problem, not modeling
the inherent relation of premises and conclusion. In this paper, we hypothesize
that the conclusion of a sufficient argument can be generated from its
premises. To study this hypothesis, we explore the potential of assessing
sufficiency based on the output of large-scale pre-trained language models. Our
best model variant achieves an F1-score of .885, outperforming the previous
state-of-the-art and being on par with human experts. While manual evaluation
reveals the quality of the generated conclusions, their impact remains low
ultimately.",1,0,0,0,1,0,0.788563,5.0,0.766257,23
http://arxiv.org/abs/2106.03635v1,GTM: A Generative Triple-Wise Model for Conversational Question Generation,12,0.153192,0.425687,"Generating some appealing questions in open-domain conversations is an
effective way to improve human-machine interactions and lead the topic to a
broader or deeper direction. To avoid dull or deviated questions, some
researchers tried to utilize answer, the ""future"" information, to guide
question generation. However, they separate a post-question-answer (PQA) triple
into two parts: post-question (PQ) and question-answer (QA) pairs, which may
hurt the overall coherence. Besides, the QA relationship is modeled as a
one-to-one mapping that is not reasonable in open-domain conversations. To
tackle these problems, we propose a generative triple-wise model with
hierarchical variations for open-domain conversational question generation
(CQG). Latent variables in three hierarchies are used to represent the shared
background of a triple and one-to-many semantic mappings in both PQ and QA
pairs. Experimental results on a large-scale CQG dataset show that our method
significantly improves the quality of questions in terms of fluency, coherence
and diversity over competitive baselines.",0,0,0,0,0,0,0.343821,9.0,0.725134,49
http://arxiv.org/abs/2101.00196v1,On Explaining Your Explanations of BERT: An Empirical Study with Sequence Classification,17,0.0289878,0.200943,"BERT, as one of the pretrianed language models, attracts the most attention
in recent years for creating new benchmarks across GLUE tasks via fine-tuning.
One pressing issue is to open up the blackbox and explain the decision makings
of BERT. A number of attribution techniques have been proposed to explain BERT
models, but are often limited to sequence to sequence tasks. In this paper, we
adapt existing attribution methods on explaining decision makings of BERT in
sequence classification tasks. We conduct extensive analyses of four existing
attribution methods by applying them to four different datasets in sentiment
analysis. We compare the reliability and robustness of each method via various
ablation studies. Furthermore, we test whether attribution methods explain
generalized semantics across semantically similar tasks. Our work provides
solid guidance for using attribution methods to explain decision makings of
BERT for downstream classification tasks.",1,0,0,0,0,0,0.853486,4.0,0.760804,32
http://arxiv.org/abs/2103.13823v2,A Novel Adaptive Minority Oversampling Technique for Improved Classification in Data Imbalanced Scenarios,3,0.0155222,0.159698,"Imbalance in the proportion of training samples belonging to different
classes often poses performance degradation of conventional classifiers. This
is primarily due to the tendency of the classifier to be biased towards the
majority classes in the imbalanced dataset. In this paper, we propose a novel
three step technique to address imbalanced data. As a first step we
significantly oversample the minority class distribution by employing the
traditional Synthetic Minority OverSampling Technique (SMOTE) algorithm using
the neighborhood of the minority class samples and in the next step we
partition the generated samples using a Gaussian-Mixture Model based clustering
algorithm. In the final step synthetic data samples are chosen based on the
weight associated with the cluster, the weight itself being determined by the
distribution of the majority class samples. Extensive experiments on several
standard datasets from diverse domains shows the usefulness of the proposed
technique in comparison with the original SMOTE and its state-of-the-art
variants algorithms.",0,1,0,0,1,0,0.0157605,17.0,0.661661,46
http://arxiv.org/abs/2103.12091v2,Transformer-Based Attention Networks for Continuous Pixel-Wise Prediction,134,0.905592,0.995632,"While convolutional neural networks have shown a tremendous impact on various
computer vision tasks, they generally demonstrate limitations in explicitly
modeling long-range dependencies due to the intrinsic locality of the
convolution operation. Initially designed for natural language processing
tasks, Transformers have emerged as alternative architectures with innate
global self-attention mechanisms to capture long-range dependencies. In this
paper, we propose TransDepth, an architecture that benefits from both
convolutional neural networks and transformers. To avoid the network losing its
ability to capture local-level details due to the adoption of transformers, we
propose a novel decoder that employs attention mechanisms based on gates.
Notably, this is the first paper that applies transformers to pixel-wise
prediction problems involving continuous labels (i.e., monocular depth
prediction and surface normal estimation). Extensive experiments demonstrate
that the proposed TransDepth achieves state-of-the-art performance on three
challenging datasets. Our code is available at:
https://github.com/ygjwd12345/TransDepth.",1,1,1,0,1,0,0.918818,5.0,0.862253,73
http://arxiv.org/abs/2112.08608v2,"QuALITY: Question Answering with Long Input Texts, Yes!",86,0.600643,0.999908,"To enable building and testing models on long-document comprehension, we
introduce QuALITY, a multiple-choice QA dataset with context passages in
English that have an average length of about 5,000 tokens, much longer than
typical current models can process. Unlike in prior work with passages, our
questions are written and validated by contributors who have read the entire
passage, rather than relying on summaries or excerpts. In addition, only half
of the questions are answerable by annotators working under tight time
constraints, indicating that skimming and simple search are not enough to
consistently perform well. Our baseline models perform poorly on this task
(55.4%) and significantly lag behind human performance (93.5%).",1,1,1,1,0,0,0.90565,5.0,0.849908,44
http://arxiv.org/abs/2103.12882v1,TeCoMiner: Topic Discovery Through Term Community Detection,3,0.00401299,0.0590467,"This note is a short description of TeCoMiner, an interactive tool for
exploring the topic content of text collections. Unlike other topic modeling
tools, TeCoMiner is not based on some generative probabilistic model but on
topological considerations about co-occurrence networks of terms. We outline
the methods used for identifying topics, describe the features of the tool, and
sketch an application, using a corpus of policy related scientific news on
environmental issues published by the European Commission over the last decade.",0,0,0,0,0,0,0.0551638,10.0,0.552135,22
http://arxiv.org/abs/2111.08609v1,"Document AI: Benchmarks, Models and Applications",47,0.738931,0.979438,"Document AI, or Document Intelligence, is a relatively new research topic
that refers to the techniques for automatically reading, understanding, and
analyzing business documents. It is an important research direction for natural
language processing and computer vision. In recent years, the popularity of
deep learning technology has greatly advanced the development of Document AI,
such as document layout analysis, visual information extraction, document
visual question answering, document image classification, etc. This paper
briefly reviews some of the representative models, tasks, and benchmark
datasets. Furthermore, we also introduce early-stage heuristic rule-based
document analysis, statistical machine learning algorithms, and deep learning
approaches especially pre-training methods. Finally, we look into future
directions for Document AI research.",0,1,0,0,0,0,0.815041,6.0,0.81898,117
http://arxiv.org/abs/2104.09993v2,Fine-grained Anomaly Detection via Multi-task Self-Supervision,6,0.0221638,0.140117,"Detecting anomalies using deep learning has become a major challenge over the
last years, and is becoming increasingly promising in several fields. The
introduction of self-supervised learning has greatly helped many methods
including anomaly detection where simple geometric transformation recognition
tasks are used. However these methods do not perform well on fine-grained
problems since they lack finer features. By combining in a multi-task framework
high-scale shape features oriented task with low-scale fine features oriented
task, our method greatly improves fine-grained anomaly detection. It
outperforms state-of-the-art with up to 31% relative error reduction measured
with AUROC on various anomaly detection problems.",0,1,0,0,1,0,0.683769,7.0,0.790205,43
http://arxiv.org/abs/2106.00829v1,ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining,49,0.476779,0.776508,"While online conversations can cover a vast amount of information in many
different formats, abstractive text summarization has primarily focused on
modeling solely news articles. This research gap is due, in part, to the lack
of standardized datasets for summarizing online discussions. To address this
gap, we design annotation protocols motivated by an
issues--viewpoints--assertions framework to crowdsource four new datasets on
diverse online conversation forms of news comments, discussion forums,
community question answering forums, and email threads. We benchmark
state-of-the-art models on our datasets and analyze characteristics associated
with the data. To create a comprehensive benchmark, we also evaluate these
models on widely-used conversation summarization datasets to establish strong
baselines in this domain. Furthermore, we incorporate argument mining through
graph construction to directly model the issues, viewpoints, and assertions
present in a conversation and filter noisy input, showing comparable or
improved results according to automatic and human evaluations.",1,1,1,1,1,0,0.574229,6.0,0.705428,79
http://arxiv.org/abs/2111.00607v3,A Systematic Investigation of Commonsense Knowledge in Large Language Models,39,0.452306,0.918191,"Language models (LMs) trained on large amounts of data have shown impressive
performance on many NLP tasks under the zero-shot and few-shot setup. Here we
aim to better understand the extent to which such models learn commonsense
knowledge -- a critical component of many NLP applications. We conduct a
systematic and rigorous zero-shot and few-shot commonsense evaluation of large
pre-trained LMs, where we: (i) carefully control for the LMs' ability to
exploit potential surface cues and annotation artefacts, and (ii) account for
variations in performance that arise from factors that are not related to
commonsense knowledge. Our findings highlight the limitations of pre-trained
LMs in acquiring commonsense knowledge without task-specific supervision;
furthermore, using larger models or few-shot evaluation are insufficient to
achieve human-level commonsense performance.",0,0,0,0,0,1,0.946496,5.0,0.892976,66
http://arxiv.org/abs/2110.03560v1,Magic dust for cross-lingual adaptation of monolingual wav2vec-2.0,18,0.214967,0.584443,"We propose a simple and effective cross-lingual transfer learning method to
adapt monolingual wav2vec-2.0 models for Automatic Speech Recognition (ASR) in
resource-scarce languages. We show that a monolingual wav2vec-2.0 is a good
few-shot ASR learner in several languages. We improve its performance further
via several iterations of Dropout Uncertainty-Driven Self-Training (DUST) by
using a moderate-sized unlabeled speech dataset in the target language. A key
finding of this work is that the adapted monolingual wav2vec-2.0 achieves
similar performance as the topline multilingual XLSR model, which is trained on
fifty-three languages, on the target language ASR task.",0,1,0,0,0,0,0.882978,5.0,0.830777,27
http://arxiv.org/abs/2108.02421v1,Intelligent Railway Foreign Object Detection: A Semi-supervised Convolutional Autoencoder Based Method,10,0.632157,0.76792,"Automated inspection and detection of foreign objects on railways is
important for rail transportation safety as it helps prevent potential
accidents and trains derailment. Most existing vision-based approaches focus on
the detection of frontal intrusion objects with prior labels, such as
categories and locations of the objects. In reality, foreign objects with
unknown categories can appear anytime on railway tracks. In this paper, we
develop a semi-supervised convolutional autoencoder based framework that only
requires railway track images without prior knowledge on the foreign objects in
the training process. It consists of three different modules, a bottleneck
feature generator as encoder, a photographic image generator as decoder, and a
reconstruction discriminator developed via adversarial learning. In the
proposed framework, the problem of detecting the presence, location, and shape
of foreign objects is addressed by comparing the input and reconstructed images
as well as setting thresholds based on reconstruction errors. The proposed
method is evaluated through comprehensive studies under different performance
criteria. The results show that the proposed method outperforms some well-known
benchmarking methods. The proposed framework is useful for data analytics via
the train Internet-of-Things (IoT) systems",0,1,0,0,1,0,0.971735,9.0,0.96245,26
http://arxiv.org/abs/2105.08261v1,KECRS: Towards Knowledge-Enriched Conversational Recommendation System,22,0.331794,0.678903,"The chit-chat-based conversational recommendation systems (CRS) provide item
recommendations to users through natural language interactions. To better
understand user's intentions, external knowledge graphs (KG) have been
introduced into chit-chat-based CRS. However, existing chit-chat-based CRS
usually generate repetitive item recommendations, and they cannot properly
infuse knowledge from KG into CRS to generate informative responses. To remedy
these issues, we first reformulate the conversational recommendation task to
highlight that the recommended items should be new and possibly interested by
users. Then, we propose the Knowledge-Enriched Conversational Recommendation
System (KECRS). Specifically, we develop the Bag-of-Entity (BOE) loss and the
infusion loss to better integrate KG with CRS for generating more diverse and
informative responses. BOE loss provides an additional supervision signal to
guide CRS to learn from both human-written utterances and KG. Infusion loss
bridges the gap between the word embeddings and entity embeddings by minimizing
distances of the same words in these two embeddings. Moreover, we facilitate
our study by constructing a high-quality KG, \ie The Movie Domain Knowledge
Graph (TMDKG). Experimental results on a large-scale dataset demonstrate that
KECRS outperforms state-of-the-art chit-chat-based CRS, in terms of both
recommendation accuracy and response generation quality.",0,0,0,1,1,0,0.93716,6.0,0.901398,40
http://arxiv.org/abs/2101.00939v1,CRSLab: An Open-Source Toolkit for Building Conversational Recommender System,51,0.443416,0.788763,"In recent years, conversational recommender system (CRS) has received much
attention in the research community. However, existing studies on CRS vary in
scenarios, goals and techniques, lacking unified, standardized implementation
or comparison. To tackle this challenge, we propose an open-source CRS toolkit
CRSLab, which provides a unified and extensible framework with highly-decoupled
modules to develop CRSs. Based on this framework, we collect 6 commonly-used
human-annotated CRS datasets and implement 18 models that include recent
techniques such as graph neural network and pre-training models. Besides, our
toolkit provides a series of automatic evaluation protocols and a human-machine
interaction interface to test and compare different CRS methods. The project
and documents are released at https://github.com/RUCAIBox/CRSLab.",1,1,0,1,0,0,0.94188,5.0,0.887242,34
http://arxiv.org/abs/2109.04456v1,NEAT: Neural Attention Fields for End-to-End Autonomous Driving,158,0.553803,0.982677,"Efficient reasoning about the semantic, spatial, and temporal structure of a
scene is a crucial prerequisite for autonomous driving. We present NEural
ATtention fields (NEAT), a novel representation that enables such reasoning for
end-to-end imitation learning models. NEAT is a continuous function which maps
locations in Bird's Eye View (BEV) scene coordinates to waypoints and
semantics, using intermediate attention maps to iteratively compress
high-dimensional 2D image features into a compact representation. This allows
our model to selectively attend to relevant regions in the input while ignoring
information irrelevant to the driving task, effectively associating the images
with the BEV representation. In a new evaluation setting involving adverse
environmental conditions and challenging scenarios, NEAT outperforms several
strong baselines and achieves driving scores on par with the privileged CARLA
expert used to generate its training data. Furthermore, visualizing the
attention maps for models with NEAT intermediate representations provides
improved interpretability.",1,1,0,0,0,0,0.710351,4.0,0.651234,81
http://arxiv.org/abs/2104.05700v1,Macro-Average: Rare Types Are Important Too,20,0.0331615,0.465189,"While traditional corpus-level evaluation metrics for machine translation
(MT) correlate well with fluency, they struggle to reflect adequacy.
Model-based MT metrics trained on segment-level human judgments have emerged as
an attractive replacement due to strong correlation results. These models,
however, require potentially expensive re-training for new domains and
languages. Furthermore, their decisions are inherently non-transparent and
appear to reflect unwelcome biases. We explore the simple type-based classifier
metric, MacroF1, and study its applicability to MT evaluation. We find that
MacroF1 is competitive on direct assessment, and outperforms others in
indicating downstream cross-lingual information retrieval task performance.
Further, we show that MacroF1 can be used to effectively compare supervised and
unsupervised neural machine translation, and reveal significant qualitative
differences in the methods' outputs.",1,1,0,0,0,0,0.114442,8.0,0.535378,52
http://arxiv.org/abs/2108.06543v1,"MMOCR: A Comprehensive Toolbox for Text Detection, Recognition and Understanding",51,0.182101,0.866766,"We present MMOCR-an open-source toolbox which provides a comprehensive
pipeline for text detection and recognition, as well as their downstream tasks
such as named entity recognition and key information extraction. MMOCR
implements 14 state-of-the-art algorithms, which is significantly more than all
the existing open-source OCR projects we are aware of to date. To facilitate
future research and industrial applications of text recognition-related
problems, we also provide a large number of trained models and detailed
benchmarks to give insights into the performance of text detection, recognition
and understanding. MMOCR is publicly released at
https://github.com/open-mmlab/mmocr.",1,1,0,0,0,0,0.360179,7.0,0.654913,47
http://arxiv.org/abs/2104.05279v2,Class-Balanced Distillation for Long-Tailed Visual Recognition,26,0.287082,0.552271,"Real-world imagery is often characterized by a significant imbalance of the
number of images per class, leading to long-tailed distributions. An effective
and simple approach to long-tailed visual recognition is to learn feature
representations and a classifier separately, with instance and class-balanced
sampling, respectively. In this work, we introduce a new framework, by making
the key observation that a feature representation learned with instance
sampling is far from optimal in a long-tailed setting. Our main contribution is
a new training method, referred to as Class-Balanced Distillation (CBD), that
leverages knowledge distillation to enhance feature representations. CBD allows
the feature representation to evolve in the second training stage, guided by
the teacher learned in the first stage. The second stage uses class-balanced
sampling, in order to focus on under-represented classes. This framework can
naturally accommodate the usage of multiple teachers, unlocking the information
from an ensemble of models to enhance recognition capabilities. Our experiments
show that the proposed technique consistently outperforms the state of the art
on long-tailed recognition benchmarks such as ImageNet-LT, iNaturalist17 and
iNaturalist18.",1,1,0,0,1,0,0.947932,5.0,0.894826,67
http://arxiv.org/abs/2104.09403v1,OmniLayout: Room Layout Reconstruction from Indoor Spherical Panoramas,8,0.188315,0.503143,"Given a single RGB panorama, the goal of 3D layout reconstruction is to
estimate the room layout by predicting the corners, floor boundary, and ceiling
boundary. A common approach has been to use standard convolutional networks to
predict the corners and boundaries, followed by post-processing to generate the
3D layout. However, the space-varying distortions in panoramic images are not
compatible with the translational equivariance property of standard
convolutions, thus degrading performance. Instead, we propose to use spherical
convolutions. The resulting network, which we call OmniLayout performs
convolutions directly on the sphere surface, sampling according to inverse
equirectangular projection and hence invariant to equirectangular distortions.
Using a new evaluation metric, we show that our network reduces the error in
the heavily distorted regions (near the poles) by approx 25 % when compared to
standard convolutional networks. Experimental results show that OmniLayout
outperforms the state-of-the-art by approx 4% on two different benchmark
datasets (PanoContext and Stanford 2D-3D). Code is available at
https://github.com/rshivansh/OmniLayout.",1,1,0,0,1,0,0.7419,10.0,0.869393,32
http://arxiv.org/abs/2107.12309v2,Spatial-Temporal Transformer for Dynamic Scene Graph Generation,90,0.774247,0.991502,"Dynamic scene graph generation aims at generating a scene graph of the given
video. Compared to the task of scene graph generation from images, it is more
challenging because of the dynamic relationships between objects and the
temporal dependencies between frames allowing for a richer semantic
interpretation. In this paper, we propose Spatial-temporal Transformer
(STTran), a neural network that consists of two core modules: (1) a spatial
encoder that takes an input frame to extract spatial context and reason about
the visual relationships within a frame, and (2) a temporal decoder which takes
the output of the spatial encoder as input in order to capture the temporal
dependencies between frames and infer the dynamic relationships. Furthermore,
STTran is flexible to take varying lengths of videos as input without clipping,
which is especially important for long videos. Our method is validated on the
benchmark dataset Action Genome (AG). The experimental results demonstrate the
superior performance of our method in terms of dynamic scene graphs. Moreover,
a set of ablative studies is conducted and the effect of each proposed module
is justified. Code available at: https://github.com/yrcong/STTran.",1,1,0,0,1,0,0.903526,8.0,0.905008,66
http://arxiv.org/abs/2109.05698v2,Detecting Textual Adversarial Examples through Randomized Substitution and Vote,8,0.13781,0.455997,"A line of work has shown that natural text processing models are vulnerable
to adversarial examples. Correspondingly, various defense methods are proposed
to mitigate the threat of textual adversarial examples, eg, adversarial
training, input transformations, detection, etc. In this work, we treat the
optimization process for synonym substitution based textual adversarial attacks
as a specific sequence of word replacement, in which each word mutually
influences other words. We identify that we could destroy such mutual
interaction and eliminate the adversarial perturbation by randomly substituting
a word with its synonyms. Based on this observation, we propose a novel textual
adversarial example detection method, termed Randomized Substitution and Vote
(RS&V), which votes the prediction label by accumulating the logits of k
samples generated by randomly substituting the words in the input text with
synonyms. The proposed RS&V is generally applicable to any existing neural
networks without modification on the architecture or extra training, and it is
orthogonal to prior work on making the classification network itself more
robust. Empirical evaluations on three benchmark datasets demonstrate that our
RS&V could detect the textual adversarial examples more successfully than the
existing detection methods while maintaining the high classification accuracy
on benign samples.",1,1,0,0,0,0,0.934381,5.0,0.878525,44
http://arxiv.org/abs/2109.13105v1,Does referent predictability affect the choice of referential form? A computational approach using masked coreference resolution,2,0.0432354,0.0228742,"It is often posited that more predictable parts of a speaker's meaning tend
to be made less explicit, for instance using shorter, less informative words.
Studying these dynamics in the domain of referring expressions has proven
difficult, with existing studies, both psycholinguistic and corpus-based,
providing contradictory results. We test the hypothesis that speakers produce
less informative referring expressions (e.g., pronouns vs. full noun phrases)
when the context is more informative about the referent, using novel
computational estimates of referent predictability. We obtain these estimates
training an existing coreference resolution system for English on a new task,
masked coreference resolution, giving us a probability distribution over
referents that is conditioned on the context but not the referring expression.
The resulting system retains standard coreference resolution performance while
yielding a better estimate of human-derived referent predictability than
previous attempts. A statistical analysis of the relationship between model
output and mention form supports the hypothesis that predictability affects the
form of a mention, both its morphosyntactic type and its length.",1,0,0,0,0,0,0.141316,15.0,0.767268,40
http://arxiv.org/abs/2103.11249v1,SELM: Software Engineering of Machine Learning Models,1,0.00192083,0.0487682,"One of the pillars of any machine learning model is its concepts. Using
software engineering, we can engineer these concepts and then develop and
expand them. In this article, we present a SELM framework for Software
Engineering of machine Learning Models. We then evaluate this framework through
a case study. Using the SELM framework, we can improve a machine learning
process efficiency and provide more accuracy in learning with less processing
hardware resources and a smaller training dataset. This issue highlights the
importance of an interdisciplinary approach to machine learning. Therefore, in
this article, we have provided interdisciplinary teams' proposals for machine
learning.",0,0,0,0,0,0,0.000329396,17.0,0.433675,22
http://arxiv.org/abs/2104.03725v1,On tuning consistent annealed sampling for denoising score matching,4,0.0290626,0.219597,"Score-based generative models provide state-of-the-art quality for image and
audio synthesis. Sampling from these models is performed iteratively, typically
employing a discretized series of noise levels and a predefined scheme. In this
note, we first overview three common sampling schemes for models trained with
denoising score matching. Next, we focus on one of them, consistent annealed
sampling, and study its hyper-parameter boundaries. We then highlight a
possible formulation of such hyper-parameter that explicitly considers those
boundaries and facilitates tuning when using few or a variable number of steps.
Finally, we highlight some connections of the formulation with other sampling
schemes.",0,0,0,0,0,0,0.977962,2.0,0.86475,11
http://arxiv.org/abs/2102.09244v2,HandTailor: Towards High-Precision Monocular 3D Hand Recovery,23,0.542904,0.540658,"3D hand pose estimation and shape recovery are challenging tasks in computer
vision. We introduce a novel framework HandTailor, which combines a
learning-based hand module and an optimization-based tailor module to achieve
high-precision hand mesh recovery from a monocular RGB image. The proposed hand
module unifies perspective projection and weak perspective projection in a
single network towards accuracy-oriented and in-the-wild scenarios. The
proposed tailor module then utilizes the coarsely reconstructed mesh model
provided by the hand module as initialization, and iteratively optimizes an
energy function to obtain better results. The tailor module is time-efficient,
costs only 8ms per frame on a modern CPU. We demonstrate that HandTailor can
get state-of-the-art performance on several public benchmarks, with impressive
qualitative results on in-the-wild experiments. Code and video are available on
our project webpage https://sites.google.com/view/handtailor.",1,1,0,0,1,0,0.967952,5.0,0.925238,46
http://arxiv.org/abs/2101.10927v1,Attention Can Reflect Syntactic Structure (If You Let It),29,0.51536,0.714292,"Since the popularization of the Transformer as a general-purpose feature
encoder for NLP, many studies have attempted to decode linguistic structure
from its novel multi-head attention mechanism. However, much of such work
focused almost exclusively on English -- a language with rigid word order and a
lack of inflectional morphology. In this study, we present decoding experiments
for multilingual BERT across 18 languages in order to test the generalizability
of the claim that dependency syntax is reflected in attention patterns. We show
that full trees can be decoded above baseline accuracy from single attention
heads, and that individual relations are often tracked by the same heads across
languages. Furthermore, in an attempt to address recent debates about the
status of attention as an explanatory mechanism, we experiment with fine-tuning
mBERT on a supervised parsing objective while freezing different series of
parameters. Interestingly, in steering the objective to learn explicit
linguistic structure, we find much of the same structure represented in the
resulting attention patterns, with interesting differences with respect to
which parameters are frozen.",0,0,0,0,0,0,0.975624,4.0,0.925678,39
http://arxiv.org/abs/2105.14184v1,E2ETag: An End-to-End Trainable Method for Generating and Detecting Fiducial Markers,10,0.222807,0.543455,"Existing fiducial markers solutions are designed for efficient detection and
decoding, however, their ability to stand out in natural environments is
difficult to infer from relatively limited analysis. Furthermore, worsening
performance in challenging image capture scenarios - such as poor exposure,
motion blur, and off-axis viewing - sheds light on their limitations. E2ETag
introduces an end-to-end trainable method for designing fiducial markers and a
complimentary detector. By introducing back-propagatable marker augmentation
and superimposition into training, the method learns to generate markers that
can be detected and classified in challenging real-world environments using a
fully convolutional detector network. Results demonstrate that E2ETag
outperforms existing methods in ideal conditions and performs much better in
the presence of motion blur, contrast fluctuations, noise, and off-axis viewing
angles. Source code and trained models are available at
https://github.com/jbpeace/E2ETag.",1,1,0,0,1,0,0.688962,21.0,0.930749,20
http://arxiv.org/abs/2104.09068v1,Image Inpainting with External-internal Learning and Monochromic Bottleneck,47,0.289418,0.735805,"Although recent inpainting approaches have demonstrated significant
improvements with deep neural networks, they still suffer from artifacts such
as blunt structures and abrupt colors when filling in the missing regions. To
address these issues, we propose an external-internal inpainting scheme with a
monochromic bottleneck that helps image inpainting models remove these
artifacts. In the external learning stage, we reconstruct missing structures
and details in the monochromic space to reduce the learning dimension. In the
internal learning stage, we propose a novel internal color propagation method
with progressive learning strategies for consistent color restoration.
Extensive experiments demonstrate that our proposed scheme helps image
inpainting models produce more structure-preserved and visually compelling
results.",1,0,0,0,0,0,0.843333,9.0,0.889745,44
http://arxiv.org/abs/2106.01352v2,NeRP: Neural Rearrangement Planning for Unknown Objects,53,0.389397,0.832171,"Robots will be expected to manipulate a wide variety of objects in complex
and arbitrary ways as they become more widely used in human environments. As
such, the rearrangement of objects has been noted to be an important benchmark
for AI capabilities in recent years. We propose NeRP (Neural Rearrangement
Planning), a deep learning based approach for multi-step neural object
rearrangement planning which works with never-before-seen objects, that is
trained on simulation data, and generalizes to the real world. We compare NeRP
to several naive and model-based baselines, demonstrating that our approach is
measurably better and can efficiently arrange unseen objects in fewer steps and
with less planning time. Finally, we demonstrate it on several challenging
rearrangement problems in the real world.",0,1,0,0,0,0,0.773973,4.0,0.696848,38
http://arxiv.org/abs/2107.12518v2,Segmentation in Style: Unsupervised Semantic Image Segmentation with Stylegan and CLIP,27,0.0596866,0.28232,"We introduce a method that allows to automatically segment images into
semantically meaningful regions without human supervision. Derived regions are
consistent across different images and coincide with human-defined semantic
classes on some datasets. In cases where semantic regions might be hard for
human to define and consistently label, our method is still able to find
meaningful and consistent semantic classes. In our work, we use pretrained
StyleGAN2 generative model: clustering in the feature space of the generative
model allows to discover semantic classes. Once classes are discovered, a
synthetic dataset with generated images and corresponding segmentation masks
can be created. After that a segmentation model is trained on the synthetic
dataset and is able to generalize to real images. Additionally, by using CLIP
we are able to use prompts defined in a natural language to discover some
desired semantic classes. We test our method on publicly available datasets and
show state-of-the-art results.",0,1,0,1,1,0,0.726432,8.0,0.83125,26
http://arxiv.org/abs/2102.07472v1,"DAC: Deep Autoencoder-based Clustering, a General Deep Learning Framework of Representation Learning",6,0.00687417,0.0494819,"Clustering performs an essential role in many real world applications, such
as market research, pattern recognition, data analysis, and image processing.
However, due to the high dimensionality of the input feature values, the data
being fed to clustering algorithms usually contains noise and thus could lead
to in-accurate clustering results. While traditional dimension reduction and
feature selection algorithms could be used to address this problem, the simple
heuristic rules used in those algorithms are based on some particular
assumptions. When those assumptions does not hold, these algorithms then might
not work. In this paper, we propose DAC, Deep Autoencoder-based Clustering, a
generalized data-driven framework to learn clustering representations using
deep neuron networks. Experiment results show that our approach could
effectively boost performance of the K-Means clustering algorithm on a variety
types of datasets.",0,1,0,0,0,1,0.00591555,17.0,0.603727,16
http://arxiv.org/abs/2102.01203v3,Emergent Unfairness in Algorithmic Fairness-Accuracy Trade-Off Research,43,0.159267,0.812382,"Across machine learning (ML) sub-disciplines, researchers make explicit
mathematical assumptions in order to facilitate proof-writing. We note that,
specifically in the area of fairness-accuracy trade-off optimization
scholarship, similar attention is not paid to the normative assumptions that
ground this approach. Such assumptions presume that 1) accuracy and fairness
are in inherent opposition to one another, 2) strict notions of mathematical
equality can adequately model fairness, 3) it is possible to measure the
accuracy and fairness of decisions independent from historical context, and 4)
collecting more data on marginalized individuals is a reasonable solution to
mitigate the effects of the trade-off. We argue that such assumptions, which
are often left implicit and unexamined, lead to inconsistent conclusions: While
the intended goal of this work may be to improve the fairness of machine
learning models, these unexamined, implicit assumptions can in fact result in
emergent unfairness. We conclude by suggesting a concrete path forward toward a
potential resolution.",0,0,0,0,0,0,0.195303,9.0,0.65156,77
http://arxiv.org/abs/2110.01519v2,Weak-shot Semantic Segmentation by Transferring Semantic Affinity and Boundary,8,0.126804,0.174162,"Weakly-supervised semantic segmentation (WSSS) with image-level labels has
been widely studied to relieve the annotation burden of the traditional
segmentation task. In this paper, we show that existing fully-annotated base
categories can help segment objects of novel categories with only image-level
labels, even if base categories and novel categories have no overlap. We refer
to this task as weak-shot semantic segmentation, which could also be treated as
WSSS with auxiliary fully-annotated categories. Recent advanced WSSS methods
usually obtain class activation maps (CAMs) and refine them by affinity
propagation. Based on the observation that semantic affinity and boundary are
class-agnostic, we propose a method under the WSSS framework to transfer
semantic affinity and boundary from base to novel categories. As a result, we
find that pixel-level annotation of base categories can facilitate affinity
learning and propagation, leading to higher-quality CAMs of novel categories.
Extensive experiments on PASCAL VOC 2012 dataset prove that our method
significantly outperforms WSSS baselines on novel categories.",0,0,0,0,0,0,0.830687,7.0,0.852133,63
http://arxiv.org/abs/2107.08362v1,Probabilistic Verification of Neural Networks Against Group Fairness,18,0.326458,0.311151,"Fairness is crucial for neural networks which are used in applications with
important societal implication. Recently, there have been multiple attempts on
improving fairness of neural networks, with a focus on fairness testing (e.g.,
generating individual discriminatory instances) and fairness training (e.g.,
enhancing fairness through augmented training). In this work, we propose an
approach to formally verify neural networks against fairness, with a focus on
independence-based fairness such as group fairness. Our method is built upon an
approach for learning Markov Chains from a user-provided neural network (i.e.,
a feed-forward neural network or a recurrent neural network) which is
guaranteed to facilitate sound analysis. The learned Markov Chain not only
allows us to verify (with Probably Approximate Correctness guarantee) whether
the neural network is fair or not, but also facilities sensitivity analysis
which helps to understand why fairness is violated. We demonstrate that with
our analysis results, the neural weights can be optimized to improve fairness.
Our approach has been evaluated with multiple models trained on benchmark
datasets and the experiment results show that our approach is effective and
efficient.",0,0,0,0,0,0,0.73609,8.0,0.834669,58
http://arxiv.org/abs/2108.10876v2,Quantum adaptive agents with efficient long-term memories,16,0.115798,0.448126,"Central to the success of adaptive systems is their ability to interpret
signals from their environment and respond accordingly -- they act as agents
interacting with their surroundings. Such agents typically perform better when
able to execute increasingly complex strategies. This comes with a cost: the
more information the agent must recall from its past experiences, the more
memory it will need. Here we investigate the power of agents capable of quantum
information processing. We uncover the most general form a quantum agent need
adopt to maximise memory compression advantages, and provide a systematic means
of encoding their memory states. We show these encodings can exhibit extremely
favourable scaling advantages relative to memory-minimal classical agents,
particularly when information must be retained about events increasingly far
into the past.",0,0,0,0,0,0,0.00984049,14.0,0.555304,74
http://arxiv.org/abs/2110.14091v1,Connect-the-Dots: Bridging Semantics between Words and Definitions via Aligning Word Sense Inventories,6,0.0546891,0.63229,"Word Sense Disambiguation (WSD) aims to automatically identify the exact
meaning of one word according to its context. Existing supervised models
struggle to make correct predictions on rare word senses due to limited
training data and can only select the best definition sentence from one
predefined word sense inventory (e.g., WordNet). To address the data sparsity
problem and generalize the model to be independent of one predefined inventory,
we propose a gloss alignment algorithm that can align definition sentences
(glosses) with the same meaning from different sense inventories to collect
rich lexical knowledge. We then train a model to identify semantic equivalence
between a target word in context and one of its glosses using these aligned
inventories, which exhibits strong transfer capability to many WSD tasks.
Experiments on benchmark datasets show that the proposed method improves
predictions on both frequent and rare word senses, outperforming prior work by
1.2% on the All-Words WSD Task and 4.3% on the Low-Shot WSD Task. Evaluation on
WiC Task also indicates that our method can better capture word meanings in
context.",1,1,0,0,1,0,0.700542,7.0,0.796813,43
http://arxiv.org/abs/2103.14512v2,Continual Speaker Adaptation for Text-to-Speech Synthesis,8,0.104207,0.458014,"Training a multi-speaker Text-to-Speech (TTS) model from scratch is
computationally expensive and adding new speakers to the dataset requires the
model to be re-trained. The naive solution of sequential fine-tuning of a model
for new speakers can lead to poor performance of older speakers. This
phenomenon is known as catastrophic forgetting. In this paper, we look at TTS
modeling from a continual learning perspective, where the goal is to add new
speakers without forgetting previous speakers. Therefore, we first propose an
experimental setup and show that serial fine-tuning for new speakers can cause
the forgetting of the earlier speakers. Then we exploit two well-known
techniques for continual learning, namely experience replay and weight
regularization. We reveal how one can mitigate the effect of degradation in
speech synthesis diversity in sequential training of new speakers using these
methods. Finally, we present a simple extension to experience replay to improve
the results in extreme setups where we have access to very small buffers.",1,1,0,0,0,0,0.891798,6.0,0.86496,20
http://arxiv.org/abs/2106.10176v1,Self-supervised Incremental Deep Graph Learning for Ethereum Phishing Scam Detection,18,0.754846,0.699811,"In recent years, phishing scams have become the crime type with the largest
money involved on Ethereum, the second-largest blockchain platform. Meanwhile,
graph neural network (GNN) has shown promising performance in various node
classification tasks. However, for Ethereum transaction data, which could be
naturally abstracted to a real-world complex graph, the scarcity of labels and
the huge volume of transaction data make it difficult to take advantage of GNN
methods. Here in this paper, to address the two challenges, we propose a
Self-supervised Incremental deep Graph learning model (SIEGE), for the phishing
scam detection problem on Ethereum. In our model, two pretext tasks designed
from spatial and temporal perspectives help us effectively learn useful node
embedding from the huge amount of unlabelled transaction data. And the
incremental paradigm allows us to efficiently handle large-scale transaction
data and help the model maintain good performance when the data distribution is
drastically changing. We collect transaction records about half a year from
Ethereum and our extensive experiments show that our model consistently
outperforms strong baselines in both transductive and inductive settings.",0,1,0,0,0,0,0.99065,5.0,0.986448,42
http://arxiv.org/abs/2107.11584v1,Extending Challenge Sets to Uncover Gender Bias in Machine Translation: Impact of Stereotypical Verbs and Adjectives,11,0.0183772,0.333416,"Human gender bias is reflected in language and text production. Because
state-of-the-art machine translation (MT) systems are trained on large corpora
of text, mostly generated by humans, gender bias can also be found in MT. For
instance when occupations are translated from a language like English, which
mostly uses gender neutral words, to a language like German, which mostly uses
a feminine and a masculine version for an occupation, a decision must be made
by the MT System. Recent research showed that MT systems are biased towards
stereotypical translation of occupations. In 2019 the first, and so far only,
challenge set, explicitly designed to measure the extent of gender bias in MT
systems has been published. In this set measurement of gender bias is solely
based on the translation of occupations. In this paper we present an extension
of this challenge set, called WiBeMT, with gender-biased adjectives and adds
sentences with gender-biased verbs. The resulting challenge set consists of
over 70, 000 sentences and has been translated with three commercial MT
systems: DeepL Translator, Microsoft Translator, and Google Translate. Results
show a gender bias for all three MT systems. This gender bias is to a great
extent significantly influenced by adjectives and to a lesser extent by verbs.",0,1,0,1,0,0,0.239003,7.0,0.584677,14
http://arxiv.org/abs/2111.00454v1,Gaussian Kernel Mixture Network for Single Image Defocus Deblurring,25,0.194763,0.603198,"Defocus blur is one kind of blur effects often seen in images, which is
challenging to remove due to its spatially variant amount. This paper presents
an end-to-end deep learning approach for removing defocus blur from a single
image, so as to have an all-in-focus image for consequent vision tasks. First,
a pixel-wise Gaussian kernel mixture (GKM) model is proposed for representing
spatially variant defocus blur kernels in an efficient linear parametric form,
with higher accuracy than existing models. Then, a deep neural network called
GKMNet is developed by unrolling a fixed-point iteration of the GKM-based
deblurring. The GKMNet is built on a lightweight scale-recurrent architecture,
with a scale-recurrent attention module for estimating the mixing coefficients
in GKM for defocus deblurring. Extensive experiments show that the GKMNet not
only noticeably outperforms existing defocus deblurring methods, but also has
its advantages in terms of model complexity and computational efficiency.",1,1,0,0,1,0,0.332485,8.0,0.685587,49
http://arxiv.org/abs/2104.01604v2,Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers,11,0.152714,0.234255,"This paper introduces Timers and Such, a new open source dataset of spoken
English commands for common voice control use cases involving numbers. We
describe the gap in existing spoken language understanding datasets that Timers
and Such fills, the design and creation of the dataset, and experiments with a
number of ASR-based and end-to-end baseline models, the code for which has been
made available as part of the SpeechBrain toolkit.",1,1,1,1,0,0,0.78256,5.0,0.76262,43
http://arxiv.org/abs/2102.06558v1,Continuous Learning in Neural Machine Translation using Bilingual Dictionaries,12,0.0293577,0.417085,"While recent advances in deep learning led to significant improvements in
machine translation, neural machine translation is often still not able to
continuously adapt to the environment. For humans, as well as for machine
translation, bilingual dictionaries are a promising knowledge source to
continuously integrate new knowledge. However, their exploitation poses several
challenges: The system needs to be able to perform one-shot learning as well as
model the morphology of source and target language.
  In this work, we proposed an evaluation framework to assess the ability of
neural machine translation to continuously learn new phrases. We integrate
one-shot learning methods for neural machine translation with different word
representations and show that it is important to address both in order to
successfully make use of bilingual dictionaries. By addressing both challenges
we are able to improve the ability to translate new, rare words and phrases
from 30% to up to 70%. The correct lemma is even generated by more than 90%.",0,1,0,0,0,0,0.0693423,8.0,0.469697,30
http://arxiv.org/abs/2106.08556v2,Coreference-Aware Dialogue Summarization,52,0.718158,0.811225,"Summarizing conversations via neural approaches has been gaining research
traction lately, yet it is still challenging to obtain practical solutions.
Examples of such challenges include unstructured information exchange in
dialogues, informal interactions between speakers, and dynamic role changes of
speakers as the dialogue evolves. Many of such challenges result in complex
coreference links. Therefore, in this work, we investigate different approaches
to explicitly incorporate coreference information in neural abstractive
dialogue summarization models to tackle the aforementioned challenges.
Experimental results show that the proposed approaches achieve state-of-the-art
performance, implying it is useful to utilize coreference information in
dialogue summarization. Evaluation results on factual correctness suggest such
coreference-aware models are better at tracing the information flow among
interlocutors and associating accurate status/actions with the corresponding
interlocutors and person mentions.",0,1,0,0,1,0,0.979974,5.0,0.950858,43
http://arxiv.org/abs/2104.08768v2,Constrained Language Models Yield Few-Shot Semantic Parsers,164,0.594305,0.976628,"We explore the use of large pretrained language models as few-shot semantic
parsers. The goal in semantic parsing is to generate a structured meaning
representation given a natural language input. However, language models are
trained to generate natural language. To bridge the gap, we use language models
to paraphrase inputs into a controlled sublanguage resembling English that can
be automatically mapped to a target meaning representation. Our results
demonstrate that with only a small amount of data and very little code to
convert into English-like representations, our blueprint for rapidly
bootstrapping semantic parsers leads to surprisingly effective performance on
multiple community tasks, greatly exceeding baseline methods also trained on
the same limited data.",1,1,0,0,0,0,0.600645,5.0,0.66098,64
http://arxiv.org/abs/2103.00121v1,Successive Subspace Learning: An Overview,13,0.0437492,0.396099,"Successive Subspace Learning (SSL) offers a light-weight unsupervised feature
learning method based on inherent statistical properties of data units (e.g.
image pixels and points in point cloud sets). It has shown promising results,
especially on small datasets. In this paper, we intuitively explain this
method, provide an overview of its development, and point out some open
questions and challenges for future research.",0,0,0,0,0,0,0.381197,3.0,0.218842,11
http://arxiv.org/abs/2104.07411v2,NICE: An Algorithm for Nearest Instance Counterfactual Explanations,41,0.809552,0.698644,"In this paper we suggest NICE: a new algorithm to generate counterfactual
explanations for heterogeneous tabular data. The design of our algorithm
specifically takes into account algorithmic requirements that often emerge in
real-life deployments: (1) the ability to provide an explanation for all
predictions, (2) being able to handle any classification model (also
non-differentiable ones), and (3) being efficient in run time. More
specifically, our approach exploits information from a nearest unlike neighbour
to speed up the search process, by iteratively introducing feature values from
this neighbour in the instance to be explained. We propose four versions of
NICE, one without optimization and, three which optimize the explanations for
one of the following properties: sparsity, proximity or plausibility. An
extensive empirical comparison on 40 datasets shows that our algorithm
outperforms the current state-of-the-art in terms of these criteria. Our
analyses show a trade-off between on the one hand plausibility and on the other
hand proximity or sparsity, with our different optimization methods offering
users the choice to select the types of counterfactuals that they prefer. An
open-source implementation of NICE can be found at
https://github.com/ADMAntwerp/NICE.",1,1,0,0,1,0,0.960135,6.0,0.926774,74
http://arxiv.org/abs/2105.09937v1,AnaXNet: Anatomy Aware Multi-label Finding Classification in Chest X-ray,24,0.0493934,0.311935,"Radiologists usually observe anatomical regions of chest X-ray images as well
as the overall image before making a decision. However, most existing deep
learning models only look at the entire X-ray image for classification, failing
to utilize important anatomical information. In this paper, we propose a novel
multi-label chest X-ray classification model that accurately classifies the
image finding and also localizes the findings to their correct anatomical
regions. Specifically, our model consists of two modules, the detection module
and the anatomical dependency module. The latter utilizes graph convolutional
networks, which enable our model to learn not only the label dependency but
also the relationship between the anatomical regions in the chest X-ray. We
further utilize a method to efficiently create an adjacency matrix for the
anatomical regions using the correlation of the label across the different
regions. Detailed experiments and analysis of our results show the
effectiveness of our method when compared to the current state-of-the-art
multi-label chest X-ray image classification methods while also providing
accurate location information.",0,1,0,0,1,0,0.232023,7.0,0.57982,36
http://arxiv.org/abs/2106.03899v2,Shifting Transformation Learning for Out-of-Distribution Detection,6,0.0819787,0.321186,"Detecting out-of-distribution (OOD) samples plays a key role in open-world
and safety-critical applications such as autonomous systems and healthcare.
Recently, self-supervised representation learning techniques (via contrastive
learning and pretext learning) have shown effective in improving OOD detection.
However, one major issue with such approaches is the choice of shifting
transformations and pretext tasks which depends on the in-domain distribution.
In this paper, we propose a simple framework that leverages a shifting
transformation learning setting for learning multiple shifted representations
of the training set for improved OOD detection. To address the problem of
selecting optimal shifting transformation and pretext tasks, we propose a
simple mechanism for automatically selecting the transformations and modulating
their effect on representation learning without requiring any OOD training
samples. In extensive experiments, we show that our simple framework
outperforms state-of-the-art OOD detection models on several image datasets. We
also characterize the criteria for a desirable OOD detector for real-world
applications and demonstrate the efficacy of our proposed technique against
state-of-the-art OOD detection techniques.",0,1,0,0,1,0,0.953534,6.0,0.918654,52
http://arxiv.org/abs/2111.09478v1,Software Engineering for Responsible AI: An Empirical Study and Operationalised Patterns,25,0.486679,0.619837,"Although artificial intelligence (AI) is solving real-world challenges and
transforming industries, there are serious concerns about its ability to behave
and make decisions in a responsible way. Many AI ethics principles and
guidelines for responsible AI have been recently issued by governments,
organisations, and enterprises. However, these AI ethics principles and
guidelines are typically high-level and do not provide concrete guidance on how
to design and develop responsible AI systems. To address this shortcoming, we
first present an empirical study where we interviewed 21 scientists and
engineers to understand the practitioners' perceptions on AI ethics principles
and their implementation. We then propose a template that enables AI ethics
principles to be operationalised in the form of concrete patterns and suggest a
list of patterns using the newly created template. These patterns provide
concrete, operationalised guidance that facilitate the development of
responsible AI systems.",0,1,0,0,0,0,0.812411,5.0,0.781096,71
http://arxiv.org/abs/2107.12571v1,CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows,264,0.636628,0.999064,"Unsupervised anomaly detection with localization has many practical
applications when labeling is infeasible and, moreover, when anomaly examples
are completely missing in the train data. While recently proposed models for
such data setup achieve high accuracy metrics, their complexity is a limiting
factor for real-time processing. In this paper, we propose a real-time model
and analytically derive its relationship to prior methods. Our CFLOW-AD model
is based on a conditional normalizing flow framework adopted for anomaly
detection with localization. In particular, CFLOW-AD consists of a
discriminatively pretrained encoder followed by a multi-scale generative
decoders where the latter explicitly estimate likelihood of the encoded
features. Our approach results in a computationally and memory-efficient model:
CFLOW-AD is faster and smaller by a factor of 10x than prior state-of-the-art
with the same input setting. Our experiments on the MVTec dataset show that
CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by
1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source
our code with fully reproducible experiments.",1,1,0,0,1,0,0.715088,6.0,0.769693,44
http://arxiv.org/abs/2102.03119v1,Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for Automated Driving using Distributional Reinforcement Learning,24,0.252397,0.648412,"For highly automated driving above SAE level~3, behavior generation
algorithms must reliably consider the inherent uncertainties of the traffic
environment, e.g. arising from the variety of human driving styles. Such
uncertainties can generate ambiguous decisions, requiring the algorithm to
appropriately balance low-probability hazardous events, e.g. collisions, and
high-probability beneficial events, e.g. quickly crossing the intersection.
State-of-the-art behavior generation algorithms lack a distributional treatment
of decision outcome. This impedes a proper risk evaluation in ambiguous
situations, often encouraging either unsafe or conservative behavior. Thus, we
propose a two-step approach for risk-sensitive behavior generation combining
offline distribution learning with online risk assessment. Specifically, we
first learn an optimal policy in an uncertain environment with Deep
Distributional Reinforcement Learning. During execution, the optimal
risk-sensitive action is selected by applying established risk criteria, such
as the Conditional Value at Risk, to the learned state-action return
distributions. In intersection crossing scenarios, we evaluate different risk
criteria and demonstrate that our approach increases safety, while maintaining
an active driving style. Our approach shall encourage further studies about the
benefits of risk-sensitive approaches for self-driving vehicles.",0,1,0,0,0,0,0.761154,4.0,0.687397,30
http://arxiv.org/abs/2111.08647v2,DataCLUE: A Benchmark Suite for Data-centric NLP,14,0.251691,0.374429,"Data-centric AI has recently proven to be more effective and
high-performance, while traditional model-centric AI delivers fewer and fewer
benefits. It emphasizes improving the quality of datasets to achieve better
model performance. This field has significant potential because of its great
practicability and getting more and more attention. However, we have not seen
significant research progress in this field, especially in NLP. We propose
DataCLUE, which is the first Data-Centric benchmark applied in NLP field. We
also provide three simple but effective baselines to foster research in this
field (improve Macro-F1 up to 5.7% point). In addition, we conduct
comprehensive experiments with human annotators and show the hardness of
DataCLUE. We also try an advanced method: the forgetting informed bootstrapping
label correction method. All the resources related to DataCLUE, including
datasets, toolkit, leaderboard, and baselines, is available online at
https://github.com/CLUEbenchmark/DataCLUE",1,0,1,1,0,0,0.952598,6.0,0.917568,18
http://arxiv.org/abs/2107.12480v1,Circular-Symmetric Correlation Layer based on FFT,1,0.00136191,0.0247573,"Despite the vast success of standard planar convolutional neural networks,
they are not the most efficient choice for analyzing signals that lie on an
arbitrarily curved manifold, such as a cylinder. The problem arises when one
performs a planar projection of these signals and inevitably causes them to be
distorted or broken where there is valuable information. We propose a
Circular-symmetric Correlation Layer (CCL) based on the formalism of
roto-translation equivariant correlation on the continuous group $S^1 \times
\mathbb{R}$, and implement it efficiently using the well-known Fast Fourier
Transform (FFT) algorithm. We showcase the performance analysis of a general
network equipped with CCL on various recognition and classification tasks and
datasets. The PyTorch package implementation of CCL is provided online.",0,0,0,0,0,0,0.00694579,12.0,0.452035,35
http://arxiv.org/abs/2108.07502v1,MV-TON: Memory-based Video Virtual Try-on network,15,0.705735,0.903713,"With the development of Generative Adversarial Network, image-based virtual
try-on methods have made great progress. However, limited work has explored the
task of video-based virtual try-on while it is important in real-world
applications. Most existing video-based virtual try-on methods usually require
clothing templates and they can only generate blurred and low-resolution
results. To address these challenges, we propose a Memory-based Video virtual
Try-On Network (MV-TON), which seamlessly transfers desired clothes to a target
person without using any clothing templates and generates high-resolution
realistic videos. Specifically, MV-TON consists of two modules: 1) a try-on
module that transfers the desired clothes from model images to frame images by
pose alignment and region-wise replacing of pixels; 2) a memory refinement
module that learns to embed the existing generated frames into the latent space
as external memory for the following frame generation. Experimental results
show the effectiveness of our method in the video virtual try-on task and its
superiority over other existing methods.",0,1,1,0,1,0,0.981344,8.0,0.97153,47
http://arxiv.org/abs/2105.01279v1,ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders,37,0.11615,0.656106,"Pre-trained text encoders have drawn sustaining attention in natural language
processing (NLP) and shown their capability in obtaining promising results in
different tasks. Recent studies illustrated that external self-supervised
signals (or knowledge extracted by unsupervised learning, such as n-grams) are
beneficial to provide useful semantic evidence for understanding languages such
as Chinese, so as to improve the performance on various downstream tasks
accordingly. To further enhance the encoders, in this paper, we propose to
pre-train n-gram-enhanced encoders with a large volume of data and advanced
techniques for training. Moreover, we try to extend the encoder to different
languages as well as different domains, where it is confirmed that the same
architecture is applicable to these varying circumstances and new
state-of-the-art performance is observed from a long list of NLP tasks across
languages and domains.",1,1,0,0,1,0,0.507831,4.0,0.511642,42
http://arxiv.org/abs/2103.11647v1,Prototypical Representation Learning for Relation Extraction,49,0.31178,0.816605,"Recognizing relations between entities is a pivotal task of relational
learning. Learning relation representations from distantly-labeled datasets is
difficult because of the abundant label noise and complicated expressions in
human language. This paper aims to learn predictive, interpretable, and robust
relation representations from distantly-labeled data that are effective in
different settings, including supervised, distantly supervised, and few-shot
learning. Instead of solely relying on the supervision from noisy labels, we
propose to learn prototypes for each relation from contextual information to
best explore the intrinsic semantics of relations. Prototypes are
representations in the feature space abstracting the essential semantics of
relations between entities in sentences. We learn prototypes based on
objectives with clear geometric interpretation, where the prototypes are unit
vectors uniformly dispersed in a unit ball, and statement embeddings are
centered at the end of their corresponding prototype vectors on the surface of
the ball. This approach allows us to learn meaningful, interpretable prototypes
for the final classification. Results on several relation learning tasks show
that our model significantly outperforms the previous state-of-the-art models.
We further demonstrate the robustness of the encoder and the interpretability
of prototypes with extensive experiments.",1,1,0,0,1,0,0.500746,11.0,0.820564,74
http://arxiv.org/abs/2109.12487v1,Parallel Refinements for Lexically Constrained Text Generation with BART,31,0.629714,0.756505,"Lexically constrained text generation aims to control the generated text by
incorporating some pre-specified keywords into the output. Previous work
injects lexical constraints into the output by controlling the decoding process
or refining the candidate output iteratively, which tends to generate generic
or ungrammatical sentences, and has high computational complexity. To address
these challenges, we propose Constrained BART (CBART) for lexically constrained
text generation. CBART leverages the pre-trained model BART and transfers part
of the generation burden from the decoder to the encoder by decomposing this
task into two sub-tasks, thereby improving the sentence quality. Concretely, we
extend BART by adding a token-level classifier over the encoder, aiming at
instructing the decoder where to replace and insert. Guided by the encoder, the
decoder refines multiple tokens of the input in one step by inserting tokens
before specific positions and re-predicting tokens with low confidence. To
further reduce the inference latency, the decoder predicts all tokens in
parallel. Experiment results on One-Billion-Word and Yelp show that CBART can
generate plausible text with high quality and diversity while significantly
accelerating inference.",1,1,0,0,0,0,0.954648,7.0,0.9314,47
http://arxiv.org/abs/2103.13559v1,Rethinking Self-Supervised Learning: Small is Beautiful,21,0.0643397,0.233212,"Self-supervised learning (SSL), in particular contrastive learning, has made
great progress in recent years. However, a common theme in these methods is
that they inherit the learning paradigm from the supervised deep learning
scenario. Current SSL methods are often pretrained for many epochs on
large-scale datasets using high resolution images, which brings heavy
computational cost and lacks flexibility. In this paper, we demonstrate that
the learning paradigm for SSL should be different from supervised learning and
the information encoded by the contrastive loss is expected to be much less
than that encoded in the labels in supervised learning via the cross entropy
loss. Hence, we propose scaled-down self-supervised learning (S3L), which
include 3 parts: small resolution, small architecture and small data. On a
diverse set of datasets, SSL methods and backbone architectures, S3L achieves
higher accuracy consistently with much less training cost when compared to
previous SSL learning paradigm. Furthermore, we show that even without a large
pretraining dataset, S3L can achieve impressive results on small data alone.
Our code has been made publically available at
https://github.com/CupidJay/Scaled-down-self-supervised-learning.",1,1,0,0,0,0,0.956841,9.0,0.948411,41
http://arxiv.org/abs/2103.02362v3,Video Sentiment Analysis with Bimodal Information-augmented Multi-Head Attention,44,0.156737,0.736051,"Humans express feelings or emotions via different channels. Take language as
an example, it entails different sentiments under different visual-acoustic
contexts. To precisely understand human intentions as well as reduce the
misunderstandings caused by ambiguity and sarcasm, we should consider
multimodal signals including textual, visual and acoustic signals. The crucial
challenge is to fuse different modalities of features for sentiment analysis.
To effectively fuse the information carried by different modalities and better
predict the sentiments, we design a novel multi-head attention based fusion
network, which is inspired by the observations that the interactions between
any two pair-wise modalities are different and they do not equally contribute
to the final sentiment prediction. By assigning the acoustic-visual,
acoustic-textual and visual-textual features with reasonable attention and
exploiting a residual structure, we attend to attain the significant features.
We conduct extensive experiments on four public multimodal datasets including
one in Chinese and three in English. The results show that our approach
outperforms the existing methods and can explain the contributions of bimodal
interaction in multiple modalities.",1,1,0,0,1,0,0.471031,4.0,0.484826,73
http://arxiv.org/abs/2108.04657v3,Differentiable Subset Pruning of Transformer Heads,41,0.554932,0.625351,"Multi-head attention, a collection of several attention mechanisms that
independently attend to different parts of the input, is the key ingredient in
the Transformer. Recent work has shown, however, that a large proportion of the
heads in a Transformer's multi-head attention mechanism can be safely pruned
away without significantly harming the performance of the model; such pruning
leads to models that are noticeably smaller and faster in practice. Our work
introduces a new head pruning technique that we term differentiable subset
pruning. Intuitively, our method learns per-head importance variables and then
enforces a user-specified hard constraint on the number of unpruned heads. The
importance variables are learned via stochastic gradient descent. We conduct
experiments on natural language inference and machine translation; we show that
differentiable subset pruning performs comparably or better than previous works
while offering precise control of the sparsity level.",0,1,0,0,0,0,0.953745,9.0,0.945934,65
http://arxiv.org/abs/2104.04721v1,Do as we do: Multiple Person Video-To-Video Transfer,1,0.00687061,0.0339814,"Our goal is to transfer the motion of real people from a source video to a
target video with realistic results. While recent advances significantly
improved image-to-image translations, only few works account for body motions
and temporal consistency. However, those focus only on video re-targeting for a
single actor/ for single actors. In this work, we propose a marker-less
approach for multiple-person video-to-video transfer using pose as an
intermediate representation. Given a source video with multiple persons dancing
or working out, our method transfers the body motion of all actors to a new set
of actors in a different video. Differently from recent ""do as I do"" methods,
we focus specifically on transferring multiple person at the same time and
tackle the related identity switch problem. Our method is able to convincingly
transfer body motion to the target video, while preserving specific features of
the target video, such as feet touching the floor and relative position of the
actors. The evaluation is performed with visual quality and appearance metrics
using publicly available videos with the permission of their owners.",0,1,0,0,0,0,0.472915,6.0,0.657482,37
http://arxiv.org/abs/2105.09432v1,Stratified Data Integration,16,0.167456,0.355455,"We propose a novel approach to the problem of semantic heterogeneity where
data are organized into a set of stratified and independent representation
layers, namely: conceptual(where a set of unique alinguistic identifiers are
connected inside a graph codifying their meaning), language(where sets of
synonyms, possibly from multiple languages, annotate concepts), knowledge(in
the form of a graph where nodes are entity types and links are properties), and
data(in the form of a graph of entities populating the previous knowledge
graph). This allows us to state the problem of semantic heterogeneity as a
problem of Representation Diversity where the different types of heterogeneity,
viz. Conceptual, Language, Knowledge, and Data, are uniformly dealt within each
single layer, independently from the others. In this paper we describe the
proposed stratified representation of data and the process by which data are
first transformed into the target representation, then suitably integrated and
then, finally, presented to the user in her preferred format. The proposed
framework has been evaluated in various pilot case studies and in a number of
industrial data integration problems.",0,0,0,0,0,0,0.0220305,13.0,0.583566,44
http://arxiv.org/abs/2108.07044v2,Towards unconstrained joint hand-object reconstruction from RGB videos,47,0.81045,0.765092,"Our work aims to obtain 3D reconstruction of hands and manipulated objects
from monocular videos. Reconstructing hand-object manipulations holds a great
potential for robotics and learning from human demonstrations. The supervised
learning approach to this problem, however, requires 3D supervision and remains
limited to constrained laboratory settings and simulators for which 3D ground
truth is available. In this paper we first propose a learning-free fitting
approach for hand-object reconstruction which can seamlessly handle two-hand
object interactions. Our method relies on cues obtained with common methods for
object detection, hand pose estimation and instance segmentation. We
quantitatively evaluate our approach and show that it can be applied to
datasets with varying levels of difficulty for which training data is
unavailable.",1,1,0,0,0,0,0.987401,6.0,0.977711,73
http://arxiv.org/abs/2105.14686v3,Fully Hyperbolic Neural Networks,59,0.339004,0.700328,"Hyperbolic neural networks have shown great potential for modeling complex
data. However, existing hyperbolic networks are not completely hyperbolic, as
they encode features in a hyperbolic space yet formalize most of their
operations in the tangent space (a Euclidean subspace) at the origin of the
hyperbolic space. This hybrid method greatly limits the modeling ability of
networks. In this paper, we propose a fully hyperbolic framework to build
hyperbolic networks based on the Lorentz model by adapting the Lorentz
transformations (including boost and rotation) to formalize essential
operations of neural networks. Moreover, we also prove that linear
transformation in tangent spaces used by existing hyperbolic networks is a
relaxation of the Lorentz rotation and does not include the boost, implicitly
limiting the capabilities of existing hyperbolic networks. The experimental
results on four NLP tasks show that our method has better performance for
building both shallow and deep networks. Our code will be released to
facilitate follow-up research.",1,0,0,0,0,0,0.349828,7.0,0.649685,71
http://arxiv.org/abs/2102.00567v1,Using Recursive KMeans and Dijkstra Algorithm to Solve CVRP,2,0.038316,0.131566,"Capacitated vehicle routing problem (CVRP) is being one of the most common
optimization problems in our days, considering the wide usage of routing
algorithms in multiple fields such as transportation domain, food delivery,
network routing, ... Capacitated vehicle routing problem is classified as an
NP-Hard problem, hence normal optimization algorithm can't solve it. In our
paper, we discuss a new way to solve the mentioned problem, using a recursive
approach of the most known clustering algorithm ""K-Means"", one of the known
shortest path algorithm ""Dijkstra"", and some mathematical operations. In this
paper, we will show how to implement those methods together in order to get the
nearest solution of the optimal route, since research and development are still
on go, this research paper may be extended with another one, that will involve
the implementational results of this thoric side.",0,1,0,0,0,0,0.992731,18.0,0.999151,3
http://arxiv.org/abs/2101.06653v1,LaneRCNN: Distributed Representations for Graph-Centric Motion Forecasting,140,0.998929,0.893133,"Forecasting the future behaviors of dynamic actors is an important task in
many robotics applications such as self-driving. It is extremely challenging as
actors have latent intentions and their trajectories are governed by complex
interactions between the other actors, themselves, and the maps. In this paper,
we propose LaneRCNN, a graph-centric motion forecasting model. Importantly,
relying on a specially designed graph encoder, we learn a local lane graph
representation per actor (LaneRoI) to encode its past motions and the local map
topology. We further develop an interaction module which permits efficient
message passing among local graph representations within a shared global lane
graph. Moreover, we parameterize the output trajectories based on lane graphs,
a more amenable prediction parameterization. Our LaneRCNN captures the
actor-to-actor and the actor-to-map relations in a distributed and map-aware
manner. We demonstrate the effectiveness of our approach on the large-scale
Argoverse Motion Forecasting Benchmark. We achieve the 1st place on the
leaderboard and significantly outperform previous best results.",0,1,0,0,1,0,0.991652,6.0,0.992699,66
http://arxiv.org/abs/2106.02853v1,Region-aware Adaptive Instance Normalization for Image Harmonization,101,0.231838,0.959116,"Image composition plays a common but important role in photo editing. To
acquire photo-realistic composite images, one must adjust the appearance and
visual style of the foreground to be compatible with the background. Existing
deep learning methods for harmonizing composite images directly learn an image
mapping network from the composite to the real one, without explicit
exploration on visual style consistency between the background and the
foreground images. To ensure the visual style consistency between the
foreground and the background, in this paper, we treat image harmonization as a
style transfer problem. In particular, we propose a simple yet effective
Region-aware Adaptive Instance Normalization (RAIN) module, which explicitly
formulates the visual style from the background and adaptively applies them to
the foreground. With our settings, our RAIN module can be used as a drop-in
module for existing image harmonization networks and is able to bring
significant improvements. Extensive experiments on the existing image
harmonization benchmark datasets show the superior capability of the proposed
method. Code is available at {https://github.com/junleen/RainNet}.",1,1,1,0,1,0,0.256778,10.0,0.717573,45
http://arxiv.org/abs/2111.03442v2,Conformer-based Hybrid ASR System for Switchboard Dataset,17,0.0660431,0.720872,"The recently proposed conformer architecture has been successfully used for
end-to-end automatic speech recognition (ASR) architectures achieving
state-of-the-art performance on different datasets. To our best knowledge, the
impact of using conformer acoustic model for hybrid ASR is not investigated. In
this paper, we present and evaluate a competitive conformer-based hybrid model
training recipe. We study different training aspects and methods to improve
word-error-rate as well as to increase training speed. We apply time
downsampling methods for efficient training and use transposed convolutions to
upsample the output sequence again. We conduct experiments on Switchboard 300h
dataset and our conformer-based hybrid model achieves competitive results
compared to other architectures. It generalizes very well on Hub5'01 test set
and outperforms the BLSTM-based hybrid model significantly.",1,1,0,0,0,0,0.178051,9.0,0.640146,40
http://arxiv.org/abs/2107.03427v2,Deep Learning for Two-Sided Matching,10,0.217843,0.30903,"We initiate the study of deep learning for the automated design of two-sided
matching mechanisms. What is of most interest is to use machine learning to
understand the possibility of new tradeoffs between strategy-proofness and
stability. These properties cannot be achieved simultaneously, but the
efficient frontier is not understood. We introduce novel differentiable
surrogates for quantifying ordinal strategy-proofness and stability and use
them to train differentiable matching mechanisms that map discrete preferences
to valid randomized matchings. We demonstrate that the efficient frontier
characterized by these learned mechanisms is substantially better than that
achievable through a convex combination of baselines of deferred acceptance
(stable and strategy-proof for only one side of the market), top trading cycles
(strategy-proof for one side, but not stable), and randomized serial
dictatorship (strategy-proof for both sides, but not stable). This gives a new
target for economic theory and opens up new possibilities for machine learning
pipelines in matching market design.",0,0,1,0,0,0,0.0541423,17.0,0.735419,59
http://arxiv.org/abs/2105.15021v1,Neural Bi-Lexicalized PCFG Induction,17,0.38693,0.713206,"Neural lexicalized PCFGs (L-PCFGs) have been shown effective in grammar
induction. However, to reduce computational complexity, they make a strong
independence assumption on the generation of the child word and thus bilexical
dependencies are ignored. In this paper, we propose an approach to parameterize
L-PCFGs without making implausible independence assumptions. Our approach
directly models bilexical dependencies and meanwhile reduces both learning and
representation complexities of L-PCFGs. Experimental results on the English WSJ
dataset confirm the effectiveness of our approach in improving both running
speed and unsupervised parsing performance.",1,0,0,0,0,0,0.541892,6.0,0.690489,57
http://arxiv.org/abs/2105.12872v1,Benchmarking Scientific Image Forgery Detectors,6,0.0754516,0.188961,"The scientific image integrity area presents a challenging research
bottleneck, the lack of available datasets to design and evaluate forensic
techniques. Its data sensitivity creates a legal hurdle that prevents one to
rely on real tampered cases to build any sort of accessible forensic benchmark.
To mitigate this bottleneck, we present an extendable open-source library that
reproduces the most common image forgery operations reported by the research
integrity community: duplication, retouching, and cleaning. Using this library
and realistic scientific images, we create a large scientific forgery image
benchmark (39,423 images) with an enriched ground-truth. In addition, concerned
about the high number of retracted papers due to image duplication, this work
evaluates the state-of-the-art copy-move detection methods in the proposed
dataset, using a new metric that asserts consistent match detection between the
source and the copied region. The dataset and source-code will be freely
available upon acceptance of the paper.",0,1,0,1,0,0,0.0209952,11.0,0.503426,38
http://arxiv.org/abs/2101.03742v1,Hierarchical Clustering using Auto-encoded Compact Representation for Time-series Analysis,5,0.0402677,0.447399,"Getting a robust time-series clustering with best choice of distance measure
and appropriate representation is always a challenge. We propose a novel
mechanism to identify the clusters combining learned compact representation of
time-series, Auto Encoded Compact Sequence (AECS) and hierarchical clustering
approach. Proposed algorithm aims to address the large computing time issue of
hierarchical clustering as learned latent representation AECS has a length much
less than the original length of time-series and at the same time want to
enhance its performance.Our algorithm exploits Recurrent Neural Network (RNN)
based under complete Sequence to Sequence(seq2seq) autoencoder and
agglomerative hierarchical clustering with a choice of best distance measure to
recommend the best clustering. Our scheme selects the best distance measure and
corresponding clustering for both univariate and multivariate time-series. We
have experimented with real-world time-series from UCR and UCI archive taken
from diverse application domains like health, smart-city, manufacturing etc.
Experimental results show that proposed method not only produce close to
benchmark results but also in some cases outperform the benchmark.",0,1,0,0,1,0,0.819305,13.0,0.917508,33
http://arxiv.org/abs/2106.07345v1,Self-Guided Contrastive Learning for BERT Sentence Representations,173,0.309613,0.901427,"Although BERT and its variants have reshaped the NLP landscape, it still
remains unclear how best to derive sentence embeddings from such pre-trained
Transformers. In this work, we propose a contrastive learning method that
utilizes self-guidance for improving the quality of BERT sentence
representations. Our method fine-tunes BERT in a self-supervised fashion, does
not rely on data augmentation, and enables the usual [CLS] token embeddings to
function as sentence vectors. Moreover, we redesign the contrastive learning
objective (NT-Xent) and apply it to sentence representation learning. We
demonstrate with extensive experiments that our approach is more effective than
competitive baselines on diverse sentence-related tasks. We also show it is
efficient at inference and robust to domain shifts.",0,1,0,0,0,0,0.862613,4.0,0.769039,48
http://arxiv.org/abs/2105.05381v4,Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective,7,0.0704221,0.16478,"Deep ensemble learning has been shown to improve accuracy by training
multiple neural networks and averaging their outputs. Ensemble learning has
also been suggested to defend against membership inference attacks that
undermine privacy. In this paper, we empirically demonstrate a trade-off
between these two goals, namely accuracy and privacy (in terms of membership
inference attacks), in deep ensembles. Using a wide range of datasets and model
architectures, we show that the effectiveness of membership inference attacks
increases when ensembling improves accuracy. We analyze the impact of various
factors in deep ensembles and demonstrate the root cause of the trade-off.
Then, we evaluate common defenses against membership inference attacks based on
regularization and differential privacy. We show that while these defenses can
mitigate the effectiveness of membership inference attacks, they simultaneously
degrade ensemble accuracy. We illustrate similar trade-off in more advanced and
state-of-the-art ensembling techniques, such as snapshot ensembles and
diversified ensemble networks. Finally, we propose a simple yet effective
defense for deep ensembles to break the trade-off and, consequently, improve
the accuracy and privacy, simultaneously.",1,1,0,0,0,0,0.900853,4.0,0.807077,71
http://arxiv.org/abs/2104.09047v1,Neural Unsupervised Semantic Role Labeling,2,0.0246828,0.0403162,"The task of semantic role labeling (SRL) is dedicated to finding the
predicate-argument structure. Previous works on SRL are mostly supervised and
do not consider the difficulty in labeling each example which can be very
expensive and time-consuming. In this paper, we present the first neural
unsupervised model for SRL. To decompose the task as two argument related
subtasks, identification and clustering, we propose a pipeline that
correspondingly consists of two neural modules. First, we train a neural model
on two syntax-aware statistically developed rules. The neural model gets the
relevance signal for each token in a sentence, to feed into a BiLSTM, and then
an adversarial layer for noise-adding and classifying simultaneously, thus
enabling the model to learn the semantic structure of a sentence. Then we
propose another neural model for argument role clustering, which is done
through clustering the learned argument embeddings biased towards their
dependency relations. Experiments on CoNLL-2009 English dataset demonstrate
that our model outperforms previous state-of-the-art baseline in terms of
non-neural models for argument identification and classification.",1,0,0,0,1,0,0.00409706,20.0,0.644756,45
http://arxiv.org/abs/2105.12995v1,ProtAugment: Unsupervised diverse short-texts paraphrasing for intent detection meta-learning,23,0.43619,0.748299,"Recent research considers few-shot intent detection as a meta-learning
problem: the model is learning to learn from a consecutive set of small tasks
named episodes. In this work, we propose ProtAugment, a meta-learning algorithm
for short texts classification (the intent detection task). ProtAugment is a
novel extension of Prototypical Networks, that limits overfitting on the bias
introduced by the few-shots classification objective at each episode. It relies
on diverse paraphrasing: a conditional language model is first fine-tuned for
paraphrasing, and diversity is later introduced at the decoding stage at each
meta-learning episode. The diverse paraphrasing is unsupervised as it is
applied to unlabelled data, and then fueled to the Prototypical Network
training objective as a consistency loss. ProtAugment is the state-of-the-art
method for intent detection meta-learning, at no extra labeling efforts and
without the need to fine-tune a conditional language model on a given
application domain.",1,1,0,0,1,0,0.898555,4.0,0.804586,43
http://arxiv.org/abs/2102.06199v3,"A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose",195,0.969255,0.556881,"While deep learning reshaped the classical motion capture pipeline with
feed-forward networks, generative models are required to recover fine alignment
via iterative refinement. Unfortunately, the existing models are usually
hand-crafted or learned in controlled conditions, only applicable to limited
domains. We propose a method to learn a generative neural body model from
unlabelled monocular videos by extending Neural Radiance Fields (NeRFs). We
equip them with a skeleton to apply to time-varying and articulated motion. A
key insight is that implicit models require the inverse of the forward
kinematics used in explicit surface models. Our reparameterization defines
spatial latent variables relative to the pose of body parts and thereby
overcomes ill-posed inverse operations with an overparameterization. This
enables learning volumetric body shape and appearance from scratch while
jointly refining the articulated pose; all without ground truth labels for
appearance, pose, or 3D shape on the input videos. When used for
novel-view-synthesis and motion capture, our neural model improves accuracy on
diverse datasets. Project website: https://lemonatsu.github.io/anerf/ .",0,0,0,0,0,0,0.981336,5.0,0.954427,80
http://arxiv.org/abs/2104.09810v1,Addressing the Vulnerability of NMT in Input Perturbations,10,0.105408,0.454524,"Neural Machine Translation (NMT) has achieved significant breakthrough in
performance but is known to suffer vulnerability to input perturbations. As
real input noise is difficult to predict during training, robustness is a big
issue for system deployment. In this paper, we improve the robustness of NMT
models by reducing the effect of noisy words through a Context-Enhanced
Reconstruction (CER) approach. CER trains the model to resist noise in two
steps: (1) perturbation step that breaks the naturalness of input sequence with
made-up words; (2) reconstruction step that defends the noise propagation by
generating better and more robust contextual representation. Experimental
results on Chinese-English (ZH-EN) and French-English (FR-EN) translation tasks
demonstrate robustness improvement on both news and social media text. Further
fine-tuning experiments on social media text show our approach can converge at
a higher position and provide a better adaptation.",0,1,0,0,0,0,0.637373,7.0,0.77212,42
http://arxiv.org/abs/2109.12872v1,Meta-Aggregator: Learning to Aggregate for 1-bit Graph Neural Networks,28,0.055755,0.402964,"In this paper, we study a novel meta aggregation scheme towards binarizing
graph neural networks (GNNs). We begin by developing a vanilla 1-bit GNN
framework that binarizes both the GNN parameters and the graph features.
Despite the lightweight architecture, we observed that this vanilla framework
suffered from insufficient discriminative power in distinguishing graph
topologies, leading to a dramatic drop in performance. This discovery motivates
us to devise meta aggregators to improve the expressive power of vanilla
binarized GNNs, of which the aggregation schemes can be adaptively changed in a
learnable manner based on the binarized features. Towards this end, we propose
two dedicated forms of meta neighborhood aggregators, an exclusive meta
aggregator termed as Greedy Gumbel Neighborhood Aggregator (GNA), and a
diffused meta aggregator termed as Adaptable Hybrid Neighborhood Aggregator
(ANA). GNA learns to exclusively pick one single optimal aggregator from a pool
of candidates, while ANA learns a hybrid aggregation behavior to simultaneously
retain the benefits of several individual aggregators. Furthermore, the
proposed meta aggregators may readily serve as a generic plugin module into
existing full-precision GNNs. Experiments across various domains demonstrate
that the proposed method yields results superior to the state of the art.",0,1,0,0,1,0,0.246059,8.0,0.640785,68
http://arxiv.org/abs/2201.02510v1,Predicting Patient Readmission Risk from Medical Text via Knowledge Graph Enhanced Multiview Graph Convolution,14,0.189689,0.666993,"Unplanned intensive care unit (ICU) readmission rate is an important metric
for evaluating the quality of hospital care. Efficient and accurate prediction
of ICU readmission risk can not only help prevent patients from inappropriate
discharge and potential dangers, but also reduce associated costs of
healthcare. In this paper, we propose a new method that uses medical text of
Electronic Health Records (EHRs) for prediction, which provides an alternative
perspective to previous studies that heavily depend on numerical and
time-series features of patients. More specifically, we extract discharge
summaries of patients from their EHRs, and represent them with multiview graphs
enhanced by an external knowledge graph. Graph convolutional networks are then
used for representation learning. Experimental results prove the effectiveness
of our method, yielding state-of-the-art performance for this task.",0,1,0,0,1,0,0.876738,5.0,0.825874,23
http://arxiv.org/abs/2103.16101v1,Large Scale Autonomous Driving Scenarios Clustering with Self-supervised Feature Extraction,13,0.148066,0.589939,"The clustering of autonomous driving scenario data can substantially benefit
the autonomous driving validation and simulation systems by improving the
simulation tests' completeness and fidelity. This article proposes a
comprehensive data clustering framework for a large set of vehicle driving
data. Existing algorithms utilize handcrafted features whose quality relies on
the judgments of human experts. Additionally, the related feature compression
methods are not scalable for a large data-set. Our approach thoroughly
considers the traffic elements, including both in-traffic agent objects and map
information. Meanwhile, we proposed a self-supervised deep learning approach
for spatial and temporal feature extraction to avoid biased data
representation. With the newly designed driving data clustering evaluation
metrics based on data-augmentation, the accuracy assessment does not require a
human-labeled data-set, which is subject to human bias. Via such unprejudiced
evaluation metrics, we have shown our approach surpasses the existing methods
that rely on handcrafted feature extractions.",0,1,0,0,0,0,0.762404,6.0,0.792208,28
http://arxiv.org/abs/2111.05901v1,An Extensive Study of User Identification via Eye Movements across Multiple Datasets,7,0.0482327,0.605294,"Several studies have reported that biometric identification based on eye
movement characteristics can be used for authentication. This paper provides an
extensive study of user identification via eye movements across multiple
datasets based on an improved version of method originally proposed by George
and Routray. We analyzed our method with respect to several factors that affect
the identification accuracy, such as the type of stimulus, the IVT parameters
(used for segmenting the trajectories into fixation and saccades), adding new
features such as higher-order derivatives of eye movements, the inclusion of
blink information, template aging, age and gender.We find that three methods
namely selecting optimal IVT parameters, adding higher-order derivatives
features and including an additional blink classifier have a positive impact on
the identification accuracy. The improvements range from a few percentage
points, up to an impressive 9 % increase on one of the datasets.",0,1,0,0,0,0,0.0141742,11.0,0.467396,58
http://arxiv.org/abs/2103.10609v1,Boosting Adversarial Transferability through Enhanced Momentum,57,0.205324,0.82171,"Deep learning models are known to be vulnerable to adversarial examples
crafted by adding human-imperceptible perturbations on benign images. Many
existing adversarial attack methods have achieved great white-box attack
performance, but exhibit low transferability when attacking other models.
Various momentum iterative gradient-based methods are shown to be effective to
improve the adversarial transferability. In what follows, we propose an
enhanced momentum iterative gradient-based method to further enhance the
adversarial transferability. Specifically, instead of only accumulating the
gradient during the iterative process, we additionally accumulate the average
gradient of the data points sampled in the gradient direction of the previous
iteration so as to stabilize the update direction and escape from poor local
maxima. Extensive experiments on the standard ImageNet dataset demonstrate that
our method could improve the adversarial transferability of momentum-based
methods by a large margin of 11.1% on average. Moreover, by incorporating with
various input transformation methods, the adversarial transferability could be
further improved significantly. We also attack several extra advanced defense
models under the ensemble-model setting, and the enhancements are remarkable
with at least 7.8% on average.",0,1,0,0,0,0,0.825774,7.0,0.849813,47
http://arxiv.org/abs/2103.09330v3,Cross-Task Instance Representation Interactions and Label Dependencies for Joint Information Extraction with Graph Convolutional Networks,58,0.152264,0.788564,"Existing works on information extraction (IE) have mainly solved the four
main tasks separately (entity mention recognition, relation extraction, event
trigger detection, and argument extraction), thus failing to benefit from
inter-dependencies between tasks. This paper presents a novel deep learning
model to simultaneously solve the four tasks of IE in a single model (called
FourIE). Compared to few prior work on jointly performing four IE tasks, FourIE
features two novel contributions to capture inter-dependencies between tasks.
First, at the representation level, we introduce an interaction graph between
instances of the four tasks that is used to enrich the prediction
representation for one instance with those from related instances of other
tasks. Second, at the label level, we propose a dependency graph for the
information types in the four IE tasks that captures the connections between
the types expressed in an input sentence. A new regularization mechanism is
introduced to enforce the consistency between the golden and predicted type
dependency graphs to improve representation learning. We show that the proposed
model achieves the state-of-the-art performance for joint IE on both
monolingual and multilingual learning settings with three different languages.",0,0,0,0,1,0,0.0653052,9.0,0.521717,39
http://arxiv.org/abs/2107.04589v2,ViTGAN: Training GANs with Vision Transformers,145,0.251754,0.885497,"Recently, Vision Transformers (ViTs) have shown competitive performance on
image recognition while requiring less vision-specific inductive biases. In
this paper, we investigate if such performance can be extended to image
generation. To this end, we integrate the ViT architecture into generative
adversarial networks (GANs). For ViT discriminators, we observe that existing
regularization methods for GANs interact poorly with self-attention, causing
serious instability during training. To resolve this issue, we introduce
several novel regularization techniques for training GANs with ViTs. For ViT
generators, we examine architectural choices for latent and pixel mapping
layers to facilitate convergence. Empirically, our approach, named ViTGAN,
achieves comparable performance to the leading CNN-based GAN models on three
datasets: CIFAR-10, CelebA, and LSUN bedroom.",1,1,0,0,0,0,0.893646,3.0,0.732492,70
http://arxiv.org/abs/2112.01671v1,"An Automatic Approach for Generating Rich, Linked Geo-Metadata from Historical Map Images",12,0.199877,0.259532,"Historical maps contain detailed geographic information difficult to find
elsewhere covering long-periods of time (e.g., 125 years for the historical
topographic maps in the US). However, these maps typically exist as scanned
images without searchable metadata. Existing approaches making historical maps
searchable rely on tedious manual work (including crowd-sourcing) to generate
the metadata (e.g., geolocations and keywords). Optical character recognition
(OCR) software could alleviate the required manual work, but the recognition
results are individual words instead of location phrases (e.g., ""Black"" and
""Mountain"" vs. ""Black Mountain""). This paper presents an end-to-end approach to
address the real-world problem of finding and indexing historical map images.
This approach automatically processes historical map images to extract their
text content and generates a set of metadata that is linked to large external
geospatial knowledge bases. The linked metadata in the RDF (Resource
Description Framework) format support complex queries for finding and indexing
historical maps, such as retrieving all historical maps covering mountain peaks
higher than 1,000 meters in California. We have implemented the approach in a
system called mapKurator. We have evaluated mapKurator using historical maps
from several sources with various map styles, scales, and coverage. Our results
show significant improvement over the state-of-the-art methods. The code has
been made publicly available as modules of the Kartta Labs project at
https://github.com/kartta-labs/Project.",1,1,0,0,1,0,0.175875,10.0,0.674774,26
http://arxiv.org/abs/2102.05406v3,Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-box Approach,81,0.684911,0.986164,"We propose a black-box reduction that turns a certain reinforcement learning
algorithm with optimal regret in a (near-)stationary environment into another
algorithm with optimal dynamic regret in a non-stationary environment,
importantly without any prior knowledge on the degree of non-stationarity. By
plugging different algorithms into our black-box, we provide a list of examples
showing that our approach not only recovers recent results for (contextual)
multi-armed bandits achieved by very specialized algorithms, but also
significantly improves the state of the art for (generalized) linear bandits,
episodic MDPs, and infinite-horizon MDPs in various ways. Specifically, in most
cases our algorithm achieves the optimal dynamic regret
$\widetilde{\mathcal{O}}(\min\{\sqrt{LT}, \Delta^{1/3}T^{2/3}\})$ where $T$ is
the number of rounds and $L$ and $\Delta$ are the number and amount of changes
of the world respectively, while previous works only obtain suboptimal bounds
and/or require the knowledge of $L$ and $\Delta$.",0,0,0,0,1,0,0.683693,4.0,0.632808,64
http://arxiv.org/abs/2108.06670v1,Deep Geospatial Interpolation Networks,2,0.0165266,0.0836241,"Interpolation in Spatio-temporal data has applications in various domains
such as climate, transportation, and mining. Spatio-Temporal interpolation is
highly challenging due to the complex spatial and temporal relationships.
However, traditional techniques such as Kriging suffer from high running time
and poor performance on data that exhibit high variance across space and time
dimensions. To this end, we propose a novel deep neural network called as Deep
Geospatial Interpolation Network(DGIN), which incorporates both spatial and
temporal relationships and has significantly lower training time. DGIN consists
of three major components: Spatial Encoder to capture the spatial dependencies,
Sequential module to incorporate the temporal dynamics, and an Attention block
to learn the importance of the temporal neighborhood around the gap. We
evaluate DGIN on the MODIS reflectance dataset from two different regions. Our
experimental results indicate that DGIN has two advantages: (a) it outperforms
alternative approaches (has lower MSE with p-value < 0.01) and, (b) it has
significantly low execution time than Kriging.",0,1,0,0,1,0,0.0487109,11.0,0.581234,11
http://arxiv.org/abs/2102.03315v1,"Think you have Solved Direct-Answer Question Answering? Try ARC-DA, the Direct-Answer AI2 Reasoning Challenge",36,0.0635626,0.459257,"We present the ARC-DA dataset, a direct-answer (""open response"", ""freeform"")
version of the ARC (AI2 Reasoning Challenge) multiple-choice dataset. While ARC
has been influential in the community, its multiple-choice format is
unrepresentative of real-world questions, and multiple choice formats can be
particularly susceptible to artifacts. The ARC-DA dataset addresses these
concerns by converting questions to direct-answer format using a combination of
crowdsourcing and expert review. The resulting dataset contains 2985 questions
with a total of 8436 valid answers (questions typically have more than one
valid answer). ARC-DA is one of the first DA datasets of natural questions that
often require reasoning, and where appropriate question decompositions are not
evident from the questions themselves. We describe the conversion approach
taken, appropriate evaluation metrics, and several strong models. Although
high, the best scores (81% GENIE, 61.4% F1, 63.2% ROUGE-L) still leave
considerable room for improvement. In addition, the dataset provides a natural
setting for new research on explanation, as many questions require reasoning to
construct answers. We hope the dataset spurs further advances in complex
question-answering by the community. ARC-DA is available at
https://allenai.org/data/arc-da",0,0,1,1,0,0,0.332857,5.0,0.497216,27
http://arxiv.org/abs/2108.05507v1,Distilling Holistic Knowledge with Graph Neural Networks,43,0.360613,0.879718,"Knowledge Distillation (KD) aims at transferring knowledge from a larger
well-optimized teacher network to a smaller learnable student network.Existing
KD methods have mainly considered two types of knowledge, namely the individual
knowledge and the relational knowledge. However, these two types of knowledge
are usually modeled independently while the inherent correlations between them
are largely ignored. It is critical for sufficient student network learning to
integrate both individual knowledge and relational knowledge while reserving
their inherent correlation. In this paper, we propose to distill the novel
holistic knowledge based on an attributed graph constructed among instances.
The holistic knowledge is represented as a unified graph-based embedding by
aggregating individual knowledge from relational neighborhood samples with
graph neural networks, the student network is learned by distilling the
holistic knowledge in a contrastive manner. Extensive experiments and ablation
studies are conducted on benchmark datasets, the results demonstrate the
effectiveness of the proposed method. The code has been published in
https://github.com/wyc-ruiker/HKD",1,0,0,0,0,0,0.762933,7.0,0.822114,42
http://arxiv.org/abs/2104.07659v1,GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds,110,0.656063,0.758569,"We present GANcraft, an unsupervised neural rendering framework for
generating photorealistic images of large 3D block worlds such as those created
in Minecraft. Our method takes a semantic block world as input, where each
block is assigned a semantic label such as dirt, grass, or water. We represent
the world as a continuous volumetric function and train our model to render
view-consistent photorealistic images for a user-controlled camera. In the
absence of paired ground truth real images for the block world, we devise a
training technique based on pseudo-ground truth and adversarial training. This
stands in contrast to prior work on neural rendering for view synthesis, which
requires ground truth images to estimate scene geometry and view-dependent
appearance. In addition to camera trajectory, GANcraft allows user control over
both scene semantics and output style. Experimental results with comparison to
strong baselines show the effectiveness of GANcraft on this novel task of
photorealistic 3D block world synthesis. The project website is available at
https://nvlabs.github.io/GANcraft/ .",1,0,0,0,0,0,0.974076,4.0,0.9215,71
http://arxiv.org/abs/2107.02173v3,Is Automated Topic Model Evaluation Broken?: The Incoherence of Coherence,91,0.323884,0.995013,"Topic model evaluation, like evaluation of other unsupervised methods, can be
contentious. However, the field has coalesced around automated estimates of
topic coherence, which rely on the frequency of word co-occurrences in a
reference corpus. Contemporary neural topic models surpass classical ones
according to these metrics. At the same time, topic model evaluation suffers
from a validation gap: automated coherence, developed for classical models, has
not been validated using human experimentation for neural models. In addition,
a meta-analysis of topic modeling literature reveals a substantial
standardization gap in automated topic modeling benchmarks. To address the
validation gap, we compare automated coherence with the two most widely
accepted human judgment tasks: topic rating and word intrusion. To address the
standardization gap, we systematically evaluate a dominant classical model and
two state-of-the-art neural models on two commonly used datasets. Automated
evaluations declare a winning model when corresponding human evaluations do
not, calling into question the validity of fully automatic evaluations
independent of human judgments.",1,0,0,0,0,1,0.116261,7.0,0.471401,107
http://arxiv.org/abs/2112.07924v2,Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation,38,0.643374,0.908928,"Knowledge-grounded dialogue systems are challenging to build due to the lack
of training data and heterogeneous knowledge sources. Existing systems perform
poorly on unseen topics due to limited topics covered in the training data. In
addition, heterogeneous knowledge sources make it challenging for systems to
generalize to other tasks because knowledge sources in different knowledge
representations require different knowledge encoders. To address these
challenges, we present PLUG, a language model that homogenizes different
knowledge sources to a unified knowledge representation for knowledge-grounded
dialogue generation tasks. PLUG is pre-trained on a dialogue generation task
conditioned on a unified essential knowledge representation. It can generalize
to different downstream knowledge-grounded dialogue generation tasks with a few
training examples. The empirical evaluation on two benchmarks shows that our
model generalizes well across different knowledge-grounded tasks. It can
achieve comparable performance with state-of-the-art methods under a
fully-supervised setting and significantly outperforms other methods in
zero-shot and few-shot settings.",0,1,0,0,1,0,0.944701,5.0,0.89071,55
http://arxiv.org/abs/2102.03529v2,Vampire With a Brain Is a Good ITP Hammer,9,0.136298,0.833076,"Vampire has been for a long time the strongest first-order automatic theorem
prover, widely used for hammer-style proof automation in ITPs such as Mizar,
Isabelle, HOL, and Coq. In this work, we considerably improve the performance
of Vampire in hammering over the full Mizar library by enhancing its saturation
procedure with efficient neural guidance. In particular, we employ a recently
proposed recursive neural network classifying the generated clauses based only
on their derivation history. Compared to previous neural methods based on
considering the logical content of the clauses, our architecture makes
evaluating a single clause much less time consuming. The resulting system shows
good learning capability and improves on the state-of-the-art performance on
the Mizar library, while proving many theorems that the related ENIGMA system
could not prove in a similar hammering evaluation.",0,1,0,0,0,0,0.208262,10.0,0.69361,47
http://arxiv.org/abs/2110.07592v3,DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances,10,0.201514,0.0769026,"Toxic speech, also known as hate speech, is regarded as one of the crucial
issues plaguing online social media today. Most recent work on toxic speech
detection is constrained to the modality of text and written conversations with
very limited work on toxicity detection from spoken utterances or using the
modality of speech. In this paper, we introduce a new dataset DeToxy, the first
publicly available toxicity annotated dataset for the English language. DeToxy
is sourced from various openly available speech databases and consists of over
2 million utterances. We believe that our dataset would act as a benchmark for
the relatively new and un-explored Spoken Language Processing task of detecting
toxicity from spoken utterances and boost further research in this space.
Finally, we also provide strong unimodal baselines for our dataset and compare
traditional two-step and E2E approaches. Our experiments show that in the case
of spoken utterances, text-based approaches are largely dependent on gold
human-annotated transcripts for their performance and also suffer from the
problem of keyword bias. However, the presence of speech files in DeToxy helps
facilitates the development of E2E speech models which alleviate both the
above-stated problems by better capturing speech clues.",0,1,1,1,0,0,0.865812,5.0,0.817592,45
http://arxiv.org/abs/2103.10255v2,Equivariant Filters for Efficient Tracking in 3D Imaging,11,0.082721,0.205444,"We demonstrate an object tracking method for 3D images with fixed
computational cost and state-of-the-art performance. Previous methods predicted
transformation parameters from convolutional layers. We instead propose an
architecture that does not include either flattening of convolutional features
or fully connected layers, but instead relies on equivariant filters to
preserve transformations between inputs and outputs (e.g. rot./trans. of inputs
rotate/translate outputs). The transformation is then derived in closed form
from the outputs of the filters. This method is useful for applications
requiring low latency, such as real-time tracking. We demonstrate our model on
synthetically augmented adult brain MRI, as well as fetal brain MRI, which is
the intended use-case.",0,1,0,0,1,0,0.360284,13.0,0.814213,22
http://arxiv.org/abs/2111.01366v1,Improved Loss Function-Based Prediction Method of Extreme Temperatures in Greenhouses,1,0.0153576,0.0838624,"The prediction of extreme greenhouse temperatures to which crops are
susceptible is essential in the field of greenhouse planting. It can help avoid
heat or freezing damage and economic losses. Therefore, it's important to
develop models that can predict them accurately. Due to the lack of extreme
temperature data in datasets, it is challenging for models to accurately
predict it. In this paper, we propose an improved loss function, which is
suitable for a variety of machine learning models. By increasing the weight of
extreme temperature samples and reducing the possibility of misjudging extreme
temperature as normal, the proposed loss function can enhance the prediction
results in extreme situations. To verify the effectiveness of the proposed
method, we implement the improved loss function in LightGBM, long short-term
memory, and artificial neural network and conduct experiments on a real-world
greenhouse dataset. The results show that the performance of models with the
improved loss function is enhanced compared to the original models in extreme
cases. The improved models can be used to guarantee the timely judgment of
extreme temperatures in agricultural greenhouses, thereby preventing
unnecessary losses caused by incorrect predictions.",0,1,0,0,0,0,0.120504,21.0,0.825619,29
http://arxiv.org/abs/2106.00188v2,PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World,60,0.7779,0.992775,"We propose PIGLeT: a model that learns physical commonsense knowledge through
interaction, and then uses this knowledge to ground language. We factorize
PIGLeT into a physical dynamics model, and a separate language model. Our
dynamics model learns not just what objects are but also what they do: glass
cups break when thrown, plastic ones don't. We then use it as the interface to
our language model, giving us a unified model of linguistic form and grounded
meaning. PIGLeT can read a sentence, simulate neurally what might happen next,
and then communicate that result through a literal symbolic representation, or
natural language.
  Experimental results show that our model effectively learns world dynamics,
along with how to communicate them. It is able to correctly forecast ""what
happens next"" given an English sentence over 80% of the time, outperforming a
100x larger, text-to-text approach by over 10%. Likewise, its natural language
summaries of physical interactions are also judged by humans as more accurate
than LM alternatives. We present comprehensive analysis showing room for future
work.",0,0,1,0,0,0,0.914326,7.0,0.898513,44
http://arxiv.org/abs/2109.07046v1,A Conditional Generative Matching Model for Multi-lingual Reply Suggestion,1,0.0744232,0.202127,"We study the problem of multilingual automated reply suggestions (RS) model
serving many languages simultaneously. Multilingual models are often challenged
by model capacity and severe data distribution skew across languages. While
prior works largely focus on monolingual models, we propose Conditional
Generative Matching models (CGM), optimized within a Variational Autoencoder
framework to address challenges arising from multi-lingual RS. CGM does so with
expressive message conditional priors, mixture densities to enhance
multi-lingual data representation, latent alignment for language
discrimination, and effective variational optimization techniques for training
multi-lingual RS. The enhancements result in performance that exceed
competitive baselines in relevance (ROUGE score) by more than 10\% on average,
and 16\% for low resource languages. CGM also shows remarkable improvements in
diversity (80\%) illustrating its expressiveness in representation of
multi-lingual data.",0,1,0,0,1,0,0.960785,6.0,0.927622,59
http://arxiv.org/abs/2105.04271v2,DocOIE: A Document-level Context-Aware Dataset for OpenIE,12,0.1178,0.660276,"Open Information Extraction (OpenIE) aims to extract structured relational
tuples (subject, relation, object) from sentences and plays critical roles for
many downstream NLP applications. Existing solutions perform extraction at
sentence level, without referring to any additional contextual information. In
reality, however, a sentence typically exists as part of a document rather than
standalone; we often need to access relevant contextual information around the
sentence before we can accurately interpret it. As there is no document-level
context-aware OpenIE dataset available, we manually annotate 800 sentences from
80 documents in two domains (Healthcare and Transportation) to form a DocOIE
dataset for evaluation. In addition, we propose DocIE, a novel document-level
context-aware OpenIE model. Our experimental results based on DocIE demonstrate
that incorporating document-level context is helpful in improving OpenIE
performance. Both DocOIE dataset and DocIE model are released for public.",0,1,1,1,0,0,0.376865,8.0,0.705236,31
http://arxiv.org/abs/2104.06936v1,IQDet: Instance-wise Quality Distribution Sampling for Object Detection,42,0.0370407,0.335587,"We propose a dense object detector with an instance-wise sampling strategy,
named IQDet. Instead of using human prior sampling strategies, we first extract
the regional feature of each ground-truth to estimate the instance-wise quality
distribution. According to a mixture model in spatial dimensions, the
distribution is more noise-robust and adapted to the semantic pattern of each
instance. Based on the distribution, we propose a quality sampling strategy,
which automatically selects training samples in a probabilistic manner and
trains with more high-quality samples. Extensive experiments on MS COCO show
that our method steadily improves baseline by nearly 2.4 AP without bells and
whistles. Moreover, our best model achieves 51.6 AP, outperforming all existing
state-of-the-art one-stage detectors and it is completely cost-free in
inference time.",0,1,0,0,1,0,0.406325,5.0,0.547874,23
http://arxiv.org/abs/2105.10831v1,Stereo Matching Based on Visual Sensitive Information,4,0.024462,0.146414,"The area of computer vision is one of the most discussed topics amongst many
scholars, and stereo matching is its most important sub fields. After the
parallax map is transformed into a depth map, it can be applied to many
intelligent fields. In this paper, a stereo matching algorithm based on visual
sensitive information is proposed by using standard images from Middlebury
dataset. Aiming at the limitation of traditional stereo matching algorithms
regarding the cost window, a cost aggregation algorithm based on the dynamic
window is proposed, and the disparity image is optimized by using left and
right consistency detection to further reduce the error matching rate. The
experimental results show that the proposed algorithm can effectively enhance
the stereo matching effect of the image providing significant improvement in
accuracy as compared with the classical census algorithm. The proposed model
code, dataset, and experimental results are available at
https://github.com/WangHewei16/Stereo-Matching.",1,1,0,0,0,0,0.00140819,10.0,0.182582,25
http://arxiv.org/abs/2105.07571v1,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,25,0.414344,0.555471,"While argument mining has achieved significant success in classifying
argumentative relations between statements (support, attack, and neutral), we
have a limited computational understanding of logical mechanisms that
constitute those relations. Most recent studies rely on black-box models, which
are not as linguistically insightful as desired. On the other hand, earlier
studies use rather simple lexical features, missing logical relations between
statements. To overcome these limitations, our work classifies argumentative
relations based on four logical and theory-informed mechanisms between two
statements, namely (i) factual consistency, (ii) sentiment coherence, (iii)
causal relation, and (iv) normative relation. We demonstrate that our
operationalization of these logical mechanisms classifies argumentative
relations without directly training on data labeled with the relations,
significantly better than several unsupervised baselines. We further
demonstrate that these mechanisms also improve supervised classifiers through
representation learning.",0,0,0,0,0,0,0.591566,7.0,0.754301,57
http://arxiv.org/abs/2103.06076v2,"Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs",65,0.353259,0.783423,"Disaggregated evaluations of AI systems, in which system performance is
assessed and reported separately for different groups of people, are
conceptually simple. However, their design involves a variety of choices. Some
of these choices influence the results that will be obtained, and thus the
conclusions that can be drawn; others influence the impacts -- both beneficial
and harmful -- that a disaggregated evaluation will have on people, including
the people whose data is used to conduct the evaluation. We argue that a deeper
understanding of these choices will enable researchers and practitioners to
design careful and conclusive disaggregated evaluations. We also argue that
better documentation of these choices, along with the underlying considerations
and tradeoffs that have been made, will help others when interpreting an
evaluation's results and conclusions.",0,0,0,0,0,1,0.617641,5.0,0.670239,75
http://arxiv.org/abs/2105.14125v1,Joint Optimization of Multi-Objective Reinforcement Learning with Policy Gradient Based Algorithm,6,0.158636,0.172199,"Many engineering problems have multiple objectives, and the overall aim is to
optimize a non-linear function of these objectives. In this paper, we formulate
the problem of maximizing a non-linear concave function of multiple long-term
objectives. A policy-gradient based model-free algorithm is proposed for the
problem. To compute an estimate of the gradient, a biased estimator is
proposed. The proposed algorithm is shown to achieve convergence to within an
$\epsilon$ of the global optima after sampling
$\mathcal{O}(\frac{M^4\sigma^2}{(1-\gamma)^8\epsilon^4})$ trajectories where
$\gamma$ is the discount factor and $M$ is the number of the agents, thus
achieving the same dependence on $\epsilon$ as the policy gradient algorithm
for the standard reinforcement learning.",0,0,0,0,0,0,0.878887,6.0,0.85629,40
http://arxiv.org/abs/2112.10807v4,Demonstration Informed Specification Search,2,0.073218,0.0545742,"This paper considers the problem of learning temporal task specifications,
e.g. automata and temporal logic, from expert demonstrations. Task
specifications are a class of sparse memory augmented rewards with explicit
support for temporal and Boolean composition. Three features make learning
temporal task specifications difficult: (1) the (countably) infinite number of
tasks under consideration; (2) an a-priori ignorance of what memory is needed
to encode the task; and (3) the discrete solution space - typically addressed
by (brute force) enumeration. To overcome these hurdles, we propose
Demonstration Informed Specification Search (DISS): a family of algorithms
requiring only black box access to a maximum entropy planner and a task sampler
from labeled examples. DISS then works by alternating between conjecturing
labeled examples to make the provided demonstrations less surprising and
sampling tasks consistent with the conjectured labeled examples. We provide a
concrete implementation of DISS in the context of tasks described by
Deterministic Finite Automata, and show that DISS is able to efficiently
identify tasks from only one or two expert demonstrations.",0,0,0,0,0,0,0.0896937,24.0,0.834409,24
http://arxiv.org/abs/2110.06274v2,LiST: Lite Prompted Self-training Makes Parameter-Efficient Few-shot Learners,10,0.0449896,0.159554,"We present a new method LiST is short for Lite Prompted Self-Training for
parameter-efficient fine-tuning of large pre-trained language models (PLMs) for
few-shot learning. LiST improves over recent methods that adopt prompt-based
fine-tuning (FN) using two key techniques. The first is the use of
self-training to leverage large amounts of unlabeled data for prompt-based FN
in few-shot settings. We use self-training in conjunction with meta-learning
for re-weighting noisy pseudo-prompt labels. Self-training is expensive as it
requires updating all the model parameters repetitively. Therefore, we use a
second technique for light-weight fine-tuning where we introduce a small number
of task-specific parameters that are fine-tuned during self-training while
keeping the PLM encoder frozen. Our experiments show that LiST can effectively
leverage unlabeled data to improve the model performance for few-shot learning.
Additionally, the fine-tuning is efficient as it only updates a small
percentage of parameters and the overall model footprint is reduced since
several tasks can share a common PLM encoder as backbone. A comprehensive study
on six NLU tasks demonstrate LiST to improve by 35% over classic fine-tuning
and 6% over prompt-based FN with 96% reduction in number of trainable
parameters when fine-tuned with no more than 30 labeled examples from each
task. With only 14M tunable parameters, LiST outperforms GPT-3 in-context
learning by 33% on few-shot NLU tasks.",1,1,0,0,0,0,0.94336,3.0,0.815079,49
http://arxiv.org/abs/2102.02971v1,Metaknowledge Extraction Based on Multi-Modal Documents,3,0.0101487,0.146544,"The triple-based knowledge in large-scale knowledge bases is most likely
lacking in structural logic and problematic of conducting knowledge hierarchy.
In this paper, we introduce the concept of metaknowledge to knowledge
engineering research for the purpose of structural knowledge construction.
Therefore, the Metaknowledge Extraction Framework and Document Structure Tree
model are presented to extract and organize metaknowledge elements (titles,
authors, abstracts, sections, paragraphs, etc.), so that it is feasible to
extract the structural knowledge from multi-modal documents. Experiment results
have proved the effectiveness of metaknowledge elements extraction by our
framework. Meanwhile, detailed examples are given to demonstrate what exactly
metaknowledge is and how to generate it. At the end of this paper, we propose
and analyze the task flow of metaknowledge applications and the associations
between knowledge and metaknowledge.",0,0,0,0,0,0,0.658631,4.0,0.615672,50
http://arxiv.org/abs/2103.11794v1,Graph Ensemble Learning over Multiple Dependency Trees for Aspect-level Sentiment Classification,49,0.30791,0.974425,"Recent work on aspect-level sentiment classification has demonstrated the
efficacy of incorporating syntactic structures such as dependency trees with
graph neural networks(GNN), but these approaches are usually vulnerable to
parsing errors. To better leverage syntactic information in the face of
unavoidable errors, we propose a simple yet effective graph ensemble technique,
GraphMerge, to make use of the predictions from differ-ent parsers. Instead of
assigning one set of model parameters to each dependency tree, we first combine
the dependency relations from different parses before applying GNNs over the
resulting graph. This allows GNN mod-els to be robust to parse errors at no
additional computational cost, and helps avoid overparameterization and
overfitting from GNN layer stacking by introducing more connectivity into the
ensemble graph. Our experiments on the SemEval 2014 Task 4 and ACL 14 Twitter
datasets show that our GraphMerge model not only outperforms models with single
dependency tree, but also beats other ensemble mod-els without adding model
parameters.",0,1,0,0,1,0,0.83444,5.0,0.795494,39
http://arxiv.org/abs/2109.03079v1,GOLD: Improving Out-of-Scope Detection in Dialogues using Data Augmentation,30,0.193453,0.545483,"Practical dialogue systems require robust methods of detecting out-of-scope
(OOS) utterances to avoid conversational breakdowns and related failure modes.
Directly training a model with labeled OOS examples yields reasonable
performance, but obtaining such data is a resource-intensive process. To tackle
this limited-data problem, previous methods focus on better modeling the
distribution of in-scope (INS) examples. We introduce GOLD as an orthogonal
technique that augments existing data to train better OOS detectors operating
in low-data regimes. GOLD generates pseudo-labeled candidates using samples
from an auxiliary dataset and keeps only the most beneficial candidates for
training through a novel filtering mechanism. In experiments across three
target benchmarks, the top GOLD model outperforms all existing methods on all
key metrics, achieving relative gains of 52.4%, 48.9% and 50.3% against median
baseline performance. We also analyze the unique properties of OOS data to
identify key factors for optimally applying our proposed method.",1,1,0,0,1,0,0.439712,6.0,0.640773,69
http://arxiv.org/abs/2107.01110v1,"Decision-Making Technology for Autonomous Vehicles Learning-Based Methods, Applications and Future Outlook",35,0.603251,0.872597,"Autonomous vehicles have a great potential in the application of both civil
and military fields, and have become the focus of research with the rapid
development of science and economy. This article proposes a brief review on
learning-based decision-making technology for autonomous vehicles since it is
significant for safer and efficient performance of autonomous vehicles.
Firstly, the basic outline of decision-making technology is provided. Secondly,
related works about learning-based decision-making methods for autonomous
vehicles are mainly reviewed with the comparison to classical decision-making
methods. In addition, applications of decision-making methods in existing
autonomous vehicles are summarized. Finally, promising research topics in the
future study of decision-making technology for autonomous vehicles are
prospected.",0,1,0,0,0,0,0.575511,5.0,0.647219,64
http://arxiv.org/abs/2103.13309v1,Are Multilingual Models Effective in Code-Switching?,58,0.330543,0.858403,"Multilingual language models have shown decent performance in multilingual
and cross-lingual natural language understanding tasks. However, the power of
these multilingual models in code-switching tasks has not been fully explored.
In this paper, we study the effectiveness of multilingual language models to
understand their capability and adaptability to the mixed-language setting by
considering the inference speed, performance, and number of parameters to
measure their practicality. We conduct experiments in three language pairs on
named entity recognition and part-of-speech tagging and compare them with
existing methods, such as using bilingual embeddings and multilingual
meta-embeddings. Our findings suggest that pre-trained multilingual models do
not necessarily guarantee high-quality representations on code-switching, while
using meta-embeddings achieves similar results with significantly fewer
parameters.",0,1,0,0,0,0,0.260764,6.0,0.532282,51
http://arxiv.org/abs/2102.12162v1,From Universal Language Model to Downstream Task: Improving RoBERTa-Based Vietnamese Hate Speech Detection,11,0.239616,0.351364,"Natural language processing is a fast-growing field of artificial
intelligence. Since the Transformer was introduced by Google in 2017, a large
number of language models such as BERT, GPT, and ELMo have been inspired by
this architecture. These models were trained on huge datasets and achieved
state-of-the-art results on natural language understanding. However,
fine-tuning a pre-trained language model on much smaller datasets for
downstream tasks requires a carefully-designed pipeline to mitigate problems of
the datasets such as lack of training data and imbalanced data. In this paper,
we propose a pipeline to adapt the general-purpose RoBERTa language model to a
specific text classification task: Vietnamese Hate Speech Detection. We first
tune the PhoBERT on our dataset by re-training the model on the Masked Language
Model task; then, we employ its encoder for text classification. In order to
preserve pre-trained weights while learning new feature representations, we
further utilize different training techniques: layer freezing, block-wise
learning rate, and label smoothing. Our experiments proved that our proposed
pipeline boosts the performance significantly, achieving a new state-of-the-art
on Vietnamese Hate Speech Detection campaign with 0.7221 F1 score.",0,1,0,0,1,0,0.877385,10.0,0.913188,38
http://arxiv.org/abs/2109.10085v1,Heterogeneous Ensemble for ESG Ratings Prediction,12,0.142212,0.811175,"Over the past years, topics ranging from climate change to human rights have
seen increasing importance for investment decisions. Hence, investors (asset
managers and asset owners) who wanted to incorporate these issues started to
assess companies based on how they handle such topics. For this assessment,
investors rely on specialized rating agencies that issue ratings along the
environmental, social and governance (ESG) dimensions. Such ratings allow them
to make investment decisions in favor of sustainability. However, rating
agencies base their analysis on subjective assessment of sustainability
reports, not provided by every company. Furthermore, due to human labor
involved, rating agencies are currently facing the challenge to scale up the
coverage in a timely manner.
  In order to alleviate these challenges and contribute to the overall goal of
supporting sustainability, we propose a heterogeneous ensemble model to predict
ESG ratings using fundamental data. This model is based on feedforward neural
network, CatBoost and XGBoost ensemble members. Given the public availability
of fundamental data, the proposed method would allow cost-efficient and
scalable creation of initial ESG ratings (also for companies without
sustainability reporting). Using our approach we are able to explain 54% of the
variation in ratings R2 using fundamental data and outperform prior work in
this area.",0,1,0,0,1,0,0.0371047,12.0,0.59295,62
http://arxiv.org/abs/2106.05209v2,Distilling Image Classifiers in Object Detectors,8,0.0780989,0.259563,"Knowledge distillation constitutes a simple yet effective way to improve the
performance of a compact student network by exploiting the knowledge of a more
powerful teacher. Nevertheless, the knowledge distillation literature remains
limited to the scenario where the student and the teacher tackle the same task.
Here, we investigate the problem of transferring knowledge not only across
architectures but also across tasks. To this end, we study the case of object
detection and, instead of following the standard detector-to-detector
distillation approach, introduce a classifier-to-detector knowledge transfer
framework. In particular, we propose strategies to exploit the classification
teacher to improve both the detector's recognition accuracy and localization
performance. Our experiments on several detectors with different backbones
demonstrate the effectiveness of our approach, allowing us to outperform the
state-of-the-art detector-to-detector distillation methods.",1,1,1,0,1,0,0.979689,8.0,0.968833,58
http://arxiv.org/abs/2109.14651v1,Uncertainty-aware Mean Teacher for Source-free Unsupervised Domain Adaptive 3D Object Detection,20,0.0895923,0.529067,"Pseudo-label based self training approaches are a popular method for
source-free unsupervised domain adaptation. However, their efficacy depends on
the quality of the labels generated by the source trained model. These labels
may be incorrect with high confidence, rendering thresholding methods
ineffective. In order to avoid reinforcing errors caused by label noise, we
propose an uncertainty-aware mean teacher framework which implicitly filters
incorrect pseudo-labels during training. Leveraging model uncertainty allows
the mean teacher network to perform implicit filtering by down-weighing losses
corresponding uncertain pseudo-labels. Effectively, we perform automatic
soft-sampling of pseudo-labeled data while aligning predictions from the
student and teacher networks. We demonstrate our method on several domain
adaptation scenarios, from cross-dataset to cross-weather conditions, and
achieve state-of-the-art performance in these cases, on the KITTI lidar target
dataset.",1,1,0,0,1,0,0.719147,5.0,0.725904,35
http://arxiv.org/abs/2112.08140v1,Improving Conversational Recommendation Systems' Quality with Context-Aware Item Meta Information,23,0.355841,0.76854,"Conversational recommendation systems (CRS) engage with users by inferring
user preferences from dialog history, providing accurate recommendations, and
generating appropriate responses. Previous CRSs use knowledge graph (KG) based
recommendation modules and integrate KG with language models for response
generation. Although KG-based approaches prove effective, two issues remain to
be solved. First, KG-based approaches ignore the information in the
conversational context but only rely on entity relations and bag of words to
recommend items. Second, it requires substantial engineering efforts to
maintain KGs that model domain-specific relations, thus leading to less
flexibility. In this paper, we propose a simple yet effective architecture
comprising a pre-trained language model (PLM) and an item metadata encoder. The
encoder learns to map item metadata to embeddings that can reflect the semantic
information in the dialog context. The PLM then consumes the semantic-aligned
item embeddings together with dialog context to generate high-quality
recommendations and responses. Instead of modeling entity relations with KGs,
our model reduces engineering complexity by directly converting each item to an
embedding. Experimental results on the benchmark dataset ReDial show that our
model obtains state-of-the-art results on both recommendation and response
generation tasks.",0,1,0,0,1,0,0.869536,9.0,0.900208,36
http://arxiv.org/abs/2112.08688v2,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,36,0.330281,0.862294,"Retrieval-augmented generation models have shown state-of-the-art performance
across many knowledge-intensive NLP tasks such as open question answering and
fact verification. These models are trained to generate the final output given
the retrieved passages, which can be irrelevant to the original query, leading
to learning spurious cues or answer memorization. This work introduces a method
to incorporate the evidentiality of passages -- whether a passage contains
correct evidence to support the output -- into training the generator. We
introduce a multi-task learning framework to jointly generate the final output
and predict the evidentiality of each passage, leveraging a new task-agnostic
method to obtain silver evidentiality labels for supervision. Our experiments
on five datasets across three knowledge-intensive tasks show that our new
evidentiality-guided generator significantly outperforms its direct counterpart
with the same-size model and advances the state of the art on FaVIQ-Ambig. We
attribute these improvements to both the auxiliary multi-task learning and
silver evidentiality mining techniques.",1,1,0,0,1,0,0.76204,5.0,0.750436,67
http://arxiv.org/abs/2105.03363v3,Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts,22,0.175283,0.677814,"This paper investigates the model-based methods in multi-agent reinforcement
learning (MARL). We specify the dynamics sample complexity and the opponent
sample complexity in MARL, and conduct a theoretic analysis of return
discrepancy upper bound. To reduce the upper bound with the intention of low
sample complexity during the whole learning process, we propose a novel
decentralized model-based MARL method, named Adaptive Opponent-wise Rollout
Policy Optimization (AORPO). In AORPO, each agent builds its multi-agent
environment model, consisting of a dynamics model and multiple opponent models,
and trains its policy with the adaptive opponent-wise rollout. We further prove
the theoretic convergence of AORPO under reasonable assumptions. Empirical
experiments on competitive and cooperative tasks demonstrate that AORPO can
achieve improved sample efficiency with comparable asymptotic performance over
the compared MARL methods.",1,0,0,0,0,0,0.735541,6.0,0.779299,45
http://arxiv.org/abs/2103.12277v1,Conditional Training with Bounding Map for Universal Lesion Detection,8,0.0167432,0.105574,"Universal Lesion Detection (ULD) in computed tomography plays an essential
role in computer-aided diagnosis. Promising ULD results have been reported by
coarse-to-fine two-stage detection approaches, but such two-stage ULD methods
still suffer from issues like imbalance of positive v.s. negative anchors
during object proposal and insufficient supervision problem during localization
regression and classification of the region of interest (RoI) proposals. While
leveraging pseudo segmentation masks such as bounding map (BM) can reduce the
above issues to some degree, it is still an open problem to effectively handle
the diverse lesion shapes and sizes in ULD. In this paper, we propose a
BM-based conditional training for two-stage ULD, which can (i) reduce positive
vs. negative anchor imbalance via BM-based conditioning (BMC) mechanism for
anchor sampling instead of traditional IoU-based rule; and (ii) adaptively
compute size-adaptive BM (ABM) from lesion bounding box, which is used for
improving lesion localization accuracy via ABMsupervised segmentation.
Experiments with four state-of-the-art methods show that the proposed approach
can bring an almost free detection accuracy improvement without requiring
expensive lesion mask annotations.",0,0,0,0,0,0,0.219221,4.0,0.248517,33
http://arxiv.org/abs/2109.06740v1,Deceptive Decision-Making Under Uncertainty,6,0.0680201,0.1568,"We study the design of autonomous agents that are capable of deceiving
outside observers about their intentions while carrying out tasks in
stochastic, complex environments. By modeling the agent's behavior as a Markov
decision process, we consider a setting where the agent aims to reach one of
multiple potential goals while deceiving outside observers about its true goal.
We propose a novel approach to model observer predictions based on the
principle of maximum entropy and to efficiently generate deceptive strategies
via linear programming. The proposed approach enables the agent to exhibit a
variety of tunable deceptive behaviors while ensuring the satisfaction of
probabilistic constraints on the behavior. We evaluate the performance of the
proposed approach via comparative user studies and present a case study on the
streets of Manhattan, New York, using real travel time distributions.",0,0,0,0,0,0,0.0163569,13.0,0.560438,42
http://arxiv.org/abs/2101.07720v1,Hyperdimensional computing as a framework for systematic aggregation of image descriptors,34,0.0894863,0.911302,"Image and video descriptors are an omnipresent tool in computer vision and
its application fields like mobile robotics. Many hand-crafted and in
particular learned image descriptors are numerical vectors with a potentially
(very) large number of dimensions. Practical considerations like memory
consumption or time for comparisons call for the creation of compact
representations. In this paper, we use hyperdimensional computing (HDC) as an
approach to systematically combine information from a set of vectors in a
single vector of the same dimensionality. HDC is a known technique to perform
symbolic processing with distributed representation in numerical vectors with
thousands of dimensions. We present a HDC implementation that is suitable for
processing the output of existing and future (deep-learning based) image
descriptors. We discuss how this can be used as a framework to process
descriptors together with additional knowledge by simple and fast vector
operations. A concrete outcome is a novel HDC-based approach to aggregate a set
of local image descriptors together with their image positions in a single
holistic descriptor. The comparison to available holistic descriptors and
aggregation methods on a series of standard mobile robotics place recognition
experiments shows a 20% improvement in average performance compared to
runner-up and 3.6x better worst-case performance.",0,0,0,0,0,0,0.0219506,11.0,0.507516,67
http://arxiv.org/abs/2104.12920v1,"Equity and Artificial Intelligence in Education: Will ""AIEd"" Amplify or Alleviate Inequities in Education?",26,0.406249,0.760799,"The development of educational AI (AIEd) systems has often been motivated by
their potential to promote educational equity and reduce achievement gaps
across different groups of learners -- for example, by scaling up the benefits
of one-on-one human tutoring to a broader audience, or by filling gaps in
existing educational services. Given these noble intentions, why might AIEd
systems have inequitable impacts in practice? In this chapter, we discuss four
lenses that can be used to examine how and why AIEd systems risk amplifying
existing inequities. Building from these lenses, we then outline possible paths
towards more equitable futures for AIEd, while highlighting debates surrounding
each proposal. In doing so, we hope to provoke new conversations around the
design of equitable AIEd, and to push ongoing conversations in the field
forward.",0,0,0,0,0,0,0.557426,6.0,0.697696,83
http://arxiv.org/abs/2102.08078v2,Restore from Restored: Single-image Inpainting,3,0.021128,0.0790689,"Recent image inpainting methods show promising results due to the power of
deep learning, which can explore external information available from a large
training dataset. However, many state-of-the-art inpainting networks are still
limited in exploiting internal information available in the given input image
at test time. To mitigate this problem, we present a novel and efficient
self-supervised fine-tuning algorithm that can adapt the parameters of fully
pre-trained inpainting networks without using ground-truth target images. We
update the parameters of the pre-trained state-of-the-art inpainting networks
by utilizing existing self-similar patches within the given input image without
changing network architecture and improve the inpainting quality by a large
margin. Qualitative and quantitative experimental results demonstrate the
superiority of the proposed algorithm, and we achieve state-of-the-art
inpainting results on publicly available numerous benchmark datasets.",0,1,0,0,1,0,0.945577,8.0,0.932381,46
http://arxiv.org/abs/2110.07160v1,Transformer over Pre-trained Transformer for Neural Text Segmentation with Enhanced Topic Coherence,30,0.537748,0.470557,"This paper proposes a transformer over transformer framework, called
Transformer$^2$, to perform neural text segmentation. It consists of two
components: bottom-level sentence encoders using pre-trained transformers, and
an upper-level transformer-based segmentation model based on the sentence
embeddings. The bottom-level component transfers the pre-trained knowledge
learned from large external corpora under both single and pair-wise supervised
NLP tasks to model the sentence embeddings for the documents. Given the
sentence embeddings, the upper-level transformer is trained to recover the
segmentation boundaries as well as the topic labels of each sentence. Equipped
with a multi-task loss and the pre-trained knowledge, Transformer$^2$ can
better capture the semantic coherence within the same segments. Our experiments
show that (1) Transformer$^2$ manages to surpass state-of-the-art text
segmentation models in terms of a commonly-used semantic coherence measure; (2)
in most cases, both single and pair-wise pre-trained knowledge contribute to
the model performance; (3) bottom-level sentence encoders pre-trained on
specific languages yield better performance than those pre-trained on specific
domains.",0,1,0,0,1,0,0.318414,14.0,0.816551,31
http://arxiv.org/abs/2108.03456v1,"A Unified Model for Zero-shot Music Source Separation, Transcription and Synthesis",21,0.827697,0.791669,"We propose a unified model for three inter-related tasks: 1) to
\textit{separate} individual sound sources from a mixed music audio, 2) to
\textit{transcribe} each sound source to MIDI notes, and 3) to\textit{
synthesize} new pieces based on the timbre of separated sources. The model is
inspired by the fact that when humans listen to music, our minds can not only
separate the sounds of different instruments, but also at the same time
perceive high-level representations such as score and timbre. To mirror such
capability computationally, we designed a pitch-timbre disentanglement module
based on a popular encoder-decoder neural architecture for source separation.
The key inductive biases are vector-quantization for pitch representation and
pitch-transformation invariant for timbre representation. In addition, we
adopted a query-by-example method to achieve \textit{zero-shot} learning, i.e.,
the model is capable of doing source separation, transcription, and synthesis
for \textit{unseen} instruments. The current design focuses on audio mixtures
of two monophonic instruments. Experimental results show that our model
outperforms existing multi-task baselines, and the transcribed score serves as
a powerful auxiliary for separation tasks.",1,0,0,0,0,0,0.898529,6.0,0.869706,30
http://arxiv.org/abs/2110.05603v2,Generalizing to New Domains by Mapping Natural Language to Lifted LTL,8,0.0114667,0.122125,"Recent work on using natural language to specify commands to robots has
grounded that language to LTL. However, mapping natural language task
specifications to LTL task specifications using language models require
probability distributions over finite vocabulary. Existing state-of-the-art
methods have extended this finite vocabulary to include unseen terms from the
input sequence to improve output generalization. However, novel
out-of-vocabulary atomic propositions cannot be generated using these methods.
To overcome this, we introduce an intermediate contextual query representation
which can be learned from single positive task specification examples,
associating a contextual query with an LTL template. We demonstrate that this
intermediate representation allows for generalization over unseen object
references, assuming accurate groundings are available. We compare our method
of mapping natural language task specifications to intermediate contextual
queries against state-of-the-art CopyNet models capable of translating natural
language to LTL, by evaluating whether correct LTL for manipulation and
navigation task specifications can be output, and show that our method
outperforms the CopyNet model on unseen object references. We demonstrate that
the grounded LTL our method outputs can be used for planning in a simulated
OO-MDP environment. Finally, we discuss some common failure modes encountered
when translating natural language task specifications to grounded LTL.",0,0,0,0,0,0,0.00134133,12.0,0.314761,16
http://arxiv.org/abs/2108.03233v1,Operational Learning-based Boundary Estimation in Electromagnetic Medical Imaging,5,0.0267624,0.233539,"Incorporating boundaries of the imaging object as a priori information to
imaging algorithms can significantly improve the performance of electromagnetic
medical imaging systems. To avoid overly complicating the system by using
different sensors and the adverse effect of the subject's movement, a
learning-based method is proposed to estimate the boundary (external contour)
of the imaged object using the same electromagnetic imaging data. While imaging
techniques may discard the reflection coefficients for being dominant and
uninformative for imaging, these parameters are made use of for boundary
detection. The learned model is verified through independent clinical human
trials by using a head imaging system with a 16-element antenna array that
works across the band 0.7-1.6 GHz. The evaluation demonstrated that the model
achieves average dissimilarity of 0.012 in Hu-moment while detecting head
boundary. The model enables fast scan and image creation while eliminating the
need for additional devices for accurate boundary estimation.",0,1,0,0,0,0,0.000639427,17.0,0.472703,39
http://arxiv.org/abs/2111.09276v1,"Induce, Edit, Retrieve: Language Grounded Multimodal Schema for Instructional Video Retrieval",13,0.208827,0.586721,"Schemata are structured representations of complex tasks that can aid
artificial intelligence by allowing models to break down complex tasks into
intermediate steps. We propose a novel system that induces schemata from web
videos and generalizes them to capture unseen tasks with the goal of improving
video retrieval performance. Our system proceeds in three major phases: (1)
Given a task with related videos, we construct an initial schema for a task
using a joint video-text model to match video segments with text representing
steps from wikiHow; (2) We generalize schemata to unseen tasks by leveraging
language models to edit the text within existing schemata. Through
generalization, we can allow our schemata to cover a more extensive range of
tasks with a small amount of learning data; (3) We conduct zero-shot
instructional video retrieval with the unseen task names as the queries. Our
schema-guided approach outperforms existing methods for video retrieval, and we
demonstrate that the schemata induced by our system are better than those
generated by other models.",0,1,0,0,0,0,0.783465,6.0,0.802639,59
http://arxiv.org/abs/2102.07847v1,Meta Back-translation,22,0.0524374,0.628129,"Back-translation is an effective strategy to improve the performance of
Neural Machine Translation~(NMT) by generating pseudo-parallel data. However,
several recent works have found that better translation quality of the
pseudo-parallel data does not necessarily lead to better final translation
models, while lower-quality but more diverse data often yields stronger
results. In this paper, we propose a novel method to generate pseudo-parallel
data from a pre-trained back-translation model. Our method is a meta-learning
algorithm which adapts a pre-trained back-translation model so that the
pseudo-parallel data it generates would train a forward-translation model to do
well on a validation set. In our evaluations in both the standard datasets WMT
En-De'14 and WMT En-Fr'14, as well as a multilingual translation setting, our
method leads to significant improvements over strong baselines. Our code will
be made available.",1,1,0,0,0,1,0.387691,6.0,0.613045,37
http://arxiv.org/abs/2104.05514v1,Self-Training with Weak Supervision,73,0.35306,0.908477,"State-of-the-art deep neural networks require large-scale labeled training
data that is often expensive to obtain or not available for many tasks. Weak
supervision in the form of domain-specific rules has been shown to be useful in
such settings to automatically generate weakly labeled training data. However,
learning with weak rules is challenging due to their inherent heuristic and
noisy nature. An additional challenge is rule coverage and overlap, where prior
work on weak supervision only considers instances that are covered by weak
rules, thus leaving valuable unlabeled data behind.
  In this work, we develop a weak supervision framework (ASTRA) that leverages
all the available data for a given task. To this end, we leverage task-specific
unlabeled data through self-training with a model (student) that considers
contextualized representations and predicts pseudo-labels for instances that
may not be covered by weak rules. We further develop a rule attention network
(teacher) that learns how to aggregate student pseudo-labels with weak rule
labels, conditioned on their fidelity and the underlying context of an
instance. Finally, we construct a semi-supervised learning objective for
end-to-end training with unlabeled data, domain-specific rules, and a small
amount of labeled data. Extensive experiments on six benchmark datasets for
text classification demonstrate the effectiveness of our approach with
significant improvements over state-of-the-art baselines.",1,1,0,0,1,0,0.578502,7.0,0.749187,43
http://arxiv.org/abs/2110.13708v1,TNTC: two-stream network with transformer-based complementarity for gait-based emotion recognition,13,0.125205,0.577302,"Recognizing the human emotion automatically from visual characteristics plays
a vital role in many intelligent applications. Recently, gait-based emotion
recognition, especially gait skeletons-based characteristic, has attracted much
attention, while many available methods have been proposed gradually. The
popular pipeline is to first extract affective features from joint skeletons,
and then aggregate the skeleton joint and affective features as the feature
vector for classifying the emotion. However, the aggregation procedure of these
emerged methods might be rigid, resulting in insufficiently exploiting the
complementary relationship between skeleton joint and affective features.
Meanwhile, the long range dependencies in both spatial and temporal domains of
the gait sequence are scarcely considered. To address these issues, we propose
a novel two-stream network with transformer-based complementarity, termed as
TNTC. Skeleton joint and affective features are encoded into two individual
images as the inputs of two streams, respectively. A new transformer-based
complementarity module (TCM) is proposed to bridge the complementarity between
two streams hierarchically via capturing long range dependencies. Experimental
results demonstrate TNTC outperforms state-of-the-art methods on the latest
dataset in terms of accuracy.",0,1,0,0,1,0,0.294514,5.0,0.467501,19
http://arxiv.org/abs/2112.03052v1,Scaling Up Influence Functions,62,0.197697,0.98674,"We address efficient calculation of influence functions for tracking
predictions back to the training data. We propose and analyze a new approach to
speeding up the inverse Hessian calculation based on Arnoldi iteration. With
this improvement, we achieve, to the best of our knowledge, the first
successful implementation of influence functions that scales to full-size
(language and vision) Transformer models with several hundreds of millions of
parameters. We evaluate our approach on image classification and
sequence-to-sequence tasks with tens to a hundred of millions of training
examples. Our code will be available at
https://github.com/google-research/jax-influence.",0,1,0,0,0,0,0.254409,7.0,0.594993,42
http://arxiv.org/abs/2110.05839v1,PLNet: Plane and Line Priors for Unsupervised Indoor Depth Estimation,19,0.247037,0.620535,"Unsupervised learning of depth from indoor monocular videos is challenging as
the artificial environment contains many textureless regions. Fortunately, the
indoor scenes are full of specific structures, such as planes and lines, which
should help guide unsupervised depth learning. This paper proposes PLNet that
leverages the plane and line priors to enhance the depth estimation. We first
represent the scene geometry using local planar coefficients and impose the
smoothness constraint on the representation. Moreover, we enforce the planar
and linear consistency by randomly selecting some sets of points that are
probably coplanar or collinear to construct simple and effective consistency
losses. To verify the proposed method's effectiveness, we further propose to
evaluate the flatness and straightness of the predicted point cloud on the
reliable planar and linear regions. The regularity of these regions indicates
quality indoor reconstruction. Experiments on NYU Depth V2 and ScanNet show
that PLNet outperforms existing methods. The code is available at
\url{https://github.com/HalleyJiang/PLNet}.",1,1,0,0,1,0,0.698832,10.0,0.857296,62
http://arxiv.org/abs/2110.07811v1,Cascaded Fast and Slow Models for Efficient Semantic Code Search,8,0.173427,0.128663,"The goal of natural language semantic code search is to retrieve a
semantically relevant code snippet from a fixed set of candidates using a
natural language query. Existing approaches are neither effective nor efficient
enough towards a practical semantic code search system. In this paper, we
propose an efficient and accurate semantic code search framework with cascaded
fast and slow models, in which a fast transformer encoder model is learned to
optimize a scalable index for fast retrieval followed by learning a slow
classification-based re-ranking model to improve the performance of the top K
results from the fast retrieval. To further reduce the high memory cost of
deploying two separate models in practice, we propose to jointly train the fast
and slow model based on a single transformer encoder with shared parameters.
The proposed cascaded approach is not only efficient and scalable, but also
achieves state-of-the-art results with an average mean reciprocal ranking (MRR)
score of 0.7795 (across 6 programming languages) as opposed to the previous
state-of-the-art result of 0.713 MRR on the CodeSearchNet benchmark.",0,1,0,0,1,0,0.991139,3.0,0.981223,24
http://arxiv.org/abs/2110.00777v1,Automated Seed Quality Testing System using GAN & Active Learning,2,0.0231468,0.268866,"Quality assessment of agricultural produce is a crucial step in minimizing
food stock wastage. However, this is currently done manually and often requires
expert supervision, especially in smaller seeds like corn. We propose a novel
computer vision-based system for automating this process. We build a novel seed
image acquisition setup, which captures both the top and bottom views. Dataset
collection for this problem has challenges of data annotation costs/time and
class imbalance. We address these challenges by i.) using a Conditional
Generative Adversarial Network (CGAN) to generate real-looking images for the
classes with lesser images and ii.) annotate a large dataset with minimal
expert human intervention by using a Batch Active Learning (BAL) based
annotation tool. We benchmark different image classification models on the
dataset obtained. We are able to get accuracies of up to 91.6% for testing the
physical purity of seed samples.",0,1,0,1,0,0,0.739209,5.0,0.737248,23
http://arxiv.org/abs/2106.10077v1,Combined Person Classification with Airborne Optical Sectioning,13,0.186192,0.480478,"Fully autonomous drones have been demonstrated to find lost or injured
persons under strongly occluding forest canopy. Airborne Optical Sectioning
(AOS), a novel synthetic aperture imaging technique, together with
deep-learning-based classification enables high detection rates under realistic
search-and-rescue conditions. We demonstrate that false detections can be
significantly suppressed and true detections boosted by combining
classifications from multiple AOS rather than single integral images. This
improves classification rates especially in the presence of occlusion. To make
this possible, we modified the AOS imaging process to support large overlaps
between subsequent integrals, enabling real-time and on-board scanning and
processing of groundspeeds up to 10 m/s.",1,1,0,0,0,0,0.0416019,14.0,0.659437,59
http://arxiv.org/abs/2104.04828v2,FreSaDa: A French Satire Data Set for Cross-Domain Satire Detection,7,0.0864531,0.0464226,"In this paper, we introduce FreSaDa, a French Satire Data Set, which is
composed of 11,570 articles from the news domain. In order to avoid reporting
unreasonably high accuracy rates due to the learning of characteristics
specific to publication sources, we divided our samples into training,
validation and test, such that the training publication sources are distinct
from the validation and test publication sources. This gives rise to a
cross-domain (cross-source) satire detection task. We employ two classification
methods as baselines for our new data set, one based on low-level features
(character n-grams) and one based on high-level features (average of CamemBERT
word embeddings). As an additional contribution, we present an unsupervised
domain adaptation method based on regarding the pairwise similarities (given by
the dot product) between the training samples and the validation samples as
features. By including these domain-specific features, we attain significant
improvements for both character n-grams and CamemBERT embeddings.",0,1,1,1,0,0,0.159494,8.0,0.580054,41
http://arxiv.org/abs/2109.13514v2,Random Dilated Shapelet Transform: A New Approach for Time Series Shapelets,13,0.177025,0.373723,"Shapelet-based algorithms are widely used for time series classification
because of their ease of interpretation, but they are currently outperformed by
recent state-of-the-art approaches. We present a new formulation of time series
shapelets including the notion of dilation, and we introduce a new shapelet
feature to enhance their discriminative power for classification. Experiments
performed on 112 datasets show that our method improves on the state-of-the-art
shapelet algorithm, and achieves comparable accuracy to recent state-of-the-art
approaches, without sacrificing neither scalability, nor interpretability.",1,1,0,0,1,0,0.77237,6.0,0.797104,24
http://arxiv.org/abs/2101.05537v1,Optimal Energy Shaping via Neural Approximators,7,0.0576072,0.214555,"We introduce optimal energy shaping as an enhancement of classical
passivity-based control methods. A promising feature of passivity theory,
alongside stability, has traditionally been claimed to be intuitive performance
tuning along the execution of a given task. However, a systematic approach to
adjust performance within a passive control framework has yet to be developed,
as each method relies on few and problem-specific practical insights. Here, we
cast the classic energy-shaping control design process in an optimal control
framework; once a task-dependent performance metric is defined, an optimal
solution is systematically obtained through an iterative procedure relying on
neural networks and gradient-based optimization. The proposed method is
validated on state-regulation tasks.",0,0,0,0,0,0,0.46521,7.0,0.703138,49
http://arxiv.org/abs/2104.11462v2,LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech,61,0.370178,0.571684,"Self-Supervised Learning (SSL) using huge unlabeled data has been
successfully explored for image and natural language processing. Recent works
also investigated SSL from speech. They were notably successful to improve
performance on downstream tasks such as automatic speech recognition (ASR).
While these works suggest it is possible to reduce dependence on labeled data
for building efficient speech systems, their evaluation was mostly made on ASR
and using multiple and heterogeneous experimental settings (most of them for
English). This questions the objective comparison of SSL approaches and the
evaluation of their impact on building speech systems. In this paper, we
propose LeBenchmark: a reproducible framework for assessing SSL from speech. It
not only includes ASR (high and low resource) tasks but also spoken language
understanding, speech translation and emotion recognition. We also focus on
speech technologies in a language different than English: French. SSL models of
different sizes are trained from carefully sourced and documented datasets.
Experiments show that SSL is beneficial for most but not all tasks which
confirms the need for exhaustive and reliable benchmarks to evaluate its real
impact. LeBenchmark is shared with the scientific community for reproducible
research in SSL from speech.",0,1,0,0,0,0,0.782707,4.0,0.703387,51
http://arxiv.org/abs/2108.04741v2,Multi-Factors Aware Dual-Attentional Knowledge Tracing,29,0.398488,0.858319,"With the increasing demands of personalized learning, knowledge tracing has
become important which traces students' knowledge states based on their
historical practices. Factor analysis methods mainly use two kinds of factors
which are separately related to students and questions to model students'
knowledge states. These methods use the total number of attempts of students to
model students' learning progress and hardly highlight the impact of the most
recent relevant practices. Besides, current factor analysis methods ignore rich
information contained in questions. In this paper, we propose Multi-Factors
Aware Dual-Attentional model (MF-DAKT) which enriches question representations
and utilizes multiple factors to model students' learning progress based on a
dual-attentional mechanism. More specifically, we propose a novel
student-related factor which records the most recent attempts on relevant
concepts of students to highlight the impact of recent exercises. To enrich
questions representations, we use a pre-training method to incorporate two
kinds of question information including questions' relation and difficulty
level. We also add a regularization term about questions' difficulty level to
restrict pre-trained question representations to fine-tuning during the process
of predicting students' performance. Moreover, we apply a dual-attentional
mechanism to differentiate contributions of factors and factor interactions to
final prediction in different practice records. At last, we conduct experiments
on several real-world datasets and results show that MF-DAKT can outperform
existing knowledge tracing methods. We also conduct several studies to validate
the effects of each component of MF-DAKT.",1,1,0,0,1,0,0.75449,12.0,0.894182,45
http://arxiv.org/abs/2104.10475v1,Camouflaged Object Segmentation with Distraction Mining,205,0.479694,0.964602,"Camouflaged object segmentation (COS) aims to identify objects that are
""perfectly"" assimilate into their surroundings, which has a wide range of
valuable applications. The key challenge of COS is that there exist high
intrinsic similarities between the candidate objects and noise background. In
this paper, we strive to embrace challenges towards effective and efficient
COS. To this end, we develop a bio-inspired framework, termed Positioning and
Focus Network (PFNet), which mimics the process of predation in nature.
Specifically, our PFNet contains two key modules, i.e., the positioning module
(PM) and the focus module (FM). The PM is designed to mimic the detection
process in predation for positioning the potential target objects from a global
perspective and the FM is then used to perform the identification process in
predation for progressively refining the coarse prediction via focusing on the
ambiguous regions. Notably, in the FM, we develop a novel distraction mining
strategy for distraction discovery and removal, to benefit the performance of
estimation. Extensive experiments demonstrate that our PFNet runs in real-time
(72 FPS) and significantly outperforms 18 cutting-edge models on three
challenging datasets under four standard metrics.",0,1,0,0,1,0,0.499936,6.0,0.670644,69
http://arxiv.org/abs/2105.08306v1,Sample Efficient Linear Meta-Learning by Alternating Minimization,17,0.0683941,0.346386,"Meta-learning synthesizes and leverages the knowledge from a given set of
tasks to rapidly learn new tasks using very little data. Meta-learning of
linear regression tasks, where the regressors lie in a low-dimensional
subspace, is an extensively-studied fundamental problem in this domain.
However, existing results either guarantee highly suboptimal estimation errors,
or require $\Omega(d)$ samples per task (where $d$ is the data dimensionality)
thus providing little gain over separately learning each task. In this work, we
study a simple alternating minimization method (MLLAM), which alternately
learns the low-dimensional subspace and the regressors. We show that, for a
constant subspace dimension MLLAM obtains nearly-optimal estimation error,
despite requiring only $\Omega(\log d)$ samples per task. However, the number
of samples required per task grows logarithmically with the number of tasks. To
remedy this in the low-noise regime, we propose a novel task subset selection
scheme that ensures the same strong statistical guarantee as MLLAM, even with
bounded number of samples per task for arbitrarily large number of tasks.",0,0,0,0,1,0,0.00985881,18.0,0.654229,37
http://arxiv.org/abs/2109.13178v1,Path Based Hierarchical Clustering on Knowledge Graphs,2,0.0,0.0705861,"Knowledge graphs have emerged as a widely adopted medium for storing
relational data, making methods for automatically reasoning with them highly
desirable. In this paper, we present a novel approach for inducing a hierarchy
of subject clusters, building upon our earlier work done in taxonomy induction.
Our method first constructs a tag hierarchy before assigning subjects to
clusters on this hierarchy. We quantitatively demonstrate our method's ability
to induce a coherent cluster hierarchy on three real-world datasets.",1,1,0,0,0,0,0.0216336,21.0,0.741332,16
http://arxiv.org/abs/2107.11201v1,A Fitness Landscape View on the Tuning of an Asynchronous Master-Worker EA for Nuclear Reactor Design,1,0.00136818,0.0201915,"In the context of the introduction of intermittent renewable energies, we
propose to optimize the main variables of the control rods of a nuclear power
plant to improve its capability to load-follow. The design problem is a
black-box combinatorial optimization problem with expensive evaluation based on
a multi-physics simulator. Therefore, we use a parallel asynchronous
master-worker Evolutionary Algorithm scaling up to thousand computing units.
One main issue is the tuning of the algorithm parameters. A fitness landscape
analysis is conducted on this expensive real-world problem to show that it
would be possible to tune the mutation parameters according to the low-cost
estimation of the fitness landscape features.",0,1,0,0,0,0,9.9007e-08,22.0,0.193749,23
http://arxiv.org/abs/2104.06245v1,Understanding Hard Negatives in Noise Contrastive Estimation,45,0.518788,0.668259,"The choice of negative examples is important in noise contrastive estimation.
Recent works find that hard negatives -- highest-scoring incorrect examples
under the model -- are effective in practice, but they are used without a
formal justification. We develop analytical tools to understand the role of
hard negatives. Specifically, we view the contrastive loss as a biased
estimator of the gradient of the cross-entropy loss, and show both
theoretically and empirically that setting the negative distribution to be the
model distribution results in bias reduction. We also derive a general form of
the score function that unifies various architectures used in text retrieval.
By combining hard negatives with appropriate score functions, we obtain strong
results on the challenging task of zero-shot entity linking.",1,0,0,0,0,0,0.971142,4.0,0.914052,40
http://arxiv.org/abs/2110.11420v2,Fast Graph Sampling for Short Video Summarization using Gershgorin Disc Alignment,2,0.0448514,0.13193,"We study the problem of efficiently summarizing a short video into several
keyframes, leveraging recent progress in fast graph sampling. Specifically, we
first construct a similarity path graph (SPG) $\mathcal{G}$, represented by
graph Laplacian matrix $\mathbf{L}$, where the similarities between adjacent
frames are encoded as positive edge weights. We show that maximizing the
smallest eigenvalue $\lambda_{\min}(\mathbf{B})$ of a coefficient matrix
$\mathbf{B} = \text{diag}(\mathbf{a}) + \mu \mathbf{L}$, where $\mathbf{a}$ is
the binary keyframe selection vector, is equivalent to minimizing a worst-case
signal reconstruction error. We prove that, after partitioning $\mathcal{G}$
into $Q$ sub-graphs $\{\mathcal{G}^q\}^Q_{q=1}$, the smallest Gershgorin circle
theorem (GCT) lower bound of $Q$ corresponding coefficient matrices -- $\min_q
\lambda^-_{\min}(\mathbf{B}^q)$ -- is a lower bound for
$\lambda_{\min}(\mathbf{B})$. This inspires a fast graph sampling algorithm to
iteratively partition $\mathcal{G}$ into $Q$ sub-graphs using $Q$ samples
(keyframes), while maximizing $\lambda^-_{\min}(\mathbf{B}^q)$ for each
sub-graph $\mathcal{G}^q$. Experimental results show that our algorithm
achieves comparable video summarization performance as state-of-the-art
methods, at a substantially reduced complexity.",0,0,0,0,0,0,0.342781,15.0,0.834829,27
http://arxiv.org/abs/2108.04728v2,Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds,71,0.314155,0.837574,"Current 3D single object tracking approaches track the target based on a
feature comparison between the target template and the search area. However,
due to the common occlusion in LiDAR scans, it is non-trivial to conduct
accurate feature comparisons on severe sparse and incomplete shapes. In this
work, we exploit the ground truth bounding box given in the first frame as a
strong cue to enhance the feature description of the target object, enabling a
more accurate feature comparison in a simple yet effective way. In particular,
we first propose the BoxCloud, an informative and robust representation, to
depict an object using the point-to-box relation. We further design an
efficient box-aware feature fusion module, which leverages the aforementioned
BoxCloud for reliable feature matching and embedding. Integrating the proposed
general components into an existing model P2B, we construct a superior
box-aware tracker (BAT). Experiments confirm that our proposed BAT outperforms
the previous state-of-the-art by a large margin on both KITTI and NuScenes
benchmarks, achieving a 15.2% improvement in terms of precision while running
~20% faster.",0,1,0,0,1,0,0.72264,5.0,0.727865,42
http://arxiv.org/abs/2104.07078v1,UDALM: Unsupervised Domain Adaptation through Language Modeling,47,0.294016,0.710637,"In this work we explore Unsupervised Domain Adaptation (UDA) of pretrained
language models for downstream tasks. We introduce UDALM, a fine-tuning
procedure, using a mixed classification and Masked Language Model loss, that
can adapt to the target domain distribution in a robust and sample efficient
manner. Our experiments show that performance of models trained with the mixed
loss scales with the amount of available target data and the mixed loss can be
effectively used as a stopping criterion during UDA training. Furthermore, we
discuss the relationship between A-distance and the target error and explore
some limitations of the Domain Adversarial Training approach. Our method is
evaluated on twelve domain pairs of the Amazon Reviews Sentiment dataset,
yielding $91.74\%$ accuracy, which is an $1.11\%$ absolute improvement over the
state-of-the-art.",1,1,0,0,1,0,0.684928,6.0,0.75577,62
http://arxiv.org/abs/2109.03764v1,Active Learning by Acquiring Contrastive Examples,136,0.280809,0.985551,"Common acquisition functions for active learning use either uncertainty or
diversity sampling, aiming to select difficult and diverse data points from the
pool of unlabeled data, respectively. In this work, leveraging the best of both
worlds, we propose an acquisition function that opts for selecting
\textit{contrastive examples}, i.e. data points that are similar in the model
feature space and yet the model outputs maximally different predictive
likelihoods. We compare our approach, CAL (Contrastive Active Learning), with a
diverse set of acquisition functions in four natural language understanding
tasks and seven datasets. Our experiments show that CAL performs consistently
better or equal than the best performing baseline across all tasks, on both
in-domain and out-of-domain data. We also conduct an extensive ablation study
of our method and we further analyze all actively acquired datasets showing
that CAL achieves a better trade-off between uncertainty and diversity compared
to other strategies.",1,1,1,0,1,1,0.221642,8.0,0.625818,55
http://arxiv.org/abs/2104.13648v2,Two stages for visual object tracking,1,0.00531526,0.0289097,"Siamese-based trackers have achived promising performance on visual object
tracking tasks. Most existing Siamese-based trackers contain two separate
branches for tracking, including classification branch and bounding box
regression branch. In addition, image segmentation provides an alternative way
to obetain the more accurate target region. In this paper, we propose a novel
tracker with two-stages: detection and segmentation. The detection stage is
capable of locating the target by Siamese networks. Then more accurate tracking
results are obtained by segmentation module given the coarse state estimation
in the first stage. We conduct experiments on four benchmarks. Our approach
achieves state-of-the-art results, with the EAO of 52.6$\%$ on VOT2016,
51.3$\%$ on VOT2018, and 39.0$\%$ on VOT2019 datasets, respectively.",0,1,0,0,1,0,0.922412,6.0,0.88819,26
http://arxiv.org/abs/2104.07064v2,Is Everything in Order? A Simple Way to Order Sentences,20,0.100968,0.446188,"The task of organizing a shuffled set of sentences into a coherent text has
been used to evaluate a machine's understanding of causal and temporal
relations. We formulate the sentence ordering task as a conditional
text-to-marker generation problem. We present Reorder-BART (Re-BART) that
leverages a pre-trained Transformer-based model to identify a coherent order
for a given set of shuffled sentences. The model takes a set of shuffled
sentences with sentence-specific markers as input and generates a sequence of
position markers of the sentences in the ordered text. Re-BART achieves the
state-of-the-art performance across 7 datasets in Perfect Match Ratio (PMR) and
Kendall's tau ($\tau$). We perform evaluations in a zero-shot setting,
showcasing that our model is able to generalize well across other datasets. We
additionally perform several experiments to understand the functioning and
limitations of our framework.",1,1,0,0,1,0,0.0641755,9.0,0.519712,34
http://arxiv.org/abs/2202.01810v1,Deep Surface Reconstruction from Point Clouds with Visibility Information,8,0.0358284,0.303985,"Most current neural networks for reconstructing surfaces from point clouds
ignore sensor poses and only operate on raw point locations. Sensor visibility,
however, holds meaningful information regarding space occupancy and surface
orientation. In this paper, we present two simple ways to augment raw point
clouds with visibility information, so it can directly be leveraged by surface
reconstruction networks with minimal adaptation. Our proposed modifications
consistently improve the accuracy of generated surfaces as well as the
generalization ability of the networks to unseen shape domains. Our code and
data is available at https://github.com/raphaelsulzer/dsrv-data.",1,1,0,0,0,0,0.318903,6.0,0.572264,53
http://arxiv.org/abs/2202.09583v1,Models and Datasets for Cross-Lingual Summarisation,39,0.379716,0.950971,"We present a cross-lingual summarisation corpus with long documents in a
source language associated with multi-sentence summaries in a target language.
The corpus covers twelve language pairs and directions for four European
languages, namely Czech, English, French and German, and the methodology for
its creation can be applied to several other languages. We derive cross-lingual
document-summary instances from Wikipedia by combining lead paragraphs and
articles' bodies from language aligned Wikipedia titles. We analyse the
proposed cross-lingual summarisation task with automatic metrics and validate
it with a human study. To illustrate the utility of our dataset we report
experiments with multi-lingual pre-trained models in supervised, zero- and
few-shot, and out-of-domain scenarios.",0,1,0,1,0,0,0.655742,7.0,0.779259,46
http://arxiv.org/abs/2210.06458v1,Efficient Knowledge Distillation from Model Checkpoints,15,0.200383,0.716099,"Knowledge distillation is an effective approach to learn compact models
(students) with the supervision of large and strong models (teachers). As
empirically there exists a strong correlation between the performance of
teacher and student models, it is commonly believed that a high performing
teacher is preferred. Consequently, practitioners tend to use a well trained
network or an ensemble of them as the teacher. In this paper, we make an
intriguing observation that an intermediate model, i.e., a checkpoint in the
middle of the training procedure, often serves as a better teacher compared to
the fully converged model, although the former has much lower accuracy. More
surprisingly, a weak snapshot ensemble of several intermediate models from a
same training trajectory can outperform a strong ensemble of independently
trained and fully converged models, when they are used as teachers. We show
that this phenomenon can be partially explained by the information bottleneck
principle: the feature representations of intermediate models can have higher
mutual information regarding the input, and thus contain more ""dark knowledge""
for effective distillation. We further propose an optimal intermediate teacher
selection algorithm based on maximizing the total task-related mutual
information. Experiments verify its effectiveness and applicability.",1,0,0,0,0,0,0.62354,9.0,0.818582,60
http://arxiv.org/abs/2205.10471v2,Retrieval-Augmented Multilingual Keyphrase Generation with Retriever-Generator Iterative Training,11,0.3113,0.193468,"Keyphrase generation is the task of automatically predicting keyphrases given
a piece of long text. Despite its recent flourishing, keyphrase generation on
non-English languages haven't been vastly investigated. In this paper, we call
attention to a new setting named multilingual keyphrase generation and we
contribute two new datasets, EcommerceMKP and AcademicMKP, covering six
languages. Technically, we propose a retrieval-augmented method for
multilingual keyphrase generation to mitigate the data shortage problem in
non-English languages. The retrieval-augmented model leverages keyphrase
annotations in English datasets to facilitate generating keyphrases in
low-resource languages. Given a non-English passage, a cross-lingual dense
passage retrieval module finds relevant English passages. Then the associated
English keyphrases serve as external knowledge for keyphrase generation in the
current language. Moreover, we develop a retriever-generator iterative training
algorithm to mine pseudo parallel passage pairs to strengthen the cross-lingual
passage retriever. Comprehensive experiments and ablations show that the
proposed approach outperforms all baselines.",1,1,1,1,0,0,0.869172,7.0,0.8715,63
http://arxiv.org/abs/2202.08771v3,Realistic Blur Synthesis for Learning Image Deblurring,26,0.228904,0.737305,"Training learning-based deblurring methods demands a tremendous amount of
blurred and sharp image pairs. Unfortunately, existing synthetic datasets are
not realistic enough, and deblurring models trained on them cannot handle real
blurred images effectively. While real datasets have recently been proposed,
they provide limited diversity of scenes and camera settings, and capturing
real datasets for diverse settings is still challenging. To resolve this, this
paper analyzes various factors that introduce differences between real and
synthetic blurred images. To this end, we present RSBlur, a novel dataset with
real blurred images and the corresponding sharp image sequences to enable a
detailed analysis of the difference between real and synthetic blur. With the
dataset, we reveal the effects of different factors in the blur generation
process. Based on the analysis, we also present a novel blur synthesis pipeline
to synthesize more realistic blur. We show that our synthesis pipeline can
improve the deblurring performance on real blurred images.",1,1,0,1,0,0,0.653579,7.0,0.778418,58
http://arxiv.org/abs/2204.08453v2,Neural Space-filling Curves,1,0.0241371,0.159292,"We present Neural Space-filling Curves (SFCs), a data-driven approach to
infer a context-based scan order for a set of images. Linear ordering of pixels
forms the basis for many applications such as video scrambling, compression,
and auto-regressive models that are used in generative modeling for images.
Existing algorithms resort to a fixed scanning algorithm such as Raster scan or
Hilbert scan. Instead, our work learns a spatially coherent linear ordering of
pixels from the dataset of images using a graph-based neural network. The
resulting Neural SFC is optimized for an objective suitable for the downstream
task when the image is traversed along with the scan line order. We show the
advantage of using Neural SFCs in downstream applications such as image
compression. Code and additional results will be made available at
https://hywang66.github.io/publication/neuralsfc.",0,1,0,0,0,0,0.324625,22.0,0.884332,46
http://arxiv.org/abs/2204.02481v1,Adversarial Robustness through the Lens of Convolutional Filters,13,0.0524157,0.54567,"Deep learning models are intrinsically sensitive to distribution shifts in
the input data. In particular, small, barely perceivable perturbations to the
input data can force models to make wrong predictions with high confidence. An
common defense mechanism is regularization through adversarial training which
injects worst-case perturbations back into training to strengthen the decision
boundaries, and to reduce overfitting. In this context, we perform an
investigation of 3x3 convolution filters that form in adversarially-trained
models. Filters are extracted from 71 public models of the linf-RobustBench
CIFAR-10/100 and ImageNet1k leaderboard and compared to filters extracted from
models built on the same architectures but trained without robust
regularization. We observe that adversarially-robust models appear to form more
diverse, less sparse, and more orthogonal convolution filters than their normal
counterparts. The largest differences between robust and normal models are
found in the deepest layers, and the very first convolution layer, which
consistently and predominantly forms filters that can partially eliminate
perturbations, irrespective of the architecture. Data & Project website:
https://github.com/paulgavrikov/cvpr22w_RobustnessThroughTheLens",0,0,0,0,0,0,0.504681,5.0,0.607506,70
http://arxiv.org/abs/2212.05276v1,Natural Logic-guided Autoregressive Multi-hop Document Retrieval for Fact Verification,7,0.0332123,0.639928,"A key component of fact verification is thevevidence retrieval, often from
multiple documents. Recent approaches use dense representations and condition
the retrieval of each document on the previously retrieved ones. The latter
step is performed over all the documents in the collection, requiring storing
their dense representations in an index, thus incurring a high memory
footprint. An alternative paradigm is retrieve-and-rerank, where documents are
retrieved using methods such as BM25, their sentences are reranked, and further
documents are retrieved conditioned on these sentences, reducing the memory
requirements. However, such approaches can be brittle as they rely on
heuristics and assume hyperlinks between documents. We propose a novel
retrieve-and-rerank method for multi-hop retrieval, that consists of a
retriever that jointly scores documents in the knowledge source and sentences
from previously retrieved documents using an autoregressive formulation and is
guided by a proof system based on natural logic that dynamically terminates the
retrieval process if the evidence is deemed sufficient. This method is
competitive with current state-of-the-art methods on FEVER, HoVer and
FEVEROUS-S, while using $5$ to $10$ times less memory than competing systems.
Evaluation on an adversarial dataset indicates improved stability of our
approach compared to commonly deployed threshold-based methods. Finally, the
proof system helps humans predict model decisions correctly more often than
using the evidence alone.",1,1,0,0,1,0,0.134727,7.0,0.493935,43
http://arxiv.org/abs/2212.11672v1,Trustworthy Social Bias Measurement,7,0.0781577,0.812324,"How do we design measures of social bias that we trust? While prior work has
introduced several measures, no measure has gained widespread trust: instead,
mounting evidence argues we should distrust these measures. In this work, we
design bias measures that warrant trust based on the cross-disciplinary theory
of measurement modeling. To combat the frequently fuzzy treatment of social
bias in NLP, we explicitly define social bias, grounded in principles drawn
from social science research. We operationalize our definition by proposing a
general bias measurement framework DivDist, which we use to instantiate 5
concrete bias measures. To validate our measures, we propose a rigorous testing
protocol with 8 testing criteria (e.g. predictive validity: do measures predict
biases in US employment?). Through our testing, we demonstrate considerable
evidence to trust our measures, showing they overcome conceptual, technical,
and empirical deficiencies present in prior measures.",1,0,0,0,0,1,0.67287,7.0,0.785938,134
http://arxiv.org/abs/2207.08501v1,Explainable Deep Belief Network based Auto encoder using novel Extended Garson Algorithm,1,0.00364907,0.0674135,"The most difficult task in machine learning is to interpret trained shallow
neural networks. Deep neural networks (DNNs) provide impressive results on a
larger number of tasks, but it is generally still unclear how decisions are
made by such a trained deep neural network. Providing feature importance is the
most important and popular interpretation technique used in shallow and deep
neural networks. In this paper, we develop an algorithm extending the idea of
Garson Algorithm to explain Deep Belief Network based Auto-encoder (DBNA). It
is used to determine the contribution of each input feature in the DBN. It can
be used for any kind of neural network with many hidden layers. The
effectiveness of this method is tested on both classification and regression
datasets taken from literature. Important features identified by this method
are compared against those obtained by Wald chi square (\c{hi}2). For 2 out of
4 classification datasets and 2 out of 5 regression datasets, our proposed
methodology resulted in the identification of better-quality features leading
to statistically more significant results vis-\`a-vis Wald \c{hi}2.",0,0,0,0,0,0,0.00511203,30.0,0.770566,48
http://arxiv.org/abs/2208.11868v2,Interpretable Multimodal Emotion Recognition using Hybrid Fusion of Speech and Image Data,9,0.214732,0.495376,"This paper proposes a multimodal emotion recognition system based on hybrid
fusion that classifies the emotions depicted by speech utterances and
corresponding images into discrete classes. A new interpretability technique
has been developed to identify the important speech & image features leading to
the prediction of particular emotion classes. The proposed system's
architecture has been determined through intensive ablation studies. It fuses
the speech & image features and then combines speech, image, and intermediate
fusion outputs. The proposed interpretability technique incorporates the divide
& conquer approach to compute shapely values denoting each speech & image
feature's importance. We have also constructed a large-scale dataset (IIT-R
SIER dataset), consisting of speech utterances, corresponding images, and class
labels, i.e., 'anger,' 'happy,' 'hate,' and 'sad.' The proposed system has
achieved 83.29% accuracy for emotion recognition. The enhanced performance of
the proposed system advocates the importance of utilizing complementary
information from multiple modalities for emotion recognition.",1,1,0,1,0,0,0.488795,10.0,0.799155,50
http://arxiv.org/abs/2209.11789v2,SAFER: Safe Collision Avoidance using Focused and Efficient Trajectory Search with Reinforcement Learning,3,0.0265224,0.446559,"Collision avoidance is key for mobile robots and agents to operate safely in
the real world. In this work we present SAFER, an efficient and effective
collision avoidance system that is able to improve safety by correcting the
control commands sent by an operator. It combines real-world reinforcement
learning (RL), search-based online trajectory planning, and automatic emergency
intervention, e.g. automatic emergency braking (AEB). The goal of the RL is to
learn an effective corrective control action that is used in a focused search
for collision-free trajectories, and to reduce the frequency of triggering
automatic emergency braking. This novel setup enables the RL policy to learn
safely and directly on mobile robots in a real-world indoor environment,
minimizing actual crashes even during training. Our real-world experiments show
that, when compared with several baselines, our approach enjoys a higher
average speed, lower crash rate, less emergency intervention, smaller
computation overhead, and smoother overall control.",0,1,0,0,0,0,0.062172,11.0,0.604058,44
http://arxiv.org/abs/2207.13440v1,Iterative Scene Graph Generation,13,0.342955,0.513511,"The task of scene graph generation entails identifying object entities and
their corresponding interaction predicates in a given image (or video). Due to
the combinatorially large solution space, existing approaches to scene graph
generation assume certain factorization of the joint distribution to make the
estimation feasible (e.g., assuming that objects are conditionally independent
of predicate predictions). However, this fixed factorization is not ideal under
all scenarios (e.g., for images where an object entailed in interaction is
small and not discernible on its own). In this work, we propose a novel
framework for scene graph generation that addresses this limitation, as well as
introduces dynamic conditioning on the image, using message passing in a Markov
Random Field. This is implemented as an iterative refinement procedure wherein
each modification is conditioned on the graph generated in the previous
iteration. This conditioning across refinement steps allows joint reasoning
over entities and relations. This framework is realized via a novel and
end-to-end trainable transformer-based architecture. In addition, the proposed
framework can improve existing approach performance. Through extensive
experiments on Visual Genome and Action Genome benchmark datasets we show
improved performance on the scene graph generation.",0,0,0,0,1,0,0.95587,7.0,0.932656,72
http://arxiv.org/abs/2203.14949v1,Controllable Dynamic Multi-Task Architectures,22,0.326531,0.549198,"Multi-task learning commonly encounters competition for resources among
tasks, specifically when model capacity is limited. This challenge motivates
models which allow control over the relative importance of tasks and total
compute cost during inference time. In this work, we propose such a
controllable multi-task network that dynamically adjusts its architecture and
weights to match the desired task preference as well as the resource
constraints. In contrast to the existing dynamic multi-task approaches that
adjust only the weights within a fixed architecture, our approach affords the
flexibility to dynamically control the total computational cost and match the
user-preferred task importance better. We propose a disentangled training of
two hypernetworks, by exploiting task affinity and a novel branching
regularized loss, to take input preferences and accordingly predict
tree-structured models with adapted weights. Experiments on three multi-task
benchmarks, namely PASCAL-Context, NYU-v2, and CIFAR-100, show the efficacy of
our approach. Project page is available at https://www.nec-labs.com/~mas/DYMU.",1,0,0,0,0,0,0.921352,9.0,0.924869,60
http://arxiv.org/abs/2205.06993v1,Improving Neural Machine Translation of Indigenous Languages with Multilingual Transfer Learning,3,0.0556965,0.271443,"Machine translation (MT) involving Indigenous languages, including those
possibly endangered, is challenging due to lack of sufficient parallel data. We
describe an approach exploiting bilingual and multilingual pretrained MT models
in a transfer learning setting to translate from Spanish to ten South American
Indigenous languages. Our models set new SOTA on five out of the ten language
pairs we consider, even doubling performance on one of these five pairs. Unlike
previous SOTA that perform data augmentation to enlarge the train sets, we
retain the low-resource setting to test the effectiveness of our models under
such a constraint. In spite of the rarity of linguistic information available
about the Indigenous languages, we offer a number of quantitative and
qualitative analyses (e.g., as to morphology, tokenization, and orthography) to
contextualize our results.",0,1,0,0,1,0,0.593179,6.0,0.714086,45
http://arxiv.org/abs/2212.08818v1,Latent Evolution Model for Change Point Detection in Time-varying Networks,5,0.0638488,0.337876,"Graph-based change point detection (CPD) play an irreplaceable role in
discovering anomalous graphs in the time-varying network. While several
techniques have been proposed to detect change points by identifying whether
there is a significant difference between the target network and successive
previous ones, they neglect the natural evolution of the network. In practice,
real-world graphs such as social networks, traffic networks, and rating
networks are constantly evolving over time. Considering this problem, we treat
the problem as a prediction task and propose a novel CPD method for dynamic
graphs via a latent evolution model. Our method focuses on learning the
low-dimensional representations of networks and capturing the evolving patterns
of these learned latent representations simultaneously. After having the
evolving patterns, a prediction of the target network can be achieved. Then, we
can detect the change points by comparing the prediction and the actual network
by leveraging a trade-off strategy, which balances the importance between the
prediction network and the normal graph pattern extracted from previous
networks. Intensive experiments conducted on both synthetic and real-world
datasets show the effectiveness and superiority of our model.",0,0,0,0,0,0,0.0300089,11.0,0.536318,55
http://arxiv.org/abs/2203.13883v6,"Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities",9,0.143008,0.469513,"As social media platforms are evolving from text-based forums into
multi-modal environments, the nature of misinformation in social media is also
transforming accordingly. Taking advantage of the fact that visual modalities
such as images and videos are more favorable and attractive to the users and
textual contents are sometimes skimmed carelessly, misinformation spreaders
have recently targeted contextual connections between the modalities e.g., text
and image. Hence many researchers have developed automatic techniques for
detecting possible cross-modal discordance in web-based content. We analyze,
categorize and identify existing approaches in addition to challenges and
shortcomings they face in order to unearth new research opportunities in the
field of multi-modal misinformation detection.",0,0,0,0,0,0,0.714623,4.0,0.654214,115
http://arxiv.org/abs/2207.07288v2,WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation,26,0.194637,0.513385,"Existing few-shot image generation approaches typically employ fusion-based
strategies, either on the image or the feature level, to produce new images.
However, previous approaches struggle to synthesize high-frequency signals with
fine details, deteriorating the synthesis quality. To address this, we propose
WaveGAN, a frequency-aware model for few-shot image generation. Concretely, we
disentangle encoded features into multiple frequency components and perform
low-frequency skip connections to preserve outline and structural information.
Then we alleviate the generator's struggles of synthesizing fine details by
employing high-frequency skip connections, thus providing informative frequency
information to the generator. Moreover, we utilize a frequency L1-loss on the
generated and real images to further impede frequency information loss.
Extensive experiments demonstrate the effectiveness and advancement of our
method on three datasets. Noticeably, we achieve new state-of-the-art with FID
42.17, LPIPS 0.3868, FID 30.35, LPIPS 0.5076, and FID 4.96, LPIPS 0.3822
respectively on Flower, Animal Faces, and VGGFace. GitHub:
https://github.com/kobeshegu/ECCV2022_WaveGAN",1,0,0,0,1,0,0.682941,7.0,0.789881,46
http://arxiv.org/abs/2204.00227v1,Perception Prioritized Training of Diffusion Models,124,0.318531,0.903955,"Diffusion models learn to restore noisy data, which is corrupted with
different levels of noise, by optimizing the weighted sum of the corresponding
loss terms, i.e., denoising score matching loss. In this paper, we show that
restoring data corrupted with certain noise levels offers a proper pretext task
for the model to learn rich visual concepts. We propose to prioritize such
noise levels over other levels during training, by redesigning the weighting
scheme of the objective function. We show that our simple redesign of the
weighting scheme significantly improves the performance of diffusion models
regardless of the datasets, architectures, and sampling strategies.",0,0,0,0,0,0,0.870682,5.0,0.821239,55
http://arxiv.org/abs/2205.03821v1,Unsupervised Homography Estimation with Coplanarity-Aware GAN,19,0.59918,0.473362,"Estimating homography from an image pair is a fundamental problem in image
alignment. Unsupervised learning methods have received increasing attention in
this field due to their promising performance and label-free training. However,
existing methods do not explicitly consider the problem of plane-induced
parallax, which will make the predicted homography compromised on multiple
planes. In this work, we propose a novel method HomoGAN to guide unsupervised
homography estimation to focus on the dominant plane. First, a multi-scale
transformer network is designed to predict homography from the feature pyramids
of input images in a coarse-to-fine fashion. Moreover, we propose an
unsupervised GAN to impose coplanarity constraint on the predicted homography,
which is realized by using a generator to predict a mask of aligned regions,
and then a discriminator to check if two masked feature maps are induced by a
single homography. To validate the effectiveness of HomoGAN and its components,
we conduct extensive experiments on a large-scale dataset, and the results show
that our matching error is 22% lower than the previous SOTA method. Code is
available at https://github.com/megvii-research/HomoGAN.",1,1,0,0,1,0,0.948138,10.0,0.947547,43
http://arxiv.org/abs/2211.05499v1,DisPositioNet: Disentangled Pose and Identity in Semantic Image Manipulation,2,0.0167464,0.0735788,"Graph representation of objects and their relations in a scene, known as a
scene graph, provides a precise and discernible interface to manipulate a scene
by modifying the nodes or the edges in the graph. Although existing works have
shown promising results in modifying the placement and pose of objects, scene
manipulation often leads to losing some visual characteristics like the
appearance or identity of objects. In this work, we propose DisPositioNet, a
model that learns a disentangled representation for each object for the task of
image manipulation using scene graphs in a self-supervised manner. Our
framework enables the disentanglement of the variational latent embeddings as
well as the feature representation in the graph. In addition to producing more
realistic images due to the decomposition of features like pose and identity,
our method takes advantage of the probabilistic sampling in the intermediate
features to generate more diverse images in object replacement or addition
tasks. The results of our experiments show that disentangling the feature
representations in the latent manifold of the model outperforms the previous
works qualitatively and quantitatively on two public benchmarks. Project Page:
https://scenegenie.github.io/DispositioNet/",0,1,0,0,1,0,0.372531,9.0,0.736347,65
http://arxiv.org/abs/2209.00820v1,Structural Bias for Aspect Sentiment Triplet Extraction,7,0.295195,0.8039,"Structural bias has recently been exploited for aspect sentiment triplet
extraction (ASTE) and led to improved performance. On the other hand, it is
recognized that explicitly incorporating structural bias would have a negative
impact on efficiency, whereas pretrained language models (PLMs) can already
capture implicit structures. Thus, a natural question arises: Is structural
bias still a necessity in the context of PLMs? To answer the question, we
propose to address the efficiency issues by using an adapter to integrate
structural bias in the PLM and using a cheap-to-compute relative position
structure in place of the syntactic dependency structure. Benchmarking
evaluation is conducted on the SemEval datasets. The results show that our
proposed structural adapter is beneficial to PLMs and achieves state-of-the-art
performance over a range of strong baselines, yet with a light parameter demand
and low latency. Meanwhile, we give rise to the concern that the current
evaluation default with data of small scale is under-confident. Consequently,
we release a large-scale dataset for ASTE. The results on the new dataset hint
that the structural adapter is confidently effective and efficient to a large
scale. Overall, we draw the conclusion that structural bias shall still be a
necessity even with PLMs.",1,1,0,1,1,0,0.936988,5.0,0.88148,37
http://arxiv.org/abs/2211.07116v1,Few-shot Metric Learning: Online Adaptation of Embedding for Retrieval,6,0.0460142,0.233086,"Metric learning aims to build a distance metric typically by learning an
effective embedding function that maps similar objects into nearby points in
its embedding space. Despite recent advances in deep metric learning, it
remains challenging for the learned metric to generalize to unseen classes with
a substantial domain gap. To tackle the issue, we explore a new problem of
few-shot metric learning that aims to adapt the embedding function to the
target domain with only a few annotated data. We introduce three few-shot
metric learning baselines and propose the Channel-Rectifier Meta-Learning
(CRML), which effectively adapts the metric space online by adjusting channels
of intermediate layers. Experimental analyses on miniImageNet, CUB-200-2011,
MPII, as well as a new dataset, miniDeepFashion, demonstrate that our method
consistently improves the learned metric by adapting it to target classes and
achieves a greater gain in image retrieval when the domain gap from the source
classes is larger.",0,0,1,1,0,0,0.497092,11.0,0.819604,46
http://arxiv.org/abs/2202.11983v1,GIAOTracker: A comprehensive framework for MCMOT with global information and optimizing strategies in VisDrone 2021,60,0.336098,0.86646,"In recent years, algorithms for multiple object tracking tasks have benefited
from great progresses in deep models and video quality. However, in challenging
scenarios like drone videos, they still suffer from problems, such as small
objects, camera movements and view changes. In this paper, we propose a new
multiple object tracker, which employs Global Information And some Optimizing
strategies, named GIAOTracker. It consists of three stages, i.e., online
tracking, global link and post-processing. Given detections in every frame, the
first stage generates reliable tracklets using information of camera motion,
object motion and object appearance. Then they are associated into trajectories
by exploiting global clues and refined through four post-processing methods.
With the effectiveness of the three stages, GIAOTracker achieves
state-of-the-art performance on the VisDrone MOT dataset and wins the 3rd place
in the VisDrone2021 MOT Challenge.",0,1,0,0,1,0,0.486981,9.0,0.776251,80
http://arxiv.org/abs/2204.06828v2,Deep Vehicle Detection in Satellite Video,3,0.0345623,0.169957,"This work presents a deep learning approach for vehicle detection in
satellite video. Vehicle detection is perhaps impossible in single EO satellite
images due to the tininess of vehicles (4-10 pixel) and their similarity to the
background. Instead, we consider satellite video which overcomes the lack of
spatial information by temporal consistency of vehicle movement. A new
spatiotemporal model of a compact $3 \times 3$ convolutional, neural network is
proposed which neglects pooling layers and uses leaky ReLUs. Then we use a
reformulation of the output heatmap including Non-Maximum-Suppression (NMS) for
the final segmentation. Empirical results on two new annotated satellite videos
reconfirm the applicability of this approach for vehicle detection. They more
importantly indicate that pre-training on WAMI data and then fine-tuning on few
annotated video frames for a new video is sufficient. In our experiment only
five annotated images yield a $F_1$ score of 0.81 on a new video showing more
complex traffic patterns than the Las Vegas video. Our best result on Las Vegas
is a $F_1$ score of 0.87 which makes the proposed approach a leading method for
this benchmark.",0,1,0,0,1,0,0.136573,11.0,0.67929,69
http://arxiv.org/abs/2203.12964v1,Knowledge Removal in Sampling-based Bayesian Inference,20,0.0399207,0.903963,"The right to be forgotten has been legislated in many countries, but its
enforcement in the AI industry would cause unbearable costs. When single data
deletion requests come, companies may need to delete the whole models learned
with massive resources. Existing works propose methods to remove knowledge
learned from data for explicitly parameterized models, which however are not
appliable to the sampling-based Bayesian inference, i.e., Markov chain Monte
Carlo (MCMC), as MCMC can only infer implicit distributions. In this paper, we
propose the first machine unlearning algorithm for MCMC. We first convert the
MCMC unlearning problem into an explicit optimization problem. Based on this
problem conversion, an {\it MCMC influence function} is designed to provably
characterize the learned knowledge from data, which then delivers the MCMC
unlearning algorithm. Theoretical analysis shows that MCMC unlearning would not
compromise the generalizability of the MCMC models. Experiments on Gaussian
mixture models and Bayesian neural networks confirm the effectiveness of the
proposed algorithm. The code is available at
\url{https://github.com/fshp971/mcmc-unlearning}.",1,0,1,0,0,0,0.0339591,12.0,0.585432,57
http://arxiv.org/abs/2206.02290v2,A knowledge graph representation learning approach to predict novel kinase-substrate interactions,3,0.0682009,0.479691,"The human proteome contains a vast network of interacting kinases and
substrates. Even though some kinases have proven to be immensely useful as
therapeutic targets, a majority are still understudied. In this work, we
present a novel knowledge graph representation learning approach to predict
novel interaction partners for understudied kinases. Our approach uses a
phosphoproteomic knowledge graph constructed by integrating data from iPTMnet,
Protein Ontology, Gene Ontology and BioKG. The representation of kinases and
substrates in this knowledge graph are learned by performing directed random
walks on triples coupled with a modified SkipGram or CBOW model. These
representations are then used as an input to a supervised classification model
to predict novel interactions for understudied kinases. We also present a
post-predictive analysis of the predicted interactions and an ablation study of
the phosphoproteomic knowledge graph to gain an insight into the biology of the
understudied kinases.",1,0,0,0,0,0,0.846957,12.0,0.918355,36
http://arxiv.org/abs/2212.09095v2,Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale,24,0.0526477,0.763926,"Language models have been shown to perform better with an increase in scale
on a wide variety of tasks via the in-context learning paradigm. In this paper,
we investigate the hypothesis that the ability of a large language model to
in-context learn-perform a task is not uniformly spread across all of its
underlying components. Using a 66 billion parameter language model (OPT-66B)
across a diverse set of 14 downstream tasks, we find this is indeed the case:
$\sim$70% of attention heads and $\sim$20% of feed forward networks can be
removed with minimal decline in task performance. We find substantial overlap
in the set of attention heads (un)important for in-context learning across
tasks and number of in-context examples. We also address our hypothesis through
a task-agnostic lens, finding that a small set of attention heads in OPT-66B
score highly on their ability to perform primitive induction operations
associated with in-context learning, namely, prefix matching and copying. These
induction heads overlap with task-specific important heads, reinforcing
arguments by Olsson et al. (arXiv:2209.11895) regarding induction head
generality to more sophisticated behaviors associated with in-context learning.
Overall, our study provides several insights that indicate large language
models may be under-trained for in-context learning and opens up questions on
how to pre-train language models to more effectively perform in-context
learning.",1,0,0,0,0,0,0.740619,4.0,0.672566,50
http://arxiv.org/abs/2204.10437v1,"DiRA: Discriminative, Restorative, and Adversarial Learning for Self-supervised Medical Image Analysis",45,0.69049,0.971302,"Discriminative learning, restorative learning, and adversarial learning have
proven beneficial for self-supervised learning schemes in computer vision and
medical imaging. Existing efforts, however, omit their synergistic effects on
each other in a ternary setup, which, we envision, can significantly benefit
deep semantic representation learning. To realize this vision, we have
developed DiRA, the first framework that unites discriminative, restorative,
and adversarial learning in a unified manner to collaboratively glean
complementary visual information from unlabeled medical images for fine-grained
semantic representation learning. Our extensive experiments demonstrate that
DiRA (1) encourages collaborative learning among three learning ingredients,
resulting in more generalizable representation across organs, diseases, and
modalities; (2) outperforms fully supervised ImageNet models and increases
robustness in small data regimes, reducing annotation cost across multiple
medical imaging applications; (3) learns fine-grained semantic representation,
facilitating accurate lesion localization with only image-level annotation; and
(4) enhances state-of-the-art restorative approaches, revealing that DiRA is a
general mechanism for united representation learning. All code and pre-trained
models are available at https: //github.com/JLiangLab/DiRA.",1,0,0,0,0,0,0.96952,5.0,0.928132,60
http://arxiv.org/abs/2206.00372v1,BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate Speech in Different Social Contexts,11,0.206679,0.763829,"Social media platforms and online streaming services have spawned a new breed
of Hate Speech (HS). Due to the massive amount of user-generated content on
these sites, modern machine learning techniques are found to be feasible and
cost-effective to tackle this problem. However, linguistically diverse datasets
covering different social contexts in which offensive language is typically
used are required to train generalizable models. In this paper, we identify the
shortcomings of existing Bangla HS datasets and introduce a large manually
labeled dataset BD-SHS that includes HS in different social contexts. The
labeling criteria were prepared following a hierarchical annotation process,
which is the first of its kind in Bangla HS to the best of our knowledge. The
dataset includes more than 50,200 offensive comments crawled from online social
networking sites and is at least 60% larger than any existing Bangla HS
datasets. We present the benchmark result of our dataset by training different
NLP models resulting in the best one achieving an F1-score of 91.0%. In our
experiments, we found that a word embedding trained exclusively using 1.47
million comments from social media and streaming sites consistently resulted in
better modeling of HS detection in comparison to other pre-trained embeddings.
Our dataset and all accompanying codes is publicly available at
github.com/naurosromim/hate-speech-dataset-for-Bengali-social-media",1,1,0,1,1,0,0.744827,7.0,0.814616,28
http://arxiv.org/abs/2208.09329v1,Causal Intervention Improves Implicit Sentiment Analysis,7,0.123941,0.234672,"Despite having achieved great success for sentiment analysis, existing neural
models struggle with implicit sentiment analysis. This may be due to the fact
that they may latch onto spurious correlations (""shortcuts"", e.g., focusing
only on explicit sentiment words), resulting in undermining the effectiveness
and robustness of the learned model. In this work, we propose a causal
intervention model for Implicit Sentiment Analysis using Instrumental Variable
(ISAIV). We first review sentiment analysis from a causal perspective and
analyze the confounders existing in this task. Then, we introduce an
instrumental variable to eliminate the confounding causal effects, thus
extracting the pure causal effect between sentence and sentiment. We compare
the proposed ISAIV model with several strong baselines on both the general
implicit sentiment analysis and aspect-based implicit sentiment analysis tasks.
The results indicate the great advantages of our model and the efficacy of
implicit sentiment reasoning.",1,0,0,0,0,0,0.372262,8.0,0.703275,63
http://arxiv.org/abs/2211.16056v2,NoisyQuant: Noisy Bias-Enhanced Post-Training Activation Quantization for Vision Transformers,17,0.188699,0.63117,"The complicated architecture and high training cost of vision transformers
urge the exploration of post-training quantization. However, the heavy-tailed
distribution of vision transformer activations hinders the effectiveness of
previous post-training quantization methods, even with advanced quantizer
designs. Instead of tuning the quantizer to better fit the complicated
activation distribution, this paper proposes NoisyQuant, a quantizer-agnostic
enhancement for the post-training activation quantization performance of vision
transformers. We make a surprising theoretical discovery that for a given
quantizer, adding a fixed Uniform noisy bias to the values being quantized can
significantly reduce the quantization error under provable conditions. Building
on the theoretical insight, NoisyQuant achieves the first success on actively
altering the heavy-tailed activation distribution with additive noisy bias to
fit a given quantizer. Extensive experiments show NoisyQuant largely improves
the post-training quantization performance of vision transformer with minimal
computation overhead. For instance, on linear uniform 6-bit activation
quantization, NoisyQuant improves SOTA top-1 accuracy on ImageNet by up to
1.7%, 1.1% and 0.5% for ViT, DeiT, and Swin Transformer respectively, achieving
on-par or even higher performance than previous nonlinear, mixed-precision
quantization.",0,1,0,0,1,0,0.778775,5.0,0.760346,48
http://arxiv.org/abs/2212.02746v1,UniGeo: Unifying Geometry Logical Reasoning via Reformulating Mathematical Expression,25,0.651597,0.370562,"Geometry problem solving is a well-recognized testbed for evaluating the
high-level multi-modal reasoning capability of deep models. In most existing
works, two main geometry problems: calculation and proving, are usually treated
as two specific tasks, hindering a deep model to unify its reasoning capability
on multiple math tasks. However, in essence, these two tasks have similar
problem representations and overlapped math knowledge which can improve the
understanding and reasoning ability of a deep model on both two tasks.
Therefore, we construct a large-scale Unified Geometry problem benchmark,
UniGeo, which contains 4,998 calculation problems and 9,543 proving problems.
Each proving problem is annotated with a multi-step proof with reasons and
mathematical expressions. The proof can be easily reformulated as a proving
sequence that shares the same formats with the annotated program sequence for
calculation problems. Naturally, we also present a unified multi-task Geometric
Transformer framework, Geoformer, to tackle calculation and proving problems
simultaneously in the form of sequence generation, which finally shows the
reasoning ability can be improved on both two tasks by unifying formulation.
Furthermore, we propose a Mathematical Expression Pretraining (MEP) method that
aims to predict the mathematical expressions in the problem solution, thus
improving the Geoformer model. Experiments on the UniGeo demonstrate that our
proposed Geoformer obtains state-of-the-art performance by outperforming
task-specific model NGS with over 5.6% and 3.2% accuracies on calculation and
proving problems, respectively.",1,0,1,1,1,0,0.764155,6.0,0.793064,41
http://arxiv.org/abs/2205.07844v2,Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion,29,0.220482,0.610219,"Motion, measured via optical flow, provides a powerful cue to discover and
learn objects in images and videos. However, compared to using appearance, it
has some blind spots, such as the fact that objects become invisible if they do
not move. In this work, we propose an approach that combines the strengths of
motion-based and appearance-based segmentation. We propose to supervise an
image segmentation network with the pretext task of predicting regions that are
likely to contain simple motion patterns, and thus likely to correspond to
objects. As the model only uses a single image as input, we can apply it in two
settings: unsupervised video segmentation, and unsupervised image segmentation.
We achieve state-of-the-art results for videos, and demonstrate the viability
of our approach on still images containing novel objects. Additionally we
experiment with different motion models and optical flow backbones and find the
method to be robust to these change. Project page and code available at
https://www.robots.ox.ac.uk/~vgg/research/gwm.",1,1,0,0,1,0,0.439474,7.0,0.691986,108
http://arxiv.org/abs/2210.15097v2,Contrastive Decoding: Open-ended Text Generation as Optimization,135,0.848238,0.980781,"Given a language model (LM), maximum probability is a poor decoding objective
for open-ended generation, because it produces short and repetitive text. On
the other hand, sampling can often produce incoherent text that drifts from the
original topics. We propose contrastive decoding (CD), a reliable decoding
approach that optimizes a contrastive objective subject to a plausibility
constraint. The contrastive objective returns the difference between the
likelihood under a large LM (called the expert, e.g. OPT-13B) and a small LM
(called the amateur, e.g. OPT-125M), and the constraint ensures that the
outputs are plausible. CD is inspired by the fact that the failures of larger
LMs (e.g., repetition, incoherence) are even more prevalent in smaller LMs, and
that this difference signals which texts should be preferred. CD requires zero
additional training, and produces higher quality text than decoding from the
larger LM alone. It also works across model scales (OPT-13B and GPT2-1.5B) and
significantly outperforms four strong decoding algorithms (e.g., nucleus,
top-k) in automatic and human evaluations across wikipedia, news and story
domains.",0,1,0,0,0,1,0.729113,8.0,0.832196,39
http://arxiv.org/abs/2207.03608v2,GaitTAKE: Gait Recognition by Temporal Attention and Keypoint-guided Embedding,12,0.137619,0.547193,"Gait recognition, which refers to the recognition or identification of a
person based on their body shape and walking styles, derived from video data
captured from a distance, is widely used in crime prevention, forensic
identification, and social security. However, to the best of our knowledge,
most of the existing methods use appearance, posture and temporal feautures
without considering a learned temporal attention mechanism for global and local
information fusion. In this paper, we propose a novel gait recognition
framework, called Temporal Attention and Keypoint-guided Embedding (GaitTAKE),
which effectively fuses temporal-attention-based global and local appearance
feature and temporal aggregated human pose feature. Experimental results show
that our proposed method achieves a new SOTA in gait recognition with rank-1
accuracy of 98.0% (normal), 97.5% (bag) and 92.2% (coat) on the CASIA-B gait
dataset; 90.4% accuracy on the OU-MVLP gait dataset.",0,1,0,0,1,0,0.31618,15.0,0.828209,19
http://arxiv.org/abs/2208.00450v1,Parameter-Parallel Distributed Variational Quantum Algorithm,2,0.0509571,0.149433,"Variational quantum algorithms (VQAs) have emerged as a promising near-term
technique to explore practical quantum advantage on noisy intermediate-scale
quantum (NISQ) devices. However, the inefficient parameter training process due
to the incompatibility with backpropagation and the cost of a large number of
measurements, posing a great challenge to the large-scale development of VQAs.
Here, we propose a parameter-parallel distributed variational quantum algorithm
(PPD-VQA), to accelerate the training process by parameter-parallel training
with multiple quantum processors. To maintain the high performance of PPD-VQA
in the realistic noise scenarios, a alternate training strategy is proposed to
alleviate the acceleration attenuation caused by noise differences among
multiple quantum processors, which is an unavoidable common problem of
distributed VQA. Besides, the gradient compression is also employed to overcome
the potential communication bottlenecks. The achieved results suggest that the
PPD-VQA could provide a practical solution for coordinating multiple quantum
processors to handle large-scale real-word applications.",0,1,0,0,0,0,0.933971,7.0,0.912905,60
http://arxiv.org/abs/2203.09053v2,Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework,13,0.125172,0.532069,"Simultaneous machine translation (SiMT) starts translating while receiving
the streaming source inputs, and hence the source sentence is always incomplete
during translating. Different from the full-sentence MT using the conventional
seq-to-seq architecture, SiMT often applies prefix-to-prefix architecture,
which forces each target word to only align with a partial source prefix to
adapt to the incomplete source in streaming inputs. However, the source words
in the front positions are always illusoryly considered more important since
they appear in more prefixes, resulting in position bias, which makes the model
pay more attention on the front source positions in testing. In this paper, we
first analyze the phenomenon of position bias in SiMT, and develop a
Length-Aware Framework to reduce the position bias by bridging the structural
gap between SiMT and full-sentence MT. Specifically, given the streaming
inputs, we first predict the full-sentence length and then fill the future
source position with positional encoding, thereby turning the streaming inputs
into a pseudo full-sentence. The proposed framework can be integrated into most
existing SiMT methods to further improve performance. Experiments on two
representative SiMT methods, including the state-of-the-art adaptive policy,
show that our method successfully reduces the position bias and thereby
achieves better SiMT performance.",0,1,0,0,1,0,0.194456,6.0,0.476531,48
http://arxiv.org/abs/2208.06242v1,Multi-Agent Reinforcement Learning with Graph Convolutional Neural Networks for optimal Bidding Strategies of Generation Units in Electricity Markets,1,0.017367,0.114822,"Finding optimal bidding strategies for generation units in electricity
markets would result in higher profit. However, it is a challenging problem due
to the system uncertainty which is due to the unknown other generation units'
strategies. Distributed optimization, where each entity or agent decides on its
bid individually, has become state of the art. However, it cannot overcome the
challenges of system uncertainties. Deep reinforcement learning is a promising
approach to learn the optimal strategy in uncertain environments. Nevertheless,
it is not able to integrate the information on the spatial system topology in
the learning process. This paper proposes a distributed learning algorithm
based on deep reinforcement learning (DRL) combined with a graph convolutional
neural network (GCN). In fact, the proposed framework helps the agents to
update their decisions by getting feedback from the environment so that it can
overcome the challenges of the uncertainties. In this proposed algorithm, the
state and connection between nodes are the inputs of the GCN, which can make
agents aware of the structure of the system. This information on the system
topology helps the agents to improve their bidding strategies and increase the
profit. We evaluate the proposed algorithm on the IEEE 30-bus system under
different scenarios. Also, to investigate the generalization ability of the
proposed approach, we test the trained model on IEEE 39-bus system. The results
show that the proposed algorithm has more generalization abilities compare to
the DRL and can result in higher profit when changing the topology of the
system.",0,1,0,0,1,0,0.100174,10.0,0.614202,29
http://arxiv.org/abs/2203.05205v1,Crowd Source Scene Change Detection and Local Map Update,1,0.0121317,0.0444982,"As scene changes with time map descriptors become outdated, affecting VPS
localization accuracy. In this work, we propose an approach to detect
structural and texture scene changes to be followed by map update. In our
method - map includes 3D points with descriptors generated either via LiDAR or
SFM. Common approaches suffer from shortcomings: 1) Direct comparison of the
two point-clouds for change detection is slow due to the need to build new
point-cloud every time we want to compare; 2) Image based comparison requires
to keep the map images adding substantial storage overhead. To circumvent this
problems, we propose an approach based on point-clouds descriptors comparison:
1) Based on VPS poses select close query and map images pairs, 2) Registration
of query images to map image descriptors, 3) Use segmentation to filter out
dynamic or short term temporal changes, 4) Compare the descriptors between
corresponding segments.",0,0,0,0,0,0,0.245433,12.0,0.760278,40
http://arxiv.org/abs/2202.08131v1,Natural Language Proof Checking in Introduction to Proof Classes -- First Experiences with Diproche,5,0.0388861,0.279264,"We present and analyze the employment of the Diproche system, a natural
language proof checker, within a one-semester mathematics beginners lecture
with 228 participants. The system is used to check the students' solution
attempts to proving exercises in Boolean set theory and elementary number
theory and to give them immediate feedback. The benefits of the employment of
the system are assessed via a questionnaire at the end of the semester and via
analyzing the solution attempts of a subgroup of the students. Based on our
results we develop approaches for future improvements.",0,1,0,0,0,0,0.000677613,10.0,0.109397,14
http://arxiv.org/abs/2204.00176v1,Better Intermediates Improve CTC Inference,1,0.00646674,0.028484,"This paper proposes a method for improved CTC inference with searched
intermediates and multi-pass conditioning. The paper first formulates
self-conditioned CTC as a probabilistic model with an intermediate prediction
as a latent representation and provides a tractable conditioning framework. We
then propose two new conditioning methods based on the new formulation: (1)
Searched intermediate conditioning that refines intermediate predictions with
beam-search, (2) Multi-pass conditioning that uses predictions of previous
inference for conditioning the next inference. These new approaches enable
better conditioning than the original self-conditioned CTC during inference and
improve the final performance. Experiments with the LibriSpeech dataset show
relative 3%/12% performance improvement at the maximum in test clean/other sets
compared to the original self-conditioned CTC.",0,0,0,0,0,0,0.128094,8.0,0.550416,31
http://arxiv.org/abs/2212.06002v2,Effective Seed-Guided Topic Discovery by Integrating Multiple Types of Contexts,7,0.353821,0.571937,"Instead of mining coherent topics from a given text corpus in a completely
unsupervised manner, seed-guided topic discovery methods leverage user-provided
seed words to extract distinctive and coherent topics so that the mined topics
can better cater to the user's interest. To model the semantic correlation
between words and seeds for discovering topic-indicative terms, existing
seed-guided approaches utilize different types of context signals, such as
document-level word co-occurrences, sliding window-based local contexts, and
generic linguistic knowledge brought by pre-trained language models. In this
work, we analyze and show empirically that each type of context information has
its value and limitation in modeling word semantics under seed guidance, but
combining three types of contexts (i.e., word embeddings learned from local
contexts, pre-trained language model representations obtained from
general-domain training, and topic-indicative sentences retrieved based on seed
information) allows them to complement each other for discovering quality
topics. We propose an iterative framework, SeedTopicMine, which jointly learns
from the three types of contexts and gradually fuses their context signals via
an ensemble ranking process. Under various sets of seeds and on multiple
datasets, SeedTopicMine consistently yields more coherent and accurate topics
than existing seed-guided topic discovery approaches.",1,1,0,0,0,0,0.737911,12.0,0.890212,51
http://arxiv.org/abs/2202.07817v1,Cross-view and Cross-domain Underwater Localization based on Optical Aerial and Acoustic Underwater Images,9,0.192607,0.528609,"Cross-view image matches have been widely explored on terrestrial image
localization using aerial images from drones or satellites. This study expands
the cross-view image match idea and proposes a cross-domain and cross-view
localization framework. The method identifies the correlation between color
aerial images and underwater acoustic images to improve the localization of
underwater vehicles that travel in partially structured environments such as
harbors and marinas. The approach is validated on a real dataset acquired by an
underwater vehicle in a marina. The results show an improvement in the
localization when compared to the dead reckoning of the vehicle.",1,1,0,0,0,0,0.115827,12.0,0.691319,30
http://arxiv.org/abs/2210.14428v2,D-Shape: Demonstration-Shaped Reinforcement Learning via Goal Conditioning,3,0.00416298,0.0952773,"While combining imitation learning (IL) and reinforcement learning (RL) is a
promising way to address poor sample efficiency in autonomous behavior
acquisition, methods that do so typically assume that the requisite behavior
demonstrations are provided by an expert that behaves optimally with respect to
a task reward. If, however, suboptimal demonstrations are provided, a
fundamental challenge appears in that the demonstration-matching objective of
IL conflicts with the return-maximization objective of RL. This paper
introduces D-Shape, a new method for combining IL and RL that uses ideas from
reward shaping and goal-conditioned RL to resolve the above conflict. D-Shape
allows learning from suboptimal demonstrations while retaining the ability to
find the optimal policy with respect to the task reward. We experimentally
validate D-Shape in sparse-reward gridworld domains, showing that it both
improves over RL in terms of sample efficiency and converges consistently to
the optimal policy in the presence of suboptimal demonstrations.",0,1,0,0,0,0,0.00939568,10.0,0.372777,43
http://arxiv.org/abs/2205.09634v2,Phylogeny-Inspired Adaptation of Multilingual Models to New Languages,21,0.244506,0.536357,"Large pretrained multilingual models, trained on dozens of languages, have
delivered promising results due to cross-lingual learning capabilities on
variety of language tasks. Further adapting these models to specific languages,
especially ones unseen during pre-training, is an important goal towards
expanding the coverage of language technologies. In this study, we show how we
can use language phylogenetic information to improve cross-lingual transfer
leveraging closely related languages in a structured, linguistically-informed
manner. We perform adapter-based training on languages from diverse language
families (Germanic, Uralic, Tupian, Uto-Aztecan) and evaluate on both syntactic
and semantic tasks, obtaining more than 20% relative performance improvements
over strong commonly used baselines, especially on languages unseen during
pre-training.",1,1,0,0,0,0,0.512219,5.0,0.611824,42
http://arxiv.org/abs/2207.05025v1,PSP-HDRI$+$: A Synthetic Dataset Generator for Pre-Training of Human-Centric Computer Vision Models,14,0.142032,0.733332,"We introduce a new synthetic data generator PSP-HDRI$+$ that proves to be a
superior pre-training alternative to ImageNet and other large-scale synthetic
data counterparts. We demonstrate that pre-training with our synthetic data
will yield a more general model that performs better than alternatives even
when tested on out-of-distribution (OOD) sets. Furthermore, using ablation
studies guided by person keypoint estimation metrics with an off-the-shelf
model architecture, we show how to manipulate our synthetic data generator to
further improve model performance.",0,1,0,1,0,0,0.553124,9.0,0.797138,40
http://arxiv.org/abs/2207.11324v2,Exploring Wasserstein Distance across Concept Embeddings for Ontology Matching,2,0.0289185,0.122438,"Measuring the distance between ontological elements is fundamental for
ontology matching. String-based distance metrics are notorious for shallow
syntactic matching. In this exploratory study, we investigate Wasserstein
distance targeting continuous space that can incorporate various types of
information. We use a pre-trained word embeddings system to embed ontology
element labels. We examine the effectiveness of Wasserstein distance for
measuring similarity between ontologies, and discovering and refining matchings
between individual elements. Our experiments with the OAEI conference track and
MSE benchmarks achieved competitive results compared to the leading systems.",0,0,0,0,0,0,0.358996,9.0,0.731139,39
http://arxiv.org/abs/2211.07263v3,Efficient Adversarial Training with Robust Early-Bird Tickets,5,0.0122655,0.292621,"Adversarial training is one of the most powerful methods to improve the
robustness of pre-trained language models (PLMs). However, this approach is
typically more expensive than traditional fine-tuning because of the necessity
to generate adversarial examples via gradient descent. Delving into the
optimization process of adversarial training, we find that robust connectivity
patterns emerge in the early training phase (typically $0.15\sim0.3$ epochs),
far before parameters converge. Inspired by this finding, we dig out robust
early-bird tickets (i.e., subnetworks) to develop an efficient adversarial
training method: (1) searching for robust tickets with structured sparsity in
the early stage; (2) fine-tuning robust tickets in the remaining time. To
extract the robust tickets as early as possible, we design a ticket convergence
metric to automatically terminate the searching process. Experiments show that
the proposed efficient adversarial training method can achieve up to $7\times
\sim 13 \times$ training speedups while maintaining comparable or even better
robustness compared to the most competitive state-of-the-art adversarial
training methods.",1,1,0,0,1,0,0.186986,7.0,0.54508,44
http://arxiv.org/abs/2203.07777v1,Social Choice Around the Block: On the Computational Social Choice of Blockchain,13,0.32445,0.621248,"One of the most innovative aspects of blockchain technology consists in the
introduction of an incentive layer to regulate the behavior of distributed
protocols. The designer of a blockchain system faces therefore issues that are
akin to those relevant for the design of economic mechanisms, and faces them in
a computational setting. From this perspective the present paper argues for the
importance of computational social choice in blockchain research. It identifies
a few challenges at the interface of the two fields that illustrate the strong
potential for cross-fertilization between them.",0,0,0,0,0,0,0.156713,18.0,0.812291,70
http://arxiv.org/abs/2210.06694v3,SubeventWriter: Iterative Sub-event Sequence Generation with Coherence Controller,6,0.108373,0.698318,"In this paper, we propose a new task of sub-event generation for an unseen
process to evaluate the understanding of the coherence of sub-event actions and
objects. To solve the problem, we design SubeventWriter, a sub-event sequence
generation framework with a coherence controller. Given an unseen process, the
framework can iteratively construct the sub-event sequence by generating one
sub-event at each iteration. We also design a very effective coherence
controller to decode more coherent sub-events. As our extensive experiments and
analysis indicate, SubeventWriter can generate more reliable and meaningful
sub-event sequences for unseen processes.",1,0,1,0,0,0,0.46425,7.0,0.702728,56
http://arxiv.org/abs/2203.09205v1,SoK: Differential Privacy on Graph-Structured Data,10,0.0652514,0.584724,"In this work, we study the applications of differential privacy (DP) in the
context of graph-structured data. We discuss the formulations of DP applicable
to the publication of graphs and their associated statistics as well as machine
learning on graph-based data, including graph neural networks (GNNs). The
formulation of DP in the context of graph-structured data is difficult, as
individual data points are interconnected (often non-linearly or sparsely).
This connectivity complicates the computation of individual privacy loss in
differentially private learning. The problem is exacerbated by an absence of a
single, well-established formulation of DP in graph settings. This issue
extends to the domain of GNNs, rendering private machine learning on
graph-structured data a challenging task. A lack of prior systematisation work
motivated us to study graph-based learning from a privacy perspective. In this
work, we systematise different formulations of DP on graphs, discuss challenges
and promising applications, including the GNN domain. We compare and separate
works into graph analysis tasks and graph learning tasks with GNNs. Finally, we
conclude our work with a discussion of open questions and potential directions
for further research in this area.",0,0,0,0,0,0,0.0783774,8.0,0.485609,115
http://arxiv.org/abs/2203.04729v1,Pretrained Domain-Specific Language Model for General Information Retrieval Tasks in the AEC Domain,26,0.145593,0.539876,"As an essential task for the architecture, engineering, and construction
(AEC) industry, information retrieval (IR) from unstructured textual data based
on natural language processing (NLP) is gaining increasing attention. Although
various deep learning (DL) models for IR tasks have been investigated in the
AEC domain, it is still unclear how domain corpora and domain-specific
pretrained DL models can improve performance in various IR tasks. To this end,
this work systematically explores the impacts of domain corpora and various
transfer learning techniques on the performance of DL models for IR tasks and
proposes a pretrained domain-specific language model for the AEC domain. First,
both in-domain and close-domain corpora are developed. Then, two types of
pretrained models, including traditional wording embedding models and
BERT-based models, are pretrained based on various domain corpora and transfer
learning strategies. Finally, several widely used DL models for IR tasks are
further trained and tested based on various configurations and pretrained
models. The result shows that domain corpora have opposite effects on
traditional word embedding models for text classification and named entity
recognition tasks but can further improve the performance of BERT-based models
in all tasks. Meanwhile, BERT-based models dramatically outperform traditional
methods in all IR tasks, with maximum improvements of 5.4% and 10.1% in the F1
score, respectively. This research contributes to the body of knowledge in two
ways: 1) demonstrating the advantages of domain corpora and pretrained DL
models and 2) opening the first domain-specific dataset and pretrained language
model for the AEC domain, to the best of our knowledge. Thus, this work sheds
light on the adoption and application of pretrained models in the AEC domain.",1,1,0,1,0,0,0.135833,9.0,0.607371,55
http://arxiv.org/abs/2212.07326v1,Mathematical model of printing-imaging channel for blind detection of fake copy detection patterns,6,0.107418,0.470879,"Nowadays, copy detection patterns (CDP) appear as a very promising
anti-counterfeiting technology for physical object protection. However, the
advent of deep learning as a powerful attacking tool has shown that the general
authentication schemes are unable to compete and fail against such attacks. In
this paper, we propose a new mathematical model of printing-imaging channel for
the authentication of CDP together with a new detection scheme based on it. The
results show that even deep learning created copy fakes unknown at the training
stage can be reliably authenticated based on the proposed approach and using
only digital references of CDP during authentication.",0,0,0,0,0,0,0.000754466,14.0,0.371531,13
http://arxiv.org/abs/2210.04311v1,Pruning Adversarially Robust Neural Networks without Adversarial Examples,5,0.0110106,0.224179,"Adversarial pruning compresses models while preserving robustness. Current
methods require access to adversarial examples during pruning. This
significantly hampers training efficiency. Moreover, as new adversarial attacks
and training methods develop at a rapid rate, adversarial pruning methods need
to be modified accordingly to keep up. In this work, we propose a novel
framework to prune a previously trained robust neural network while maintaining
adversarial robustness, without further generating adversarial examples. We
leverage concurrent self-distillation and pruning to preserve knowledge in the
original model as well as regularizing the pruned model via the Hilbert-Schmidt
Information Bottleneck. We comprehensively evaluate our proposed framework and
show its superior performance in terms of both adversarial robustness and
efficiency when pruning architectures trained on the MNIST, CIFAR-10, and
CIFAR-100 datasets against five state-of-the-art attacks. Code is available at
https://github.com/neu-spiral/PwoA/.",1,1,0,0,0,0,0.160424,8.0,0.580848,46
http://arxiv.org/abs/2210.06710v2,Large Language Models are few(1)-shot Table Reasoners,63,0.791213,0.794004,"Recent literature has shown that large language models (LLMs) are generally
excellent few-shot reasoners to solve text reasoning tasks. However, the
capability of LLMs on table reasoning tasks is yet to be explored. In this
paper, we aim at understanding how well LLMs can perform table-related tasks
with few-shot in-context learning. Specifically, we evaluated LLMs on popular
table QA and fact verification datasets like WikiTableQuestion, FetaQA,
TabFact, and FEVEROUS and found that LLMs are competent at complex reasoning
over table structures, though these models are not pre-trained on any table
corpus. When combined with `chain of thoughts' prompting, LLMs can achieve very
strong performance with only a 1-shot demonstration, even on par with some SoTA
models. We show that LLMs are even more competent at generating comprehensive
long-form answers on FetaQA than tuned T5-large. We further manually studied
the reasoning chains elicited from LLMs and found that these reasoning chains
are highly consistent with the underlying semantic form. We believe that LLMs
can serve as a simple yet generic baseline for future research. The code and
data are released in https://github.com/wenhuchen/TableCoT.",1,1,0,0,0,0,0.951495,5.0,0.899567,48
http://arxiv.org/abs/2203.08472v2,Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects,13,0.240695,0.536357,"In this paper, we tackle the task of estimating the 3D orientation of
previously-unseen objects from monocular images. This task contrasts with the
one considered by most existing deep learning methods which typically assume
that the testing objects have been observed during training. To handle the
unseen objects, we follow a retrieval-based strategy and prevent the network
from learning object-specific features by computing multi-scale local
similarities between the query image and synthetically-generated reference
images. We then introduce an adaptive fusion module that robustly aggregates
the local similarities into a global similarity score of pairwise images.
Furthermore, we speed up the retrieval process by developing a fast retrieval
strategy. Our experiments on the LineMOD, LineMOD-Occluded, and T-LESS datasets
show that our method yields a significantly better generalization to unseen
objects than previous works. Our code and pre-trained models are available at
https://sailor-z.github.io/projects/Unseen_Object_Pose.html.",1,1,1,0,0,0,0.963333,9.0,0.954029,42
http://arxiv.org/abs/2206.09363v1,Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning,62,0.513953,0.995101,"Conversational recommender systems (CRS) aim to proactively elicit user
preference and recommend high-quality items through natural language
conversations. Typically, a CRS consists of a recommendation module to predict
preferred items for users and a conversation module to generate appropriate
responses. To develop an effective CRS, it is essential to seamlessly integrate
the two modules. Existing works either design semantic alignment strategies, or
share knowledge resources and representations between the two modules. However,
these approaches still rely on different architectures or techniques to develop
the two modules, making it difficult for effective module integration.
  To address this problem, we propose a unified CRS model named UniCRS based on
knowledge-enhanced prompt learning. Our approach unifies the recommendation and
conversation subtasks into the prompt learning paradigm, and utilizes
knowledge-enhanced prompts based on a fixed pre-trained language model (PLM) to
fulfill both subtasks in a unified approach. In the prompt design, we include
fused knowledge representations, task-specific soft tokens, and the dialogue
context, which can provide sufficient contextual information to adapt the PLM
for the CRS task. Besides, for the recommendation subtask, we also incorporate
the generated response template as an important part of the prompt, to enhance
the information interaction between the two subtasks. Extensive experiments on
two public CRS datasets have demonstrated the effectiveness of our approach.",1,1,0,0,0,0,0.82575,5.0,0.789723,39
http://arxiv.org/abs/2203.01248v1,WaveY-Net: Physics-augmented deep learning for high-speed electromagnetic simulation and optimization,16,0.149155,0.844433,"The calculation of electromagnetic field distributions within structured
media is central to the optimization and validation of photonic devices. We
introduce WaveY-Net, a hybrid data- and physics-augmented convolutional neural
network that can predict electromagnetic field distributions with ultra fast
speeds and high accuracy for entire classes of dielectric photonic structures.
This accuracy is achieved by training the neural network to learn only the
magnetic near-field distributions of a system and to use a discrete formalism
of Maxwell's equations in two ways: as physical constraints in the loss
function and as a means to calculate the electric fields from the magnetic
fields. As a model system, we construct a surrogate simulator for periodic
silicon nanostructure arrays and show that the high speed simulator can be
directly and effectively used in the local and global freeform optimization of
metagratings. We anticipate that physics-augmented networks will serve as a
viable Maxwell simulator replacement for many classes of photonic systems,
transforming the way they are designed.",0,1,0,0,0,0,0.797689,6.0,0.809881,67
http://arxiv.org/abs/2211.00526v1,Leveraging Graph-based Cross-modal Information Fusion for Neural Sign Language Translation,4,0.106176,0.335657,"Sign Language (SL), as the mother tongue of the deaf community, is a special
visual language that most hearing people cannot understand. In recent years,
neural Sign Language Translation (SLT), as a possible way for bridging
communication gap between the deaf and the hearing people, has attracted
widespread academic attention. We found that the current mainstream end-to-end
neural SLT models, which tries to learning language knowledge in a weakly
supervised manner, could not mine enough semantic information under the
condition of low data resources. Therefore, we propose to introduce additional
word-level semantic knowledge of sign language linguistics to assist in
improving current end-to-end neural SLT models. Concretely, we propose a novel
neural SLT model with multi-modal feature fusion based on the dynamic graph, in
which the cross-modal information, i.e. text and video, is first assembled as a
dynamic graph according to their correlation, and then the graph is processed
by a multi-modal graph encoder to generate the multi-modal embeddings for
further usage in the subsequent neural translation models. To the best of our
knowledge, we are the first to introduce graph neural networks, for fusing
multi-modal information, into neural sign language translation models.
Moreover, we conducted experiments on a publicly available popular SLT dataset
RWTH-PHOENIX-Weather-2014T. and the quantitative experiments show that our
method can improve the model.",0,1,0,0,0,0,0.569323,10.0,0.821906,47
http://arxiv.org/abs/2210.01512v2,Code-Switching without Switching: Language Agnostic End-to-End Speech Translation,8,0.379334,0.687652,"We propose a) a Language Agnostic end-to-end Speech Translation model (LAST),
and b) a data augmentation strategy to increase code-switching (CS)
performance. With increasing globalization, multiple languages are increasingly
used interchangeably during fluent speech. Such CS complicates traditional
speech recognition and translation, as we must recognize which language was
spoken first and then apply a language-dependent recognizer and subsequent
translation component to generate the desired target language output. Such a
pipeline introduces latency and errors. In this paper, we eliminate the need
for that, by treating speech recognition and translation as one unified
end-to-end speech translation problem. By training LAST with both input
languages, we decode speech into one target language, regardless of the input
language. LAST delivers comparable recognition and speech translation accuracy
in monolingual usage, while reducing latency and error rate considerably when
CS is observed.",0,1,0,0,0,0,0.943729,7.0,0.921073,29
http://arxiv.org/abs/2209.02215v1,Reference Resolution and Context Change in Multimodal Situated Dialogue for Exploring Data Visualizations,1,0.00569066,0.0663935,"Reference resolution, which aims to identify entities being referred to by a
speaker, is more complex in real world settings: new referents may be created
by processes the agents engage in and/or be salient only because they belong to
the shared physical setting. Our focus is on resolving references to
visualizations on a large screen display in multimodal dialogue; crucially,
reference resolution is directly involved in the process of creating new
visualizations. We describe our annotations for user references to
visualizations appearing on a large screen via language and hand gesture and
also new entity establishment, which results from executing the user request to
create a new visualization. We also describe our reference resolution pipeline
which relies on an information-state architecture to maintain dialogue context.
We report results on detecting and resolving references, effectiveness of
contextual information on the model, and under-specified requests for creating
visualizations. We also experiment with conventional CRF and deep learning /
transformer models (BiLSTM-CRF and BERT-CRF) for tagging references in user
utterance text. Our results show that transfer learning significantly boost
performance of the deep learning methods, although CRF still out-performs them,
suggesting that conventional methods may generalize better for low resource
data.",0,1,0,1,0,0,0.00511798,14.0,0.508438,47
http://arxiv.org/abs/2207.02632v2,Network Pruning via Feature Shift Minimization,2,0.0134287,0.204435,"Channel pruning is widely used to reduce the complexity of deep network
models. Recent pruning methods usually identify which parts of the network to
discard by proposing a channel importance criterion. However, recent studies
have shown that these criteria do not work well in all conditions. In this
paper, we propose a novel Feature Shift Minimization (FSM) method to compress
CNN models, which evaluates the feature shift by converging the information of
both features and filters. Specifically, we first investigate the compression
efficiency with some prevalent methods in different layer-depths and then
propose the feature shift concept. Then, we introduce an approximation method
to estimate the magnitude of the feature shift, since it is difficult to
compute it directly. Besides, we present a distribution-optimization algorithm
to compensate for the accuracy loss and improve the network compression
efficiency. The proposed method yields state-of-the-art performance on various
benchmark networks and datasets, verified by extensive experiments. Our codes
are available at: https://github.com/lscgx/FSM.",1,1,0,0,1,0,0.466619,9.0,0.769575,52
http://arxiv.org/abs/2212.10786v2,Multi-hop Evidence Retrieval for Cross-document Relation Extraction,6,0.208554,0.711505,"Relation Extraction (RE) has been extended to cross-document scenarios
because many relations are not simply described in a single document. This
inevitably brings the challenge of efficient open-space evidence retrieval to
support the inference of cross-document relations, along with the challenge of
multi-hop reasoning on top of entities and evidence scattered in an open set of
documents. To combat these challenges, we propose MR.COD (Multi-hop evidence
retrieval for Cross-document relation extraction), which is a multi-hop
evidence retrieval method based on evidence path mining and ranking. We explore
multiple variants of retrievers to show evidence retrieval is essential in
cross-document RE. We also propose a contextual dense retriever for this
setting. Experiments on CodRED show that evidence retrieval with MR.COD
effectively acquires crossdocument evidence and boosts end-to-end RE
performance in both closed and open settings.",1,1,1,0,0,0,0.778229,6.0,0.800015,57
http://arxiv.org/abs/2205.11631v2,Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer,28,0.0182408,0.595334,"In Neural Machine Translation (NMT), each token prediction is conditioned on
the source sentence and the target prefix (what has been previously translated
at a decoding step). However, previous work on interpretability in NMT has
mainly focused solely on source sentence tokens' attributions. Therefore, we
lack a full understanding of the influences of every input token (source
sentence and target prefix) in the model predictions. In this work, we propose
an interpretability method that tracks input tokens' attributions for both
contexts. Our method, which can be extended to any encoder-decoder
Transformer-based model, allows us to better comprehend the inner workings of
current NMT models. We apply the proposed method to both bilingual and
multilingual Transformers and present insights into their behaviour.",0,0,0,0,0,0,0.115708,6.0,0.382455,37
http://arxiv.org/abs/2203.04637v1,LEBP -- Language Expectation & Binding Policy: A Two-Stream Framework for Embodied Vision-and-Language Interaction Task Learning Agents,15,0.699943,0.360943,"People always desire an embodied agent that can perform a task by
understanding language instruction. Moreover, they also want to monitor and
expect agents to understand commands the way they expected. But, how to build
such an embodied agent is still unclear. Recently, people can explore this
problem with the Vision-and-Language Interaction benchmark ALFRED, which
requires an agent to perform complicated daily household tasks following
natural language instructions in unseen scenes. In this paper, we propose LEBP
-- Language Expectation and Binding Policy Module to tackle the ALFRED. The
LEBP contains a two-stream process: 1) It first conducts a language expectation
module to generate an expectation describing how to perform tasks by
understanding the language instruction. The expectation consists of a sequence
of sub-steps for the task (e.g., Pick an apple). The expectation allows people
to access and check the understanding results of instructions before the agent
takes actual actions, in case the task might go wrong. 2) Then, it uses the
binding policy module to bind sub-steps in expectation to actual actions to
specific scenarios. Actual actions include navigation and object manipulation.
Experimental results suggest our approach achieves comparable performance to
currently published SOTA methods and can avoid large decay from seen scenarios
to unseen scenarios.",0,1,0,0,1,0,0.981644,5.0,0.955261,26
http://arxiv.org/abs/2202.05998v1,What Makes Good Contrastive Learning on Small-Scale Wearable-based Tasks?,24,0.0558704,0.418547,"Self-supervised learning establishes a new paradigm of learning
representations with much fewer or even no label annotations. Recently there
has been remarkable progress on large-scale contrastive learning models which
require substantial computing resources, yet such models are not practically
optimal for small-scale tasks. To fill the gap, we aim to study contrastive
learning on the wearable-based activity recognition task. Specifically, we
conduct an in-depth study of contrastive learning from both algorithmic-level
and task-level perspectives. For algorithmic-level analysis, we decompose
contrastive models into several key components and conduct rigorous
experimental evaluations to better understand the efficacy and rationale behind
contrastive learning. More importantly, for task-level analysis, we show that
the wearable-based signals bring unique challenges and opportunities to
existing contrastive models, which cannot be readily solved by existing
algorithms. Our thorough empirical studies suggest important practices and shed
light on future research challenges. In the meantime, this paper presents an
open-source PyTorch library \texttt{CL-HAR}, which can serve as a practical
tool for researchers. The library is highly modularized and easy to use, which
opens up avenues for exploring novel contrastive models quickly in the future.",1,1,0,0,0,0,0.430204,4.0,0.453789,47
http://arxiv.org/abs/2203.07085v1,Interpretability for Language Learners Using Example-Based Grammatical Error Correction,22,0.477267,0.986321,"Grammatical Error Correction (GEC) should not focus only on high accuracy of
corrections but also on interpretability for language learning. However,
existing neural-based GEC models mainly aim at improving accuracy, and their
interpretability has not been explored. A promising approach for improving
interpretability is an example-based method, which uses similar retrieved
examples to generate corrections. In addition, examples are beneficial in
language learning, helping learners understand the basis of grammatically
incorrect/correct texts and improve their confidence in writing. Therefore, we
hypothesize that incorporating an example-based method into GEC can improve
interpretability as well as support language learners. In this study, we
introduce an Example-Based GEC (EB-GEC) that presents examples to language
learners as a basis for a correction result. The examples consist of pairs of
correct and incorrect sentences similar to a given input and its predicted
correction. Experiments demonstrate that the examples presented by EB-GEC help
language learners decide to accept or refuse suggestions from the GEC output.
Furthermore, the experiments also show that retrieved examples improve the
accuracy of corrections.",1,1,0,0,0,0,0.454411,8.0,0.736188,58
http://arxiv.org/abs/2210.14650v1,MOCHA: A Multi-Task Training Approach for Coherent Text Generation from Cognitive Perspective,3,0.0152203,0.0567198,"Teaching neural models to generate narrative coherent texts is a critical
problem. Recent pre-trained language models have achieved promising results,
but there is still a gap between human written texts and machine-generated
outputs. In this work, we propose a novel multi-task training strategy for
coherent text generation grounded on the cognitive theory of writing, which
empowers the model to learn essential subskills needed for writing including
planning and reviewing besides end-to-end generation. We extensively evaluate
our model on three open-ended generation tasks including story generation, news
article writing and argument generation. Experiments show that our model
achieves better results on both few-shot and fully-supervised settings than
strong baselines, and human evaluations confirm that our model can generate
more coherent outputs.",1,1,0,0,0,0,0.184531,7.0,0.542984,46
http://arxiv.org/abs/2202.04824v2,AdaPrompt: Adaptive Model Training for Prompt-based NLP,35,0.4088,0.598129,"Prompt-based learning, with its capability to tackle zero-shot and few-shot
NLP tasks, has gained much attention in community. The main idea is to bridge
the gap between NLP downstream tasks and language modeling (LM), by mapping
these tasks into natural language prompts, which are then filled by pre-trained
language models (PLMs). However, for prompt learning, there are still two
salient gaps between NLP tasks and pretraining. First, prompt information is
not necessarily sufficiently present during LM pretraining. Second,
task-specific data are not necessarily well represented during pretraining. We
address these two issues by proposing AdaPrompt, adaptively retrieving external
data for continual pretraining of PLMs by making use of both task and prompt
characteristics. In addition, we make use of knowledge in Natural Language
Inference models for deriving adaptive verbalizers. Experimental results on
five NLP benchmarks show that AdaPrompt can improve over standard PLMs in
few-shot settings. In addition, in zero-shot settings, our method outperforms
standard prompt-based methods by up to 26.35\% relative error reduction.",1,1,0,0,0,0,0.938048,5.0,0.882703,55
http://arxiv.org/abs/2202.12795v2,Equilibrium Aggregation: Encoding Sets via Optimization,5,0.0259102,0.211275,"Processing sets or other unordered, potentially variable-sized inputs in
neural networks is usually handled by aggregating a number of input tensors
into a single representation. While a number of aggregation methods already
exist from simple sum pooling to multi-head attention, they are limited in
their representational power both from theoretical and empirical perspectives.
On the search of a principally more powerful aggregation strategy, we propose
an optimization-based method called Equilibrium Aggregation. We show that many
existing aggregation methods can be recovered as special cases of Equilibrium
Aggregation and that it is provably more efficient in some important cases.
Equilibrium Aggregation can be used as a drop-in replacement in many existing
architectures and applications. We validate its efficiency on three different
tasks: median estimation, class counting, and molecular property prediction. In
all experiments, Equilibrium Aggregation achieves higher performance than the
other aggregation techniques we test.",1,0,0,0,0,1,0.428256,8.0,0.726134,71
http://arxiv.org/abs/2210.16315v3,Beyond calibration: estimating the grouping loss of modern neural networks,11,0.334729,0.313612,"The ability to ensure that a classifier gives reliable confidence scores is
essential to ensure informed decision-making. To this end, recent work has
focused on miscalibration, i.e., the over or under confidence of model scores.
Yet calibration is not enough: even a perfectly calibrated classifier with the
best possible accuracy can have confidence scores that are far from the true
posterior probabilities. This is due to the grouping loss, created by samples
with the same confidence scores but different true posterior probabilities.
Proper scoring rule theory shows that given the calibration loss, the missing
piece to characterize individual errors is the grouping loss. While there are
many estimators of the calibration loss, none exists for the grouping loss in
standard settings. Here, we propose an estimator to approximate the grouping
loss. We show that modern neural network architectures in vision and NLP
exhibit grouping loss, notably in distribution shifts settings, which
highlights the importance of pre-production validation.",1,0,0,0,0,0,0.669481,12.0,0.874358,39
http://arxiv.org/abs/2204.00498v1,Evaluating the Text-to-SQL Capabilities of Large Language Models,66,0.908757,0.999249,"We perform an empirical evaluation of Text-to-SQL capabilities of the Codex
language model. We find that, without any finetuning, Codex is a strong
baseline on the Spider benchmark; we also analyze the failure modes of Codex in
this setting. Furthermore, we demonstrate on the GeoQuery and Scholar
benchmarks that a small number of in-domain examples provided in the prompt
enables Codex to perform better than state-of-the-art models finetuned on such
few-shot examples.",0,1,0,0,0,0,0.988533,4.0,0.97189,23
http://arxiv.org/abs/2207.12054v1,A Reference Data Model for Process-Related User Interaction Logs,7,0.143666,0.350129,"User interaction (UI) logs are high-resolution event logs that record
low-level activities performed by a user during the execution of a task in an
information system. Each event in a UI log corresponds to a single interaction
between the user and the interface, such as clicking a button or entering a
string into a text field. UI logs are used for purposes like task mining or
robotic process automation (RPA), but each study and tool relies on a different
conceptualization and implementation of the elements and attributes that
constitute user interactions. This lack of standardization makes it difficult
to integrate UI logs from different sources and to combine tools for UI data
collection with downstream analytics or automation solutions. To address this,
we propose a universally applicable reference data model for process-related UI
logs. Based on a review of scientific literature and industry solutions, this
model includes the core attributes of UI logs, but remains flexible with regard
to the scope, level of abstraction, and case notion. We provide an
implementation of the model as an extension to the XES interchange standard for
event logs and demonstrate its practical applicability in a real-life RPA
scenario.",0,1,0,0,0,0,0.0224133,11.0,0.509434,39
http://arxiv.org/abs/2204.02181v1,Vision Transformer Equipped with Neural Resizer on Facial Expression Recognition Task,5,0.0350649,0.52048,"When it comes to wild conditions, Facial Expression Recognition is often
challenged with low-quality data and imbalanced, ambiguous labels. This field
has much benefited from CNN based approaches; however, CNN models have
structural limitation to see the facial regions in distant. As a remedy,
Transformer has been introduced to vision fields with global receptive field,
but requires adjusting input spatial size to the pretrained models to enjoy
their strong inductive bias at hands. We herein raise a question whether using
the deterministic interpolation method is enough to feed low-resolution data to
Transformer. In this work, we propose a novel training framework, Neural
Resizer, to support Transformer by compensating information and downscaling in
a data-driven manner trained with loss function balancing the noisiness and
imbalance. Experiments show our Neural Resizer with F-PDLS loss function
improves the performance with Transformer variants in general and nearly
achieves the state-of-the-art performance.",0,1,0,0,1,0,0.576846,6.0,0.706627,26
http://arxiv.org/abs/2206.13754v1,DistSPECTRL: Distributing Specifications in Multi-Agent Reinforcement Learning Systems,3,0.0355324,0.121108,"While notable progress has been made in specifying and learning objectives
for general cyber-physical systems, applying these methods to distributed
multi-agent systems still pose significant challenges. Among these are the need
to (a) craft specification primitives that allow expression and interplay of
both local and global objectives, (b) tame explosion in the state and action
spaces to enable effective learning, and (c) minimize coordination frequency
and the set of engaged participants for global objectives. To address these
challenges, we propose a novel specification framework that allows natural
composition of local and global objectives used to guide training of a
multi-agent system. Our technique enables learning expressive policies that
allow agents to operate in a coordination-free manner for local objectives,
while using a decentralized communication protocol for enforcing global ones.
Experimental results support our claim that sophisticated multi-agent
distributed planning problems can be effectively realized using
specification-guided learning.",1,0,0,0,0,0,0.50476,10.0,0.803776,22
http://arxiv.org/abs/2202.08345v2,Learning Smooth Neural Functions via Lipschitz Regularization,59,0.295121,0.879769,"Neural implicit fields have recently emerged as a useful representation for
3D shapes. These fields are commonly represented as neural networks which map
latent descriptors and 3D coordinates to implicit function values. The latent
descriptor of a neural field acts as a deformation handle for the 3D shape it
represents. Thus, smoothness with respect to this descriptor is paramount for
performing shape-editing operations. In this work, we introduce a novel
regularization designed to encourage smooth latent spaces in neural fields by
penalizing the upper bound on the field's Lipschitz constant. Compared with
prior Lipschitz regularized networks, ours is computationally fast, can be
implemented in four lines of code, and requires minimal hyperparameter tuning
for geometric applications. We demonstrate the effectiveness of our approach on
shape interpolation and extrapolation as well as partial shape reconstruction
from 3D point clouds, showing both qualitative and quantitative improvements
over existing state-of-the-art and non-regularized baselines.",0,0,0,0,1,0,0.371774,8.0,0.703067,60
http://arxiv.org/abs/2205.07006v1,Integration of Text and Graph-based Features for Detecting Mental Health Disorders from Voice,1,0.112146,0.167945,"With the availability of voice-enabled devices such as smart phones, mental
health disorders could be detected and treated earlier, particularly
post-pandemic. The current methods involve extracting features directly from
audio signals. In this paper, two methods are used to enrich voice analysis for
depression detection: graph transformation of voice signals, and natural
language processing of the transcript based on representational learning, fused
together to produce final class labels. The results of experiments with the
DAIC-WOZ dataset suggest that integration of text-based voice classification
and learning from low level and graph-based voice signal features can improve
the detection of mental disorders like depression.",0,1,0,0,1,0,0.800046,7.0,0.838084,29
http://arxiv.org/abs/2211.11238v4,RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments,14,0.100623,0.775592,"Camera relocalization has various applications in autonomous driving.
Previous camera pose regression models consider only ideal scenarios where
there is little environmental perturbation. To deal with challenging driving
environments that may have changing seasons, weather, illumination, and the
presence of unstable objects, we propose RobustLoc, which derives its
robustness against perturbations from neural differential equations. Our model
uses a convolutional neural network to extract feature maps from multi-view
images, a robust neural differential equation diffusion block module to diffuse
information interactively, and a branched pose decoder with multi-layer
training to estimate the vehicle poses. Experiments demonstrate that RobustLoc
surpasses current state-of-the-art camera pose regression models and achieves
robust performance in various environments. Our code is released at:
https://github.com/sijieaaa/RobustLoc",1,1,0,0,1,0,0.260828,7.0,0.59914,33
http://arxiv.org/abs/2210.06254v2,Zero-Shot On-the-Fly Event Schema Induction,9,0.185538,0.810376,"What are the events involved in a pandemic outbreak? What steps should be
taken when planning a wedding? The answers to these questions can be found by
collecting many documents on the complex event of interest, extracting relevant
information, and analyzing it. We present a new approach in which large
language models are utilized to generate source documents that allow
predicting, given a high-level event definition, the specific events,
arguments, and relations between them to construct a schema that describes the
complex event in its entirety. Using our model, complete schemas on any topic
can be generated on-the-fly without any manual data collection, i.e., in a
zero-shot manner. Moreover, we develop efficient methods to extract pertinent
information from texts and demonstrate in a series of experiments that these
schemas are considered to be more complete than human-curated ones in the
majority of examined scenarios. Finally, we show that this framework is
comparable in performance with previous supervised schema induction methods
that rely on collecting real texts while being more general and flexible
without the need for a predefined ontology.",0,1,1,0,0,0,0.637117,7.0,0.772021,85
http://arxiv.org/abs/2202.01323v1,PanoDepth: A Two-Stage Approach for Monocular Omnidirectional Depth Estimation,9,0.10569,0.480173,"Omnidirectional 3D information is essential for a wide range of applications
such as Virtual Reality, Autonomous Driving, Robotics, etc. In this paper, we
propose a novel, model-agnostic, two-stage pipeline for omnidirectional
monocular depth estimation. Our proposed framework PanoDepth takes one 360
image as input, produces one or more synthesized views in the first stage, and
feeds the original image and the synthesized images into the subsequent stereo
matching stage. In the second stage, we propose a differentiable Spherical
Warping Layer to handle omnidirectional stereo geometry efficiently and
effectively. By utilizing the explicit stereo-based geometric constraints in
the stereo matching stage, PanoDepth can generate dense high-quality depth. We
conducted extensive experiments and ablation studies to evaluate PanoDepth with
both the full pipeline as well as the individual modules in each stage. Our
results show that PanoDepth outperforms the state-of-the-art approaches by a
large margin for 360 monocular depth estimation.",0,1,0,0,1,0,0.532426,7.0,0.730912,69
http://arxiv.org/abs/2212.13185v3,Generalized Differentiable RANSAC,9,0.124331,0.871734,"We propose $\nabla$-RANSAC, a generalized differentiable RANSAC that allows
learning the entire randomized robust estimation pipeline. The proposed
approach enables the use of relaxation techniques for estimating the gradients
in the sampling distribution, which are then propagated through a
differentiable solver. The trainable quality function marginalizes over the
scores from all the models estimated within $\nabla$-RANSAC to guide the
network learning accurate and useful inlier probabilities or to train feature
detection and matching networks. Our method directly maximizes the probability
of drawing a good hypothesis, allowing us to learn better sampling
distributions. We test $\nabla$-RANSAC on various real-world scenarios on
fundamental and essential matrix estimation, and 3D point cloud registration,
outdoors and indoors, with handcrafted and learning-based features. It is
superior to the state-of-the-art in terms of accuracy while running at a
similar speed to its less accurate alternatives. The code and trained models
are available at https://github.com/weitong8591/differentiable_ransac.",1,0,0,0,1,0,0.338791,14.0,0.821994,80
http://arxiv.org/abs/2201.08531v3,Black-box Prompt Learning for Pre-trained Language Models,48,0.372639,0.447845,"The increasing scale of general-purpose Pre-trained Language Models (PLMs)
necessitates the study of more efficient adaptation across different downstream
tasks. In this paper, we establish a Black-box Discrete Prompt Learning (BDPL)
to resonate with pragmatic interactions between the cloud infrastructure and
edge devices. Particularly, instead of fine-tuning the model in the cloud, we
adapt PLMs by prompt learning, which efficiently optimizes only a few
parameters of the discrete prompts. Moreover, we consider the scenario that we
do not have access to the parameters and gradients of the pre-trained models,
except for its outputs given inputs. This black-box setting secures the cloud
infrastructure from potential attack and misuse to cause a single-point
failure, which is preferable to the white-box counterpart by current
infrastructures. Under this black-box constraint, we apply a variance-reduced
policy gradient algorithm to estimate the gradients of parameters in the
categorical distribution of each discrete prompt. In light of our method, the
user devices can efficiently tune their tasks by querying the PLMs bounded by a
range of API calls. Our experiments on RoBERTa and GPT-3 demonstrate that the
proposed algorithm achieves significant improvement on eight benchmarks in a
cloud-device collaboration manner. Finally, we conduct in-depth case studies to
comprehensively analyze our method in terms of various data sizes, prompt
lengths, training budgets, optimization objectives, prompt transferability, and
explanations of the learned prompts. Our code will be available at
https://github.com/shizhediao/Black-Box-Prompt-Learning.",0,1,0,0,0,0,0.910204,4.0,0.817569,85
http://arxiv.org/abs/2210.05815v1,Underspecification in Scene Description-to-Depiction Tasks,25,0.703881,0.908343,"Questions regarding implicitness, ambiguity and underspecification are
crucial for understanding the task validity and ethical concerns of multimodal
image+text systems, yet have received little attention to date. This position
paper maps out a conceptual framework to address this gap, focusing on systems
which generate images depicting scenes from scene descriptions. In doing so, we
account for how texts and images convey meaning differently. We outline a set
of core challenges concerning textual and visual ambiguity, as well as risks
that may be amplified by ambiguous and underspecified elements. We propose and
discuss strategies for addressing these challenges, including generating
visually ambiguous images, and generating a set of diverse images.",0,0,0,0,0,0,0.836694,7.0,0.855009,91
http://arxiv.org/abs/2207.11565v1,Context based lemmatizer for Polish language,1,0.041657,0.28529,"Lemmatization is the process of grouping together the inflected forms of a
word so they can be analysed as a single item, identified by the word's lemma,
or dictionary form. In computational linguistics, lemmatisation is the
algorithmic process of determining the lemma of a word based on its intended
meaning. Unlike stemming, lemmatisation depends on correctly identifying the
intended part of speech and meaning of a word in a sentence, as well as within
the larger context surrounding that sentence. As a result, developing efficient
lemmatisation algorithm is the complex task. In recent years it can be observed
that deep learning models used for this task outperform other methods including
machine learning algorithms. In this paper the polish lemmatizer based on
Google T5 model is presented. The training was run with different context
lengths. The model achieves the best results for polish language lemmatisation
process.",0,1,0,0,0,0,0.419451,11.0,0.798305,12
http://arxiv.org/abs/2204.06772v1,ViTOL: Vision Transformer for Weakly Supervised Object Localization,17,0.229209,0.735191,"Weakly supervised object localization (WSOL) aims at predicting object
locations in an image using only image-level category labels. Common challenges
that image classification models encounter when localizing objects are, (a)
they tend to look at the most discriminative features in an image that confines
the localization map to a very small region, (b) the localization maps are
class agnostic, and the models highlight objects of multiple classes in the
same image and, (c) the localization performance is affected by background
noise. To alleviate the above challenges we introduce the following simple
changes through our proposed method ViTOL. We leverage the vision-based
transformer for self-attention and introduce a patch-based attention dropout
layer (p-ADL) to increase the coverage of the localization map and a gradient
attention rollout mechanism to generate class-dependent attention maps. We
conduct extensive quantitative, qualitative and ablation experiments on the
ImageNet-1K and CUB datasets. We achieve state-of-the-art MaxBoxAcc-V2
localization scores of 70.47% and 73.17% on the two datasets respectively. Code
is available on https://github.com/Saurav-31/ViTOL",1,1,0,0,1,0,0.864581,8.0,0.885425,34
http://arxiv.org/abs/2212.05034v1,SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model,95,0.90823,0.873921,"Generic image inpainting aims to complete a corrupted image by borrowing
surrounding information, which barely generates novel content. By contrast,
multi-modal inpainting provides more flexible and useful controls on the
inpainted content, \eg, a text prompt can be used to describe an object with
richer attributes, and a mask can be used to constrain the shape of the
inpainted object rather than being only considered as a missing area. We
propose a new diffusion-based model named SmartBrush for completing a missing
region with an object using both text and shape-guidance. While previous work
such as DALLE-2 and Stable Diffusion can do text-guided inapinting they do not
support shape guidance and tend to modify background texture surrounding the
generated object. Our model incorporates both text and shape guidance with
precision control. To preserve the background better, we propose a novel
training and sampling strategy by augmenting the diffusion U-net with
object-mask prediction. Lastly, we introduce a multi-task training strategy by
jointly training inpainting with text-to-image generation to leverage more
training data. We conduct extensive experiments showing that our model
outperforms all baselines in terms of visual quality, mask controllability, and
background preservation.",1,1,0,0,1,0,0.989058,2.0,0.949002,32
http://arxiv.org/abs/2207.03433v2,Semi-supervised Object Detection via Virtual Category Learning,5,0.0809557,0.317087,"Due to the costliness of labelled data in real-world applications,
semi-supervised object detectors, underpinned by pseudo labelling, are
appealing. However, handling confusing samples is nontrivial: discarding
valuable confusing samples would compromise the model generalisation while
using them for training would exacerbate the confirmation bias issue caused by
inevitable mislabelling. To solve this problem, this paper proposes to use
confusing samples proactively without label correction. Specifically, a virtual
category (VC) is assigned to each confusing sample such that they can safely
contribute to the model optimisation even without a concrete label. It is
attributed to specifying the embedding distance between the training sample and
the virtual category as the lower bound of the inter-class distance. Moreover,
we also modify the localisation loss to allow high-quality boundaries for
location regression. Extensive experiments demonstrate that the proposed VC
learning significantly surpasses the state-of-the-art, especially with small
amounts of available labels.",1,1,0,0,1,0,0.967106,7.0,0.945512,43
http://arxiv.org/abs/2211.11763v1,DS-GPS : A Deep Statistical Graph Poisson Solver (for faster CFD simulations),1,0.00408945,0.0446911,"This paper proposes a novel Machine Learning-based approach to solve a
Poisson problem with mixed boundary conditions. Leveraging Graph Neural
Networks, we develop a model able to process unstructured grids with the
advantage of enforcing boundary conditions by design. By directly minimizing
the residual of the Poisson equation, the model attempts to learn the physics
of the problem without the need for exact solutions, in contrast to most
previous data-driven processes where the distance with the available solutions
is minimized.",0,1,0,0,0,0,0.124696,6.0,0.395756,23
http://arxiv.org/abs/2112.15304v1,An Intelligent Self-driving Truck System For Highway Transportation,8,0.122352,0.658314,"Recently, there have been many advances in autonomous driving society,
attracting a lot of attention from academia and industry. However, existing
works mainly focus on cars, extra development is still required for
self-driving truck algorithms and models. In this paper, we introduce an
intelligent self-driving truck system. Our presented system consists of three
main components, 1) a realistic traffic simulation module for generating
realistic traffic flow in testing scenarios, 2) a high-fidelity truck model
which is designed and evaluated for mimicking real truck response in real-world
deployment, 3) an intelligent planning module with learning-based decision
making algorithm and multi-mode trajectory planner, taking into account the
truck's constraints, road slope changes, and the surrounding traffic flow. We
provide quantitative evaluations for each component individually to demonstrate
the fidelity and performance of each part. We also deploy our proposed system
on a real truck and conduct real world experiments which shows our system's
capacity of mitigating sim-to-real gap. Our code is available at
https://github.com/InceptioResearch/IITS",1,1,0,0,0,0,0.642429,9.0,0.824288,43
http://arxiv.org/abs/2210.01969v5,Option-Aware Adversarial Inverse Reinforcement Learning for Robotic Control,13,0.0977668,0.60274,"Hierarchical Imitation Learning (HIL) has been proposed to recover
highly-complex behaviors in long-horizon tasks from expert demonstrations by
modeling the task hierarchy with the option framework. Existing methods either
overlook the causal relationship between the subtask and its corresponding
policy or cannot learn the policy in an end-to-end fashion, which leads to
suboptimality. In this work, we develop a novel HIL algorithm based on
Adversarial Inverse Reinforcement Learning and adapt it with the
Expectation-Maximization algorithm in order to directly recover a hierarchical
policy from the unannotated demonstrations. Further, we introduce a directed
information term to the objective function to enhance the causality and propose
a Variational Autoencoder framework for learning with our objectives in an
end-to-end fashion. Theoretical justifications and evaluations on challenging
robotic control tasks are provided to show the superiority of our algorithm.
The codes are available at https://github.com/LucasCJYSDL/HierAIRL.",1,0,0,0,0,0,0.301244,13.0,0.797277,41
http://arxiv.org/abs/2202.10492v1,CaMEL: Mean Teacher Learning for Image Captioning,23,0.0910202,0.463523,"Describing images in natural language is a fundamental step towards the
automatic modeling of connections between the visual and textual modalities. In
this paper we present CaMEL, a novel Transformer-based architecture for image
captioning. Our proposed approach leverages the interaction of two
interconnected language models that learn from each other during the training
phase. The interplay between the two language models follows a mean teacher
learning paradigm with knowledge distillation. Experimentally, we assess the
effectiveness of the proposed solution on the COCO dataset and in conjunction
with different visual feature extractors. When comparing with existing
proposals, we demonstrate that our model provides state-of-the-art caption
quality with a significantly reduced number of parameters. According to the
CIDEr metric, we obtain a new state of the art on COCO when training without
using external data. The source code and trained models are publicly available
at: https://github.com/aimagelab/camel.",1,1,0,0,1,0,0.667289,6.0,0.747718,63
http://arxiv.org/abs/2208.04379v1,A Systematic Evaluation of Response Selection for Open Domain Dialogue,7,0.0284407,0.787324,"Recent progress on neural approaches for language processing has triggered a
resurgence of interest on building intelligent open-domain chatbots. However,
even the state-of-the-art neural chatbots cannot produce satisfying responses
for every turn in a dialog. A practical solution is to generate multiple
response candidates for the same context, and then perform response
ranking/selection to determine which candidate is the best. Previous work in
response selection typically trains response rankers using synthetic data that
is formed from existing dialogs by using a ground truth response as the single
appropriate response and constructing inappropriate responses via random
selection or using adversarial methods. In this work, we curated a dataset
where responses from multiple response generators produced for the same dialog
context are manually annotated as appropriate (positive) and inappropriate
(negative). We argue that such training data better matches the actual use case
examples, enabling the models to learn to rank responses effectively. With this
new dataset, we conduct a systematic evaluation of state-of-the-art methods for
response selection, and demonstrate that both strategies of using multiple
positive candidates and using manually verified hard negative candidates can
bring in significant performance improvement in comparison to using the
adversarial training data, e.g., increase of 3% and 13% in Recall@1 score,
respectively.",0,1,0,1,0,0,0.138311,6.0,0.414303,43
http://arxiv.org/abs/2212.08071v2,MAViL: Masked Audio-Video Learners,27,0.238777,0.904404,"We present Masked Audio-Video Learners (MAViL) to train audio-visual
representations. Our approach learns with three complementary forms of
self-supervision: (1) reconstruction of masked audio and video input data, (2)
intra- and inter-modal contrastive learning with masking, and (3) self-training
by reconstructing joint audio-video contextualized features learned from the
first two objectives. Pre-training with MAViL not only enables the model to
perform well in audio-visual classification and retrieval tasks but also
improves representations of each modality in isolation, without using
information from the other modality for fine-tuning or inference. Empirically,
MAViL sets a new state-of-the-art on AudioSet (53.1 mAP) and VGGSound (67.1%
accuracy). For the first time, a self-supervised audio-visual model outperforms
ones that use external supervision on these benchmarks.",1,0,0,0,1,0,0.824103,6.0,0.823869,107
http://arxiv.org/abs/2203.12670v1,Competency Assessment for Autonomous Agents using Deep Generative Models,8,0.165798,0.438298,"For autonomous agents to act as trustworthy partners to human users, they
must be able to reliably communicate their competency for the tasks they are
asked to perform. Towards this objective, we develop probabilistic world models
based on deep generative modelling that allow for the simulation of agent
trajectories and accurate calculation of tasking outcome probabilities. By
combining the strengths of conditional variational autoencoders with recurrent
neural networks, the deep generative world model can probabilistically forecast
trajectories over long horizons to task completion. We show how these
forecasted trajectories can be used to calculate outcome probability
distributions, which enable the precise assessment of agent competency for
specific tasks and initial settings.",0,1,0,0,0,0,0.724114,9.0,0.849275,35
http://arxiv.org/abs/2206.11160v1,The Problem of Semantic Shift in Longitudinal Monitoring of Social Media: A Case Study on Mental Health During the COVID-19 Pandemic,2,0.0325647,0.0454806,"Social media allows researchers to track societal and cultural changes over
time based on language analysis tools. Many of these tools rely on statistical
algorithms which need to be tuned to specific types of language. Recent studies
have shown the absence of appropriate tuning, specifically in the presence of
semantic shift, can hinder robustness of the underlying methods. However,
little is known about the practical effect this sensitivity may have on
downstream longitudinal analyses. We explore this gap in the literature through
a timely case study: understanding shifts in depression during the course of
the COVID-19 pandemic. We find that inclusion of only a small number of
semantically-unstable features can promote significant changes in longitudinal
estimates of our target outcome. At the same time, we demonstrate that a
recently-introduced method for measuring semantic shift may be used to
proactively identify failure points of language-based models and, in turn,
improve predictive generalization.",0,1,0,0,0,0,0.22349,9.0,0.668442,104
http://arxiv.org/abs/2206.10786v4,Generative Pretraining for Black-Box Optimization,12,0.130248,0.566485,"Many problems in science and engineering involve optimizing an expensive
black-box function over a high-dimensional space. For such black-box
optimization (BBO) problems, we typically assume a small budget for online
function evaluations, but also often have access to a fixed, offline dataset
for pretraining. Prior approaches seek to utilize the offline data to
approximate the function or its inverse but are not sufficiently accurate far
from the data distribution. We propose BONET, a generative framework for
pretraining a novel black-box optimizer using offline datasets. In BONET, we
train an autoregressive model on fixed-length trajectories derived from an
offline dataset. We design a sampling strategy to synthesize trajectories from
offline data using a simple heuristic of rolling out monotonic transitions from
low-fidelity to high-fidelity samples. Empirically, we instantiate BONET using
a causally masked Transformer and evaluate it on Design-Bench, where we rank
the best on average, outperforming state-of-the-art baselines.",1,0,0,0,1,0,0.515292,6.0,0.677981,60
http://arxiv.org/abs/2207.05289v1,PLM-ICD: Automatic ICD Coding with Pretrained Language Models,29,0.758295,0.523438,"Automatically classifying electronic health records (EHRs) into diagnostic
codes has been challenging to the NLP community. State-of-the-art methods
treated this problem as a multilabel classification problem and proposed
various architectures to model this problem. However, these systems did not
leverage the superb performance of pretrained language models, which achieved
superb performance on natural language understanding tasks. Prior work has
shown that pretrained language models underperformed on this task with the
regular finetuning scheme. Therefore, this paper aims at analyzing the causes
of the underperformance and developing a framework for automatic ICD coding
with pretrained language models. We spotted three main issues through the
experiments: 1) large label space, 2) long input sequences, and 3) domain
mismatch between pretraining and fine-tuning. We propose PLMICD, a framework
that tackles the challenges with various strategies. The experimental results
show that our proposed framework can overcome the challenges and achieves
state-of-the-art performance in terms of multiple metrics on the benchmark
MIMIC data. The source code is available at https://github.com/MiuLab/PLM-ICD",1,1,0,0,1,0,0.963012,7.0,0.940518,41
http://arxiv.org/abs/2203.16788v1,"ESGBERT: Language Model to Help with Classification Tasks Related to Companies Environmental, Social, and Governance Practices",16,0.213766,0.334218,"Environmental, Social, and Governance (ESG) are non-financial factors that
are garnering attention from investors as they increasingly look to apply these
as part of their analysis to identify material risks and growth opportunities.
Some of this attention is also driven by clients who, now more aware than ever,
are demanding for their money to be managed and invested responsibly. As the
interest in ESG grows, so does the need for investors to have access to
consumable ESG information. Since most of it is in text form in reports,
disclosures, press releases, and 10-Q filings, we see a need for sophisticated
NLP techniques for classification tasks for ESG text. We hypothesize that an
ESG domain-specific pre-trained model will help with such and study building of
the same in this paper. We explored doing this by fine-tuning BERTs pre-trained
weights using ESG specific text and then further fine-tuning the model for a
classification task. We were able to achieve accuracy better than the original
BERT and baseline models in environment-specific classification tasks.",0,1,0,0,0,0,0.444761,11.0,0.805467,18
http://arxiv.org/abs/2201.07703v2,Q-ViT: Fully Differentiable Quantization for Vision Transformer,28,0.0,0.808892,"In this paper, we propose a fully differentiable quantization method for
vision transformer (ViT) named as Q-ViT, in which both of the quantization
scales and bit-widths are learnable parameters. Specifically, based on our
observation that heads in ViT display different quantization robustness, we
leverage head-wise bit-width to squeeze the size of Q-ViT while preserving
performance. In addition, we propose a novel technique named switchable scale
to resolve the convergence problem in the joint training of quantization scales
and bit-widths. In this way, Q-ViT pushes the limits of ViT quantization to
3-bit without heavy performance drop. Moreover, we analyze the quantization
robustness of every architecture component of ViT and show that the Multi-head
Self-Attention (MSA) and the Gaussian Error Linear Units (GELU) are the key
aspects for ViT quantization. This study provides some insights for further
research about ViT quantization. Extensive experiments on different ViT models,
such as DeiT and Swin Transformer show the effectiveness of our quantization
method. In particular, our method outperforms the state-of-the-art uniform
quantization method by 1.5% on DeiT-Tiny.",1,1,0,0,1,0,0.255991,6.0,0.528694,46
http://arxiv.org/abs/2203.13722v2,Probing Pre-Trained Language Models for Cross-Cultural Differences in Values,53,0.940103,0.997702,"Language embeds information about social, cultural, and political values
people hold. Prior work has explored social and potentially harmful biases
encoded in Pre-Trained Language models (PTLMs). However, there has been no
systematic study investigating how values embedded in these models vary across
cultures. In this paper, we introduce probes to study which values across
cultures are embedded in these models, and whether they align with existing
theories and cross-cultural value surveys. We find that PTLMs capture
differences in values across cultures, but those only weakly align with
established value surveys. We discuss implications of using mis-aligned models
in cross-cultural settings, as well as ways of aligning PTLMs with value
surveys.",0,0,0,0,0,0,0.958727,5.0,0.909962,75
http://arxiv.org/abs/2206.03633v1,Ensembles for Uncertainty Estimation: Benefits of Prior Functions and Bootstrapping,10,0.0488129,0.656316,"In machine learning, an agent needs to estimate uncertainty to efficiently
explore and adapt and to make effective decisions. A common approach to
uncertainty estimation maintains an ensemble of models. In recent years,
several approaches have been proposed for training ensembles, and conflicting
views prevail with regards to the importance of various ingredients of these
approaches. In this paper, we aim to address the benefits of two ingredients --
prior functions and bootstrapping -- which have come into question. We show
that prior functions can significantly improve an ensemble agent's joint
predictions across inputs and that bootstrapping affords additional benefits if
the signal-to-noise ratio varies across inputs. Our claims are justified by
both theoretical and experimental results.",0,0,0,0,0,0,0.145287,9.0,0.615443,40
http://arxiv.org/abs/2205.04502v1,Multiview Stereo with Cascaded Epipolar RAFT,23,0.163202,0.877271,"We address multiview stereo (MVS), an important 3D vision task that
reconstructs a 3D model such as a dense point cloud from multiple calibrated
images. We propose CER-MVS (Cascaded Epipolar RAFT Multiview Stereo), a new
approach based on the RAFT (Recurrent All-Pairs Field Transforms) architecture
developed for optical flow. CER-MVS introduces five new changes to RAFT:
epipolar cost volumes, cost volume cascading, multiview fusion of cost volumes,
dynamic supervision, and multiresolution fusion of depth maps. CER-MVS is
significantly different from prior work in multiview stereo. Unlike prior work,
which operates by updating a 3D cost volume, CER-MVS operates by updating a
disparity field. Furthermore, we propose an adaptive thresholding method to
balance the completeness and accuracy of the reconstructed point clouds.
Experiments show that our approach achieves competitive performance on DTU (the
second best among known results) and state-of-the-art performance on the
Tanks-and-Temples benchmark (both the intermediate and advanced set). Code is
available at https://github.com/princeton-vl/CER-MVS",0,1,0,0,1,0,0.608006,6.0,0.720828,44
http://arxiv.org/abs/2209.07740v1,Computing Abductive Explanations for Boosted Trees,5,0.170148,0.271404,"Boosted trees is a dominant ML model, exhibiting high accuracy. However,
boosted trees are hardly intelligible, and this is a problem whenever they are
used in safety-critical applications. Indeed, in such a context, rigorous
explanations of the predictions made are expected. Recent work have shown how
subset-minimal abductive explanations can be derived for boosted trees, using
automated reasoning techniques. However, the generation of such well-founded
explanations is intractable in the general case. To improve the scalability of
their generation, we introduce the notion of tree-specific explanation for a
boosted tree. We show that tree-specific explanations are abductive
explanations that can be computed in polynomial time. We also explain how to
derive a subset-minimal abductive explanation from a tree-specific explanation.
Experiments on various datasets show the computational benefits of leveraging
tree-specific explanations for deriving subset-minimal abductive explanations.",0,0,0,0,0,0,0.822643,7.0,0.848349,51
http://arxiv.org/abs/2201.00304v1,Informed Multi-context Entity Alignment,8,0.218045,0.556485,"Entity alignment is a crucial step in integrating knowledge graphs (KGs) from
multiple sources. Previous attempts at entity alignment have explored different
KG structures, such as neighborhood-based and path-based contexts, to learn
entity embeddings, but they are limited in capturing the multi-context
features. Moreover, most approaches directly utilize the embedding similarity
to determine entity alignment without considering the global interaction among
entities and relations. In this work, we propose an Informed Multi-context
Entity Alignment (IMEA) model to address these issues. In particular, we
introduce Transformer to flexibly capture the relation, path, and neighborhood
contexts, and design holistic reasoning to estimate alignment probabilities
based on both embedding similarity and the relation/entity functionality. The
alignment evidence obtained from holistic reasoning is further injected back
into the Transformer via the proposed soft label editing to inform embedding
learning. Experimental results on several benchmark datasets demonstrate the
superiority of our IMEA model compared with existing state-of-the-art entity
alignment methods.",0,0,0,0,1,0,0.963685,6.0,0.93153,36
http://arxiv.org/abs/2203.16898v1,Semantic-shape Adaptive Feature Modulation for Semantic Image Synthesis,18,0.137187,0.238035,"Recent years have witnessed substantial progress in semantic image synthesis,
it is still challenging in synthesizing photo-realistic images with rich
details. Most previous methods focus on exploiting the given semantic map,
which just captures an object-level layout for an image. Obviously, a
fine-grained part-level semantic layout will benefit object details generation,
and it can be roughly inferred from an object's shape. In order to exploit the
part-level layouts, we propose a Shape-aware Position Descriptor (SPD) to
describe each pixel's positional feature, where object shape is explicitly
encoded into the SPD feature. Furthermore, a Semantic-shape Adaptive Feature
Modulation (SAFM) block is proposed to combine the given semantic map and our
positional features to produce adaptively modulated features. Extensive
experiments demonstrate that the proposed SPD and SAFM significantly improve
the generation of objects with rich details. Moreover, our method performs
favorably against the SOTA methods in terms of quantitative and qualitative
evaluation. The source code and model are available at
https://github.com/cszy98/SAFM.",0,1,0,0,1,0,0.816471,10.0,0.891847,42
http://arxiv.org/abs/2210.16740v1,Search to Pass Messages for Temporal Knowledge Graph Completion,5,0.0975386,0.60653,"Completing missing facts is a fundamental task for temporal knowledge graphs
(TKGs). Recently, graph neural network (GNN) based methods, which can
simultaneously explore topological and temporal information, have become the
state-of-the-art (SOTA) to complete TKGs. However, these studies are based on
hand-designed architectures and fail to explore the diverse topological and
temporal properties of TKG. To address this issue, we propose to use neural
architecture search (NAS) to design data-specific message passing architecture
for TKG completion. In particular, we develop a generalized framework to
explore topological and temporal information in TKGs. Based on this framework,
we design an expressive search space to fully capture various properties of
different TKGs. Meanwhile, we adopt a search algorithm, which trains a supernet
structure by sampling single path for efficient search with less cost. We
further conduct extensive experiments on three benchmark datasets. The results
show that the searched architectures by our method achieve the SOTA
performances. Besides, the searched models can also implicitly reveal diverse
properties in different TKGs. Our code is released in
https://github.com/striderdu/SPA.",1,1,0,0,1,0,0.776443,7.0,0.827822,52
http://arxiv.org/abs/2203.04831v1,Automatic Language Identification for Celtic Texts,2,0.0221681,0.0827117,"Language identification is an important Natural Language Processing task. It
has been thoroughly researched in the literature. However, some issues are
still open. This work addresses the identification of the related low-resource
languages on the example of the Celtic language family.
  This work's main goals were: (1) to collect the dataset of three Celtic
languages; (2) to prepare a method to identify the languages from the Celtic
family, i.e. to train a successful classification model; (3) to evaluate the
influence of different feature extraction methods, and explore the
applicability of the unsupervised models as a feature extraction technique; (4)
to experiment with the unsupervised feature extraction on a reduced annotated
set.
  We collected a new dataset including Irish, Scottish, Welsh and English
records. We tested supervised models such as SVM and neural networks with
traditional statistical features alongside the output of clustering,
autoencoder, and topic modelling methods. The analysis showed that the
unsupervised features could serve as a valuable extension to the n-gram feature
vectors. It led to an improvement in performance for more entangled classes.
The best model achieved a 98\% F1 score and 97\% MCC. The dense neural network
consistently outperformed the SVM model.
  The low-resource languages are also challenging due to the scarcity of
available annotated training data. This work evaluated the performance of the
classifiers using the unsupervised feature extraction on the reduced labelled
dataset to handle this issue. The results uncovered that the unsupervised
feature vectors are more robust to the labelled set reduction. Therefore, they
proved to help achieve comparable classification performance with much less
labelled data.",0,1,0,1,0,0,0.00505189,11.0,0.373191,27
http://arxiv.org/abs/2203.13838v1,Analyzing Generalization of Vision and Language Navigation to Unseen Outdoor Areas,17,0.524187,0.458816,"Vision and language navigation (VLN) is a challenging visually-grounded
language understanding task. Given a natural language navigation instruction, a
visual agent interacts with a graph-based environment equipped with panorama
images and tries to follow the described route. Most prior work has been
conducted in indoor scenarios where best results were obtained for navigation
on routes that are similar to the training routes, with sharp drops in
performance when testing on unseen environments. We focus on VLN in outdoor
scenarios and find that in contrast to indoor VLN, most of the gain in outdoor
VLN on unseen data is due to features like junction type embedding or heading
delta that are specific to the respective environment graph, while image
information plays a very minor role in generalizing VLN to unseen outdoor
areas. These findings show a bias to specifics of graph representations of
urban environments, demanding that VLN tasks grow in scale and diversity of
geographical environments.",1,1,0,1,0,0,0.919283,7.0,0.901936,34
http://arxiv.org/abs/2207.13572v2,Membership Inference Attacks via Adversarial Examples,3,0.0240477,0.132383,"The raise of machine learning and deep learning led to significant
improvement in several domains. This change is supported by both the dramatic
rise in computation power and the collection of large datasets. Such massive
datasets often include personal data which can represent a threat to privacy.
Membership inference attacks are a novel direction of research which aims at
recovering training data used by a learning algorithm. In this paper, we
develop a mean to measure the leakage of training data leveraging a quantity
appearing as a proxy of the total variation of a trained model near its
training samples. We extend our work by providing a novel defense mechanism.
Our contributions are supported by empirical evidence through convincing
numerical experiments.",0,0,0,0,0,0,0.722356,8.0,0.829816,83
http://arxiv.org/abs/2205.14217v1,Diffusion-LM Improves Controllable Text Generation,447,0.997075,0.999017,"Controlling the behavior of language models (LMs) without re-training is a
major open problem in natural language generation. While recent works have
demonstrated successes on controlling simple sentence attributes (e.g.,
sentiment), there has been little progress on complex, fine-grained controls
(e.g., syntactic structure). To address this challenge, we develop a new
non-autoregressive language model based on continuous diffusions that we call
Diffusion-LM. Building upon the recent successes of diffusion models in
continuous domains, Diffusion-LM iteratively denoises a sequence of Gaussian
vectors into word vectors, yielding a sequence of intermediate latent
variables. The continuous, hierarchical nature of these intermediate variables
enables a simple gradient-based algorithm to perform complex, controllable
generation tasks. We demonstrate successful control of Diffusion-LM for six
challenging fine-grained control tasks, significantly outperforming prior work.",1,0,0,0,0,0,0.961826,5.0,0.914802,59
http://arxiv.org/abs/2211.09446v1,Detecting Arbitrary Keypoints on Limbs and Skis with Sparse Partly Correct Segmentation Masks,5,0.04758,0.559356,"Analyses based on the body posture are crucial for top-class athletes in many
sports disciplines. If at all, coaches label only the most important keypoints,
since manual annotations are very costly. This paper proposes a method to
detect arbitrary keypoints on the limbs and skis of professional ski jumpers
that requires a few, only partly correct segmentation masks during training.
Our model is based on the Vision Transformer architecture with a special design
for the input tokens to query for the desired keypoints. Since we use
segmentation masks only to generate ground truth labels for the freely
selectable keypoints, partly correct segmentation masks are sufficient for our
training procedure. Hence, there is no need for costly hand-annotated
segmentation masks. We analyze different training techniques for freely
selected and standard keypoints, including pseudo labels, and show in our
experiments that only a few partly correct segmentation masks are sufficient
for learning to detect arbitrary keypoints on limbs and skis.",1,1,0,1,0,0,0.23829,7.0,0.584186,25
http://arxiv.org/abs/2210.12818v1,Pushing the Efficiency Limit Using Structured Sparse Convolutions,2,0.03316,0.125902,"Weight pruning is among the most popular approaches for compressing deep
convolutional neural networks. Recent work suggests that in a randomly
initialized deep neural network, there exist sparse subnetworks that achieve
performance comparable to the original network. Unfortunately, finding these
subnetworks involves iterative stages of training and pruning, which can be
computationally expensive. We propose Structured Sparse Convolution (SSC),
which leverages the inherent structure in images to reduce the parameters in
the convolutional filter. This leads to improved efficiency of convolutional
architectures compared to existing methods that perform pruning at
initialization. We show that SSC is a generalization of commonly used layers
(depthwise, groupwise and pointwise convolution) in ``efficient
architectures.'' Extensive experiments on well-known CNN models and datasets
show the effectiveness of the proposed method. Architectures based on SSC
achieve state-of-the-art performance compared to baselines on CIFAR-10,
CIFAR-100, Tiny-ImageNet, and ImageNet classification benchmarks.",1,1,0,0,1,0,0.900533,9.0,0.914101,64
http://arxiv.org/abs/2210.16239v1,Hyperspectral images classification and Dimensionality Reduction using Homogeneity feature and mutual information,4,0.025838,0.022293,"The Hyperspectral image (HSI) contains several hundred bands of the same
region called the Ground Truth (GT). The bands are taken in juxtaposed
frequencies, but some of them are noisily measured or contain no information.
For the classification, the selection of bands, affects significantly the
results of classification, in fact, using a subset of relevant bands, these
results can be better than those obtained using all bands, from which the need
to reduce the dimensionality of the HSI. In this paper, a categorization of
dimensionality reduction methods, according to the generation process, is
presented. Furthermore, we reproduce an algorithm based on mutual information
(MI) to reduce dimensionality by features selection and we introduce an
algorithm using mutual information and homogeneity. The two schemas are a
filter strategy. Finally, to validate this, we consider the case study AVIRIS
HSI 92AV3C.
  Keywords: Hyperspectrale images; classification; features selection; mutual
information; homogeneity",0,1,0,0,0,0,0.0379314,15.0,0.675857,10
http://arxiv.org/abs/2202.12350v2,DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation,32,0.100294,0.771033,"Natural language processing (NLP) algorithms have become very successful, but
they still struggle when applied to out-of-distribution examples. In this paper
we propose a controllable generation approach in order to deal with this domain
adaptation (DA) challenge. Given an input text example, our DoCoGen algorithm
generates a domain-counterfactual textual example (D-con) - that is similar to
the original in all aspects, including the task label, but its domain is
changed to a desired one. Importantly, DoCoGen is trained using only unlabeled
examples from multiple domains - no NLP task labels or parallel pairs of
textual examples and their domain-counterfactuals are required. We show that
DoCoGen can generate coherent counterfactuals consisting of multiple sentences.
We use the D-cons generated by DoCoGen to augment a sentiment classifier and a
multi-label intent classifier in 20 and 78 DA setups, respectively, where
source-domain labeled data is scarce. Our model outperforms strong baselines
and improves the accuracy of a state-of-the-art unsupervised DA algorithm.",1,1,0,1,1,0,0.338217,5.0,0.501162,67
http://arxiv.org/abs/2208.00639v1,Dress Well via Fashion Cognitive Learning,2,0.0191053,0.11968,"Fashion compatibility models enable online retailers to easily obtain a large
number of outfit compositions with good quality. However, effective fashion
recommendation demands precise service for each customer with a deeper
cognition of fashion. In this paper, we conduct the first study on fashion
cognitive learning, which is fashion recommendations conditioned on personal
physical information. To this end, we propose a Fashion Cognitive Network (FCN)
to learn the relationships among visual-semantic embedding of outfit
composition and appearance features of individuals. FCN contains two
submodules, namely outfit encoder and Multi-label Graph Neural Network
(ML-GCN). The outfit encoder uses a convolutional layer to encode an outfit
into an outfit embedding. The latter module learns label classifiers via
stacked GCN. We conducted extensive experiments on the newly collected O4U
dataset, and the results provide strong qualitative and quantitative evidence
that our framework outperforms alternative methods.",0,1,1,1,1,0,0.14121,8.0,0.563526,31
http://arxiv.org/abs/2203.14517v1,REGTR: End-to-end Point Cloud Correspondences with Transformers,91,0.829798,0.987995,"Despite recent success in incorporating learning into point cloud
registration, many works focus on learning feature descriptors and continue to
rely on nearest-neighbor feature matching and outlier filtering through RANSAC
to obtain the final set of correspondences for pose estimation. In this work,
we conjecture that attention mechanisms can replace the role of explicit
feature matching and RANSAC, and thus propose an end-to-end framework to
directly predict the final set of correspondences. We use a network
architecture consisting primarily of transformer layers containing self and
cross attentions, and train it to predict the probability each point lies in
the overlapping region and its corresponding position in the other point cloud.
The required rigid transformation can then be estimated directly from the
predicted correspondences without further post-processing. Despite its
simplicity, our approach achieves state-of-the-art performance on 3DMatch and
ModelNet benchmarks. Our source code can be found at
https://github.com/yewzijian/RegTR .",1,1,0,0,1,0,0.970297,7.0,0.949719,64
http://arxiv.org/abs/2201.06539v1,Spatiotemporal Costmap Inference for MPC via Deep Inverse Reinforcement Learning,18,0.401627,0.777634,"It can be difficult to autonomously produce driver behavior so that it
appears natural to other traffic participants. Through Inverse Reinforcement
Learning (IRL), we can automate this process by learning the underlying reward
function from human demonstrations. We propose a new IRL algorithm that learns
a goal-conditioned spatiotemporal reward function. The resulting costmap is
used by Model Predictive Controllers (MPCs) to perform a task without any
hand-designing or hand-tuning of the cost function. We evaluate our proposed
Goal-conditioned SpatioTemporal Zeroing Maximum Entropy Deep IRL (GSTZ)-MEDIRL
framework together with MPC in the CARLA simulator for autonomous driving, lane
keeping, and lane changing tasks in a challenging dense traffic highway
scenario. Our proposed methods show higher success rates compared to other
baseline methods including behavior cloning, state-of-the-art RL policies, and
MPC with a learning-based behavior prediction model.",0,1,0,0,0,0,0.805329,9.0,0.875899,38
http://arxiv.org/abs/2210.06150v1,Annotating Norwegian Language Varieties on Twitter for Part-of-Speech,5,0.279777,0.739761,"Norwegian Twitter data poses an interesting challenge for Natural Language
Processing (NLP) tasks. These texts are difficult for models trained on
standardized text in one of the two Norwegian written forms (Bokm{\aa}l and
Nynorsk), as they contain both the typical variation of social media text, as
well as a large amount of dialectal variety. In this paper we present a novel
Norwegian Twitter dataset annotated with POS-tags. We show that models trained
on Universal Dependency (UD) data perform worse when evaluated against this
dataset, and that models trained on Bokm{\aa}l generally perform better than
those trained on Nynorsk. We also see that performance on dialectal tweets is
comparable to the written standards for some models. Finally we perform a
detailed analysis of the errors that models commonly make on this data.",0,1,0,1,0,0,0.0636562,15.0,0.711267,28
http://arxiv.org/abs/2210.11610v2,Large Language Models Can Self-Improve,270,0.810093,1.0,"Large Language Models (LLMs) have achieved excellent performances in various
tasks. However, fine-tuning an LLM requires extensive supervision. Human, on
the other hand, may improve their reasoning abilities by self-thinking without
external inputs. In this work, we demonstrate that an LLM is also capable of
self-improving with only unlabeled datasets. We use a pre-trained LLM to
generate ""high-confidence"" rationale-augmented answers for unlabeled questions
using Chain-of-Thought prompting and self-consistency, and fine-tune the LLM
using those self-generated solutions as target outputs. We show that our
approach improves the general reasoning ability of a 540B-parameter LLM
(74.4%->82.1% on GSM8K, 78.2%->83.0% on DROP, 90.0%->94.4% on OpenBookQA, and
63.4%->67.9% on ANLI-A3) and achieves state-of-the-art-level performance,
without any ground truth label. We conduct ablation studies and show that
fine-tuning on reasoning is critical for self-improvement.",0,0,0,0,1,0,0.893382,4.0,0.799093,54
http://arxiv.org/abs/2204.00790v2,SAD: A Large-scale Dataset towards Airport Detection in Synthetic Aperture Radar Images,1,0.0400747,0.0147331,"Airports have an important role in both military and civilian domains. The
synthetic aperture radar (SAR) based airport detection has received increasing
attention in recent years. However, due to the high cost of SAR imaging and
annotation process, there is no publicly available SAR dataset for airport
detection. As a result, deep learning methods have not been fully used in
airport detection tasks. To provide a benchmark for airport detection research
in SAR images, this paper introduces a large-scale SAR Airport Dataset (SAD).
In order to adequately reflect the demands of real world applications, it
contains 624 SAR images from Sentinel 1B and covers 104 airfield instances with
different scales, orientations and shapes. The experiments of multiple deep
learning approach on this dataset proves its effectiveness. It developing
state-of-the-art airport area detection algorithms or other relevant tasks.",1,1,1,1,0,0,0.394619,11.0,0.791018,41
http://arxiv.org/abs/2203.00412v1,Interpretable Molecular Graph Generation via Monotonic Constraints,17,0.269005,0.626729,"Designing molecules with specific properties is a long-lasting research
problem and is central to advancing crucial domains such as drug discovery and
material science. Recent advances in deep graph generative models treat
molecule design as graph generation problems which provide new opportunities
toward the breakthrough of this long-lasting problem. Existing models, however,
have many shortcomings, including poor interpretability and controllability
toward desired molecular properties. This paper focuses on new methodologies
for molecule generation with interpretable and controllable deep generative
models, by proposing new monotonically-regularized graph variational
autoencoders. The proposed models learn to represent the molecules with latent
variables and then learn the correspondence between them and molecule
properties parameterized by polynomial functions. To further improve the
intepretability and controllability of molecule generation towards desired
properties, we derive new objectives which further enforce monotonicity of the
relation between some latent variables and target molecule properties such as
toxicity and clogP. Extensive experimental evaluation demonstrates the
superiority of the proposed framework on accuracy, novelty, disentanglement,
and control towards desired molecular properties. The code is open-source at
https://anonymous.4open.science/r/MDVAE-FD2C.",0,0,0,0,0,0,0.610128,9.0,0.814527,52
http://arxiv.org/abs/2206.14530v1,Deep Active Visual Attention for Real-time Robot Motion Generation: Emergence of Tool-body Assimilation and Adaptive Tool-use,4,0.080323,0.170053,"Sufficiently perceiving the environment is a critical factor in robot motion
generation. Although the introduction of deep visual processing models have
contributed in extending this ability, existing methods lack in the ability to
actively modify what to perceive; humans perform internally during visual
cognitive processes. This paper addresses the issue by proposing a novel robot
motion generation model, inspired by a human cognitive structure. The model
incorporates a state-driven active top-down visual attention module, which
acquires attentions that can actively change targets based on task states. We
term such attentions as role-based attentions, since the acquired attention
directed to targets that shared a coherent role throughout the motion. The
model was trained on a robot tool-use task, in which the role-based attentions
perceived the robot grippers and tool as identical end-effectors, during object
picking and object dragging motions respectively. This is analogous to a
biological phenomenon called tool-body assimilation, in which one regards a
handled tool as an extension of one's body. The results suggested an
improvement of flexibility in model's visual perception, which sustained stable
attention and motion even if it was provided with untrained tools or exposed to
experimenter's distractions.",0,0,0,0,0,0,0.133998,14.0,0.74655,33
http://arxiv.org/abs/2203.12907v1,Mono vs Multilingual BERT: A Case Study in Hindi and Marathi Named Entity Recognition,7,0.0485881,0.608526,"Named entity recognition (NER) is the process of recognising and classifying
important information (entities) in text. Proper nouns, such as a person's
name, an organization's name, or a location's name, are examples of entities.
The NER is one of the important modules in applications like human resources,
customer support, search engines, content classification, and academia. In this
work, we consider NER for low-resource Indian languages like Hindi and Marathi.
The transformer-based models have been widely used for NER tasks. We consider
different variations of BERT like base-BERT, RoBERTa, and AlBERT and benchmark
them on publicly available Hindi and Marathi NER datasets. We provide an
exhaustive comparison of different monolingual and multilingual
transformer-based models and establish simple baselines currently missing in
the literature. We show that the monolingual MahaRoBERTa model performs the
best for Marathi NER whereas the multilingual XLM-RoBERTa performs the best for
Hindi NER. We also perform cross-language evaluation and present mixed
observations.",0,1,0,0,0,0,0.0103914,12.0,0.48575,36
http://arxiv.org/abs/2203.10627v2,Enriching Unsupervised User Embedding via Medical Concepts,1,0.0180868,0.056089,"Clinical notes in Electronic Health Records (EHR) present rich documented
information of patients to inference phenotype for disease diagnosis and study
patient characteristics for cohort selection. Unsupervised user embedding aims
to encode patients into fixed-length vectors without human supervisions.
Medical concepts extracted from the clinical notes contain rich connections
between patients and their clinical categories. However, existing unsupervised
approaches of user embeddings from clinical notes do not explicitly incorporate
medical concepts. In this study, we propose a concept-aware unsupervised user
embedding that jointly leverages text documents and medical concepts from two
clinical corpora, MIMIC-III and Diabetes. We evaluate user embeddings on both
extrinsic and intrinsic tasks, including phenotype classification, in-hospital
mortality prediction, patient retrieval, and patient relatedness. Experiments
on the two clinical corpora show our approach exceeds unsupervised baselines,
and incorporating medical concepts can significantly improve the baseline
performance.",0,1,0,0,0,0,0.3948,8.0,0.712725,61
http://arxiv.org/abs/2206.06522v2,LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning,120,0.889395,0.987927,"Fine-tuning large pre-trained models on downstream tasks has been adopted in
a variety of domains recently. However, it is costly to update the entire
parameter set of large pre-trained models. Although recently proposed
parameter-efficient transfer learning (PETL) techniques allow updating a small
subset of parameters (e.g. only using 2% of parameters) inside a pre-trained
backbone network for a new task, they only reduce the training memory
requirement by up to 30%. This is because the gradient computation for the
trainable parameters still requires backpropagation through the large
pre-trained backbone model. To address this, we propose Ladder Side-Tuning
(LST), a new PETL technique that can reduce training memory requirements by
more substantial amounts. Unlike existing parameter-efficient methods that
insert additional parameters inside backbone networks, we train a ladder side
network, a small and separate network that takes intermediate activations as
input via shortcut connections (called ladders) from backbone networks and
makes predictions. LST has significantly lower memory requirements than
previous methods, because it does not require backpropagation through the
backbone network, but instead only through the side network and ladder
connections. We evaluate our method with various models (T5 and CLIP-T5) on
both NLP (GLUE) and vision-and-language (VQA, GQA, NLVR2 , MSCOCO) tasks. LST
saves 69% of the memory costs to fine-tune the whole network, while other
methods only save 26% of that in similar parameter usages (hence, 2.7x more
memory savings). Moreover, LST achieves higher accuracy than Adapter and LoRA
in a low-memory regime. To further show the advantage of this better memory
efficiency, we also apply LST to larger T5 models, attaining better GLUE
performance than full fine-tuning and other PETL methods. The
accuracy-efficiency trade-off also holds on VL tasks.",0,1,0,0,0,0,0.959131,6.0,0.925483,68
http://arxiv.org/abs/2203.00108v1,MRI-GAN: A Generalized Approach to Detect DeepFakes using Perceptual Image Assessment,4,0.174212,0.0577344,"DeepFakes are synthetic videos generated by swapping a face of an original
image with the face of somebody else. In this paper, we describe our work to
develop general, deep learning-based models to classify DeepFake content. We
propose a novel framework for using Generative Adversarial Network (GAN)-based
models, we call MRI-GAN, that utilizes perceptual differences in images to
detect synthesized videos. We test our MRI-GAN approach and a
plain-frames-based model using the DeepFake Detection Challenge Dataset. Our
plain frames-based-model achieves 91% test accuracy and a model which uses our
MRI-GAN framework with Structural Similarity Index Measurement (SSIM) for the
perceptual differences achieves 74% test accuracy. The results of MRI-GAN are
preliminary and may be improved further by modifying the choice of loss
function, tuning hyper-parameters, or by using a more advanced perceptual
similarity metric.",1,1,0,0,0,0,0.99325,6.0,0.999942,26
http://arxiv.org/abs/2212.04800v3,AUC Maximization for Low-Resource Named Entity Recognition,6,0.0380321,0.34534,"Current work in named entity recognition (NER) uses either cross entropy (CE)
or conditional random fields (CRF) as the objective/loss functions to optimize
the underlying NER model. Both of these traditional objective functions for the
NER problem generally produce adequate performance when the data distribution
is balanced and there are sufficient annotated training examples. But since NER
is inherently an imbalanced tagging problem, the model performance under the
low-resource settings could suffer using these standard objective functions.
Based on recent advances in area under the ROC curve (AUC) maximization, we
propose to optimize the NER model by maximizing the AUC score. We give evidence
that by simply combining two binary-classifiers that maximize the AUC score,
significant performance improvement over traditional loss functions is achieved
under low-resource NER settings. We also conduct extensive experiments to
demonstrate the advantages of our method under the low-resource and
highly-imbalanced data distribution settings. To the best of our knowledge,
this is the first work that brings AUC maximization to the NER setting.
Furthermore, we show that our method is agnostic to different types of NER
embeddings, models and domains. The code to replicate this work will be
provided upon request.",1,1,0,0,0,0,0.149721,10.0,0.657158,48
http://arxiv.org/abs/2211.06409v2,Capabilities for Better ML Engineering,2,0.0074522,0.254747,"In spite of machine learning's rapid growth, its engineering support is
scattered in many forms, and tends to favor certain engineering stages,
stakeholders, and evaluation preferences. We envision a capability-based
framework, which uses fine-grained specifications for ML model behaviors to
unite existing efforts towards better ML engineering. We use concrete scenarios
(model design, debugging, and maintenance) to articulate capabilities' broad
applications across various different dimensions, and their impact on building
safer, more generalizable and more trustworthy models that reflect human needs.
Through preliminary experiments, we show capabilities' potential for reflecting
model generalizability, which can provide guidance for ML engineering process.
We discuss challenges and opportunities for capabilities' integration into ML
engineering.",1,0,0,0,0,1,0.475224,7.0,0.707389,32
http://arxiv.org/abs/2206.07751v5,On the Identifiability of Nonlinear ICA: Sparsity and Beyond,29,0.66152,0.994915,"Nonlinear independent component analysis (ICA) aims to recover the underlying
independent latent sources from their observable nonlinear mixtures. How to
make the nonlinear ICA model identifiable up to certain trivial indeterminacies
is a long-standing problem in unsupervised learning. Recent breakthroughs
reformulate the standard independence assumption of sources as conditional
independence given some auxiliary variables (e.g., class labels and/or
domain/time indexes) as weak supervision or inductive bias. However, nonlinear
ICA with unconditional priors cannot benefit from such developments. We explore
an alternative path and consider only assumptions on the mixing process, such
as Structural Sparsity. We show that under specific instantiations of such
constraints, the independent latent sources can be identified from their
nonlinear mixtures up to a permutation and a component-wise transformation,
thus achieving nontrivial identifiability of nonlinear ICA without auxiliary
variables. We provide estimation methods and validate the theoretical results
experimentally. The results on image data suggest that our conditions may hold
in a number of practical data generating processes.",1,0,0,0,0,0,0.553841,11.0,0.834203,46
http://arxiv.org/abs/2212.12050v2,A Semantic Framework for Neural-Symbolic Computing,1,0.00771804,0.112222,"Two approaches to AI, neural networks and symbolic systems, have been proven
very successful for an array of AI problems. However, neither has been able to
achieve the general reasoning ability required for human-like intelligence. It
has been argued that this is due to inherent weaknesses in each approach.
Luckily, these weaknesses appear to be complementary, with symbolic systems
being adept at the kinds of things neural networks have trouble with and
vice-versa. The field of neural-symbolic AI attempts to exploit this asymmetry
by combining neural networks and symbolic AI into integrated systems. Often
this has been done by encoding symbolic knowledge into neural networks.
Unfortunately, although many different methods for this have been proposed,
there is no common definition of an encoding to compare them. We seek to
rectify this problem by introducing a semantic framework for neural-symbolic
AI, which is then shown to be general enough to account for a large family of
neural-symbolic systems. We provide a number of examples and proofs of the
application of the framework to the neural encoding of various forms of
knowledge representation and neural network. These, at first sight disparate
approaches, are all shown to fall within the framework's formal definition of
what we call semantic encoding for neural-symbolic AI.",0,0,0,0,0,0,0.0172119,17.0,0.666887,57
http://arxiv.org/abs/2211.12551v1,Sparse Probabilistic Circuits via Pruning and Growing,9,0.160329,0.836845,"Probabilistic circuits (PCs) are a tractable representation of probability
distributions allowing for exact and efficient computation of likelihoods and
marginals. There has been significant recent progress on improving the scale
and expressiveness of PCs. However, PC training performance plateaus as model
size increases. We discover that most capacity in existing large PC structures
is wasted: fully-connected parameter layers are only sparsely used. We propose
two operations: pruning and growing, that exploit the sparsity of PC
structures. Specifically, the pruning operation removes unimportant
sub-networks of the PC for model compression and comes with theoretical
guarantees. The growing operation increases model capacity by increasing the
size of the latent space. By alternatingly applying pruning and growing, we
increase the capacity that is meaningfully used, allowing us to significantly
scale up PC learning. Empirically, our learner achieves state-of-the-art
likelihoods on MNIST-family image datasets and on Penn Tree Bank language data
compared to other PC learners and less tractable deep generative models such as
flow-based models and variational autoencoders (VAEs).",1,1,0,0,1,0,0.293066,8.0,0.666451,67
http://arxiv.org/abs/2201.01503v2,Towards Uniform Point Distribution in Feature-preserving Point Cloud Filtering,10,0.23853,0.315988,"As a popular representation of 3D data, point cloud may contain noise and
need to be filtered before use. Existing point cloud filtering methods either
cannot preserve sharp features or result in uneven point distribution in the
filtered output. To address this problem, this paper introduces a point cloud
filtering method that considers both point distribution and feature
preservation during filtering. The key idea is to incorporate a repulsion term
with a data term in energy minimization. The repulsion term is responsible for
the point distribution, while the data term is to approximate the noisy
surfaces while preserving the geometric features. This method is capable of
handling models with fine-scale features and sharp features. Extensive
experiments show that our method yields better results with a more uniform
point distribution ($5.8\times10^{-5}$ Chamfer Distance on average) in seconds.",0,1,0,0,1,0,0.646037,8.0,0.80355,38
http://arxiv.org/abs/2203.06419v1,"When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues",16,0.145387,0.602522,"Indirect speech such as sarcasm achieves a constellation of discourse goals
in human communication. While the indirectness of figurative language warrants
speakers to achieve certain pragmatic goals, it is challenging for AI agents to
comprehend such idiosyncrasies of human communication. Though sarcasm
identification has been a well-explored topic in dialogue analysis, for
conversational systems to truly grasp a conversation's innate meaning and
generate appropriate responses, simply detecting sarcasm is not enough; it is
vital to explain its underlying sarcastic connotation to capture its true
essence. In this work, we study the discourse structure of sarcastic
conversations and propose a novel task - Sarcasm Explanation in Dialogue (SED).
Set in a multimodal and code-mixed setting, the task aims to generate natural
language explanations of satirical conversations. To this end, we curate WITS,
a new dataset to support our task. We propose MAF (Modality Aware Fusion), a
multimodal context-aware attention and global information fusion module to
capture multimodality and use it to benchmark WITS. The proposed attention
module surpasses the traditional multimodal fusion baselines and reports the
best performance on almost all metrics. Lastly, we carry out detailed analyses
both quantitatively and qualitatively.",0,0,1,1,0,0,0.0915996,10.0,0.604788,50
http://arxiv.org/abs/2209.07143v1,HARP: Autoregressive Latent Video Prediction with High-Fidelity Image Generator,18,0.105158,0.819026,"Video prediction is an important yet challenging problem; burdened with the
tasks of generating future frames and learning environment dynamics. Recently,
autoregressive latent video models have proved to be a powerful video
prediction tool, by separating the video prediction into two sub-problems:
pre-training an image generator model, followed by learning an autoregressive
prediction model in the latent space of the image generator. However,
successfully generating high-fidelity and high-resolution videos has yet to be
seen. In this work, we investigate how to train an autoregressive latent video
prediction model capable of predicting high-fidelity future frames with minimal
modification to existing models, and produce high-resolution (256x256) videos.
Specifically, we scale up prior models by employing a high-fidelity image
generator (VQ-GAN) with a causal transformer model, and introduce additional
techniques of top-k sampling and data augmentation to further improve video
prediction quality. Despite the simplicity, the proposed method achieves
competitive performance to state-of-the-art approaches on standard video
prediction benchmarks with fewer parameters, and enables high-resolution video
prediction on complex and large-scale datasets. Videos are available at
https://sites.google.com/view/harp-videos/home.",0,1,0,0,1,0,0.603711,7.0,0.759037,57
http://arxiv.org/abs/2208.09916v1,A Web Application for Experimenting and Validating Remote Measurement of Vital Signs,3,0.0960185,0.490844,"With a surge in online medical advising remote monitoring of patient vitals
is required. This can be facilitated with the Remote Photoplethysmography
(rPPG) techniques that compute vital signs from facial videos. It involves
processing video frames to obtain skin pixels, extracting the cardiac data from
it and applying signal processing filters to extract the Blood Volume Pulse
(BVP) signal. Different algorithms are applied to the BVP signal to estimate
the various vital signs. We implemented a web application framework to measure
a person's Heart Rate (HR), Heart Rate Variability (HRV), Oxygen Saturation
(SpO2), Respiration Rate (RR), Blood Pressure (BP), and stress from the face
video. The rPPG technique is highly sensitive to illumination and motion
variation. The web application guides the users to reduce the noise due to
these variations and thereby yield a cleaner BVP signal. The accuracy and
robustness of the framework was validated with the help of volunteers.",0,1,0,0,0,0,0.400901,10.0,0.772177,30
http://arxiv.org/abs/2212.00280v1,GRiT: A Generative Region-to-text Transformer for Object Understanding,65,0.171819,0.997571,"This paper presents a Generative RegIon-to-Text transformer, GRiT, for object
understanding. The spirit of GRiT is to formulate object understanding as
<region, text> pairs, where region locates objects and text describes objects.
For example, the text in object detection denotes class names while that in
dense captioning refers to descriptive sentences. Specifically, GRiT consists
of a visual encoder to extract image features, a foreground object extractor to
localize objects, and a text decoder to generate open-set object descriptions.
With the same model architecture, GRiT can understand objects via not only
simple nouns, but also rich descriptive sentences including object attributes
or actions. Experimentally, we apply GRiT to object detection and dense
captioning tasks. GRiT achieves 60.4 AP on COCO 2017 test-dev for object
detection and 15.5 mAP on Visual Genome for dense captioning. Code is available
at https://github.com/JialianW/GRiT",1,1,0,0,1,1,0.790552,5.0,0.76747,47
http://arxiv.org/abs/2212.07593v3,Enhanced Training of Query-Based Object Detection via Selective Query Recollection,15,0.321782,0.555931,"This paper investigates a phenomenon where query-based object detectors
mispredict at the last decoding stage while predicting correctly at an
intermediate stage. We review the training process and attribute the overlooked
phenomenon to two limitations: lack of training emphasis and cascading errors
from decoding sequence. We design and present Selective Query Recollection
(SQR), a simple and effective training strategy for query-based object
detectors. It cumulatively collects intermediate queries as decoding stages go
deeper and selectively forwards the queries to the downstream stages aside from
the sequential structure. Such-wise, SQR places training emphasis on later
stages and allows later stages to work with intermediate queries from earlier
stages directly. SQR can be easily plugged into various query-based object
detectors and significantly enhances their performance while leaving the
inference pipeline unchanged. As a result, we apply SQR on Adamixer, DAB-DETR,
and Deformable-DETR across various settings (backbone, number of queries,
schedule) and consistently brings 1.4-2.8 AP improvement.",1,1,0,0,0,0,0.949217,7.0,0.926079,39
http://arxiv.org/abs/2207.14255v1,Efficient Training of Language Models to Fill in the Middle,97,0.136619,0.719577,"We show that autoregressive language models can learn to infill text after we
apply a straightforward transformation to the dataset, which simply moves a
span of text from the middle of a document to its end. While this data
augmentation has garnered much interest in recent years, we provide extensive
evidence that training models with a large fraction of data transformed in this
way does not harm the original left-to-right generative capability, as measured
by perplexity and sampling evaluations across a wide range of scales. Given the
usefulness, simplicity, and efficiency of training models to fill-in-the-middle
(FIM), we suggest that future autoregressive language models be trained with
FIM by default. To this end, we run a series of ablations on key
hyperparameters, such as the data transformation frequency, the structure of
the transformation, and the method of selecting the infill span. We use these
ablations to prescribe strong default settings and best practices to train FIM
models. We have released our best infilling model trained with best practices
in our API, and release our infilling benchmarks to aid future research.",0,1,0,0,0,0,0.345775,6.0,0.588876,56
http://arxiv.org/abs/2206.02171v3,Near-Term Advances in Quantum Natural Language Processing,5,0.0311055,0.148897,"This paper describes experiments showing that some tasks in natural language
processing (NLP) can already be performed using quantum computers, though so
far only with small datasets.
  We demonstrate various approaches to topic classification. The first uses an
explicit word-based approach, in which word-topic scoring weights are
implemented as fractional rotations of individual qubit, and a new phrase is
classified based on the accumulation of these weights in a scoring qubit using
entangling controlled-NOT gates. This is compared with more scalable quantum
encodings of word embedding vectors, which are used in the computation of
kernel values in a quantum support vector machine: this approach achieved an
average of 62% accuracy on classification tasks involving over 10000 words,
which is the largest such quantum computing experiment to date.
  We describe a quantum probability approach to bigram modeling that can be
applied to sequences of words and formal concepts, investigating a generative
approximation to these distributions using a quantum circuit Born machine, and
an approach to ambiguity resolution in verb-noun composition using single-qubit
rotations for simple nouns and 2-qubit controlled-NOT gates for simple verbs.
  The smaller systems described have been run successfully on physical quantum
computers, and the larger ones have been simulated. We show that statistically
meaningful results can be obtained using real datasets, but this is much more
difficult to predict than with easier artificial language examples used
previously in developing quantum NLP systems.
  Other approaches to quantum NLP are compared, partly with respect to
contemporary issues including informal language, fluency, and truthfulness.",0,0,0,0,0,0,0.111504,9.0,0.583934,70
http://arxiv.org/abs/2210.03930v1,Hierarchical Graph Transformer with Adaptive Node Sampling,41,0.395771,0.987943,"The Transformer architecture has achieved remarkable success in a number of
domains including natural language processing and computer vision. However,
when it comes to graph-structured data, transformers have not achieved
competitive performance, especially on large graphs. In this paper, we identify
the main deficiencies of current graph transformers:(1) Existing node sampling
strategies in Graph Transformers are agnostic to the graph characteristics and
the training process. (2) Most sampling strategies only focus on local
neighbors and neglect the long-range dependencies in the graph. We conduct
experimental investigations on synthetic datasets to show that existing
sampling strategies are sub-optimal. To tackle the aforementioned problems, we
formulate the optimization strategies of node sampling in Graph Transformer as
an adversary bandit problem, where the rewards are related to the attention
weights and can vary in the training procedure. Meanwhile, we propose a
hierarchical attention scheme with graph coarsening to capture the long-range
interactions while reducing computational complexity. Finally, we conduct
extensive experiments on real-world datasets to demonstrate the superiority of
our method over existing graph transformers and popular GNNs.",1,0,0,0,1,0,0.760338,6.0,0.791201,61
http://arxiv.org/abs/2210.09723v4,Textual Entailment Recognition with Semantic Features from Empirical Text Representation,1,0.00144058,0.0409291,"Textual entailment recognition is one of the basic natural language
understanding(NLU) tasks. Understanding the meaning of sentences is a
prerequisite before applying any natural language processing(NLP) techniques to
automatically recognize the textual entailment. A text entails a hypothesis if
and only if the true value of the hypothesis follows the text. Classical
approaches generally utilize the feature value of each word from word embedding
to represent the sentences. In this paper, we propose a novel approach to
identifying the textual entailment relationship between text and hypothesis,
thereby introducing a new semantic feature focusing on empirical
threshold-based semantic text representation. We employ an element-wise
Manhattan distance vector-based feature that can identify the semantic
entailment relationship between the text-hypothesis pair. We carried out
several experiments on a benchmark entailment classification(SICK-RTE) dataset.
We train several machine learning(ML) algorithms applying both semantic and
lexical features to classify the text-hypothesis pair as entailment, neutral,
or contradiction. Our empirical sentence representation technique enriches the
semantic information of the texts and hypotheses found to be more efficient
than the classical ones. In the end, our approach significantly outperforms
known methods in understanding the meaning of the sentences for the textual
entailment classification task.",0,1,0,0,1,0,0.00136912,14.0,0.414119,27
http://arxiv.org/abs/2210.12114v1,Modelling Control Arguments via Cooperation Logic in Unforeseen Scenarios,1,0.0132548,0.100082,"The intent of control argumentation frameworks is to specifically model
strategic scenarios from the perspective of an agent by extending the standard
model of argumentation framework in a way that takes unquantified uncertainty
regarding arguments and attacks into account. They do not, however, adequately
account for coalition formation and interactions among a set of agents in an
uncertain environment. To address this challenge, we propose a formalism of a
multi-agent scenario via cooperation logic and investigate agents' strategies
and actions in a dynamic environment.",0,0,0,0,0,0,0.00045126,19.0,0.509859,14
http://arxiv.org/abs/2209.00218v2,Isotropic Representation Can Improve Dense Retrieval,3,0.0873057,0.123073,"The recent advancement in language representation modeling has broadly
affected the design of dense retrieval models. In particular, many of the
high-performing dense retrieval models evaluate representations of query and
document using BERT, and subsequently apply a cosine-similarity based scoring
to determine the relevance. BERT representations, however, are known to follow
an anisotropic distribution of a narrow cone shape and such an anisotropic
distribution can be undesirable for the cosine-similarity based scoring. In
this work, we first show that BERT-based DR also follows an anisotropic
distribution. To cope with the problem, we introduce unsupervised
post-processing methods of Normalizing Flow and whitening, and develop
token-wise method in addition to the sequence-wise method for applying the
post-processing methods to the representations of dense retrieval models. We
show that the proposed methods can effectively enhance the representations to
be isotropic, then we perform experiments with ColBERT and RepBERT to show that
the performance (NDCG at 10) of document re-ranking can be improved by
5.17\%$\sim$8.09\% for ColBERT and 6.88\%$\sim$22.81\% for RepBERT. To examine
the potential of isotropic representation for improving the robustness of DR
models, we investigate out-of-distribution tasks where the test dataset differs
from the training dataset. The results show that isotropic representation can
achieve a generally improved performance. For instance, when training dataset
is MS-MARCO and test dataset is Robust04, isotropy post-processing can improve
the baseline performance by up to 24.98\%. Furthermore, we show that an
isotropic model trained with an out-of-distribution dataset can even outperform
a baseline model trained with the in-distribution dataset.",1,1,0,0,0,0,0.850304,6.0,0.838661,44
http://arxiv.org/abs/2205.07290v2,Meta Self-Refinement for Robust Learning with Weak Supervision,6,0.0346948,0.316988,"Training deep neural networks (DNNs) under weak supervision has attracted
increasing research attention as it can significantly reduce the annotation
cost. However, labels from weak supervision can be noisy, and the high capacity
of DNNs enables them to easily overfit the label noise, resulting in poor
generalization. Recent methods leverage self-training to build noise-resistant
models, in which a teacher trained under weak supervision is used to provide
highly confident labels for teaching the students. Nevertheless, the teacher
derived from such frameworks may have fitted a substantial amount of noise and
therefore produce incorrect pseudo-labels with high confidence, leading to
severe error propagation. In this work, we propose Meta Self-Refinement (MSR),
a noise-resistant learning framework, to effectively combat label noise from
weak supervision. Instead of relying on a fixed teacher trained with noisy
labels, we encourage the teacher to refine its pseudo-labels. At each training
step, MSR performs a meta gradient descent on the current mini-batch to
maximize the student performance on a clean validation set. Extensive
experimentation on eight NLP benchmarks demonstrates that MSR is robust against
label noise in all settings and outperforms state-of-the-art methods by up to
11.4% in accuracy and 9.26% in F1 score.",1,1,0,0,1,0,0.538728,7.0,0.73344,50
http://arxiv.org/abs/2211.13112v1,"This is the way: designing and compiling LEPISZCZE, a comprehensive NLP benchmark for Polish",7,0.0643138,0.328077,"The availability of compute and data to train larger and larger language
models increases the demand for robust methods of benchmarking the true
progress of LM training. Recent years witnessed significant progress in
standardized benchmarking for English. Benchmarks such as GLUE, SuperGLUE, or
KILT have become de facto standard tools to compare large language models.
Following the trend to replicate GLUE for other languages, the KLEJ benchmark
has been released for Polish. In this paper, we evaluate the progress in
benchmarking for low-resourced languages. We note that only a handful of
languages have such comprehensive benchmarks. We also note the gap in the
number of tasks being evaluated by benchmarks for resource-rich English/Chinese
and the rest of the world. In this paper, we introduce LEPISZCZE (the Polish
word for glew, the Middle English predecessor of glue), a new, comprehensive
benchmark for Polish NLP with a large variety of tasks and high-quality
operationalization of the benchmark. We design LEPISZCZE with flexibility in
mind. Including new models, datasets, and tasks is as simple as possible while
still offering data versioning and model tracking. In the first run of the
benchmark, we test 13 experiments (task and dataset pairs) based on the five
most recent LMs for Polish. We use five datasets from the Polish benchmark and
add eight novel datasets. As the paper's main contribution, apart from
LEPISZCZE, we provide insights and experiences learned while creating the
benchmark for Polish as the blueprint to design similar benchmarks for other
low-resourced languages.",1,1,0,1,0,0,0.446646,5.0,0.573181,62
http://arxiv.org/abs/2208.02361v1,A Multibranch Convolutional Neural Network for Hyperspectral Unmixing,10,0.162077,0.632268,"Hyperspectral unmixing remains one of the most challenging tasks in the
analysis of such data. Deep learning has been blooming in the field and proved
to outperform other classic unmixing techniques, and can be effectively
deployed onboard Earth observation satellites equipped with hyperspectral
imagers. In this letter, we follow this research pathway and propose a
multi-branch convolutional neural network that benefits from fusing spectral,
spatial, and spectral-spatial features in the unmixing process. The results of
our experiments, backed up with the ablation study, revealed that our
techniques outperform others from the literature and lead to higher-quality
fractional abundance estimation. Also, we investigated the influence of
reducing the training sets on the capabilities of all algorithms and their
robustness against noise, as capturing large and representative ground-truth
sets is time-consuming and costly in practice, especially in emerging Earth
observation scenarios.",1,0,0,0,0,0,0.189997,7.0,0.547618,22
http://arxiv.org/abs/2212.03038v2,Unifying Short and Long-Term Tracking with Graph Hierarchies,17,0.194636,0.775434,"Tracking objects over long videos effectively means solving a spectrum of
problems, from short-term association for un-occluded objects to long-term
association for objects that are occluded and then reappear in the scene.
Methods tackling these two tasks are often disjoint and crafted for specific
scenarios, and top-performing approaches are often a mix of techniques, which
yields engineering-heavy solutions that lack generality. In this work, we
question the need for hybrid approaches and introduce SUSHI, a unified and
scalable multi-object tracker. Our approach processes long clips by splitting
them into a hierarchy of subclips, which enables high scalability. We leverage
graph neural networks to process all levels of the hierarchy, which makes our
model unified across temporal scales and highly general. As a result, we obtain
significant improvements over state-of-the-art on four diverse datasets. Our
code and models are available at bit.ly/sushi-mot.",0,1,0,0,1,0,0.613387,8.0,0.792452,77
http://arxiv.org/abs/2201.08860v1,GreaseLM: Graph REASoning Enhanced Language Models for Question Answering,127,0.745963,0.99987,"Answering complex questions about textual narratives requires reasoning over
both stated context and the world knowledge that underlies it. However,
pretrained language models (LM), the foundation of most modern QA systems, do
not robustly represent latent relationships between concepts, which is
necessary for reasoning. While knowledge graphs (KG) are often used to augment
LMs with structured representations of world knowledge, it remains an open
question how to effectively fuse and reason over the KG representations and the
language context, which provides situational constraints and nuances. In this
work, we propose GreaseLM, a new model that fuses encoded representations from
pretrained LMs and graph neural networks over multiple layers of modality
interaction operations. Information from both modalities propagates to the
other, allowing language context representations to be grounded by structured
world knowledge, and allowing linguistic nuances (e.g., negation, hedging) in
the context to inform the graph representations of knowledge. Our results on
three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA)
and medical question answering (i.e., MedQA-USMLE) domains demonstrate that
GreaseLM can more reliably answer questions that require reasoning over both
situational constraints and structured knowledge, even outperforming models 8x
larger.",0,0,0,0,1,0,0.899179,5.0,0.844207,49
http://arxiv.org/abs/2210.14353v2,"RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering",13,0.132261,0.698401,"We introduce RoMQA, the first benchmark for robust, multi-evidence,
multi-answer question answering (QA). RoMQA contains clusters of questions that
are derived from related constraints mined from the Wikidata knowledge graph.
RoMQA evaluates robustness of QA models to varying constraints by measuring
worst-case performance within each question cluster. Compared to prior QA
datasets, RoMQA has more human-written questions that require reasoning over
more evidence text and have, on average, many more correct answers. In
addition, human annotators rate RoMQA questions as more natural or likely to be
asked by people. We evaluate state-of-the-art large language models in
zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is
challenging: zero-shot and few-shot models perform similarly to naive
baselines, while supervised retrieval methods perform well below gold evidence
upper bounds. Moreover, existing models are not robust to variations in
question constraints, but can be made more robust by tuning on clusters of
related questions. Our results show that RoMQA is a challenging benchmark for
large language models, and provides a quantifiable test to build more robust QA
methods.",1,1,1,1,0,0,0.907726,9.0,0.917658,24
http://arxiv.org/abs/2210.08709v2,A Unified Positive-Unlabeled Learning Framework for Document-Level Relation Extraction with Different Levels of Labeling,8,0.195912,0.786775,"Document-level relation extraction (RE) aims to identify relations between
entities across multiple sentences. Most previous methods focused on
document-level RE under full supervision. However, in real-world scenario, it
is expensive and difficult to completely label all relations in a document
because the number of entity pairs in document-level RE grows quadratically
with the number of entities. To solve the common incomplete labeling problem,
we propose a unified positive-unlabeled learning framework - shift and squared
ranking loss positive-unlabeled (SSR-PU) learning. We use positive-unlabeled
(PU) learning on document-level RE for the first time. Considering that labeled
data of a dataset may lead to prior shift of unlabeled data, we introduce a PU
learning under prior shift of training data. Also, using none-class score as an
adaptive threshold, we propose squared ranking loss and prove its Bayesian
consistency with multi-label ranking metrics. Extensive experiments demonstrate
that our method achieves an improvement of about 14 F1 points relative to the
previous baseline with incomplete labeling. In addition, it outperforms
previous state-of-the-art results under both fully supervised and extremely
unlabeled settings as well.",0,1,0,0,1,0,0.686879,5.0,0.707997,45
http://arxiv.org/abs/2203.10621v1,Immersive Text Game and Personality Classification,1,0.0336747,0.0120734,"We designed and built a game called \textit{Immersive Text Game}, which
allows the player to choose a story and a character, and interact with other
characters in the story in an immersive manner of dialogues. The game is based
on several latest models, including text generation language model, information
extraction model, commonsense reasoning model, and psychology evaluation model.
In the past, similar text games usually let players choose from limited actions
instead of answering on their own, and not every time what characters said are
determined by the player. Through the combination of these models and elaborate
game mechanics and modes, the player will find some novel experiences as driven
through the storyline.",0,1,0,0,0,0,0.963151,16.0,0.974048,22
http://arxiv.org/abs/2205.02343v1,Convolutional and Residual Networks Provably Contain Lottery Tickets,9,0.203614,0.926726,"The Lottery Ticket Hypothesis continues to have a profound practical impact
on the quest for small scale deep neural networks that solve modern deep
learning tasks at competitive performance. These lottery tickets are identified
by pruning large randomly initialized neural networks with architectures that
are as diverse as their applications. Yet, theoretical insights that attest
their existence have been mostly focused on deep fully-connected feed forward
networks with ReLU activation functions. We prove that also modern
architectures consisting of convolutional and residual layers that can be
equipped with almost arbitrary activation functions can contain lottery tickets
with high probability.",0,0,0,0,0,0,0.852969,5.0,0.808276,47
http://arxiv.org/abs/2207.13649v2,Explain My Surprise: Learning Efficient Long-Term Memory by Predicting Uncertain Outcomes,5,0.0166283,0.214331,"In many sequential tasks, a model needs to remember relevant events from the
distant past to make correct predictions. Unfortunately, a straightforward
application of gradient based training requires intermediate computations to be
stored for every element of a sequence. This requires to store prohibitively
large intermediate data if a sequence consists of thousands or even millions
elements, and as a result, makes learning of very long-term dependencies
infeasible. However, the majority of sequence elements can usually be predicted
by taking into account only temporally local information. On the other hand,
predictions affected by long-term dependencies are sparse and characterized by
high uncertainty given only local information. We propose MemUP, a new training
method that allows to learn long-term dependencies without backpropagating
gradients through the whole sequence at a time. This method can potentially be
applied to any recurrent architecture. LSTM network trained with MemUP performs
better or comparable to baselines while requiring to store less intermediate
data.",1,0,0,0,0,1,0.132736,9.0,0.604614,47
http://arxiv.org/abs/2208.09719v1,Cognitive Modeling of Semantic Fluency Using Transformers,1,0.0155298,0.0275761,"Can deep language models be explanatory models of human cognition? If so,
what are their limits? In order to explore this question, we propose an
approach called hyperparameter hypothesization that uses predictive
hyperparameter tuning in order to find individuating descriptors of
cognitive-behavioral profiles. We take the first step in this approach by
predicting human performance in the semantic fluency task (SFT), a well-studied
task in cognitive science that has never before been modeled using
transformer-based language models (TLMs). In our task setup, we compare several
approaches to predicting which word an individual performing SFT will utter
next. We report preliminary evidence suggesting that, despite obvious
implementational differences in how people and TLMs learn and use language,
TLMs can be used to identify individual differences in human fluency task
behaviors better than existing computational models, and may offer insights
into human memory retrieval strategies -- cognitive process not typically
considered to be the kinds of things TLMs can model. Finally, we discuss the
implications of this work for cognitive modeling of knowledge representations.",0,0,0,0,1,0,0.22532,11.0,0.729569,45
http://arxiv.org/abs/2208.07943v1,TRoVE: Transforming Road Scene Datasets into Photorealistic Virtual Environments,3,0.042824,0.289401,"High-quality structured data with rich annotations are critical components in
intelligent vehicle systems dealing with road scenes. However, data curation
and annotation require intensive investments and yield low-diversity scenarios.
The recently growing interest in synthetic data raises questions about the
scope of improvement in such systems and the amount of manual work still
required to produce high volumes and variations of simulated data. This work
proposes a synthetic data generation pipeline that utilizes existing datasets,
like nuScenes, to address the difficulties and domain-gaps present in simulated
datasets. We show that using annotations and visual cues from existing
datasets, we can facilitate automated multi-modal data generation, mimicking
real scene properties with high-fidelity, along with mechanisms to diversify
samples in a physically meaningful way. We demonstrate improvements in mIoU
metrics by presenting qualitative and quantitative experiments with real and
synthetic data for semantic segmentation on the Cityscapes and KITTI-STEP
datasets. All relevant code and data is released on github
(https://github.com/shubham1810/trove_toolkit).",1,1,0,0,0,0,0.566425,8.0,0.776383,51
http://arxiv.org/abs/2210.09345v1,CrossRE: A Cross-Domain Dataset for Relation Extraction,14,0.141449,0.638642,"Relation Extraction (RE) has attracted increasing attention, but current RE
evaluation is limited to in-domain evaluation setups. Little is known on how
well a RE system fares in challenging, but realistic out-of-distribution
evaluation setups. To address this gap, we propose CrossRE, a new,
freely-available cross-domain benchmark for RE, which comprises six distinct
text domains and includes multi-label annotations. An additional innovation is
that we release meta-data collected during annotation, to include explanations
and flags of difficult instances. We provide an empirical evaluation with a
state-of-the-art model for relation classification. As the meta-data enables us
to shed new light on the state-of-the-art model, we provide a comprehensive
analysis on the impact of difficult cases and find correlations between model
and human annotations. Overall, our empirical investigation highlights the
difficulty of cross-domain RE. We release our dataset, to spur more research in
this direction.",0,1,1,1,0,0,0.362399,9.0,0.732461,34
http://arxiv.org/abs/2201.05887v2,Domain Adaptation via Bidirectional Cross-Attention Transformer,16,0.0500383,0.492483,"Domain Adaptation (DA) aims to leverage the knowledge learned from a source
domain with ample labeled data to a target domain with unlabeled data only.
Most existing studies on DA contribute to learning domain-invariant feature
representations for both domains by minimizing the domain gap based on
convolution-based neural networks. Recently, vision transformers significantly
improved performance in multiple vision tasks. Built on vision transformers, in
this paper we propose a Bidirectional Cross-Attention Transformer (BCAT) for DA
with the aim to improve the performance. In the proposed BCAT, the attention
mechanism can extract implicit source and target mixup feature representations
to narrow the domain discrepancy. Specifically, in BCAT, we design a
weight-sharing quadruple-branch transformer with a bidirectional
cross-attention mechanism to learn domain-invariant feature representations.
Extensive experiments demonstrate that the proposed BCAT model achieves
superior performance on four benchmark datasets over existing state-of-the-art
DA methods that are based on convolutions or transformers.",0,1,0,0,1,0,0.633575,7.0,0.770645,40
http://arxiv.org/abs/2206.02909v2,"Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data",18,0.0702471,0.414772,"Advances in deep learning for human activity recognition have been relatively
limited due to the lack of large labelled datasets. In this study, we leverage
self-supervised learning techniques on the UK-Biobank activity tracker
dataset--the largest of its kind to date--containing more than 700,000
person-days of unlabelled wearable sensor data. Our resulting activity
recognition model consistently outperformed strong baselines across seven
benchmark datasets, with an F1 relative improvement of 2.5%-100% (median
18.4%), the largest improvements occurring in the smaller datasets. In contrast
to previous studies, our results generalise across external datasets, devices,
and environments. Our open-source model will help researchers and developers to
build customisable and generalisable activity classifiers with high
performance.",1,1,0,0,1,1,0.133382,9.0,0.605194,68
http://arxiv.org/abs/2208.04011v1,Information Extraction from Scanned Invoice Images using Text Analysis and Layout Features,9,0.170226,0.414656,"While storing invoice content as metadata to avoid paper document processing
may be the future trend, almost all of daily issued invoices are still printed
on paper or generated in digital formats such as PDFs. In this paper, we
introduce the OCRMiner system for information extraction from scanned document
images which is based on text analysis techniques in combination with layout
features to extract indexing metadata of (semi-)structured documents. The
system is designed to process the document in a similar way a human reader
uses, i.e. to employ different layout and text attributes in a coordinated
decision. The system consists of a set of interconnected modules that start
with (possibly erroneous) character-based output from a standard OCR system and
allow to apply different techniques and to expand the extracted knowledge at
each step. Using an open source OCR, the system is able to recover the invoice
data in 90% for English and in 88% for the Czech set.",0,1,0,0,0,0,0.151064,7.0,0.511611,47
http://arxiv.org/abs/2207.04873v2,Hierarchical Average Precision Training for Pertinent Image Retrieval,4,0.107434,0.12649,"Image Retrieval is commonly evaluated with Average Precision (AP) or
Recall@k. Yet, those metrics, are limited to binary labels and do not take into
account errors' severity. This paper introduces a new hierarchical AP training
method for pertinent image retrieval (HAP-PIER). HAPPIER is based on a new H-AP
metric, which leverages a concept hierarchy to refine AP by integrating errors'
importance and better evaluate rankings. To train deep models with H-AP, we
carefully study the problem's structure and design a smooth lower bound
surrogate combined with a clustering loss that ensures consistent ordering.
Extensive experiments on 6 datasets show that HAPPIER significantly outperforms
state-of-the-art methods for hierarchical retrieval, while being on par with
the latest approaches when evaluating fine-grained ranking performances.
Finally, we show that HAPPIER leads to better organization of the embedding
space, and prevents most severe failure cases of non-hierarchical methods. Our
code is publicly available at: https://github.com/elias-ramzi/HAPPIER.",1,0,1,0,1,0,0.771442,12.0,0.898323,59
http://arxiv.org/abs/2207.06130v2,Fuse It More Deeply! A Variational Transformer with Layer-Wise Latent Variable Inference for Text Generation,17,0.323138,0.205987,"The past several years have witnessed Variational Auto-Encoder's superiority
in various text generation tasks. However, due to the sequential nature of the
text, auto-regressive decoders tend to ignore latent variables and then reduce
to simple language models, known as the KL vanishing problem, which would
further deteriorate when VAE is combined with Transformer-based structures. To
ameliorate this problem, we propose DELLA, a novel variational Transformer
framework. DELLA learns a series of layer-wise latent variables with each
inferred from those of lower layers and tightly coupled with the hidden states
by low-rank tensor product. In this way, DELLA forces these posterior latent
variables to be fused deeply with the whole computation path and hence
incorporate more information. We theoretically demonstrate that our method can
be regarded as entangling latent variables to avoid posterior information
decrease through layers, enabling DELLA to get higher non-zero KL values even
without any annealing or thresholding tricks. Experiments on four unconditional
and three conditional generation tasks show that DELLA could better alleviate
KL vanishing and improve both quality and diversity compared to several strong
baselines.",1,0,0,0,0,0,0.903244,9.0,0.915424,55
http://arxiv.org/abs/2201.08542v1,Can Model Compression Improve NLP Fairness,18,0.0537591,0.656412,"Model compression techniques are receiving increasing attention; however, the
effect of compression on model fairness is still under explored. This is the
first paper to examine the effect of distillation and pruning on the toxicity
and bias of generative language models. We test Knowledge Distillation and
Pruning methods on the GPT2 model and found a consistent pattern of toxicity
and bias reduction after model distillation; this result can be potentially
interpreted by existing line of research which describes model compression as a
regularization technique; our work not only serves as a reference for safe
deployment of compressed models, but also extends the discussion of
""compression as regularization"" into the setting of neural LMs, and hints at
the possibility of using compression to develop fairer models.",0,0,0,0,0,0,0.465282,5.0,0.584436,35
http://arxiv.org/abs/2205.07121v1,Revisiting Facial Key Point Detection: An Efficient Approach Using Deep Neural Networks,4,0.0521806,0.462075,"Facial landmark detection is a widely researched field of deep learning as
this has a wide range of applications in many fields. These key points are
distinguishing characteristic points on the face, such as the eyes center, the
eye's inner and outer corners, the mouth center, and the nose tip from which
human emotions and intent can be explained. The focus of our work has been
evaluating transfer learning models such as MobileNetV2 and NasNetMobile,
including custom CNN architectures. The objective of the research has been to
develop efficient deep learning models in terms of model size, parameters, and
inference time and to study the effect of augmentation imputation and
fine-tuning on these models. It was found that while augmentation techniques
produced lower RMSE scores than imputation techniques, they did not affect the
inference time. MobileNetV2 architecture produced the lowest RMSE and inference
time. Moreover, our results indicate that manually optimized CNN architectures
performed similarly to Auto Keras tuned architecture. However, manually
optimized architectures yielded better inference time and training curves.",0,1,0,0,0,1,0.252387,10.0,0.715568,19
http://arxiv.org/abs/2204.00613v1,On the Importance of Asymmetry for Siamese Representation Learning,37,0.162712,0.642189,"Many recent self-supervised frameworks for visual representation learning are
based on certain forms of Siamese networks. Such networks are conceptually
symmetric with two parallel encoders, but often practically asymmetric as
numerous mechanisms are devised to break the symmetry. In this work, we conduct
a formal study on the importance of asymmetry by explicitly distinguishing the
two encoders within the network -- one produces source encodings and the other
targets. Our key insight is keeping a relatively lower variance in target than
source generally benefits learning. This is empirically justified by our
results from five case studies covering different variance-oriented designs,
and is aligned with our preliminary theoretical analysis on the baseline.
Moreover, we find the improvements from asymmetric designs generalize well to
longer training schedules, multiple other frameworks and newer backbones.
Finally, the combined effect of several asymmetric designs achieves a
state-of-the-art accuracy on ImageNet linear probing and competitive results on
downstream transfer. We hope our exploration will inspire more research in
exploiting asymmetry for Siamese representation learning.",0,0,0,0,1,0,0.897473,5.0,0.84274,47
http://arxiv.org/abs/2211.04996v1,ParGAN: Learning Real Parametrizable Transformations,1,0.00208175,0.0640061,"Current methods for image-to-image translation produce compelling results,
however, the applied transformation is difficult to control, since existing
mechanisms are often limited and non-intuitive. We propose ParGAN, a
generalization of the cycle-consistent GAN framework to learn image
transformations with simple and intuitive controls. The proposed generator
takes as input both an image and a parametrization of the transformation. We
train this network to preserve the content of the input image while ensuring
that the result is consistent with the given parametrization. Our approach does
not require paired data and can learn transformations across several tasks and
datasets. We show how, with disjoint image domains with no annotated
parametrization, our framework can create smooth interpolations as well as
learn multiple transformations simultaneously.",0,1,0,0,0,0,0.19825,11.0,0.716435,33
http://arxiv.org/abs/2203.12940v2,mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot Filling,3,0.0799341,0.160136,"Zero-shot slot filling has received considerable attention to cope with the
problem of limited available data for the target domain. One of the important
factors in zero-shot learning is to make the model learn generalized and
reliable representations. For this purpose, we present mcBERT, which stands for
momentum contrastive learning with BERT, to develop a robust zero-shot slot
filling model. mcBERT uses BERT to initialize the two encoders, the query
encoder and key encoder, and is trained by applying momentum contrastive
learning. Our experimental results on the SNIPS benchmark show that mcBERT
substantially outperforms the previous models, recording a new
state-of-the-art. Besides, we also show that each component composing mcBERT
contributes to the performance improvement.",0,1,0,0,1,0,0.792971,8.0,0.855594,16
http://arxiv.org/abs/2203.10882v2,Efficient Remote Photoplethysmography with Temporal Derivative Modules and Time-Shift Invariant Loss,17,0.14294,0.66878,"We present a lightweight neural model for remote heart rate estimation
focused on the efficient spatio-temporal learning of facial
photoplethysmography (PPG) based on i) modelling of PPG dynamics by
combinations of multiple convolutional derivatives, and ii) increased
flexibility of the model to learn possible offsets between the facial video PPG
and the ground truth. PPG dynamics are modelled by a Temporal Derivative Module
(TDM) constructed by the incremental aggregation of multiple convolutional
derivatives, emulating a Taylor series expansion up to the desired order.
Robustness to ground truth offsets is handled by the introduction of TALOS
(Temporal Adaptive LOcation Shift), a new temporal loss to train learning-based
models. We verify the effectiveness of our model by reporting accuracy and
efficiency metrics on the public PURE and UBFC-rPPG datasets. Compared to
existing models, our approach shows competitive heart rate estimation accuracy
with a much lower number of parameters and lower computational cost.",1,1,0,0,0,0,0.491129,6.0,0.666392,46
http://arxiv.org/abs/2205.12254v1,Interpretation Quality Score for Measuring the Quality of interpretability methods,2,0.0141454,0.210828,"Machine learning (ML) models have been applied to a wide range of natural
language processing (NLP) tasks in recent years. In addition to making accurate
decisions, the necessity of understanding how models make their decisions has
become apparent in many applications. To that end, many interpretability
methods that help explain the decision processes of ML models have been
developed. Yet, there currently exists no widely-accepted metric to evaluate
the quality of explanations generated by these methods. As a result, there
currently is no standard way of measuring to what degree an interpretability
method achieves an intended objective. Moreover, there is no accepted standard
of performance by which we can compare and rank the current existing
interpretability methods. In this paper, we propose a novel metric for
quantifying the quality of explanations generated by interpretability methods.
We compute the metric on three NLP tasks using six interpretability methods and
present our results.",0,0,0,0,0,0,0.460231,8.0,0.738381,36
http://arxiv.org/abs/2203.09510v1,DetMatch: Two Teachers are Better Than One for Joint 2D and 3D Semi-Supervised Object Detection,14,0.175114,0.499327,"While numerous 3D detection works leverage the complementary relationship
between RGB images and point clouds, developments in the broader framework of
semi-supervised object recognition remain uninfluenced by multi-modal fusion.
Current methods develop independent pipelines for 2D and 3D semi-supervised
learning despite the availability of paired image and point cloud frames.
Observing that the distinct characteristics of each sensor cause them to be
biased towards detecting different objects, we propose DetMatch, a flexible
framework for joint semi-supervised learning on 2D and 3D modalities. By
identifying objects detected in both sensors, our pipeline generates a cleaner,
more robust set of pseudo-labels that both demonstrates stronger performance
and stymies single-modality error propagation. Further, we leverage the richer
semantics of RGB images to rectify incorrect 3D class predictions and improve
localization of 3D boxes. Evaluating on the challenging KITTI and Waymo
datasets, we improve upon strong semi-supervised learning methods and observe
higher quality pseudo-labels. Code will be released at
https://github.com/Divadi/DetMatch",0,1,0,0,0,0,0.910172,5.0,0.854026,87
http://arxiv.org/abs/2210.13673v1,Evaluating Parameter Efficient Learning for Generation,3,0.00658425,0.100147,"Parameter efficient learning methods (PERMs) have recently gained significant
attention as they provide an efficient way for pre-trained language models
(PLMs) to adapt to a downstream task. However, these conclusions are mostly
drawn from in-domain evaluations over the full training set. In this paper, we
present comparisons between PERMs and finetuning from three new perspectives:
(1) the effect of sample and model size to in-domain evaluations, (2)
generalization to unseen domains and new datasets, and (3) the faithfulness of
generations. Our results show that for in-domain settings (a) there is a cross
point of sample size for which PERMs will perform better than finetuning when
training with fewer samples, and (b) larger PLMs have larger cross points. For
cross-domain and cross-dataset cases, we show that (a) Adapter (Houlsby et al.,
2019) performs the best amongst all the PERMs studied here, and (b) it
outperforms finetuning if the task dataset is below a certain size. We also
compare the faithfulness of generations and show that PERMs can achieve better
faithfulness score than finetuning, especially for small training set, by as
much as 6%. Finally, we apply Adapter to MT-NLG 530b (Smith et al., 2022) and
achieve new state-of-the-art results on Xsum (Narayan et al., 2018) for all
ROUGE scores (ROUGE-1 49.17, ROUGE-2 27.20, ROUGE-L 40.98).",0,1,0,0,1,0,0.572987,4.0,0.557288,54
http://arxiv.org/abs/2208.08106v1,Disentangling Identity and Pose for Facial Expression Recognition,10,0.0593559,0.798104,"Facial expression recognition (FER) is a challenging problem because the
expression component is always entangled with other irrelevant factors, such as
identity and head pose. In this work, we propose an identity and pose
disentangled facial expression recognition (IPD-FER) model to learn more
discriminative feature representation. We regard the holistic facial
representation as the combination of identity, pose and expression. These three
components are encoded with different encoders. For identity encoder, a well
pre-trained face recognition model is utilized and fixed during training, which
alleviates the restriction on specific expression training data in previous
works and makes the disentanglement practicable on in-the-wild datasets. At the
same time, the pose and expression encoder are optimized with corresponding
labels. Combining identity and pose feature, a neutral face of input individual
should be generated by the decoder. When expression feature is added, the input
image should be reconstructed. By comparing the difference between synthesized
neutral and expressional images of the same individual, the expression
component is further disentangled from identity and pose. Experimental results
verify the effectiveness of our method on both lab-controlled and in-the-wild
databases and we achieve state-of-the-art recognition performance.",0,1,0,0,1,0,0.137403,9.0,0.608746,49
http://arxiv.org/abs/2205.01019v2,HarmoF0: Logarithmic Scale Dilated Convolution For Pitch Estimation,11,0.224136,0.328853,"Sounds, especially music, contain various harmonic components scattered in
the frequency dimension. It is difficult for normal convolutional neural
networks to observe these overtones. This paper introduces a multiple rates
dilated causal convolution (MRDC-Conv) method to capture the harmonic structure
in logarithmic scale spectrograms efficiently. The harmonic is helpful for
pitch estimation, which is important for many sound processing applications. We
propose HarmoF0, a fully convolutional network, to evaluate the MRDC-Conv and
other dilated convolutions in pitch estimation. The results show that this
model outperforms the DeepF0, yields state-of-the-art performance in three
datasets, and simultaneously reduces more than 90% parameters. We also find
that it has stronger noise resistance and fewer octave errors. The code and
pre-trained model are available at https://github.com/WX-Wei/HarmoF0.",1,1,0,0,1,0,0.649843,12.0,0.869896,20
http://arxiv.org/abs/2203.05604v1,Deep Learning-Based Perceptual Stimulus Encoder for Bionic Vision,11,0.0149442,0.19968,"Retinal implants have the potential to treat incurable blindness, yet the
quality of the artificial vision they produce is still rudimentary. An
outstanding challenge is identifying electrode activation patterns that lead to
intelligible visual percepts (phosphenes). Here we propose a PSE based on CNN
that is trained in an end-to-end fashion to predict the electrode activation
patterns required to produce a desired visual percept. We demonstrate the
effectiveness of the encoder on MNIST using a psychophysically validated
phosphene model tailored to individual retinal implant users. The present work
constitutes an essential first step towards improving the quality of the
artificial vision provided by retinal implants.",0,1,0,0,0,0,0.0262029,6.0,0.126987,11
http://arxiv.org/abs/2210.12942v1,Are Current Task-oriented Dialogue Systems Able to Satisfy Impolite Users?,3,0.129212,0.383945,"Task-oriented dialogue (TOD) systems have assisted users on many tasks,
including ticket booking and service inquiries. While existing TOD systems have
shown promising performance in serving customer needs, these systems mostly
assume that users would interact with the dialogue agent politely. This
assumption is unrealistic as impatient or frustrated customers may also
interact with TOD systems impolitely. This paper aims to address this research
gap by investigating impolite users' effects on TOD systems. Specifically, we
constructed an impolite dialogue corpus and conducted extensive experiments to
evaluate the state-of-the-art TOD systems on our impolite dialogue corpus. Our
experimental results show that existing TOD systems are unable to handle
impolite user utterances. We also present a data augmentation method to improve
TOD performance in impolite dialogues. Nevertheless, handling impolite
dialogues remains a very challenging research task. We hope by releasing the
impolite dialogue corpus and establishing the benchmark evaluations, more
researchers are encouraged to investigate this new challenging research task.",0,0,1,1,0,0,0.916558,7.0,0.900039,56
http://arxiv.org/abs/2206.06029v1,Mediators: Conversational Agents Explaining NLP Model Behavior,14,0.165688,0.651645,"The human-centric explainable artificial intelligence (HCXAI) community has
raised the need for framing the explanation process as a conversation between
human and machine. In this position paper, we establish desiderata for
Mediators, text-based conversational agents which are capable of explaining the
behavior of neural models interactively using natural language. From the
perspective of natural language processing (NLP) research, we engineer a
blueprint of such a Mediator for the task of sentiment analysis and assess how
far along current research is on the path towards dialogue-based explanations.",0,0,0,0,0,0,0.50119,5.0,0.605496,109
http://arxiv.org/abs/2210.14250v1,Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature,21,0.225516,0.83929,"Literary translation is a culturally significant task, but it is bottlenecked
by the small number of qualified literary translators relative to the many
untranslated works published around the world. Machine translation (MT) holds
potential to complement the work of human translators by improving both
training procedures and their overall efficiency. Literary translation is less
constrained than more traditional MT settings since translators must balance
meaning equivalence, readability, and critical interpretability in the target
language. This property, along with the complex discourse-level context present
in literary texts, also makes literary MT more challenging to computationally
model and evaluate. To explore this task, we collect a dataset (Par3) of
non-English language novels in the public domain, each aligned at the paragraph
level to both human and automatic English translations. Using Par3, we discover
that expert literary translators prefer reference human translations over
machine-translated paragraphs at a rate of 84%, while state-of-the-art
automatic MT metrics do not correlate with those preferences. The experts note
that MT outputs contain not only mistranslations, but also discourse-disrupting
errors and stylistic inconsistencies. To address these problems, we train a
post-editing model whose output is preferred over normal MT output at a rate of
69% by experts. We publicly release Par3 at
https://github.com/katherinethai/par3/ to spur future research into literary
MT.",1,1,0,1,0,0,0.146901,9.0,0.616773,50
http://arxiv.org/abs/2210.02019v1,Atari-5: Distilling the Arcade Learning Environment down to Five Games,6,0.0543082,0.791756,"The Arcade Learning Environment (ALE) has become an essential benchmark for
assessing the performance of reinforcement learning algorithms. However, the
computational cost of generating results on the entire 57-game dataset limits
ALE's use and makes the reproducibility of many results infeasible. We propose
a novel solution to this problem in the form of a principled methodology for
selecting small but representative subsets of environments within a benchmark
suite. We applied our method to identify a subset of five ALE games, called
Atari-5, which produces 57-game median score estimates within 10% of their true
values. Extending the subset to 10-games recovers 80% of the variance for
log-scores for all games within the 57-game set. We show this level of
compression is possible due to a high degree of correlation between many of the
games in ALE.",1,1,0,0,0,0,0.505264,10.0,0.80392,33
http://arxiv.org/abs/2207.09689v1,Uncertainty Inspired Underwater Image Enhancement,47,0.850669,0.994254,"A main challenge faced in the deep learning-based Underwater Image
Enhancement (UIE) is that the ground truth high-quality image is unavailable.
Most of the existing methods first generate approximate reference maps and then
train an enhancement network with certainty. This kind of method fails to
handle the ambiguity of the reference map. In this paper, we resolve UIE into
distribution estimation and consensus process. We present a novel probabilistic
network to learn the enhancement distribution of degraded underwater images.
Specifically, we combine conditional variational autoencoder with adaptive
instance normalization to construct the enhancement distribution. After that,
we adopt a consensus process to predict a deterministic result based on a set
of samples from the distribution. By learning the enhancement distribution, our
method can cope with the bias introduced in the reference map labeling to some
extent. Additionally, the consensus process is useful to capture a robust and
stable result. We examined the proposed method on two widely used real-world
underwater image enhancement datasets. Experimental results demonstrate that
our approach enables sampling possible enhancement predictions. Meanwhile, the
consensus estimate yields competitive performance compared with
state-of-the-art UIE methods. Code available at
https://github.com/zhenqifu/PUIE-Net.",1,1,0,0,0,0,0.894185,8.0,0.899968,60
http://arxiv.org/abs/2210.15543v1,Beyond the Return: Off-policy Function Estimation under User-specified Error-measuring Distributions,6,0.0754096,0.749518,"Off-policy evaluation often refers to two related tasks: estimating the
expected return of a policy and estimating its value function (or other
functions of interest, such as density ratios). While recent works on
marginalized importance sampling (MIS) show that the former can enjoy provable
guarantees under realizable function approximation, the latter is only known to
be feasible under much stronger assumptions such as prohibitively expressive
discriminators. In this work, we provide guarantees for off-policy function
estimation under only realizability, by imposing proper regularization on the
MIS objectives. Compared to commonly used regularization in MIS, our
regularizer is much more flexible and can account for an arbitrary
user-specified distribution, under which the learned function will be close to
the groundtruth. We provide exact characterization of the optimal dual solution
that needs to be realized by the discriminator class, which determines the
data-coverage assumption in the case of value-function learning. As another
surprising observation, the regularizer can be altered to relax the
data-coverage requirement, and completely eliminate it in the ideal case with
strong side information.",0,0,0,0,0,0,0.61463,8.0,0.792875,42
http://arxiv.org/abs/2205.13636v2,Quark: Controllable Text Generation with Reinforced Unlearning,123,0.441677,0.882168,"Large-scale language models often learn behaviors that are misaligned with
user expectations. Generated text may contain offensive or toxic language,
contain significant repetition, or be of a different sentiment than desired by
the user. We consider the task of unlearning these misalignments by fine-tuning
the language model on signals of what not to do. We introduce Quantized Reward
Konditioning (Quark), an algorithm for optimizing a reward function that
quantifies an (un)wanted property, while not straying too far from the original
model. Quark alternates between (i) collecting samples with the current
language model, (ii) sorting them into quantiles based on reward, with each
quantile identified by a reward token prepended to the language model's input,
and (iii) using a standard language modeling loss on samples from each quantile
conditioned on its reward token, while remaining nearby the original language
model via a KL-divergence penalty. By conditioning on a high-reward token at
generation time, the model generates text that exhibits less of the unwanted
property. For unlearning toxicity, negative sentiment, and repetition, our
experiments show that Quark outperforms both strong baselines and
state-of-the-art reinforcement learning methods like PPO (Schulman et al.
2017), while relying only on standard language modeling primitives.",1,0,1,0,0,0,0.414708,6.0,0.627713,99
http://arxiv.org/abs/2210.05498v1,Adversarial Contrastive Learning for Evidence-aware Fake News Detection with Graph Neural Networks,10,0.162208,0.72153,"The prevalence and perniciousness of fake news have been a critical issue on
the Internet, which stimulates the development of automatic fake news detection
in turn. In this paper, we focus on evidence-based fake news detection, where
several evidences are utilized to probe the veracity of news (i.e., a claim).
Most previous methods first employ sequential models to embed the semantic
information and then capture the claim-evidence interaction based on attention
mechanisms. Despite their effectiveness, they still suffer from three
weaknesses. Firstly, sequential models fail to integrate the relevant
information that is scattered far apart in evidences. Secondly, they
underestimate much redundant information in evidences may be useless or
harmful. Thirdly, insufficient data utilization limits the separability and
reliability of representations captured by the model. To solve these problems,
we propose a unified Graph-based sEmantic structure mining framework with
ConTRAstive Learning, namely GETRAL in short. Specifically, we first model
claims and evidences as graph-structured data to capture the long-distance
semantic dependency. Consequently, we reduce information redundancy by
performing graph structure learning. Then the fine-grained semantic
representations are fed into the claim-evidence interaction module for
predictions. Finally, an adversarial contrastive learning module is applied to
make full use of data and strengthen representation learning. Comprehensive
experiments have demonstrated the superiority of GETRAL over the
state-of-the-arts and validated the efficacy of semantic mining with graph
structure and contrastive learning.",1,0,0,0,1,0,0.759844,7.0,0.820823,85
http://arxiv.org/abs/2210.08855v2,PeerDA: Data Augmentation via Modeling Peer Relation for Span Identification Tasks,6,0.124728,0.254682,"Span identification aims at identifying specific text spans from text input
and classifying them into pre-defined categories. Different from previous works
that merely leverage the Subordinate (SUB) relation (i.e. if a span is an
instance of a certain category) to train models, this paper for the first time
explores the Peer (PR) relation, which indicates that two spans are instances
of the same category and share similar features. Specifically, a novel Peer
Data Augmentation (PeerDA) approach is proposed which employs span pairs with
the PR relation as the augmentation data for training. PeerDA has two unique
advantages: (1) There are a large number of PR span pairs for augmenting the
training data. (2) The augmented data can prevent the trained model from
over-fitting the superficial span-category mapping by pushing the model to
leverage the span semantics. Experimental results on ten datasets over four
diverse tasks across seven domains demonstrate the effectiveness of PeerDA.
Notably, PeerDA achieves state-of-the-art results on six of them.",1,1,1,0,1,0,0.710948,5.0,0.72132,97
http://arxiv.org/abs/2210.13952v5,KnowGL: Knowledge Generation and Linking from Text,9,0.153023,0.635611,"We propose KnowGL, a tool that allows converting text into structured
relational data represented as a set of ABox assertions compliant with the TBox
of a given Knowledge Graph (KG), such as Wikidata. We address this problem as a
sequence generation task by leveraging pre-trained sequence-to-sequence
language models, e.g. BART. Given a sentence, we fine-tune such models to
detect pairs of entity mentions and jointly generate a set of facts consisting
of the full set of semantic annotations for a KG, such as entity labels, entity
types, and their relationships. To showcase the capabilities of our tool, we
build a web application consisting of a set of UI widgets that help users to
navigate through the semantic data extracted from a given input text. We make
the KnowGL model available at https://huggingface.co/ibm/knowgl-large.",0,1,0,0,0,0,0.883227,3.0,0.718293,25
http://arxiv.org/abs/2205.03650v2,Distilling Inter-Class Distance for Semantic Segmentation,13,0.410587,0.671495,"Knowledge distillation is widely adopted in semantic segmentation to reduce
the computation cost.The previous knowledge distillation methods for semantic
segmentation focus on pixel-wise feature alignment and intra-class feature
variation distillation, neglecting to transfer the knowledge of the inter-class
distance in the feature space, which is important for semantic segmentation. To
address this issue, we propose an Inter-class Distance Distillation (IDD)
method to transfer the inter-class distance in the feature space from the
teacher network to the student network. Furthermore, semantic segmentation is a
position-dependent task,thus we exploit a position information distillation
module to help the student network encode more position information. Extensive
experiments on three popular datasets: Cityscapes, Pascal VOC and ADE20K show
that our method is helpful to improve the accuracy of semantic segmentation
models and achieves the state-of-the-art performance. E.g. it boosts the
benchmark model(""PSPNet+ResNet18"") by 7.50% in accuracy on the Cityscapes
dataset.",0,1,0,0,1,1,0.991276,9.0,0.994107,32
http://arxiv.org/abs/2210.08726v3,"RARR: Researching and Revising What Language Models Say, Using Language Models",115,0.863112,0.986403,"Language models (LMs) now excel at many tasks such as few-shot learning,
question answering, reasoning, and dialog. However, they sometimes generate
unsupported or misleading content. A user cannot easily determine whether their
outputs are trustworthy or not, because most LMs do not have any built-in
mechanism for attribution to external evidence. To enable attribution while
still preserving all the powerful advantages of recent generation models, we
propose RARR (Retrofit Attribution using Research and Revision), a system that
1) automatically finds attribution for the output of any text generation model
and 2) post-edits the output to fix unsupported content while preserving the
original output as much as possible. When applied to the output of several
state-of-the-art LMs on a diverse set of generation tasks, we find that RARR
significantly improves attribution while otherwise preserving the original
input to a much greater degree than previously explored edit models.
Furthermore, the implementation of RARR requires only a handful of training
examples, a large language model, and standard web search.",0,1,0,0,0,1,0.83524,5.0,0.796032,117
http://arxiv.org/abs/2203.10941v1,Transfer Dynamics in Emergent Evolutionary Curricula,5,0.0339143,0.194582,"PINSKY is a system for open-ended learning through neuroevolution in
game-based domains. It builds on the Paired Open-Ended Trailblazer (POET)
system, which originally explored learning and environment generation for
bipedal walkers, and adapts it to games in the General Video Game AI (GVGAI)
system. Previous work showed that by co-evolving levels and neural network
policies, levels could be found for which successful policies could not be
created via optimization alone. Studied in the realm of Artificial Life as a
potentially open-ended alternative to gradient-based fitness, minimal criteria
(MC)-based selection helps foster diversity in evolutionary populations. The
main question addressed by this paper is how the open-ended learning actually
works, focusing in particular on the role of transfer of policies from one
evolutionary branch (""species"") to another. We analyze the dynamics of the
system through creating phylogenetic trees, analyzing evolutionary trajectories
of policies, and temporally breaking down transfers according to species type.
Furthermore, we analyze the impact of the minimal criterion on generated level
diversity and inter-species transfer. The most insightful finding is that
inter-species transfer, while rare, is crucial to the system's success.",0,0,0,0,0,0,0.269595,9.0,0.692522,60
http://arxiv.org/abs/2202.11836v1,Sky Computing: Accelerating Geo-distributed Computing in Federated Learning,1,0.0424671,0.0582988,"Federated learning is proposed by Google to safeguard data privacy through
training models locally on users' devices. However, with deep learning models
growing in size to achieve better results, it becomes increasingly difficult to
accommodate the whole model on one single device. Thus, model parallelism is
then used to divide the model weights among several devices. With this logic,
the approach currently used evenly allocates weights among devices. However, in
reality, a computation bottleneck may occur resulting from variant computing
power of different users' devices. To address this problem, load balancing is
needed to allocate the model weights based on the computational capability of
the device. In this paper, we proposed Sky Computing, a load-balanced model
parallelism framework to adaptively allocate the weights to devices. Sky
Computing outperforms the baseline method by 55% in training time when training
160-layer BERT with 64 nodes. The source code can be found at
https://github.com/hpcaitech/SkyComputing.",1,1,0,0,1,0,0.938595,7.0,0.916671,23
http://arxiv.org/abs/2210.11536v1,CONSISTENT: Open-Ended Question Generation From News Articles,6,0.0297056,0.398173,"Recent work on question generation has largely focused on factoid questions
such as who, what, where, when about basic facts. Generating open-ended why,
how, what, etc. questions that require long-form answers have proven more
difficult. To facilitate the generation of open-ended questions, we propose
CONSISTENT, a new end-to-end system for generating open-ended questions that
are answerable from and faithful to the input text. Using news articles as a
trustworthy foundation for experimentation, we demonstrate our model's strength
over several baselines using both automatic and human=based evaluations. We
contribute an evaluation dataset of expert-generated open-ended questions.We
discuss potential downstream applications for news media organizations.",1,1,0,1,0,0,0.247637,7.0,0.590524,45
http://arxiv.org/abs/2206.00856v1,MentSum: A Resource for Exploring Summarization of Mental Health Online Posts,6,0.184059,0.49556,"Mental health remains a significant challenge of public health worldwide.
With increasing popularity of online platforms, many use the platforms to share
their mental health conditions, express their feelings, and seek help from the
community and counselors. Some of these platforms, such as Reachout, are
dedicated forums where the users register to seek help. Others such as Reddit
provide subreddits where the users publicly but anonymously post their mental
health distress. Although posts are of varying length, it is beneficial to
provide a short, but informative summary for fast processing by the counselors.
To facilitate research in summarization of mental health online posts, we
introduce Mental Health Summarization dataset, MentSum, containing over 24k
carefully selected user posts from Reddit, along with their short user-written
summary (called TLDR) in English from 43 mental health subreddits. This
domain-specific dataset could be of interest not only for generating short
summaries on Reddit, but also for generating summaries of posts on the
dedicated mental health forums such as Reachout. We further evaluate both
extractive and abstractive state-of-the-art summarization baselines in terms of
Rouge scores, and finally conduct an in-depth human evaluation study of both
user-written and system-generated summaries, highlighting challenges in this
research.",0,1,0,1,0,0,0.596933,10.0,0.829477,64
http://arxiv.org/abs/2208.12367v2,A Compact Pretraining Approach for Neural Language Models,1,0.0,0.0230007,"Domain adaptation for large neural language models (NLMs) is coupled with
massive amounts of unstructured data in the pretraining phase. In this study,
however, we show that pretrained NLMs learn in-domain information more
effectively and faster from a compact subset of the data that focuses on the
key information in the domain. We construct these compact subsets from the
unstructured data using a combination of abstractive summaries and extractive
keywords. In particular, we rely on BART to generate abstractive summaries, and
KeyBERT to extract keywords from these summaries (or the original unstructured
text directly). We evaluate our approach using six different settings: three
datasets combined with two distinct NLMs. Our results reveal that the
task-specific classifiers trained on top of NLMs pretrained using our method
outperform methods based on traditional pretraining, i.e., random masking on
the entire data, as well as methods without pretraining. Further, we show that
our strategy reduces pretraining time by up to five times compared to vanilla
pretraining. The code for all of our experiments is publicly available at
https://github.com/shahriargolchin/compact-pretraining.",1,1,0,0,0,0,0.840772,10.0,0.899892,24
http://arxiv.org/abs/2205.02496v1,Are GAN-based Morphs Threatening Face Recognition?,29,0.23796,0.716655,"Morphing attacks are a threat to biometric systems where the biometric
reference in an identity document can be altered. This form of attack presents
an important issue in applications relying on identity documents such as border
security or access control. Research in generation of face morphs and their
detection is developing rapidly, however very few datasets with morphing
attacks and open-source detection toolkits are publicly available. This paper
bridges this gap by providing two datasets and the corresponding code for four
types of morphing attacks: two that rely on facial landmarks based on OpenCV
and FaceMorpher, and two that use StyleGAN 2 to generate synthetic morphs. We
also conduct extensive experiments to assess the vulnerability of four
state-of-the-art face recognition systems, including FaceNet, VGG-Face,
ArcFace, and ISV. Surprisingly, the experiments demonstrate that, although
visually more appealing, morphs based on StyleGAN 2 do not pose a significant
threat to the state to face recognition systems, as these morphs were
outmatched by the simple morphs that are based facial landmarks.",1,1,0,1,0,0,0.246031,9.0,0.680683,31
http://arxiv.org/abs/2209.00522v2,Implicit and Efficient Point Cloud Completion for 3D Single Object Tracking,6,0.147962,0.278834,"The point cloud based 3D single object tracking has drawn increasing
attention. Although many breakthroughs have been achieved, we also reveal two
severe issues. By extensive analysis, we find the prediction manner of current
approaches is non-robust, i.e., exposing a misalignment gap between prediction
score and actually localization accuracy. Another issue is the sparse point
returns will damage the feature matching procedure of the SOT task. Based on
these insights, we introduce two novel modules, i.e., Adaptive Refine
Prediction (ARP) and Target Knowledge Transfer (TKT), to tackle them,
respectively. To this end, we first design a strong pipeline to extract
discriminative features and conduct the matching with the attention mechanism.
Then, ARP module is proposed to tackle the misalignment issue by aggregating
all predicted candidates with valuable clues. Finally, TKT module is designed
to effectively overcome incomplete point cloud due to sparse and occlusion
issues. We call our overall framework PCET. By conducting extensive experiments
on the KITTI and Waymo Open Dataset, our model achieves state-of-the-art
performance while maintaining a lower computational cost.",0,1,0,0,1,0,0.930564,5.0,0.87433,43
http://arxiv.org/abs/2206.02421v1,MorisienMT: A Dataset for Mauritian Creole Machine Translation,6,0.132774,0.811124,"In this paper, we describe MorisienMT, a dataset for benchmarking machine
translation quality of Mauritian Creole. Mauritian Creole (Morisien) is the
lingua franca of the Republic of Mauritius and is a French-based creole
language. MorisienMT consists of a parallel corpus between English and
Morisien, French and Morisien and a monolingual corpus for Morisien. We first
give an overview of Morisien and then describe the steps taken to create the
corpora and, from it, the training and evaluation splits. Thereafter, we
establish a variety of baseline models using the created parallel corpora as
well as large French--English corpora for transfer learning. We release our
datasets publicly for research purposes and hope that this spurs research for
Morisien machine translation.",0,1,1,1,0,0,0.210123,11.0,0.722375,20
http://arxiv.org/abs/2205.03589v2,Learning Disentangled Textual Representations via Statistical Measures of Similarity,16,0.1416,0.67503,"When working with textual data, a natural application of disentangled
representations is fair classification where the goal is to make predictions
without being biased (or influenced) by sensitive attributes that may be
present in the data (e.g., age, gender or race). Dominant approaches to
disentangle a sensitive attribute from textual representations rely on learning
simultaneously a penalization term that involves either an adversarial loss
(e.g., a discriminator) or an information measure (e.g., mutual information).
However, these methods require the training of a deep neural network with
several parameter updates for each update of the representation model. As a
matter of fact, the resulting nested optimization loop is both time consuming,
adding complexity to the optimization dynamic, and requires a fine
hyperparameter selection (e.g., learning rates, architecture). In this work, we
introduce a family of regularizers for learning disentangled representations
that do not require training. These regularizers are based on statistical
measures of similarity between the conditional probability distributions with
respect to the sensitive attributes. Our novel regularizers do not require
additional training, are faster and do not involve additional tuning while
achieving better results both when combined with pretrained and randomly
initialized text encoders.",0,0,0,0,0,0,0.318834,7.0,0.633331,88
http://arxiv.org/abs/2210.16877v1,On Rate-Distortion Theory in Capacity-Limited Cognition & Reinforcement Learning,2,0.141274,0.303438,"Throughout the cognitive-science literature, there is widespread agreement
that decision-making agents operating in the real world do so under limited
information-processing capabilities and without access to unbounded cognitive
or computational resources. Prior work has drawn inspiration from this fact and
leveraged an information-theoretic model of such behaviors or policies as
communication channels operating under a bounded rate constraint. Meanwhile, a
parallel line of work also capitalizes on the same principles from
rate-distortion theory to formalize capacity-limited decision making through
the notion of a learning target, which facilitates Bayesian regret bounds for
provably-efficient learning algorithms. In this paper, we aim to elucidate this
latter perspective by presenting a brief survey of these information-theoretic
models of capacity-limited decision making in biological and artificial agents.",0,0,0,0,0,0,0.606257,12.0,0.860017,137
http://arxiv.org/abs/2203.04907v2,KPE: Keypoint Pose Encoding for Transformer-based Image Generation,5,0.0508237,0.101623,"Transformers have recently been shown to generate high quality images from
text input. However, the existing method of pose conditioning using skeleton
image tokens is computationally inefficient and generate low quality images.
Therefore we propose a new method; Keypoint Pose Encoding (KPE); KPE is 10
times more memory efficient and over 73% faster at generating high quality
images from text input conditioned on the pose. The pose constraint improves
the image quality and reduces errors on body extremities such as arms and legs.
The additional benefits include invariance to changes in the target image
domain and image resolution, making it easily scalable to higher resolution
images. We demonstrate the versatility of KPE by generating photorealistic
multiperson images derived from the DeepFashion dataset. We also introduce a
evaluation method People Count Error (PCE) that is effective in detecting error
in generated human images.",0,1,0,0,0,0,0.965391,6.0,0.933931,43
http://arxiv.org/abs/2206.09457v2,All you need is feedback: Communication with block attention feedback codes,19,0.0866664,0.398667,"Deep learning based channel code designs have recently gained interest as an
alternative to conventional coding algorithms, particularly for channels for
which existing codes do not provide effective solutions. Communication over a
feedback channel is one such problem, for which promising results have recently
been obtained by employing various deep learning architectures. In this paper,
we introduce a novel learning-aided code design for feedback channels, called
generalized block attention feedback (GBAF) codes, which i) employs a modular
architecture that can be implemented using different neural network
architectures; ii) provides order-of-magnitude improvements in the probability
of error compared to existing designs; and iii) can transmit at desired code
rates.",0,1,0,0,1,0,0.108089,11.0,0.656583,36
http://arxiv.org/abs/2209.12557v1,Device-friendly Guava fruit and leaf disease detection using deep learning,3,0.0812885,0.314037,"This work presents a deep learning-based plant disease diagnostic system
using images of fruits and leaves. Five state-of-the-art convolutional neural
networks (CNN) have been employed for implementing the system. Hitherto model
accuracy has been the focus for such applications and model optimization has
not been accounted for the model to be applicable to end-user devices. Two
model quantization techniques such as float16 and dynamic range quantization
have been applied to the five state-of-the-art CNN architectures. The study
shows that the quantized GoogleNet model achieved the size of 0.143 MB with an
accuracy of 97%, which is the best candidate model considering the size
criterion. The EfficientNet model achieved the size of 4.2MB with an accuracy
of 99%, which is the best model considering the performance criterion. The
source codes are available at
https://github.com/CompostieAI/Guava-disease-detection.",1,1,0,0,0,0,0.299834,7.0,0.62271,24
http://arxiv.org/abs/2211.15616v1,Weight Predictor Network with Feature Selection for Small Sample Tabular Biomedical Data,5,0.132886,0.456113,"Tabular biomedical data is often high-dimensional but with a very small
number of samples. Although recent work showed that well-regularised simple
neural networks could outperform more sophisticated architectures on tabular
data, they are still prone to overfitting on tiny datasets with many
potentially irrelevant features. To combat these issues, we propose Weight
Predictor Network with Feature Selection (WPFS) for learning neural networks
from high-dimensional and small sample data by reducing the number of learnable
parameters and simultaneously performing feature selection. In addition to the
classification network, WPFS uses two small auxiliary networks that together
output the weights of the first layer of the classification model. We evaluate
on nine real-world biomedical datasets and demonstrate that WPFS outperforms
other standard as well as more recent methods typically applied to tabular
data. Furthermore, we investigate the proposed feature selection mechanism and
show that it improves performance while providing useful insights into the
learning task.",1,1,0,0,1,0,0.718054,13.0,0.894343,48
http://arxiv.org/abs/2210.13007v2,Iterative Patch Selection for High-Resolution Image Recognition,5,0.0386948,0.666843,"High-resolution images are prevalent in various applications, such as
autonomous driving and computer-aided diagnosis. However, training neural
networks on such images is computationally challenging and easily leads to
out-of-memory errors even on modern GPUs. We propose a simple method, Iterative
Patch Selection (IPS), which decouples the memory usage from the input size and
thus enables the processing of arbitrarily large images under tight hardware
constraints. IPS achieves this by selecting only the most salient patches,
which are then aggregated into a global representation for image recognition.
For both patch selection and aggregation, a cross-attention based transformer
is introduced, which exhibits a close connection to Multiple Instance Learning.
Our method demonstrates strong performance and has wide applicability across
different domains, training regimes and image sizes while using minimal
accelerator memory. For example, we are able to finetune our model on
whole-slide images consisting of up to 250k patches (>16 gigapixels) with only
5 GB of GPU VRAM at a batch size of 16.",1,1,0,0,0,0,0.439507,8.0,0.7305,46
http://arxiv.org/abs/2207.01756v1,Universal Domain Adaptive Object Detector,11,0.122208,0.539209,"Universal domain adaptive object detection (UniDAOD)is more challenging than
domain adaptive object detection (DAOD) since the label space of the source
domain may not be the same as that of the target and the scale of objects in
the universal scenarios can vary dramatically (i.e, category shift and scale
shift). To this end, we propose US-DAF, namely Universal Scale-Aware Domain
Adaptive Faster RCNN with Multi-Label Learning, to reduce the negative transfer
effect during training while maximizing transferability as well as
discriminability in both domains under a variety of scales. Specifically, our
method is implemented by two modules: 1) We facilitate the feature alignment of
common classes and suppress the interference of private classes by designing a
Filter Mechanism module to overcome the negative transfer caused by category
shift. 2) We fill the blank of scale-aware adaptation in object detection by
introducing a new Multi-Label Scale-Aware Adapter to perform individual
alignment between the corresponding scale for two domains. Experiments show
that US-DAF achieves state-of-the-art results on three scenarios (i.e,
Open-Set, Partial-Set, and Closed-Set) and yields 7.1% and 5.9% relative
improvement on benchmark datasets Clipart1k and Watercolor in particular.",0,1,1,0,1,0,0.855164,10.0,0.90492,40
http://arxiv.org/abs/2203.09093v2,Semantic-aligned Fusion Transformer for One-shot Object Detection,18,0.0951119,0.488785,"One-shot object detection aims at detecting novel objects according to merely
one given instance. With extreme data scarcity, current approaches explore
various feature fusions to obtain directly transferable meta-knowledge. Yet,
their performances are often unsatisfactory. In this paper, we attribute this
to inappropriate correlation methods that misalign query-support semantics by
overlooking spatial structures and scale variances. Upon analysis, we leverage
the attention mechanism and propose a simple but effective architecture named
Semantic-aligned Fusion Transformer (SaFT) to resolve these issues.
Specifically, we equip SaFT with a vertical fusion module (VFM) for cross-scale
semantic enhancement and a horizontal fusion module (HFM) for cross-sample
feature fusion. Together, they broaden the vision for each feature point from
the support to a whole augmented feature pyramid from the query, facilitating
semantic-aligned associations. Extensive experiments on multiple benchmarks
demonstrate the superiority of our framework. Without fine-tuning on novel
classes, it brings significant performance gains to one-stage baselines,
lifting state-of-the-art results to a higher level.",0,1,0,0,1,0,0.686472,6.0,0.756478,67
http://arxiv.org/abs/2201.09696v2,Unified Question Generation with Continual Lifelong Learning,6,0.0297056,0.11822,"Question Generation (QG), as a challenging Natural Language Processing task,
aims at generating questions based on given answers and context. Existing QG
methods mainly focus on building or training models for specific QG datasets.
These works are subject to two major limitations: (1) They are dedicated to
specific QG formats (e.g., answer-extraction or multi-choice QG), therefore, if
we want to address a new format of QG, a re-design of the QG model is required.
(2) Optimal performance is only achieved on the dataset they were just trained
on. As a result, we have to train and keep various QG models for different QG
datasets, which is resource-intensive and ungeneralizable.
  To solve the problems, we propose a model named Unified-QG based on lifelong
learning techniques, which can continually learn QG tasks across different
datasets and formats. Specifically, we first build a format-convert encoding to
transform different kinds of QG formats into a unified representation. Then, a
method named \emph{STRIDER} (\emph{S}imilari\emph{T}y \emph{R}egular\emph{I}zed
\emph{D}ifficult \emph{E}xample \emph{R}eplay) is built to alleviate
catastrophic forgetting in continual QG learning. Extensive experiments were
conducted on $8$ QG datasets across $4$ QG formats (answer-extraction,
answer-abstraction, multi-choice, and boolean QG) to demonstrate the
effectiveness of our approach. Experimental results demonstrate that our
Unified-QG can effectively and continually adapt to QG tasks when datasets and
formats vary. In addition, we verify the ability of a single trained Unified-QG
model in improving $8$ Question Answering (QA) systems' performance through
generating synthetic QA data.",0,1,0,0,0,0,0.382232,7.0,0.665715,95
http://arxiv.org/abs/2203.03073v2,ILDAE: Instance-Level Difficulty Analysis of Evaluation Data,15,0.162763,0.252541,"Knowledge of questions' difficulty level helps a teacher in several ways,
such as estimating students' potential quickly by asking carefully selected
questions and improving quality of examination by modifying trivial and hard
questions. Can we extract such benefits of instance difficulty in NLP? To this
end, we conduct Instance-Level Difficulty Analysis of Evaluation data (ILDAE)
in a large-scale setup of 23 datasets and demonstrate its five novel
applications: 1) conducting efficient-yet-accurate evaluations with fewer
instances saving computational cost and time, 2) improving quality of existing
evaluation datasets by repairing erroneous and trivial instances, 3) selecting
the best model based on application requirements, 4) analyzing dataset
characteristics for guiding future data creation, 5) estimating Out-of-Domain
performance reliably. Comprehensive experiments for these applications result
in several interesting findings, such as evaluation using just 5% instances
(selected via ILDAE) achieves as high as 0.93 Kendall correlation with
evaluation using complete dataset and computing weighted accuracy using
difficulty scores leads to 5.2% higher correlation with Out-of-Domain
performance. We release the difficulty scores and hope our analyses and
findings will bring more attention to this important yet understudied field of
leveraging instance difficulty in evaluations.",0,0,0,0,0,0,0.805358,6.0,0.813863,62
http://arxiv.org/abs/2210.04468v2,Distill the Image to Nowhere: Inversion Knowledge Distillation for Multimodal Machine Translation,8,0.126505,0.468744,"Past works on multimodal machine translation (MMT) elevate bilingual setup by
incorporating additional aligned vision information. However, an image-must
requirement of the multimodal dataset largely hinders MMT's development --
namely that it demands an aligned form of [image, source text, target text].
This limitation is generally troublesome during the inference phase especially
when the aligned image is not provided as in the normal NMT setup. Thus, in
this work, we introduce IKD-MMT, a novel MMT framework to support the
image-free inference phase via an inversion knowledge distillation scheme. In
particular, a multimodal feature generator is executed with a knowledge
distillation module, which directly generates the multimodal feature from
(only) source texts as the input. While there have been a few prior works
entertaining the possibility to support image-free inference for machine
translation, their performances have yet to rival the image-must translation.
In our experiments, we identify our method as the first image-free approach to
comprehensively rival or even surpass (almost) all image-must frameworks, and
achieved the state-of-the-art result on the often-used Multi30k benchmark. Our
code and data are available at: https://github.com/pengr/IKD-mmt/tree/master..",1,1,1,0,1,0,0.259377,11.0,0.744315,48
http://arxiv.org/abs/2205.13621v2,Differentially Private Decoding in Large Language Models,17,0.113926,0.898162,"Recent large-scale natural language processing (NLP) systems use a
pre-trained Large Language Model (LLM) on massive and diverse corpora as a
headstart. In practice, the pre-trained model is adapted to a wide array of
tasks via fine-tuning on task-specific datasets. LLMs, while effective, have
been shown to memorize instances of training data thereby potentially revealing
private information processed during pre-training. The potential leakage might
further propagate to the downstream tasks for which LLMs are fine-tuned. On the
other hand, privacy-preserving algorithms usually involve retraining from
scratch, which is prohibitively expensive for LLMs. In this work, we propose a
simple, easy to interpret, and computationally lightweight perturbation
mechanism to be applied to an already trained model at the decoding stage. Our
perturbation mechanism is model-agnostic and can be used in conjunction with
any LLM. We provide theoretical analysis showing that the proposed mechanism is
differentially private, and experimental results showing a privacy-utility
trade-off.",0,1,0,0,0,0,0.542682,7.0,0.73502,30
http://arxiv.org/abs/2203.08304v3,Hyperdecoders: Instance-specific decoders for multi-task NLP,12,0.0900912,0.465664,"We investigate input-conditioned hypernetworks for multi-tasking in NLP,
generating parameter-efficient adaptations for a decoder using a hypernetwork
conditioned on the output of an encoder. This approach produces a unique
decoder adaptation for every input instance, allowing the network a larger
degree of flexibility than prior work that only produces one decoder adaptation
per task. We apply our method to sequence classification tasks, extractive QA,
and summarisation and find that it surpasses previous parameter efficient
fine-tuning methods and often outperforms fully finetuning the underlying
model. An analysis of the embeddings used by our hypernetwork shows that they
are sensitive to output label and type, suggesting that our approach better
maps from encoder representations to output labels. Our code is publicly
available at https://github.com/allenai/hyperdecoders.",1,1,0,0,0,0,0.837406,6.0,0.831246,84
http://arxiv.org/abs/2209.05122v1,Data Augmentation by Selecting Mixed Classes Considering Distance Between Classes,2,0.0057569,0.0982838,"Data augmentation is an essential technique for improving recognition
accuracy in object recognition using deep learning. Methods that generate mixed
data from multiple data sets, such as mixup, can acquire new diversity that is
not included in the training data, and thus contribute significantly to
accuracy improvement. However, since the data selected for mixing are randomly
sampled throughout the training process, there are cases where appropriate
classes or data are not selected. In this study, we propose a data augmentation
method that calculates the distance between classes based on class
probabilities and can select data from suitable classes to be mixed in the
training process. Mixture data is dynamically adjusted according to the
training trend of each class to facilitate training. The proposed method is
applied in combination with conventional methods for generating mixed data.
Evaluation experiments show that the proposed method improves recognition
performance on general and long-tailed image recognition datasets.",0,1,0,0,0,1,0.499565,7.0,0.717542,23
http://arxiv.org/abs/2208.01817v1,Neural Contourlet Network for Monocular 360 Depth Estimation,6,0.0833547,0.550373,"For a monocular 360 image, depth estimation is a challenging because the
distortion increases along the latitude. To perceive the distortion, existing
methods devote to designing a deep and complex network architecture. In this
paper, we provide a new perspective that constructs an interpretable and sparse
representation for a 360 image. Considering the importance of the geometric
structure in depth estimation, we utilize the contourlet transform to capture
an explicit geometric cue in the spectral domain and integrate it with an
implicit cue in the spatial domain. Specifically, we propose a neural
contourlet network consisting of a convolutional neural network and a
contourlet transform branch. In the encoder stage, we design a spatial-spectral
fusion module to effectively fuse two types of cues. Contrary to the encoder,
we employ the inverse contourlet transform with learned low-pass subbands and
band-pass directional subbands to compose the depth in the decoder. Experiments
on the three popular panoramic image datasets demonstrate that the proposed
approach outperforms the state-of-the-art schemes with faster convergence. Code
is available at
https://github.com/zhijieshen-bjtu/Neural-Contourlet-Network-for-MODE.",1,1,0,0,1,0,0.361002,7.0,0.655325,44
http://arxiv.org/abs/2203.12870v3,RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization,40,0.280371,0.870943,"6-DoF object pose estimation from a monocular image is challenging, and a
post-refinement procedure is generally needed for high-precision estimation. In
this paper, we propose a framework based on a recurrent neural network (RNN)
for object pose refinement, which is robust to erroneous initial poses and
occlusions. During the recurrent iterations, object pose refinement is
formulated as a non-linear least squares problem based on the estimated
correspondence field (between a rendered image and the observed image). The
problem is then solved by a differentiable Levenberg-Marquardt (LM) algorithm
enabling end-to-end training. The correspondence field estimation and pose
refinement are conducted alternatively in each iteration to recover the object
poses. Furthermore, to improve the robustness to occlusion, we introduce a
consistency-check mechanism based on the learned descriptors of the 3D model
and observed 2D images, which downweights the unreliable correspondences during
pose optimization. Extensive experiments on LINEMOD, Occlusion-LINEMOD, and
YCB-Video datasets validate the effectiveness of our method and demonstrate
state-of-the-art performance.",1,1,0,0,1,0,0.633617,7.0,0.770662,63
http://arxiv.org/abs/2204.09952v1,Recovering Patient Journeys: A Corpus of Biomedical Entities and Relations on Twitter (BEAR),3,0.0647616,0.272249,"Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys.",0,1,1,1,0,0,0.206516,10.0,0.692662,50
http://arxiv.org/abs/2209.09115v2,Compositional Law Parsing with Latent Random Functions,4,0.152218,0.603469,"Human cognition has compositionality. We understand a scene by decomposing
the scene into different concepts (e.g., shape and position of an object) and
learning the respective laws of these concepts, which may be either natural
(e.g., laws of motion) or man-made (e.g., laws of a game). The automatic
parsing of these laws indicates the model's ability to understand the scene,
which makes law parsing play a central role in many visual tasks. This paper
proposes a deep latent variable model for Compositional LAw Parsing (CLAP),
which achieves the human-like compositionality ability through an
encoding-decoding architecture to represent concepts in the scene as latent
variables. CLAP employs concept-specific latent random functions instantiated
with Neural Processes to capture the law of concepts. Our experimental results
demonstrate that CLAP outperforms the baseline methods in multiple visual tasks
such as intuitive physics, abstract visual reasoning, and scene representation.
The law manipulation experiments illustrate CLAP's interpretability by
modifying specific latent random functions on samples. For example, CLAP learns
the laws of position-changing and appearance constancy from the moving balls in
a scene, making it possible to exchange laws between samples or compose
existing laws into novel laws.",1,0,0,0,0,0,0.863583,8.0,0.884965,59
http://arxiv.org/abs/2212.08230v4,An Energy-aware and Fault-tolerant Deep Reinforcement Learning based approach for Multi-agent Patrolling Problems,1,0.00872153,0.139771,"Autonomous vehicles are suited for continuous area patrolling problems.
However, finding an optimal patrolling strategy can be challenging for many
reasons. Firstly, patrolling environments are often complex and can include
unknown environmental factors, such as wind or landscape. Secondly, autonomous
vehicles can have failures or hardware constraints, such as limited battery
life. Importantly, patrolling large areas often requires multiple agents that
need to collectively coordinate their actions. In this work, we consider these
limitations and propose an approach based on model-free, deep multi-agent
reinforcement learning. In this approach, the agents are trained to patrol an
environment with various unknown dynamics and factors. They can automatically
recharge themselves to support continuous collective patrolling. A distributed
homogeneous multi-agent architecture is proposed, where all patrolling agents
execute identical policies locally based on their local observations and shared
location information. This architecture provides a patrolling system that can
tolerate agent failures and allow supplementary agents to be added to replace
failed agents or to increase the overall patrol performance. The solution is
validated through simulation experiments from multiple perspectives, including
the overall patrol performance, the efficiency of battery recharging
strategies, the overall fault tolerance, and the ability to cooperate with
supplementary agents.",0,1,0,0,0,0,0.000491743,18.0,0.487403,55
http://arxiv.org/abs/2210.06954v1,Darwinian Model Upgrades: Model Evolving with Selective Compatibility,3,0.00488428,0.150483,"The traditional model upgrading paradigm for retrieval requires recomputing
all gallery embeddings before deploying the new model (dubbed as
""backfilling""), which is quite expensive and time-consuming considering
billions of instances in industrial applications. BCT presents the first step
towards backward-compatible model upgrades to get rid of backfilling. It is
workable but leaves the new model in a dilemma between new feature
discriminativeness and new-to-old compatibility due to the undifferentiated
compatibility constraints. In this work, we propose Darwinian Model Upgrades
(DMU), which disentangle the inheritance and variation in the model evolving
with selective backward compatibility and forward adaptation, respectively. The
old-to-new heritable knowledge is measured by old feature discriminativeness,
and the gallery features, especially those of poor quality, are evolved in a
lightweight manner to become more adaptive in the new latent space. We
demonstrate the superiority of DMU through comprehensive experiments on
large-scale landmark retrieval and face recognition benchmarks. DMU effectively
alleviates the new-to-new degradation and improves new-to-old compatibility,
rendering a more proper model upgrading paradigm in large-scale retrieval
systems.",0,1,0,0,0,0,0.105689,5.0,0.239727,24
http://arxiv.org/abs/2210.08873v2,Semi-Supervised Knowledge-Grounded Pre-training for Task-Oriented Dialog Systems,14,0.267643,0.885175,"Recent advances in neural approaches greatly improve task-oriented dialogue
(TOD) systems which assist users to accomplish their goals. However, such
systems rely on costly manually labeled dialogs which are not available in
practical scenarios. In this paper, we present our models for Track 2 of the
SereTOD 2022 challenge, which is the first challenge of building
semi-supervised and reinforced TOD systems on a large-scale real-world Chinese
TOD dataset MobileCS. We build a knowledge-grounded dialog model to formulate
dialog history and local KB as input and predict the system response. And we
perform semi-supervised pre-training both on the labeled and unlabeled data.
Our system achieves the first place both in the automatic evaluation and human
interaction, especially with higher BLEU (+7.64) and Success (+13.6\%) than the
second place.",1,1,0,0,1,0,0.396015,7.0,0.672256,23
http://arxiv.org/abs/2212.06385v2,TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models of Different Modalities,12,0.267468,0.397541,"Recently, the success of pre-training in text domain has been fully extended
to vision, audio, and cross-modal scenarios. The proposed pre-training models
of different modalities are showing a rising trend of homogeneity in their
model structures, which brings the opportunity to implement different
pre-training models within a uniform framework. In this paper, we present
TencentPretrain, a toolkit supporting pre-training models of different
modalities. The core feature of TencentPretrain is the modular design. The
toolkit uniformly divides pre-training models into 5 components: embedding,
encoder, target embedding, decoder, and target. As almost all of common modules
are provided in each component, users can choose the desired modules from
different components to build a complete pre-training model. The modular design
enables users to efficiently reproduce existing pre-training models or build
brand-new one. We test the toolkit on text, vision, and audio benchmarks and
show that it can match the performance of the original implementations.",1,1,0,0,0,0,0.954764,7.0,0.931519,48
http://arxiv.org/abs/2209.07263v4,"Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)",12,0.0397858,0.452609,"We study the average robustness notion in deep neural networks in (selected)
wide and narrow, deep and shallow, as well as lazy and non-lazy training
settings. We prove that in the under-parameterized setting, width has a
negative effect while it improves robustness in the over-parameterized setting.
The effect of depth closely depends on the initialization and the training
mode. In particular, when initialized with LeCun initialization, depth helps
robustness with the lazy training regime. In contrast, when initialized with
Neural Tangent Kernel (NTK) and He-initialization, depth hurts the robustness.
Moreover, under the non-lazy training regime, we demonstrate how the width of a
two-layer ReLU network benefits robustness. Our theoretical developments
improve the results by [Huang et al. NeurIPS21; Wu et al. NeurIPS21] and are
consistent with [Bubeck and Sellke NeurIPS21; Bubeck et al. COLT21].",1,0,0,0,0,0,0.203085,7.0,0.558256,63
http://arxiv.org/abs/2211.02973v1,Mixture-Net: Low-Rank Deep Image Prior Inspired by Mixture Models for Spectral Image Recovery,5,0.059751,0.387464,"This paper proposes a non-data-driven deep neural network for spectral image
recovery problems such as denoising, single hyperspectral image
super-resolution, and compressive spectral imaging reconstruction. Unlike
previous methods, the proposed approach, dubbed Mixture-Net, implicitly learns
the prior information through the network. Mixture-Net consists of a deep
generative model whose layers are inspired by the linear and non-linear
low-rank mixture models, where the recovered image is composed of a weighted
sum between the linear and non-linear decomposition. Mixture-Net also provides
a low-rank decomposition interpreted as the spectral image abundances and
endmembers, helpful in achieving remote sensing tasks without running
additional routines. The experiments show the MixtureNet effectiveness
outperforming state-of-the-art methods in recovery quality with the advantage
of architecture interpretability.",0,1,0,0,1,0,0.189012,8.0,0.603443,56
http://arxiv.org/abs/2204.09484v1,Generalizing to the Future: Mitigating Entity Bias in Fake News Detection,38,0.727194,0.722496,"The wide dissemination of fake news is increasingly threatening both
individuals and society. Fake news detection aims to train a model on the past
news and detect fake news of the future. Though great efforts have been made,
existing fake news detection methods overlooked the unintended entity bias in
the real-world data, which seriously influences models' generalization ability
to future data. For example, 97\% of news pieces in 2010-2017 containing the
entity `Donald Trump' are real in our data, but the percentage falls down to
merely 33\% in 2018. This would lead the model trained on the former set to
hardly generalize to the latter, as it tends to predict news pieces about
`Donald Trump' as real for lower training loss. In this paper, we propose an
entity debiasing framework (\textbf{ENDEF}) which generalizes fake news
detection models to the future data by mitigating entity bias from a
cause-effect perspective. Based on the causal graph among entities, news
contents, and news veracity, we separately model the contribution of each cause
(entities and contents) during training. In the inference stage, we remove the
direct effect of the entities to mitigate entity bias. Extensive offline
experiments on the English and Chinese datasets demonstrate that the proposed
framework can largely improve the performance of base fake news detectors, and
online tests verify its superiority in practice. To the best of our knowledge,
this is the first work to explicitly improve the generalization ability of fake
news detection models to the future data. The code has been released at
https://github.com/ICTMCG/ENDEF-SIGIR2022.",1,1,0,0,1,0,0.909563,6.0,0.877887,44
http://arxiv.org/abs/2204.12511v2,PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions,91,0.857382,0.922778,"Cross-entropy loss and focal loss are the most common choices when training
deep neural networks for classification problems. Generally speaking, however,
a good loss function can take on much more flexible forms, and should be
tailored for different tasks and datasets. Motivated by how functions can be
approximated via Taylor expansion, we propose a simple framework, named
PolyLoss, to view and design loss functions as a linear combination of
polynomial functions. Our PolyLoss allows the importance of different
polynomial bases to be easily adjusted depending on the targeting tasks and
datasets, while naturally subsuming the aforementioned cross-entropy loss and
focal loss as special cases. Extensive experimental results show that the
optimal choice within the PolyLoss is indeed dependent on the task and dataset.
Simply by introducing one extra hyperparameter and adding one line of code, our
Poly-1 formulation outperforms the cross-entropy loss and focal loss on 2D
image classification, instance segmentation, object detection, and 3D object
detection tasks, sometimes by a large margin.",1,0,1,0,1,1,0.898875,7.0,0.888532,41
http://arxiv.org/abs/2212.09849v5,Dataless Knowledge Fusion by Merging Weights of Language Models,55,0.615862,0.991309,"Fine-tuning pre-trained language models has become the prevalent paradigm for
building downstream NLP models. Oftentimes fine-tuned models are readily
available but their training data is not, due to data privacy or intellectual
property concerns. This creates a barrier to fusing knowledge across individual
models to yield a better single model. In this paper, we study the problem of
merging individual models built on different training data sets to obtain a
single model that performs well both across all data set domains and can
generalize on out-of-domain data. We propose a dataless knowledge fusion method
that merges models in their parameter space, guided by weights that minimize
prediction differences between the merged model and the individual models. Over
a battery of evaluation settings, we show that the proposed method
significantly outperforms baselines such as Fisher-weighted averaging or model
ensembling. Further, we find that our method is a promising alternative to
multi-task learning that can preserve or sometimes improve over the individual
models without access to the training data. Finally, model merging is more
efficient than training a multi-task model, thus making it applicable to a
wider set of scenarios.",1,1,0,0,0,0,0.698034,8.0,0.821344,58
http://arxiv.org/abs/2209.08779v1,Neural-Symbolic Entangled Framework for Complex Query Answering,18,0.669833,0.835968,"Answering complex queries over knowledge graphs (KG) is an important yet
challenging task because of the KG incompleteness issue and cascading errors
during reasoning. Recent query embedding (QE) approaches to embed the entities
and relations in a KG and the first-order logic (FOL) queries into a low
dimensional space, answering queries by dense similarity search. However,
previous works mainly concentrate on the target answers, ignoring intermediate
entities' usefulness, which is essential for relieving the cascading error
problem in logical query answering. In addition, these methods are usually
designed with their own geometric or distributional embeddings to handle
logical operators like union, intersection, and negation, with the sacrifice of
the accuracy of the basic operator - projection, and they could not absorb
other embedding methods to their models. In this work, we propose a Neural and
Symbolic Entangled framework (ENeSy) for complex query answering, which enables
the neural and symbolic reasoning to enhance each other to alleviate the
cascading error and KG incompleteness. The projection operator in ENeSy could
be any embedding method with the capability of link prediction, and the other
FOL operators are handled without parameters. With both neural and symbolic
reasoning results contained, ENeSy answers queries in ensembles. ENeSy achieves
the SOTA performance on several benchmarks, especially in the setting of the
training model only with the link prediction task.",0,0,0,0,1,0,0.980554,11.0,0.978343,31
http://arxiv.org/abs/2204.08128v1,Less is More: Learning to Refine Dialogue History for Personalized Dialogue Generation,32,0.384411,0.896592,"Personalized dialogue systems explore the problem of generating responses
that are consistent with the user's personality, which has raised much
attention in recent years. Existing personalized dialogue systems have tried to
extract user profiles from dialogue history to guide personalized response
generation. Since the dialogue history is usually long and noisy, most existing
methods truncate the dialogue history to model the user's personality. Such
methods can generate some personalized responses, but a large part of dialogue
history is wasted, leading to sub-optimal performance of personalized response
generation. In this work, we propose to refine the user dialogue history on a
large scale, based on which we can handle more dialogue history and obtain more
abundant and accurate persona information. Specifically, we design an MSP model
which consists of three personal information refiners and a personalized
response generator. With these multi-level refiners, we can sparsely extract
the most valuable information (tokens) from the dialogue history and leverage
other similar users' data to enhance personalization. Experimental results on
two real-world datasets demonstrate the superiority of our model in generating
more informative and personalized responses.",0,1,0,0,0,0,0.534013,9.0,0.791205,47
http://arxiv.org/abs/2204.00656v1,Consistency driven Sequential Transformers Attention Model for Partially Observable Scenes,12,0.0403706,0.177354,"Most hard attention models initially observe a complete scene to locate and
sense informative glimpses, and predict class-label of a scene based on
glimpses. However, in many applications (e.g., aerial imaging), observing an
entire scene is not always feasible due to the limited time and resources
available for acquisition. In this paper, we develop a Sequential Transformers
Attention Model (STAM) that only partially observes a complete image and
predicts informative glimpse locations solely based on past glimpses. We design
our agent using DeiT-distilled and train it with a one-step actor-critic
algorithm. Furthermore, to improve classification performance, we introduce a
novel training objective, which enforces consistency between the class
distribution predicted by a teacher model from a complete image and the class
distribution predicted by our agent using glimpses. When the agent senses only
4% of the total image area, the inclusion of the proposed consistency loss in
our training objective yields 3% and 8% higher accuracy on ImageNet and fMoW
datasets, respectively. Moreover, our agent outperforms previous
state-of-the-art by observing nearly 27% and 42% fewer pixels in glimpses on
ImageNet and fMoW.",1,1,0,0,1,0,0.552314,6.0,0.695331,55
http://arxiv.org/abs/2209.09368v1,The first neural machine translation system for the Erzya language,1,0.00248002,0.0962424,"We present the first neural machine translation system for translation
between the endangered Erzya language and Russian and the dataset collected by
us to train and evaluate it. The BLEU scores are 17 and 19 for translation to
Erzya and Russian respectively, and more than half of the translations are
rated as acceptable by native speakers. We also adapt our model to translate
between Erzya and 10 other languages, but without additional parallel data, the
quality on these directions remains low. We release the translation models
along with the collected text corpus, a new language identification model, and
a multilingual sentence encoder adapted for the Erzya language. These resources
will be available at https://github.com/slone-nlp/myv-nmt.",1,1,1,1,0,0,0.0885246,6.0,0.335346,30
http://arxiv.org/abs/2207.03041v1,Vision Transformers: State of the Art and Research Challenges,10,0.0488886,0.20978,"Transformers have achieved great success in natural language processing. Due
to the powerful capability of self-attention mechanism in transformers,
researchers develop the vision transformers for a variety of computer vision
tasks, such as image recognition, object detection, image segmentation, pose
estimation, and 3D reconstruction. This paper presents a comprehensive overview
of the literature on different architecture designs and training tricks
(including self-supervised learning) for vision transformers. Our goal is to
provide a systematic review with the open research opportunities.",0,0,0,0,0,0,0.956387,3.0,0.844121,57
http://arxiv.org/abs/2206.00845v1,Hyperspherical Consistency Regularization,20,0.230127,0.868667,"Recent advances in contrastive learning have enlightened diverse applications
across various semi-supervised fields. Jointly training supervised learning and
unsupervised learning with a shared feature encoder becomes a common scheme.
Though it benefits from taking advantage of both feature-dependent information
from self-supervised learning and label-dependent information from supervised
learning, this scheme remains suffering from bias of the classifier. In this
work, we systematically explore the relationship between self-supervised
learning and supervised learning, and study how self-supervised learning helps
robust data-efficient deep learning. We propose hyperspherical consistency
regularization (HCR), a simple yet effective plug-and-play method, to
regularize the classifier using feature-dependent information and thus avoid
bias from labels. Specifically, HCR first projects logits from the classifier
and feature projections from the projection head on the respective hypersphere,
then it enforces data points on hyperspheres to have similar structures by
minimizing binary cross entropy of pairwise distances' similarity metrics.
Extensive experiments on semi-supervised and weakly-supervised learning
demonstrate the effectiveness of our method, by showing superior performance
with HCR.",0,0,0,0,0,0,0.88419,8.0,0.894841,95
http://arxiv.org/abs/2207.02186v1,NeuralPassthrough: Learned Real-Time View Synthesis for VR,14,0.102994,0.257087,"Virtual reality (VR) headsets provide an immersive, stereoscopic visual
experience, but at the cost of blocking users from directly observing their
physical environment. Passthrough techniques are intended to address this
limitation by leveraging outward-facing cameras to reconstruct the images that
would otherwise be seen by the user without the headset. This is inherently a
real-time view synthesis challenge, since passthrough cameras cannot be
physically co-located with the eyes. Existing passthrough techniques suffer
from distracting reconstruction artifacts, largely due to the lack of accurate
depth information (especially for near-field and disoccluded objects), and also
exhibit limited image quality (e.g., being low resolution and monochromatic).
In this paper, we propose the first learned passthrough method and assess its
performance using a custom VR headset that contains a stereo pair of RGB
cameras. Through both simulations and experiments, we demonstrate that our
learned passthrough method delivers superior image quality compared to
state-of-the-art methods, while meeting strict VR requirements for real-time,
perspective-correct stereoscopic view synthesis over a wide field of view for
desktop-connected headsets.",1,1,0,0,1,0,0.558077,7.0,0.74114,42
http://arxiv.org/abs/2206.07080v1,Measuring Inconsistency in Declarative Process Specifications,6,0.0977817,0.342388,"We address the problem of measuring inconsistency in declarative process
specifications, with an emphasis on linear temporal logic on fixed traces
(LTLff). As we will show, existing inconsistency measures for classical logic
cannot provide a meaningful assessment of inconsistency in LTL in general, as
they cannot adequately handle the temporal operators. We therefore propose a
novel paraconsistent semantics as a framework for inconsistency measurement. We
then present two new inconsistency measures based on these semantics and show
that they satisfy important desirable properties. We show how these measures
can be applied to declarative process models and investigate the computational
complexity of the introduced approach.",0,0,0,0,0,0,0.00176075,22.0,0.63861,26
http://arxiv.org/abs/2201.01810v2,Privacy-Friendly Peer-to-Peer Energy Trading: A Game Theoretical Approach,5,0.235408,0.362125,"In this paper, we propose a decentralized, privacy-friendly energy trading
platform (PFET) based on game theoretical approach - specifically Stackelberg
competition. Unlike existing trading schemes, PFET provides a competitive
market in which prices and demands are determined based on competition, and
computations are performed in a decentralized manner which does not rely on
trusted third parties. It uses homomorphic encryption cryptosystem to encrypt
sensitive information of buyers and sellers such as sellers$'$ prices and
buyers$'$ demands. Buyers calculate total demand on particular seller using an
encrypted data and sensitive buyer profile data is hidden from sellers. Hence,
privacy of both sellers and buyers is preserved. Through privacy analysis and
performance evaluation, we show that PFET preserves users$'$ privacy in an
efficient manner.",0,1,0,0,0,0,0.602892,9.0,0.812336,19
http://arxiv.org/abs/2205.00034v2,What do we Really Know about State of the Art NER?,11,0.0659075,0.824037,"Named Entity Recognition (NER) is a well researched NLP task and is widely
used in real world NLP scenarios. NER research typically focuses on the
creation of new ways of training NER, with relatively less emphasis on
resources and evaluation. Further, state of the art (SOTA) NER models, trained
on standard datasets, typically report only a single performance measure
(F-score) and we don't really know how well they do for different entity types
and genres of text, or how robust are they to new, unseen entities. In this
paper, we perform a broad evaluation of NER using a popular dataset, that takes
into consideration various text genres and sources constituting the dataset at
hand. Additionally, we generate six new adversarial test sets through small
perturbations in the original test set, replacing select entities while
retaining the context. We also train and test our models on randomly generated
train/dev/test splits followed by an experiment where the models are trained on
a select set of genres but tested genres not seen in training. These
comprehensive evaluation strategies were performed using three SOTA NER models.
Based on our results, we recommend some useful reporting practices for NER
researchers, that could help in providing a better understanding of a SOTA
model's performance in future.",0,1,0,0,0,1,0.373935,4.0,0.40798,44
http://arxiv.org/abs/2212.04994v1,Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning,41,0.091832,0.858513,"We introduce Patch Aligned Contrastive Learning (PACL), a modified
compatibility function for CLIP's contrastive loss, intending to train an
alignment between the patch tokens of the vision encoder and the CLS token of
the text encoder. With such an alignment, a model can identify regions of an
image corresponding to a given text input, and therefore transfer seamlessly to
the task of open vocabulary semantic segmentation without requiring any
segmentation annotations during training. Using pre-trained CLIP encoders with
PACL, we are able to set the state-of-the-art on the task of open vocabulary
zero-shot segmentation on 4 different segmentation benchmarks: Pascal VOC,
Pascal Context, COCO Stuff and ADE20K. Furthermore, we show that PACL is also
applicable to image-level predictions and when used with a CLIP backbone,
provides a general improvement in zero-shot classification accuracy compared to
CLIP, across a suite of 12 image classification datasets.",0,1,0,0,1,0,0.650563,5.0,0.688143,64
http://arxiv.org/abs/2209.01416v1,MMKGR: Multi-hop Multi-modal Knowledge Graph Reasoning,11,0.269119,0.551736,"Multi-modal knowledge graphs (MKGs) include not only the relation triplets,
but also related multi-modal auxiliary data (i.e., texts and images), which
enhance the diversity of knowledge. However, the natural incompleteness has
significantly hindered the applications of MKGs. To tackle the problem,
existing studies employ the embedding-based reasoning models to infer the
missing knowledge after fusing the multi-modal features. However, the reasoning
performance of these methods is limited due to the following problems: (1)
ineffective fusion of multi-modal auxiliary features; (2) lack of complex
reasoning ability as well as inability to conduct the multi-hop reasoning which
is able to infer more missing knowledge. To overcome these problems, we propose
a novel model entitled MMKGR (Multi-hop Multi-modal Knowledge Graph Reasoning).
Specifically, the model contains the following two components: (1) a unified
gate-attention network which is designed to generate effective multi-modal
complementary features through sufficient attention interaction and noise
reduction; (2) a complementary feature-aware reinforcement learning method
which is proposed to predict missing elements by performing the multi-hop
reasoning process, based on the features obtained in component (1). The
experimental results demonstrate that MMKGR outperforms the state-of-the-art
approaches in the MKG reasoning task.",0,0,0,0,1,0,0.591417,9.0,0.808855,80
http://arxiv.org/abs/2202.09014v1,How Well Do Self-Supervised Methods Perform in Cross-Domain Few-Shot Learning?,3,0.00945542,0.0646932,"Cross-domain few-shot learning (CDFSL) remains a largely unsolved problem in
the area of computer vision, while self-supervised learning presents a
promising solution. Both learning methods attempt to alleviate the dependency
of deep networks on the requirement of large-scale labeled data. Although
self-supervised methods have recently advanced dramatically, their utility on
CDFSL is relatively unexplored. In this paper, we investigate the role of
self-supervised representation learning in the context of CDFSL via a thorough
evaluation of existing methods. It comes as a surprise that even with shallow
architectures or small training datasets, self-supervised methods can perform
favorably compared to the existing SOTA methods. Nevertheless, no single
self-supervised approach dominates all datasets indicating that existing
self-supervised methods are not universally applicable. In addition, we find
that representations extracted from self-supervised methods exhibit stronger
robustness than the supervised method. Intriguingly, whether self-supervised
representations perform well on the source domain has little correlation with
their applicability on the target domain. As part of our study, we conduct an
objective measurement of the performance for six kinds of representative
classifiers. The results suggest Prototypical Classifier as the standard
evaluation recipe for CDFSL.",0,1,0,0,0,0,0.834152,6.0,0.829417,45
http://arxiv.org/abs/2207.11984v2,RA-Depth: Resolution Adaptive Self-Supervised Monocular Depth Estimation,27,0.157666,0.906333,"Existing self-supervised monocular depth estimation methods can get rid of
expensive annotations and achieve promising results. However, these methods
suffer from severe performance degradation when directly adopting a model
trained on a fixed resolution to evaluate at other different resolutions. In
this paper, we propose a resolution adaptive self-supervised monocular depth
estimation method (RA-Depth) by learning the scale invariance of the scene
depth. Specifically, we propose a simple yet efficient data augmentation method
to generate images with arbitrary scales for the same scene. Then, we develop a
dual high-resolution network that uses the multi-path encoder and decoder with
dense interactions to aggregate multi-scale features for accurate depth
inference. Finally, to explicitly learn the scale invariance of the scene
depth, we formulate a cross-scale depth consistency loss on depth predictions
with different scales. Extensive experiments on the KITTI, Make3D and NYU-V2
datasets demonstrate that RA-Depth not only achieves state-of-the-art
performance, but also exhibits a good ability of resolution adaptation.",1,1,1,0,1,0,0.523843,9.0,0.788018,49
http://arxiv.org/abs/2203.01576v1,Occlusion-Aware Cost Constructor for Light Field Depth Estimation,43,0.6119,0.991032,"Matching cost construction is a key step in light field (LF) depth
estimation, but was rarely studied in the deep learning era. Recent deep
learning-based LF depth estimation methods construct matching cost by
sequentially shifting each sub-aperture image (SAI) with a series of predefined
offsets, which is complex and time-consuming. In this paper, we propose a
simple and fast cost constructor to construct matching cost for LF depth
estimation. Our cost constructor is composed by a series of convolutions with
specifically designed dilation rates. By applying our cost constructor to SAI
arrays, pixels under predefined disparities can be integrated and matching cost
can be constructed without using any shifting operation. More importantly, the
proposed cost constructor is occlusion-aware and can handle occlusions by
dynamically modulating pixels from different views. Based on the proposed cost
constructor, we develop a deep network for LF depth estimation. Our network
ranks first on the commonly used 4D LF benchmark in terms of the mean square
error (MSE), and achieves a faster running time than other state-of-the-art
methods.",0,1,0,0,1,0,0.593536,8.0,0.785686,42
http://arxiv.org/abs/2211.13225v1,Learning to Imitate Object Interactions from Internet Videos,14,0.0413555,0.693131,"We study the problem of imitating object interactions from Internet videos.
This requires understanding the hand-object interactions in 4D, spatially in 3D
and over time, which is challenging due to mutual hand-object occlusions. In
this paper we make two main contributions: (1) a novel reconstruction technique
RHOV (Reconstructing Hands and Objects from Videos), which reconstructs 4D
trajectories of both the hand and the object using 2D image cues and temporal
smoothness constraints; (2) a system for imitating object interactions in a
physics simulator with reinforcement learning. We apply our reconstruction
technique to 100 challenging Internet videos. We further show that we can
successfully imitate a range of different object interactions in a physics
simulator. Our object-centric approach is not limited to human-like
end-effectors and can learn to imitate object interactions using different
embodiments, like a robotic arm with a parallel jaw gripper.",0,1,0,0,0,0,0.149447,7.0,0.509941,66
http://arxiv.org/abs/2210.15933v1,PSFormer: Point Transformer for 3D Salient Object Detection,1,0.00732024,0.0202627,"We propose PSFormer, an effective point transformer model for 3D salient
object detection. PSFormer is an encoder-decoder network that takes full
advantage of transformers to model the contextual information in both
multi-scale point- and scene-wise manners. In the encoder, we develop a Point
Context Transformer (PCT) module to capture region contextual features at the
point level; PCT contains two different transformers to excavate the
relationship among points. In the decoder, we develop a Scene Context
Transformer (SCT) module to learn context representations at the scene level;
SCT contains both Upsampling-and-Transformer blocks and Multi-context
Aggregation units to integrate the global semantic and multi-level features
from the encoder into the global scene context. Experiments show clear
improvements of PSFormer over its competitors and validate that PSFormer is
more robust to challenging cases such as small objects, multiple objects, and
objects with complex structures.",0,1,0,0,1,0,0.899941,6.0,0.870723,15
http://arxiv.org/abs/2208.05787v1,Unsupervised Face Morphing Attack Detection via Self-paced Anomaly Detection,7,0.404072,0.688597,"The supervised-learning-based morphing attack detection (MAD) solutions
achieve outstanding success in dealing with attacks from known morphing
techniques and known data sources. However, given variations in the morphing
attacks, the performance of supervised MAD solutions drops significantly due to
the insufficient diversity and quantity of the existing MAD datasets. To
address this concern, we propose a completely unsupervised MAD solution via
self-paced anomaly detection (SPL-MAD) by leveraging the existing large-scale
face recognition (FR) datasets and the unsupervised nature of convolutional
autoencoders. Using general FR datasets that might contain unintentionally and
unlabeled manipulated samples to train an autoencoder can lead to a diverse
reconstruction behavior of attack and bona fide samples. We analyze this
behavior empirically to provide a solid theoretical ground for designing our
unsupervised MAD solution. This also results in proposing to integrate our
adapted modified self-paced learning paradigm to enhance the reconstruction
error separability between the bona fide and attack samples in a completely
unsupervised manner. Our experimental results on a diverse set of MAD
evaluation datasets show that the proposed unsupervised SPL-MAD solution
outperforms the overall performance of a wide range of supervised MAD solutions
and provides higher generalizability on unknown attacks.",1,1,0,0,0,0,0.935243,8.0,0.924683,55
http://arxiv.org/abs/2210.11543v1,Object Goal Navigation Based on Semantics and RGB Ego View,1,0.0156557,0.0419559,"This paper presents an architecture and methodology to empower a service
robot to navigate an indoor environment with semantic decision making, given
RGB ego view. This method leverages the knowledge of robot's actuation
capability and that of scenes, objects and their relations -- represented in a
semantic form. The robot navigates based on GeoSem map - a relational
combination of geometric and semantic map. The goal given to the robot is to
find an object in a unknown environment with no navigational map and only
egocentric RGB camera perception. The approach is tested both on a simulation
environment and real life indoor settings. The presented approach was found to
outperform human users in gamified evaluations with respect to average
completion time.",0,1,0,0,0,0,0.168414,10.0,0.670003,13
http://arxiv.org/abs/2204.07288v1,Characterizing the Efficiency vs. Accuracy Trade-off for Long-Context NLP Models,5,0.117798,0.35213,"With many real-world applications of Natural Language Processing (NLP)
comprising of long texts, there has been a rise in NLP benchmarks that measure
the accuracy of models that can handle longer input sequences. However, these
benchmarks do not consider the trade-offs between accuracy, speed, and power
consumption as input sizes or model sizes are varied. In this work, we perform
a systematic study of this accuracy vs. efficiency trade-off on two widely used
long-sequence models - Longformer-Encoder-Decoder (LED) and Big Bird - during
fine-tuning and inference on four datasets from the SCROLLS benchmark. To study
how this trade-off differs across hyperparameter settings, we compare the
models across four sequence lengths (1024, 2048, 3072, 4096) and two model
sizes (base and large) under a fixed resource budget. We find that LED
consistently achieves better accuracy at lower energy costs than Big Bird. For
summarization, we find that increasing model size is more energy efficient than
increasing sequence length for higher accuracy. However, this comes at the cost
of a large drop in inference speed. For question answering, we find that
smaller models are both more efficient and more accurate due to the larger
training batch sizes possible under a fixed resource budget.",1,1,0,0,0,0,0.97273,5.0,0.934407,23
http://arxiv.org/abs/2210.02506v1,Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors,5,0.294035,0.786445,"Video game testing requires game-specific knowledge as well as common sense
reasoning about the events in the game. While AI-driven agents can satisfy the
first requirement, it is not yet possible to meet the second requirement
automatically. Therefore, video game testing often still relies on manual
testing, and human testers are required to play the game thoroughly to detect
bugs. As a result, it is challenging to fully automate game testing. In this
study, we explore the possibility of leveraging the zero-shot capabilities of
large language models for video game bug detection. By formulating the bug
detection problem as a question-answering task, we show that large language
models can identify which event is buggy in a sequence of textual descriptions
of events from a game. To this end, we introduce the GameBugDescriptions
benchmark dataset, which consists of 167 buggy gameplay videos and a total of
334 question-answer pairs across 8 games. We extensively evaluate the
performance of six models across the OPT and InstructGPT large language model
families on our benchmark dataset. Our results show promising results for
employing language models to detect video game bugs. With the proper prompting
technique, we could achieve an accuracy of 70.66%, and on some video games, up
to 78.94%. Our code, evaluation data and the benchmark can be found on
https://asgaardlab.github.io/LLMxBugs",0,1,0,1,0,0,0.940052,4.0,0.856317,54
http://arxiv.org/abs/2203.05789v1,FLAG: Flow-based 3D Avatar Generation from Sparse Observations,35,0.308601,0.894228,"To represent people in mixed reality applications for collaboration and
communication, we need to generate realistic and faithful avatar poses.
However, the signal streams that can be applied for this task from head-mounted
devices (HMDs) are typically limited to head pose and hand pose estimates.
While these signals are valuable, they are an incomplete representation of the
human body, making it challenging to generate a faithful full-body avatar. We
address this challenge by developing a flow-based generative model of the 3D
human body from sparse observations, wherein we learn not only a conditional
distribution of 3D human pose, but also a probabilistic mapping from
observations to the latent space from which we can generate a plausible pose
along with uncertainty estimates for the joints. We show that our approach is
not only a strong predictive model, but can also act as an efficient pose prior
in different optimization settings where a good initial latent code plays a
major role.",0,1,0,0,0,0,0.826667,5.0,0.790326,56
http://arxiv.org/abs/2206.08362v3,Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces,13,0.268472,0.57126,"We introduce a unified framework for group equivariant networks on
homogeneous spaces derived from a Fourier perspective. We consider
tensor-valued feature fields, before and after a convolutional layer. We
present a unified derivation of kernels via the Fourier domain by leveraging
the sparsity of Fourier coefficients of the lifted feature fields. The sparsity
emerges when the stabilizer subgroup of the homogeneous space is a compact Lie
group. We further introduce a nonlinear activation, via an elementwise
nonlinearity on the regular representation after lifting and projecting back to
the field through an equivariant convolution. We show that other methods
treating features as the Fourier coefficients in the stabilizer subgroup are
special cases of our activation. Experiments on $SO(3)$ and $SE(3)$ show
state-of-the-art performance in spherical vector field regression, point cloud
classification, and molecular completion.",0,0,0,0,1,0,0.869669,7.0,0.871768,54
http://arxiv.org/abs/2212.06711v4,On Text-based Personality Computing: Challenges and Future Directions,3,0.159961,0.273428,"Text-based personality computing (TPC) has gained many research interests in
NLP. In this paper, we describe 15 challenges that we consider deserving the
attention of the research community. These challenges are organized by the
following topics: personality taxonomies, measurement quality, datasets,
performance evaluation, modelling choices, as well as ethics and fairness. When
addressing each challenge, not only do we combine perspectives from both NLP
and social sciences, but also offer concrete suggestions. We hope to inspire
more valid and reliable TPC research.",0,0,0,0,0,0,0.263821,11.0,0.746119,151
http://arxiv.org/abs/2203.13620v1,Semi-Supervised Formality Style Transfer with Consistency Training,12,0.130388,0.750027,"Formality style transfer (FST) is a task that involves paraphrasing an
informal sentence into a formal one without altering its meaning. To address
the data-scarcity problem of existing parallel datasets, previous studies tend
to adopt a cycle-reconstruction scheme to utilize additional unlabeled data,
where the FST model mainly benefits from target-side unlabeled sentences. In
this work, we propose a simple yet effective semi-supervised framework to
better utilize source-side unlabeled sentences based on consistency training.
Specifically, our approach augments pseudo-parallel data obtained from a
source-side informal sentence by enforcing the model to generate similar
outputs for its perturbed version. Moreover, we empirically examined the
effects of various data perturbation methods and propose effective data
filtering strategies to improve our framework. Experimental results on the
GYAFC benchmark demonstrate that our approach can achieve state-of-the-art
results, even with less than 40% of the parallel data.",1,1,0,0,1,0,0.768217,6.0,0.795056,38
http://arxiv.org/abs/2205.07014v1,SaiNet: Stereo aware inpainting behind objects with generative networks,1,0.0463467,0.0739639,"In this work, we present an end-to-end network for stereo-consistent image
inpainting with the objective of inpainting large missing regions behind
objects. The proposed model consists of an edge-guided UNet-like network using
Partial Convolutions. We enforce multi-view stereo consistency by introducing a
disparity loss. More importantly, we develop a training scheme where the model
is learned from realistic stereo masks representing object occlusions, instead
of the more common random masks. The technique is trained in a supervised way.
Our evaluation shows competitive results compared to previous state-of-the-art
techniques.",0,1,0,0,1,0,0.698283,14.0,0.89796,38
http://arxiv.org/abs/2203.09555v1,On the expressive power of message-passing neural networks as global feature map transformers,5,0.0883166,0.376225,"We investigate the power of message-passing neural networks (MPNNs) in their
capacity to transform the numerical features stored in the nodes of their input
graphs. Our focus is on global expressive power, uniformly over all input
graphs, or over graphs of bounded degree with features from a bounded domain.
Accordingly, we introduce the notion of a global feature map transformer
(GFMT). As a yardstick for expressiveness, we use a basic language for GFMTs,
which we call MPLang. Every MPNN can be expressed in MPLang, and our results
clarify to which extent the converse inclusion holds. We consider exact versus
approximate expressiveness; the use of arbitrary activation functions; and the
case where only the ReLU activation function is allowed.",0,0,0,0,0,0,0.711486,7.0,0.801157,24
http://arxiv.org/abs/2212.06344v3,DA Wand: Distortion-Aware Selection using Neural Mesh Parameterization,2,0.0525868,0.109653,"We present a neural technique for learning to select a local sub-region
around a point which can be used for mesh parameterization. The motivation for
our framework is driven by interactive workflows used for decaling, texturing,
or painting on surfaces. Our key idea is to incorporate segmentation
probabilities as weights of a classical parameterization method, implemented as
a novel differentiable parameterization layer within a neural network
framework. We train a segmentation network to select 3D regions that are
parameterized into 2D and penalized by the resulting distortion, giving rise to
segmentations which are distortion-aware. Following training, a user can use
our system to interactively select a point on the mesh and obtain a large,
meaningful region around the selection which induces a low-distortion
parameterization. Our code and project page are currently available.",1,1,0,0,0,0,0.0170548,21.0,0.729897,82
http://arxiv.org/abs/2212.10190v1,Pay Attention to Your Tone: Introducing a New Dataset for Polite Language Rewrite,2,0.0325068,0.205569,"We introduce \textsc{PoliteRewrite} -- a dataset for polite language rewrite
which is a novel sentence rewrite task. Compared with previous text style
transfer tasks that can be mostly addressed by slight token- or phrase-level
edits, polite language rewrite requires deep understanding and extensive
sentence-level edits over an offensive and impolite sentence to deliver the
same message euphemistically and politely, which is more challenging -- not
only for NLP models but also for human annotators to rewrite with effort. To
alleviate the human effort for efficient annotation, we first propose a novel
annotation paradigm by a collaboration of human annotators and GPT-3.5 to
annotate \textsc{PoliteRewrite}. The released dataset has 10K polite sentence
rewrites annotated collaboratively by GPT-3.5 and human, which can be used as
gold standard for training, validation and test; and 100K high-quality polite
sentence rewrites by GPT-3.5 without human review. We wish this work (The
dataset (10K+100K) will be released soon) could contribute to the research on
more challenging sentence rewrite, and provoke more thought in future on
resource annotation paradigm with the help of the large-scaled pretrained
models.",0,1,1,1,0,0,0.907591,7.0,0.894043,9
http://arxiv.org/abs/2209.13495v1,Personalized Game Difficulty Prediction Using Factorization Machines,2,0.0312273,0.228748,"The accurate and personalized estimation of task difficulty provides many
opportunities for optimizing user experience. However, user diversity makes
such difficulty estimation hard, in that empirical measurements from some user
sample do not necessarily generalize to others. In this paper, we contribute a
new approach for personalized difficulty estimation of game levels, borrowing
methods from content recommendation. Using factorization machines (FM) on a
large dataset from a commercial puzzle game, we are able to predict difficulty
as the number of attempts a player requires to pass future game levels, based
on observed attempt counts from earlier levels and levels played by others. In
addition to performance and scalability, FMs offer the benefit that the learned
latent variable model can be used to study the characteristics of both players
and game levels that contribute to difficulty. We compare the approach to a
simple non-personalized baseline and a personalized prediction using Random
Forests. Our results suggest that FMs are a promising tool enabling game
designers to both optimize player experience and learn more about their players
and the game.",0,1,0,1,0,0,0.0082174,11.0,0.417562,57
http://arxiv.org/abs/2203.04713v6,Defending Black-box Skeleton-based Human Activity Classifiers,6,0.130484,0.62166,"Skeletal motions have been heavily replied upon for human activity
recognition (HAR). Recently, a universal vulnerability of skeleton-based HAR
has been identified across a variety of classifiers and data, calling for
mitigation. To this end, we propose the first black-box defense method for
skeleton-based HAR to our best knowledge. Our method is featured by full
Bayesian treatments of the clean data, the adversaries and the classifier,
leading to (1) a new Bayesian Energy-based formulation of robust discriminative
classifiers, (2) a new adversary sampling scheme based on natural motion
manifolds, and (3) a new post-train Bayesian strategy for black-box defense. We
name our framework Bayesian Energy-based Adversarial Training or BEAT. BEAT is
straightforward but elegant, which turns vulnerable black-box classifiers into
robust ones without sacrificing accuracy. It demonstrates surprising and
universal effectiveness across a wide range of skeletal HAR classifiers and
datasets, under various attacks. Code is available at
https://github.com/realcrane/RobustActionRecogniser.",0,0,0,0,0,0,0.812657,6.0,0.81771,80
http://arxiv.org/abs/2202.05685v1,SuperCon: Supervised Contrastive Learning for Imbalanced Skin Lesion Classification,3,0.0697215,0.292919,"Convolutional neural networks (CNNs) have achieved great success in skin
lesion classification. A balanced dataset is required to train a good model.
However, due to the appearance of different skin lesions in practice, severe or
even deadliest skin lesion types (e.g., melanoma) naturally have quite small
amount represented in a dataset. In that, classification performance
degradation occurs widely, it is significantly important to have CNNs that work
well on class imbalanced skin lesion image dataset. In this paper, we propose
SuperCon, a two-stage training strategy to overcome the class imbalance problem
on skin lesion classification. It contains two stages: (i) representation
training that tries to learn a feature representation that closely aligned
among intra-classes and distantly apart from inter-classes, and (ii) classifier
fine-tuning that aims to learn a classifier that correctly predict the label
based on the learnt representations. In the experimental evaluation, extensive
comparisons have been made among our approach and other existing approaches on
skin lesion benchmark datasets. The results show that our two-stage training
strategy effectively addresses the class imbalance classification problem, and
significantly improves existing works in terms of F1-score and AUC score,
resulting in state-of-the-art performance.",1,1,0,0,1,0,0.769214,8.0,0.84666,37
http://arxiv.org/abs/2206.03132v2,CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities,5,0.0279029,0.473595,"An increasing number of monitoring systems have been developed in smart
cities to ensure that real-time operations of a city satisfy safety and
performance requirements. However, many existing city requirements are written
in English with missing, inaccurate, or ambiguous information. There is a high
demand for assisting city policy makers in converting human-specified
requirements to machine-understandable formal specifications for monitoring
systems. To tackle this limitation, we build CitySpec, the first intelligent
assistant system for requirement specification in smart cities. To create
CitySpec, we first collect over 1,500 real-world city requirements across
different domains from over 100 cities and extract city-specific knowledge to
generate a dataset of city vocabulary with 3,061 words. We also build a
translation model and enhance it through requirement synthesis and develop a
novel online learning framework with validation under uncertainty. The
evaluation results on real-world city requirements show that CitySpec increases
the sentence-level accuracy of requirement specification from 59.02% to 86.64%,
and has strong adaptability to a new city and a new domain (e.g., F1 score for
requirements in Seattle increases from 77.6% to 93.75% with online learning).",0,1,0,1,0,0,0.383235,9.0,0.740375,18
http://arxiv.org/abs/2201.02861v2,Decoupling Makes Weakly Supervised Local Feature Better,31,0.320163,0.90894,"Weakly supervised learning can help local feature methods to overcome the
obstacle of acquiring a large-scale dataset with densely labeled
correspondences. However, since weak supervision cannot distinguish the losses
caused by the detection and description steps, directly conducting weakly
supervised learning within a joint describe-then-detect pipeline suffers
limited performance. In this paper, we propose a decoupled describe-then-detect
pipeline tailored for weakly supervised local feature learning. Within our
pipeline, the detection step is decoupled from the description step and
postponed until discriminative and robust descriptors are learned. In addition,
we introduce a line-to-window search strategy to explicitly use the camera pose
information for better descriptor learning. Extensive experiments show that our
method, namely PoSFeat (Camera Pose Supervised Feature), outperforms previous
fully and weakly supervised methods and achieves state-of-the-art performance
on a wide range of downstream tasks.",1,0,0,0,0,0,0.669208,8.0,0.811444,60
http://arxiv.org/abs/2206.01332v3,Optimal Activation Functions for the Random Features Regression Model,2,0.0,0.161977,"The asymptotic mean squared test error and sensitivity of the Random Features
Regression model (RFR) have been recently studied. We build on this work and
identify in closed-form the family of Activation Functions (AFs) that minimize
a combination of the test error and sensitivity of the RFR under different
notions of functional parsimony. We find scenarios under which the optimal AFs
are linear, saturated linear functions, or expressible in terms of Hermite
polynomials. Finally, we show how using optimal AFs impacts well-established
properties of the RFR model, such as its double descent curve, and the
dependency of its optimal regularization parameter on the observation noise
level.",1,0,0,0,0,0,0.407855,8.0,0.718038,80
http://arxiv.org/abs/2203.15685v1,EnvEdit: Environment Editing for Vision-and-Language Navigation,50,0.377016,0.72194,"In Vision-and-Language Navigation (VLN), an agent needs to navigate through
the environment based on natural language instructions. Due to limited
available data for agent training and finite diversity in navigation
environments, it is challenging for the agent to generalize to new, unseen
environments. To address this problem, we propose EnvEdit, a data augmentation
method that creates new environments by editing existing environments, which
are used to train a more generalizable agent. Our augmented environments can
differ from the seen environments in three diverse aspects: style, object
appearance, and object classes. Training on these edit-augmented environments
prevents the agent from overfitting to existing environments and helps
generalize better to new, unseen environments. Empirically, on both the
Room-to-Room and the multi-lingual Room-Across-Room datasets, we show that our
proposed EnvEdit method gets significant improvements in all metrics on both
pre-trained and non-pre-trained VLN agents, and achieves the new
state-of-the-art on the test leaderboard. We further ensemble the VLN agents
augmented on different edited environments and show that these edit methods are
complementary. Code and data are available at
https://github.com/jialuli-luka/EnvEdit",1,1,0,1,1,0,0.537455,7.0,0.73293,81
http://arxiv.org/abs/2204.07300v1,Dense Learning based Semi-Supervised Object Detection,35,0.540066,0.864572,"Semi-supervised object detection (SSOD) aims to facilitate the training and
deployment of object detectors with the help of a large amount of unlabeled
data. Though various self-training based and consistency-regularization based
SSOD methods have been proposed, most of them are anchor-based detectors,
ignoring the fact that in many real-world applications anchor-free detectors
are more demanded. In this paper, we intend to bridge this gap and propose a
DenSe Learning (DSL) based anchor-free SSOD algorithm. Specifically, we achieve
this goal by introducing several novel techniques, including an Adaptive
Filtering strategy for assigning multi-level and accurate dense pixel-wise
pseudo-labels, an Aggregated Teacher for producing stable and precise
pseudo-labels, and an uncertainty-consistency-regularization term among scales
and shuffled patches for improving the generalization capability of the
detector. Extensive experiments are conducted on MS-COCO and PASCAL-VOC, and
the results show that our proposed DSL method records new state-of-the-art SSOD
performance, surpassing existing methods by a large margin. Codes can be found
at \textcolor{blue}{https://github.com/chenbinghui1/DSL}.",1,1,0,0,1,0,0.922369,7.0,0.904132,52
http://arxiv.org/abs/2210.11204v1,PalGAN: Image Colorization with Palette Generative Adversarial Networks,13,0.0361106,0.595831,"Multimodal ambiguity and color bleeding remain challenging in colorization.
To tackle these problems, we propose a new GAN-based colorization approach
PalGAN, integrated with palette estimation and chromatic attention. To
circumvent the multimodality issue, we present a new colorization formulation
that estimates a probabilistic palette from the input gray image first, then
conducts color assignment conditioned on the palette through a generative
model. Further, we handle color bleeding with chromatic attention. It studies
color affinities by considering both semantic and intensity correlation. In
extensive experiments, PalGAN outperforms state-of-the-arts in quantitative
evaluation and visual comparison, delivering notable diverse, contrastive, and
edge-preserving appearances. With the palette design, our method enables color
transfer between images even with irrelevant contexts.",1,1,0,0,1,0,0.0755181,10.0,0.584618,58
http://arxiv.org/abs/2207.06202v3,Adversarially-Aware Robust Object Detector,14,0.0602321,0.641784,"Object detection, as a fundamental computer vision task, has achieved a
remarkable progress with the emergence of deep neural networks. Nevertheless,
few works explore the adversarial robustness of object detectors to resist
adversarial attacks for practical applications in various real-world scenarios.
Detectors have been greatly challenged by unnoticeable perturbation, with sharp
performance drop on clean images and extremely poor performance on adversarial
images. In this work, we empirically explore the model training for adversarial
robustness in object detection, which greatly attributes to the conflict
between learning clean images and adversarial images. To mitigate this issue,
we propose a Robust Detector (RobustDet) based on adversarially-aware
convolution to disentangle gradients for model learning on clean and
adversarial images. RobustDet also employs the Adversarial Image Discriminator
(AID) and Consistent Features with Reconstruction (CFR) to ensure a reliable
robustness. Extensive experiments on PASCAL VOC and MS-COCO demonstrate that
our model effectively disentangles gradients and significantly enhances the
detection robustness with maintaining the detection ability on clean images.",1,1,0,0,1,0,0.54403,10.0,0.814891,38
http://arxiv.org/abs/2207.12317v1,ALTO: A Large-Scale Dataset for UAV Visual Place Recognition and Localization,9,0.0382027,0.812782,"We present the ALTO dataset, a vision-focused dataset for the development and
benchmarking of Visual Place Recognition and Localization methods for Unmanned
Aerial Vehicles. The dataset is composed of two long (approximately 150km and
260km) trajectories flown by a helicopter over Ohio and Pennsylvania, and it
includes high precision GPS-INS ground truth location data, high precision
accelerometer readings, laser altimeter readings, and RGB downward facing
camera imagery. In addition, we provide reference imagery over the flight
paths, which makes this dataset suitable for VPR benchmarking and other tasks
common in Localization, such as image registration and visual odometry. To the
author's knowledge, this is the largest real-world aerial-vehicle dataset of
this kind. Our dataset is available at https://github.com/MetaSLAM/ALTO.",1,1,1,1,0,0,0.000497266,19.0,0.51497,5
http://arxiv.org/abs/2203.01296v1,Half Wavelet Attention on M-Net+ for Low-Light Image Enhancement,35,0.649534,0.895265,"Low-Light Image Enhancement is a computer vision task which intensifies the
dark images to appropriate brightness. It can also be seen as an ill-posed
problem in image restoration domain. With the success of deep neural networks,
the convolutional neural networks surpass the traditional algorithm-based
methods and become the mainstream in the computer vision area. To advance the
performance of enhancement algorithms, we propose an image enhancement network
(HWMNet) based on an improved hierarchical model: M-Net+. Specifically, we use
a half wavelet attention block on M-Net+ to enrich the features from wavelet
domain. Furthermore, our HWMNet has competitive performance results on two
image enhancement datasets in terms of quantitative metrics and visual quality.
The source code and pretrained model are available at
https://github.com/FanChiMao/HWMNet.",1,1,0,0,1,0,0.8586,6.0,0.843591,41
http://arxiv.org/abs/2204.07580v2,mGPT: Few-Shot Learners Go Multilingual,87,0.45172,0.847959,"Recent studies report that autoregressive language models can successfully
solve many NLP tasks via zero- and few-shot learning paradigms, which opens up
new possibilities for using the pre-trained language models. This paper
introduces two autoregressive GPT-like models with 1.3 billion and 13 billion
parameters trained on 60 languages from 25 language families using Wikipedia
and Colossal Clean Crawled Corpus. We reproduce the GPT-3 architecture using
GPT-2 sources and the sparse attention mechanism; Deepspeed and Megatron
frameworks allow us to parallelize the training and inference steps
effectively. The resulting models show performance on par with the recently
released XGLM models by Facebook, covering more languages and enhancing NLP
possibilities for low resource languages of CIS countries and Russian small
nations. We detail the motivation for the choices of the architecture design,
thoroughly describe the data preparation pipeline, and train five small
versions of the model to choose the most optimal multilingual tokenization
strategy. We measure the model perplexity in all covered languages and evaluate
it on the wide spectre of multilingual tasks, including classification,
generative, sequence labeling and knowledge probing. The models were evaluated
with the zero-shot and few-shot methods. Furthermore, we compared the
classification tasks with the state-of-the-art multilingual model XGLM. source
code and the mGPT XL model are publicly released.",0,1,0,0,0,0,0.773643,4.0,0.696603,115
http://arxiv.org/abs/2204.11673v1,Incorporating Explicit Knowledge in Pre-trained Language Models for Passage Re-ranking,16,0.0542346,0.554433,"Passage re-ranking is to obtain a permutation over the candidate passage set
from retrieval stage. Re-rankers have been boomed by Pre-trained Language
Models (PLMs) due to their overwhelming advantages in natural language
understanding. However, existing PLM based re-rankers may easily suffer from
vocabulary mismatch and lack of domain specific knowledge. To alleviate these
problems, explicit knowledge contained in knowledge graph is carefully
introduced in our work. Specifically, we employ the existing knowledge graph
which is incomplete and noisy, and first apply it in passage re-ranking task.
To leverage a reliable knowledge, we propose a novel knowledge graph
distillation method and obtain a knowledge meta graph as the bridge between
query and passage. To align both kinds of embedding in the latent space, we
employ PLM as text encoder and graph neural network over knowledge meta graph
as knowledge encoder. Besides, a novel knowledge injector is designed for the
dynamic interaction between text and knowledge encoder. Experimental results
demonstrate the effectiveness of our method especially in queries requiring
in-depth domain knowledge.",1,1,0,0,0,0,0.40783,6.0,0.624037,53
http://arxiv.org/abs/2211.12040v3,Rethinking Implicit Neural Representations for Vision Learners,5,0.0222409,0.252537,"Implicit Neural Representations (INRs) are powerful to parameterize
continuous signals in computer vision. However, almost all INRs methods are
limited to low-level tasks, e.g., image/video compression, super-resolution,
and image generation. The questions on how to explore INRs to high-level tasks
and deep networks are still under-explored. Existing INRs methods suffer from
two problems: 1) narrow theoretical definitions of INRs are inapplicable to
high-level tasks; 2) lack of representation capabilities to deep networks.
Motivated by the above facts, we reformulate the definitions of INRs from a
novel perspective and propose an innovative Implicit Neural Representation
Network (INRN), which is the first study of INRs to tackle both low-level and
high-level tasks. Specifically, we present three key designs for basic blocks
in INRN along with two different stacking ways and corresponding loss
functions. Extensive experiments with analysis on both low-level tasks (image
fitting) and high-level vision tasks (image classification, object detection,
instance segmentation) demonstrate the effectiveness of the proposed method.",0,0,0,0,0,0,0.720557,6.0,0.772246,26
http://arxiv.org/abs/2212.09254v1,TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization,9,0.0445343,0.591278,"Robustness evaluation against adversarial examples has become increasingly
important to unveil the trustworthiness of the prevailing deep models in
natural language processing (NLP). However, in contrast to the computer vision
domain where the first-order projected gradient descent (PGD) is used as the
benchmark approach to generate adversarial examples for robustness evaluation,
there lacks a principled first-order gradient-based robustness evaluation
framework in NLP. The emerging optimization challenges lie in 1) the discrete
nature of textual inputs together with the strong coupling between the
perturbation location and the actual content, and 2) the additional constraint
that the perturbed text should be fluent and achieve a low perplexity under a
language model. These challenges make the development of PGD-like NLP attacks
difficult. To bridge the gap, we propose TextGrad, a new attack generator using
gradient-driven optimization, supporting high-accuracy and high-quality
assessment of adversarial robustness in NLP. Specifically, we address the
aforementioned challenges in a unified optimization framework. And we develop
an effective convex relaxation method to co-optimize the continuously-relaxed
site selection and perturbation variables and leverage an effective sampling
method to establish an accurate mapping from the continuous optimization
variables to the discrete textual perturbations. Moreover, as a first-order
attack generation method, TextGrad can be baked into adversarial training to
further improve the robustness of NLP models. Extensive experiments are
provided to demonstrate the effectiveness of TextGrad not only in attack
generation for robustness evaluation but also in adversarial defense.",1,1,0,0,1,0,0.616703,8.0,0.79358,64
http://arxiv.org/abs/2204.07061v1,Egocentric Human-Object Interaction Detection Exploiting Synthetic Data,13,0.332866,0.762107,"We consider the problem of detecting Egocentric HumanObject Interactions
(EHOIs) in industrial contexts. Since collecting and labeling large amounts of
real images is challenging, we propose a pipeline and a tool to generate
photo-realistic synthetic First Person Vision (FPV) images automatically
labeled for EHOI detection in a specific industrial scenario. To tackle the
problem of EHOI detection, we propose a method that detects the hands, the
objects in the scene, and determines which objects are currently involved in an
interaction. We compare the performance of our method with a set of
state-of-the-art baselines. Results show that using a synthetic dataset
improves the performance of an EHOI detection system, especially when few real
data are available. To encourage research on this topic, we publicly release
the proposed dataset at the following url:
https://iplab.dmi.unict.it/EHOI_SYNTH/.",1,1,0,1,0,0,0.593744,9.0,0.809562,35
http://arxiv.org/abs/2210.12410v1,The Shared Task on Gender Rewriting,1,0.019977,0.134897,"In this paper, we present the results and findings of the Shared Task on
Gender Rewriting, which was organized as part of the Seventh Arabic Natural
Language Processing Workshop. The task of gender rewriting refers to generating
alternatives of a given sentence to match different target user gender contexts
(e.g., female speaker with a male listener, a male speaker with a male
listener, etc.). This requires changing the grammatical gender (masculine or
feminine) of certain words referring to the users. In this task, we focus on
Arabic, a gender-marking morphologically rich language. A total of five teams
from four countries participated in the shared task.",1,1,1,1,0,0,0.788069,7.0,0.832826,37
http://arxiv.org/abs/2207.12381v1,LightX3ECG: A Lightweight and eXplainable Deep Learning System for 3-lead Electrocardiogram Classification,15,0.38556,0.964725,"Cardiovascular diseases (CVDs) are a group of heart and blood vessel
disorders that is one of the most serious dangers to human health, and the
number of such patients is still growing. Early and accurate detection plays a
key role in successful treatment and intervention. Electrocardiogram (ECG) is
the gold standard for identifying a variety of cardiovascular abnormalities. In
clinical practices and most of the current research, standard 12-lead ECG is
mainly used. However, using a lower number of leads can make ECG more prevalent
as it can be conveniently recorded by portable or wearable devices. In this
research, we develop a novel deep learning system to accurately identify
multiple cardiovascular abnormalities by using only three ECG leads.",1,1,0,0,1,0,0.499561,9.0,0.780309,73
http://arxiv.org/abs/2206.14264v1,Simple and Effective Knowledge-Driven Query Expansion for QA-Based Product Attribute Extraction,10,0.140728,0.338282,"A key challenge in attribute value extraction (AVE) from e-commerce sites is
how to handle a large number of attributes for diverse products. Although this
challenge is partially addressed by a question answering (QA) approach which
finds a value in product data for a given query (attribute), it does not work
effectively for rare and ambiguous queries. We thus propose simple
knowledge-driven query expansion based on possible answers (values) of a query
(attribute) for QA-based AVE. We retrieve values of a query (attribute) from
the training data to expand the query. We train a model with two tricks,
knowledge dropout and knowledge token mixing, which mimic the imperfection of
the value knowledge in testing. Experimental results on our cleaned version of
AliExpress dataset show that our method improves the performance of AVE (+6.08
macro F1), especially for rare and ambiguous attributes (+7.82 and +6.86 macro
F1, respectively).",1,1,0,0,0,0,0.310998,7.0,0.62901,24
http://arxiv.org/abs/2204.07553v2,Improving Rare Word Recognition with LM-aware MWER Training,11,0.086362,0.807174,"Language models (LMs) significantly improve the recognition accuracy of
end-to-end (E2E) models on words rarely seen during training, when used in
either the shallow fusion or the rescoring setups. In this work, we introduce
LMs in the learning of hybrid autoregressive transducer (HAT) models in the
discriminative training framework, to mitigate the training versus inference
gap regarding the use of LMs. For the shallow fusion setup, we use LMs during
both hypotheses generation and loss computation, and the LM-aware MWER-trained
model achieves 10\% relative improvement over the model trained with standard
MWER on voice search test sets containing rare words. For the rescoring setup,
we learn a small neural module to generate per-token fusion weights in a
data-dependent manner. This model achieves the same rescoring WER as regular
MWER-trained model, but without the need for sweeping fusion weights.",0,1,0,0,0,0,0.132941,9.0,0.604799,35
http://arxiv.org/abs/2207.09025v1,Indoor Localization for Personalized Ambient Assisted Living of Multiple Users in Multi-Floor Smart Environments,22,0.148757,0.916186,"This paper presents a multifunctional interdisciplinary framework that makes
four scientific contributions towards the development of personalized ambient
assisted living, with a specific focus to address the different and dynamic
needs of the diverse aging population in the future of smart living
environments. First, it presents a probabilistic reasoning-based mathematical
approach to model all possible forms of user interactions for any activity
arising from the user diversity of multiple users in such environments. Second,
it presents a system that uses this approach with a machine learning method to
model individual user profiles and user-specific user interactions for
detecting the dynamic indoor location of each specific user. Third, to address
the need to develop highly accurate indoor localization systems for increased
trust, reliance, and seamless user acceptance, the framework introduces a novel
methodology where two boosting approaches Gradient Boosting and the AdaBoost
algorithm are integrated and used on a decision tree-based learning model to
perform indoor localization. Fourth, the framework introduces two novel
functionalities to provide semantic context to indoor localization in terms of
detecting each user's floor-specific location as well as tracking whether a
specific user was located inside or outside a given spatial region in a
multi-floor-based indoor setting. These novel functionalities of the proposed
framework were tested on a dataset of localization-related Big Data collected
from 18 different users who navigated in 3 buildings consisting of 5 floors and
254 indoor spatial regions. The results show that this approach of indoor
localization for personalized AAL that models each specific user always
achieves higher accuracy as compared to the traditional approach of modeling an
average user.",0,1,0,0,0,0,0.0501086,7.0,0.346085,114
http://arxiv.org/abs/2204.03161v1,Flexible Sampling for Long-tailed Skin Lesion Classification,5,0.0866045,0.359225,"Most of the medical tasks naturally exhibit a long-tailed distribution due to
the complex patient-level conditions and the existence of rare diseases.
Existing long-tailed learning methods usually treat each class equally to
re-balance the long-tailed distribution. However, considering that some
challenging classes may present diverse intra-class distributions, re-balancing
all classes equally may lead to a significant performance drop. To address
this, in this paper, we propose a curriculum learning-based framework called
Flexible Sampling for the long-tailed skin lesion classification task.
Specifically, we initially sample a subset of training data as anchor points
based on the individual class prototypes. Then, these anchor points are used to
pre-train an inference model to evaluate the per-class learning difficulty.
Finally, we use a curriculum sampling module to dynamically query new samples
from the rest training samples with the learning difficulty-aware sampling
probability. We evaluated our model against several state-of-the-art methods on
the ISIC dataset. The results with two long-tailed settings have demonstrated
the superiority of our proposed training strategy, which achieves a new
benchmark for long-tailed skin lesion classification.",0,1,0,0,1,0,0.937869,7.0,0.916068,22
http://arxiv.org/abs/2207.01420v1,Comparing Feature Importance and Rule Extraction for Interpretability on Text Data,1,0.00998175,0.119221,"Complex machine learning algorithms are used more and more often in critical
tasks involving text data, leading to the development of interpretability
methods. Among local methods, two families have emerged: those computing
importance scores for each feature and those extracting simple logical rules.
In this paper we show that using different methods can lead to unexpectedly
different explanations, even when applied to simple models for which we would
expect qualitative coincidence. To quantify this effect, we propose a new
approach to compare explanations produced by different methods.",1,0,0,0,0,0,0.609888,9.0,0.814454,17
http://arxiv.org/abs/2203.09937v1,"On the sensitivity of pose estimation neural networks: rotation parameterizations, Lipschitz constants, and provable bounds",1,0.00312391,0.0543873,"In this paper, we approach the task of determining sensitivity bounds for
pose estimation neural networks. This task is particularly challenging as it
requires characterizing the sensitivity of 3D rotations. We develop a
sensitivity measure that describes the maximum rotational change in a network's
output with respect to a Euclidean change in its input. We show that this
measure is a type of Lipschitz constant, and that it is bounded by the product
of a network's Euclidean Lipschitz constant and an intrinsic property of a
rotation parameterization which we call the ""distance ratio constant"". We
derive the distance ratio constant for several rotation parameterizations, and
then discuss why the structure of most of these parameterizations makes it
difficult to construct a pose estimation network with provable sensitivity
bounds. However, we show that sensitivity bounds can be computed for networks
which parameterize rotation using unconstrained exponential coordinates. We
then construct and train such a network and compute sensitivity bounds for it.",1,0,0,0,0,0,0.258586,9.0,0.687101,20
http://arxiv.org/abs/2203.10479v1,Optimizing Camera Placements for Overlapped Coverage with 3D Camera Projections,2,0.118319,0.0716476,"This paper proposes a method to compute camera 6Dof poses to achieve a user
defined coverage. The camera placement problem is modeled as a combinatorial
optimization where given the maximum number of cameras, a camera set is
selected from a larger pool of possible camera poses. We propose to minimize
the squared error between the desired and the achieved coverage, and formulate
the non-linear cost function as a mixed integer linear programming problem. A
camera lens model is utilized to project the cameras view on a 3D voxel map to
compute a coverage score which makes the optimization problem in real
environments tractable. Experimental results in two real retail store
environments demonstrate the better performance of the proposed formulation in
terms of coverage and overlap for triangulation compared to existing methods.",0,1,0,0,0,0,0.00938171,21.0,0.701251,37
http://arxiv.org/abs/2212.01844v1,Pair-Based Joint Encoding with Relational Graph Convolutional Networks for Emotion-Cause Pair Extraction,6,0.483915,0.868504,"Emotion-cause pair extraction (ECPE) aims to extract emotion clauses and
corresponding cause clauses, which have recently received growing attention.
Previous methods sequentially encode features with a specified order. They
first encode the emotion and cause features for clause extraction and then
combine them for pair extraction. This lead to an imbalance in inter-task
feature interaction where features extracted later have no direct contact with
the former. To address this issue, we propose a novel Pair-Based Joint Encoding
(PBJE) network, which generates pairs and clauses features simultaneously in a
joint feature encoding manner to model the causal relationship in clauses. PBJE
can balance the information flow among emotion clauses, cause clauses and
pairs. From a multi-relational perspective, we construct a heterogeneous
undirected graph and apply the Relational Graph Convolutional Network (RGCN) to
capture the various relationship between clauses and the relationship between
pairs and clauses. Experimental results show that PBJE achieves
state-of-the-art performance on the Chinese benchmark corpus.",1,1,0,0,1,0,0.981112,5.0,0.953827,39
http://arxiv.org/abs/2202.02476v1,Semantic Similarity Computing Model Based on Multi Model Fine-Grained Nonlinear Fusion,19,0.0570696,0.764845,"Natural language processing (NLP) task has achieved excellent performance in
many fields, including semantic understanding, automatic summarization, image
recognition and so on. However, most of the neural network models for NLP
extract the text in a fine-grained way, which is not conducive to grasp the
meaning of the text from a global perspective. To alleviate the problem, the
combination of the traditional statistical method and deep learning model as
well as a novel model based on multi model nonlinear fusion are proposed in
this paper. The model uses the Jaccard coefficient based on part of speech,
Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm
to measure the similarity of sentences respectively. According to the
calculation accuracy of each model, the normalized weight coefficient is
obtained and the calculation results are compared. The weighted vector is input
into the fully connected neural network to give the final classification
results. As a result, the statistical sentence similarity evaluation algorithm
reduces the granularity of feature extraction, so it can grasp the sentence
features globally. Experimental results show that the matching of sentence
similarity calculation method based on multi model nonlinear fusion is 84%, and
the F1 value of the model is 75%.",0,0,0,0,0,0,0.000932499,12.0,0.284449,48
http://arxiv.org/abs/2207.05282v2,PseudoClick: Interactive Image Segmentation with Click Imitation,33,0.29936,0.77027,"The goal of click-based interactive image segmentation is to obtain precise
object segmentation masks with limited user interaction, i.e., by a minimal
number of user clicks. Existing methods require users to provide all the
clicks: by first inspecting the segmentation mask and then providing points on
mislabeled regions, iteratively. We ask the question: can our model directly
predict where to click, so as to further reduce the user interaction cost? To
this end, we propose {\PseudoClick}, a generic framework that enables existing
segmentation networks to propose candidate next clicks. These automatically
generated clicks, termed pseudo clicks in this work, serve as an imitation of
human clicks to refine the segmentation mask.",0,1,0,0,1,1,0.666934,9.0,0.831705,57
http://arxiv.org/abs/2210.11803v1,Revisiting Checkpoint Averaging for Neural Machine Translation,9,0.0945414,0.364203,"Checkpoint averaging is a simple and effective method to boost the
performance of converged neural machine translation models. The calculation is
cheap to perform and the fact that the translation improvement almost comes for
free, makes it widely adopted in neural machine translation research. Despite
the popularity, the method itself simply takes the mean of the model parameters
from several checkpoints, the selection of which is mostly based on empirical
recipes without many justifications. In this work, we revisit the concept of
checkpoint averaging and consider several extensions. Specifically, we
experiment with ideas such as using different checkpoint selection strategies,
calculating weighted average instead of simple mean, making use of gradient
information and fine-tuning the interpolation weights on development data. Our
results confirm the necessity of applying checkpoint averaging for optimal
performance, but also suggest that the landscape between the converged
checkpoints is rather flat and not much further improvement compared to simple
averaging is to be obtained.",0,1,0,0,0,0,0.254069,7.0,0.594771,39
http://arxiv.org/abs/2205.08159v1,SEMI-FND: Stacked Ensemble Based Multimodal Inference For Faster Fake News Detection,18,0.0354197,0.541593,"Fake News Detection (FND) is an essential field in natural language
processing that aims to identify and check the truthfulness of major claims in
a news article to decide the news veracity. FND finds its uses in preventing
social, political and national damage caused due to misrepresentation of facts
which may harm a certain section of society. Further, with the explosive rise
in fake news dissemination over social media, including images and text, it has
become imperative to identify fake news faster and more accurately. To solve
this problem, this work investigates a novel multimodal stacked ensemble-based
approach (SEMIFND) to fake news detection. Focus is also kept on ensuring
faster performance with fewer parameters. Moreover, to improve multimodal
performance, a deep unimodal analysis is done on the image modality to identify
NasNet Mobile as the most appropriate model for the task. For text, an ensemble
of BERT and ELECTRA is used. The approach was evaluated on two datasets:
Twitter MediaEval and Weibo Corpus. The suggested framework offered accuracies
of 85.80% and 86.83% on the Twitter and Weibo datasets respectively. These
reported metrics are found to be superior when compared to similar recent
works. Further, we also report a reduction in the number of parameters used in
training when compared to recent relevant works. SEMI-FND offers an overall
parameter reduction of at least 20% with unimodal parametric reduction on text
being 60%. Therefore, based on the investigations presented, it is concluded
that the application of a stacked ensembling significantly improves FND over
other approaches while also improving speed.",0,1,0,0,1,0,0.0468788,8.0,0.419285,52
http://arxiv.org/abs/2207.13457v1,Reducing the Vision and Language Bias for Temporal Sentence Grounding,32,0.361204,0.869615,"Temporal sentence grounding (TSG) is an important yet challenging task in
multimedia information retrieval. Although previous TSG methods have achieved
decent performance, they tend to capture the selection biases of frequently
appeared video-query pairs in the dataset rather than present robust multimodal
reasoning abilities, especially for the rarely appeared pairs. In this paper,
we study the above issue of selection biases and accordingly propose a
Debiasing-TSG (D-TSG) model to filter and remove the negative biases in both
vision and language modalities for enhancing the model generalization ability.
Specifically, we propose to alleviate the issue from two perspectives: 1)
Feature distillation. We built a multi-modal debiasing branch to firstly
capture the vision and language biases, and then apply a bias identification
module to explicitly recognize the true negative biases and remove them from
the benign multi-modal representations. 2) Contrastive sample generation. We
construct two types of negative samples to enforce the model to accurately
learn the aligned multi-modal semantics and make complete semantic reasoning.
We apply the proposed model to both commonly and rarely appeared TSG cases, and
demonstrate its effectiveness by achieving the state-of-the-art performance on
three benchmark datasets (ActivityNet Caption, TACoS, and Charades-STA).",0,1,0,0,1,0,0.842512,6.0,0.834148,51
http://arxiv.org/abs/2206.05418v1,SAIBench: Benchmarking AI for Science,4,0.0,0.0204902,"Scientific research communities are embracing AI-based solutions to target
tractable scientific tasks and improve research workflows. However, the
development and evaluation of such solutions are scattered across multiple
disciplines. We formalize the problem of scientific AI benchmarking, and
propose a system called SAIBench in the hope of unifying the efforts and
enabling low-friction on-boarding of new disciplines. The system approaches
this goal with SAIL, a domain-specific language to decouple research problems,
AI models, ranking criteria, and software/hardware configuration into reusable
modules. We show that this approach is flexible and can adapt to problems, AI
models, and evaluation methods defined in different perspectives. The project
homepage is https://www.computercouncil.org/SAIBench",0,0,0,0,0,1,0.0282975,7.0,0.262843,37
http://arxiv.org/abs/2205.01290v1,DrugEHRQA: A Question Answering Dataset on Structured and Unstructured Electronic Health Records For Medicine Related Queries,7,0.107996,0.235378,"This paper develops the first question answering dataset (DrugEHRQA)
containing question-answer pairs from both structured tables and unstructured
notes from a publicly available Electronic Health Record (EHR). EHRs contain
patient records, stored in structured tables and unstructured clinical notes.
The information in structured and unstructured EHRs is not strictly disjoint:
information may be duplicated, contradictory, or provide additional context
between these sources. Our dataset has medication-related queries, containing
over 70,000 question-answer pairs. To provide a baseline model and help analyze
the dataset, we have used a simple model (MultimodalEHRQA) which uses the
predictions of a modality selection network to choose between EHR tables and
clinical notes to answer the questions. This is used to direct the questions to
the table-based or text-based state-of-the-art QA model. In order to address
the problem arising from complex, nested queries, this is the first time
Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers (RAT-SQL)
has been used to test the structure of query templates in EHR data. Our goal is
to provide a benchmark dataset for multi-modal QA systems, and to open up new
avenues of research in improving question answering over EHR structured data by
using context from unstructured clinical data.",0,1,1,1,0,0,0.529414,5.0,0.62158,30
http://arxiv.org/abs/2212.04103v1,GTFLAT: Game Theory Based Add-On For Empowering Federated Learning Aggregation Techniques,1,0.00486186,0.0545831,"GTFLAT, as a game theory-based add-on, addresses an important research
question: How can a federated learning algorithm achieve better performance and
training efficiency by setting more effective adaptive weights for averaging in
the model aggregation phase? The main objectives for the ideal method of
answering the question are: (1) empowering federated learning algorithms to
reach better performance in fewer communication rounds, notably in the face of
heterogeneous scenarios, and last but not least, (2) being easy to use
alongside the state-of-the-art federated learning algorithms as a new module.
To this end, GTFLAT models the averaging task as a strategic game among active
users. Then it proposes a systematic solution based on the population game and
evolutionary dynamics to find the equilibrium. In contrast with existing
approaches that impose the weights on the participants, GTFLAT concludes a
self-enforcement agreement among clients in a way that none of them is
motivated to deviate from it individually. The results reveal that, on average,
using GTFLAT increases the top-1 test accuracy by 1.38%, while it needs 21.06%
fewer communication rounds to reach the accuracy.",0,1,0,0,0,0,0.365962,7.0,0.657789,38
http://arxiv.org/abs/2202.09483v1,Data-Driven Mitigation of Adversarial Text Perturbation,7,0.0379862,0.418859,"Social networks have become an indispensable part of our lives, with billions
of people producing ever-increasing amounts of text. At such scales, content
policies and their enforcement become paramount. To automate moderation,
questionable content is detected by Natural Language Processing (NLP)
classifiers. However, high-performance classifiers are hampered by misspellings
and adversarial text perturbations. In this paper, we classify intentional and
unintentional adversarial text perturbation into ten types and propose a
deobfuscation pipeline to make NLP models robust to such perturbations. We
propose Continuous Word2Vec (CW2V), our data-driven method to learn word
embeddings that ensures that perturbations of words have embeddings similar to
those of the original words. We show that CW2V embeddings are generally more
robust to text perturbations than embeddings based on character ngrams. Our
robust classification pipeline combines deobfuscation and classification, using
proposed defense methods and word embeddings to classify whether Facebook posts
are requesting engagement such as likes. Our pipeline results in engagement
bait classification that goes from 0.70 to 0.67 AUC with adversarial text
perturbation, while character ngram-based word embedding methods result in
downstream classification that goes from 0.76 to 0.64.",0,1,0,0,0,0,0.334627,7.0,0.641803,20
http://arxiv.org/abs/2205.06230v2,Simple Open-Vocabulary Object Detection with Vision Transformers,197,0.844463,0.999984,"Combining simple architectures with large-scale pre-training has led to
massive improvements in image classification. For object detection,
pre-training and scaling approaches are less well established, especially in
the long-tailed and open-vocabulary setting, where training data is relatively
scarce. In this paper, we propose a strong recipe for transferring image-text
models to open-vocabulary object detection. We use a standard Vision
Transformer architecture with minimal modifications, contrastive image-text
pre-training, and end-to-end detection fine-tuning. Our analysis of the scaling
properties of this setup shows that increasing image-level pre-training and
model size yield consistent improvements on the downstream detection task. We
provide the adaptation strategies and regularizations needed to attain very
strong performance on zero-shot text-conditioned and one-shot image-conditioned
object detection. Code and models are available on GitHub.",1,1,0,0,0,0,0.954261,4.0,0.879262,48
http://arxiv.org/abs/2202.06371v1,Omnifont Persian OCR System Using Primitives,6,0.0970669,0.715982,"In this paper, we introduce a model-based omnifont Persian OCR system. The
system uses a set of 8 primitive elements as structural features for
recognition. First, the scanned document is preprocessed. After normalizing the
preprocessed image, text rows and sub-words are separated and then thinned.
After recognition of dots in sub-words, strokes are extracted and primitive
elements of each sub-word are recognized using the strokes. Finally, the
primitives are compared with a predefined set of character identification
vectors in order to identify sub-word characters. The separation and
recognition steps of the system are concurrent, eliminating unavoidable errors
of independent separation of letters. The system has been tested on documents
with 14 standard Persian fonts in 6 sizes. The achieved precision is 97.06%.",0,1,0,0,0,0,1.51558e-06,25.0,0.399634,7
http://arxiv.org/abs/2208.05321v1,A Frequency-aware Software Cache for Large Recommendation System Embeddings,1,0.00280861,0.0550609,"Deep learning recommendation models (DLRMs) have been widely applied in
Internet companies. The embedding tables of DLRMs are too large to fit on GPU
memory entirely. We propose a GPU-based software cache approaches to
dynamically manage the embedding table in the CPU and GPU memory space by
leveraging the id's frequency statistics of the target dataset. Our proposed
software cache is efficient in training entire DLRMs on GPU in a synchronized
update manner. It is also scaled to multiple GPUs in combination with the
widely used hybrid parallel training approaches. Evaluating our prototype
system shows that we can keep only 1.5% of the embedding parameters in the GPU
to obtain a decent end-to-end training speed.",1,1,0,0,0,0,0.423521,3.0,0.264736,10
http://arxiv.org/abs/2202.00159v3,Content Addressable Memory Without Catastrophic Forgetting by Heteroassociation with a Fixed Scaffold,11,0.163046,0.379098,"Content-addressable memory (CAM) networks, so-called because stored items can
be recalled by partial or corrupted versions of the items, exhibit near-perfect
recall of a small number of information-dense patterns below capacity and a
'memory cliff' beyond, such that inserting a single additional pattern results
in catastrophic loss of all stored patterns. We propose a novel CAM
architecture, Memory Scaffold with Heteroassociation (MESH), that factorizes
the problems of internal attractor dynamics and association with external
content to generate a CAM continuum without a memory cliff: Small numbers of
patterns are stored with complete information recovery matching standard CAMs,
while inserting more patterns still results in partial recall of every pattern,
with a graceful trade-off between pattern number and pattern richness.
Motivated by the architecture of the Entorhinal-Hippocampal memory circuit in
the brain, MESH is a tripartite architecture with pairwise interactions that
uses a predetermined set of internally stabilized states together with
heteroassociation between the internal states and arbitrary external patterns.
We show analytically and experimentally that for any number of stored patterns,
MESH nearly saturates the total information bound (given by the number of
synapses) for CAM networks, outperforming all existing CAM models.",1,0,0,0,1,0,0.00116276,26.0,0.678238,49
http://arxiv.org/abs/2210.00588v1,DFA: Dynamic Feature Aggregation for Efficient Video Object Detection,7,0.0379545,0.622218,"Video object detection is a fundamental yet challenging task in computer
vision. One practical solution is to take advantage of temporal information
from the video and apply feature aggregation to enhance the object features in
each frame. Though effective, those existing methods always suffer from low
inference speeds because they use a fixed number of frames for feature
aggregation regardless of the input frame. Therefore, this paper aims to
improve the inference speed of the current feature aggregation-based video
object detectors while maintaining their performance. To achieve this goal, we
propose a vanilla dynamic aggregation module that adaptively selects the frames
for feature enhancement. Then, we extend the vanilla dynamic aggregation module
to a more effective and reconfigurable deformable version. Finally, we
introduce inplace distillation loss to improve the representations of objects
aggregated with fewer frames. Extensive experimental results validate the
effectiveness and efficiency of our proposed methods: On the ImageNet VID
benchmark, integrated with our proposed methods, FGFA and SELSA can improve the
inference speed by 31% and 76% respectively while getting comparable
performance on accuracy.",0,1,0,0,0,0,0.235904,7.0,0.582535,55
http://arxiv.org/abs/2204.02337v1,Multi-Scale Representation Learning on Proteins,66,0.333461,0.52746,"Proteins are fundamental biological entities mediating key roles in cellular
function and disease. This paper introduces a multi-scale graph construction of
a protein -- HoloProt -- connecting surface to structure and sequence. The
surface captures coarser details of the protein, while sequence as primary
component and structure -- comprising secondary and tertiary components --
capture finer details. Our graph encoder then learns a multi-scale
representation by allowing each level to integrate the encoding from level(s)
below with the graph at that level. We test the learned representation on
different tasks, (i.) ligand binding affinity (regression), and (ii.) protein
function prediction (classification). On the regression task, contrary to
previous methods, our model performs consistently and reliably across different
dataset splits, outperforming all baselines on most splits. On the
classification task, it achieves a performance close to the top-performing
model while using 10x fewer parameters. To improve the memory efficiency of our
construction, we segment the multiplex protein surface manifold into molecular
superpixels and substitute the surface with these superpixels at little to no
performance loss.",0,1,0,0,0,0,0.282529,11.0,0.753456,69
http://arxiv.org/abs/2201.05922v1,Addressing the Challenges of Cross-Lingual Hate Speech Detection,3,0.204818,0.0877459,"The goal of hate speech detection is to filter negative online content aiming
at certain groups of people. Due to the easy accessibility of social media
platforms it is crucial to protect everyone which requires building hate speech
detection systems for a wide range of languages. However, the available labeled
hate speech datasets are limited making it problematic to build systems for
many languages. In this paper we focus on cross-lingual transfer learning to
support hate speech detection in low-resource languages. We leverage
cross-lingual word embeddings to train our neural network systems on the source
language and apply it to the target language, which lacks labeled examples, and
show that good performance can be achieved. We then incorporate unlabeled
target language data for further model improvements by bootstrapping labels
using an ensemble of different model architectures. Furthermore, we investigate
the issue of label imbalance of hate speech datasets, since the high ratio of
non-hate examples compared to hate examples often leads to low model
performance. We test simple data undersampling and oversampling techniques and
show their effectiveness.",0,1,0,0,0,0,0.964683,9.0,0.955283,36
http://arxiv.org/abs/2206.09249v1,RuArg-2022: Argument Mining Evaluation,8,0.157353,0.425209,"Argumentation analysis is a field of computational linguistics that studies
methods for extracting arguments from texts and the relationships between them,
as well as building argumentation structure of texts. This paper is a report of
the organizers on the first competition of argumentation analysis systems
dealing with Russian language texts within the framework of the Dialogue
conference. During the competition, the participants were offered two tasks:
stance detection and argument classification. A corpus containing 9,550
sentences (comments on social media posts) on three topics related to the
COVID-19 pandemic (vaccination, quarantine, and wearing masks) was prepared,
annotated, and used for training and testing. The system that won the first
place in both tasks used the NLI (Natural Language Inference) variant of the
BERT architecture, automatic translation into English to apply a specialized
BERT model, retrained on Twitter posts discussing COVID-19, as well as
additional masking of target entities. This system showed the following
results: for the stance detection task an F1-score of 0.6968, for the argument
classification task an F1-score of 0.7404. We hope that the prepared dataset
and baselines will help to foster further research on argument mining for the
Russian language.",0,1,0,1,0,0,0.352055,5.0,0.511147,48
http://arxiv.org/abs/2207.00880v1,Biological Robots: Perspectives on an Emerging Interdisciplinary Field,9,0.114827,0.70404,"Advances in science and engineering often reveal the limitations of classical
approaches initially used to understand, predict, and control phenomena. With
progress, conceptual categories must often be re-evaluated to better track
recently discovered invariants across disciplines. It is essential to refine
frameworks and resolve conflicting boundaries between disciplines such that
they better facilitate, not restrict, experimental approaches and capabilities.
In this essay, we discuss issues at the intersection of developmental biology,
computer science, and robotics. In the context of biological robots, we explore
changes across concepts and previously distinct fields that are driven by
recent advances in materials, information, and life sciences. Herein, each
author provides their own perspective on the subject, framed by their own
disciplinary training. We argue that as with computation, certain aspects of
developmental biology and robotics are not tied to specific materials; rather,
the consilience of these fields can help to shed light on issues of multi-scale
control, self-assembly, and relationships between form and function. We hope
new fields can emerge as boundaries arising from technological limitations are
overcome, furthering practical applications from regenerative medicine to
useful synthetic living machines.",0,0,0,0,0,0,0.0829268,8.0,0.492967,121
http://arxiv.org/abs/2205.12701v2,Eliciting and Understanding Cross-Task Skills with Task-Level Mixture-of-Experts,4,0.347164,0.150036,"Recent works suggest that transformer models are capable of multi-tasking on
diverse NLP tasks and adapting to new tasks efficiently. However, the potential
of these multi-task models may be limited as they use the same set of
parameters for all tasks. In contrast, humans tackle tasks in a more flexible
way, by making proper presumptions on what skills and knowledge are relevant
and executing only the necessary computations. Inspired by this, we propose to
use task-level mixture-of-expert models, which has a collection of transformer
layers (i.e., experts) and a router component that chooses from these experts
dynamically and flexibly. We find that these models help improve the average
performance gain (ARG) metric by 2.6% when adapting to unseen tasks in the
few-shot setting and by 5.6% in the zero-shot generalization setting. Further,
we show that the learned routing decisions partly rediscover human
categorization of NLP tasks -- certain experts are strongly associated with
extractive tasks, some with classification tasks, and some with tasks requiring
world knowledge.",1,0,0,0,0,0,0.984205,7.0,0.973314,166
http://arxiv.org/abs/2202.13785v3,CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,25,0.451533,0.784557,"Knowledge graphs store a large number of factual triples while they are still
incomplete, inevitably. The previous knowledge graph completion (KGC) models
predict missing links between entities merely relying on fact-view data,
ignoring the valuable commonsense knowledge. The previous knowledge graph
embedding (KGE) techniques suffer from invalid negative sampling and the
uncertainty of fact-view link prediction, limiting KGC's performance. To
address the above challenges, we propose a novel and scalable Commonsense-Aware
Knowledge Embedding (CAKE) framework to automatically extract commonsense from
factual triples with entity concepts. The generated commonsense augments
effective self-supervision to facilitate both high-quality negative sampling
(NS) and joint commonsense and fact-view link prediction. Experimental results
on the KGC task demonstrate that assembling our framework could enhance the
performance of the original KGE models, and the proposed commonsense-aware NS
module is superior to other NS techniques. Besides, our proposed framework
could be easily adaptive to various KGE models and explain the predicted
results.",1,0,0,0,0,0,0.922304,8.0,0.916075,39
http://arxiv.org/abs/2203.01645v1,Selective Residual M-Net for Real Image Denoising,12,0.0419388,0.36953,"Image restoration is a low-level vision task which is to restore degraded
images to noise-free images. With the success of deep neural networks, the
convolutional neural networks surpass the traditional restoration methods and
become the mainstream in the computer vision area. To advance the performanceof
denoising algorithms, we propose a blind real image denoising network (SRMNet)
by employing a hierarchical architecture improved from U-Net. Specifically, we
use a selective kernel with residual block on the hierarchical structure called
M-Net to enrich the multi-scale semantic information. Furthermore, our SRMNet
has competitive performance results on two synthetic and two real-world noisy
datasets in terms of quantitative metrics and visual quality. The source code
and pretrained model are available at
https://github.com/TentativeGitHub/SRMNet.",1,1,0,0,1,0,0.183747,8.0,0.599521,57
http://arxiv.org/abs/2209.01478v1,Equivariant Self-Supervision for Musical Tempo Estimation,5,0.146046,0.905989,"Self-supervised methods have emerged as a promising avenue for representation
learning in the recent years since they alleviate the need for labeled
datasets, which are scarce and expensive to acquire. Contrastive methods are a
popular choice for self-supervision in the audio domain, and typically provide
a learning signal by forcing the model to be invariant to some transformations
of the input. These methods, however, require measures such as negative
sampling or some form of regularisation to be taken to prevent the model from
collapsing on trivial solutions. In this work, instead of invariance, we
propose to use equivariance as a self-supervision signal to learn audio tempo
representations from unlabelled data. We derive a simple loss function that
prevents the network from collapsing on a trivial solution during training,
without requiring any form of regularisation or negative sampling. Our
experiments show that it is possible to learn meaningful representations for
tempo estimation by solely relying on equivariant self-supervision, achieving
performance comparable with supervised methods on several benchmarks. As an
added benefit, our method only requires moderate compute resources and
therefore remains accessible to a wide research community.",0,0,0,0,0,0,0.872068,5.0,0.82229,52
http://arxiv.org/abs/2201.09146v2,Question rewriting? Assessing its importance for conversational question answering,16,0.374472,0.311409,"In conversational question answering, systems must correctly interpret the
interconnected interactions and generate knowledgeable answers, which may
require the retrieval of relevant information from a background repository.
Recent approaches to this problem leverage neural language models, although
different alternatives can be considered in terms of modules for (a)
representing user questions in context, (b) retrieving the relevant background
information, and (c) generating the answer. This work presents a conversational
question answering system designed specifically for the Search-Oriented
Conversational AI (SCAI) shared task, and reports on a detailed analysis of its
question rewriting module. In particular, we considered different variations of
the question rewriting module to evaluate the influence on the subsequent
components, and performed a careful analysis of the results obtained with the
best system configuration. Our system achieved the best performance in the
shared task and our analysis emphasizes the importance of the conversation
context representation for the overall system performance.",0,1,0,0,1,0,0.983241,5.0,0.959762,13
http://arxiv.org/abs/2204.13348v1,Deep Generalized Unfolding Networks for Image Restoration,104,0.318615,0.998185,"Deep neural networks (DNN) have achieved great success in image restoration.
However, most DNN methods are designed as a black box, lacking transparency and
interpretability. Although some methods are proposed to combine traditional
optimization algorithms with DNN, they usually demand pre-defined degradation
processes or handcrafted assumptions, making it difficult to deal with complex
and real-world applications. In this paper, we propose a Deep Generalized
Unfolding Network (DGUNet) for image restoration. Concretely, without loss of
interpretability, we integrate a gradient estimation strategy into the gradient
descent step of the Proximal Gradient Descent (PGD) algorithm, driving it to
deal with complex and real-world image degradation. In addition, we design
inter-stage information pathways across proximal mapping in different PGD
iterations to rectify the intrinsic information loss in most deep unfolding
networks (DUN) through a multi-scale and spatial-adaptive way. By integrating
the flexible gradient descent and informative proximal mapping, we unfold the
iterative PGD algorithm into a trainable DNN. Extensive experiments on various
image restoration tasks demonstrate the superiority of our method in terms of
state-of-the-art performance, interpretability, and generalizability. The
source code is available at
https://github.com/MC-E/Deep-Generalized-Unfolding-Networks-for-Image-Restoration.",1,1,0,0,1,1,0.314033,10.0,0.741485,101
http://arxiv.org/abs/2202.02950v1,Jury Learning: Integrating Dissenting Voices into Machine Learning Models,99,0.0654538,0.80373,"Whose labels should a machine learning (ML) algorithm learn to emulate? For
ML tasks ranging from online comment toxicity to misinformation detection to
medical diagnosis, different groups in society may have irreconcilable
disagreements about ground truth labels. Supervised ML today resolves these
label disagreements implicitly using majority vote, which overrides minority
groups' labels. We introduce jury learning, a supervised ML approach that
resolves these disagreements explicitly through the metaphor of a jury:
defining which people or groups, in what proportion, determine the classifier's
prediction. For example, a jury learning model for online toxicity might
centrally feature women and Black jurors, who are commonly targets of online
harassment. To enable jury learning, we contribute a deep learning architecture
that models every annotator in a dataset, samples from annotators' models to
populate the jury, then runs inference to classify. Our architecture enables
juries that dynamically adapt their composition, explore counterfactuals, and
visualize dissent.",0,0,1,0,0,0,0.0191189,7.0,0.20616,97
http://arxiv.org/abs/2211.16693v1,Visual-tactile Fusion for Transparent Object Grasping in Complex Backgrounds,2,0.0680999,0.438341,"The accurate detection and grasping of transparent objects are challenging
but of significance to robots. Here, a visual-tactile fusion framework for
transparent object grasping under complex backgrounds and variant light
conditions is proposed, including the grasping position detection, tactile
calibration, and visual-tactile fusion based classification. First, a
multi-scene synthetic grasping dataset generation method with a Gaussian
distribution based data annotation is proposed. Besides, a novel grasping
network named TGCNN is proposed for grasping position detection, showing good
results in both synthetic and real scenes. In tactile calibration, inspired by
human grasping, a fully convolutional network based tactile feature extraction
method and a central location based adaptive grasping strategy are designed,
improving the success rate by 36.7% compared to direct grasping. Furthermore, a
visual-tactile fusion method is proposed for transparent objects
classification, which improves the classification accuracy by 34%. The proposed
framework synergizes the advantages of vision and touch, and greatly improves
the grasping efficiency of transparent objects.",0,1,0,1,0,0,0.0664934,10.0,0.571412,67
http://arxiv.org/abs/2203.07805v1,On the focusing of thermal images,26,0.263365,0.426022,"In this paper we present a new thermographic image database suitable for the
analysis of automatic focus measures. This database consists of 8 different
sets of scenes, where each scene contains one image for 96 different focus
positions. Using this database we evaluate the usefulness of six focus measures
with the goal to determine the optimal focus position. Experimental results
reveal that an accurate automatic detection of optimal focus position is
possible, even with a low computational burden. We also present an acquisition
tool able to help the acquisition of thermal images. To the best of our
knowledge, this is the first study about automatic focus of thermal images.",0,1,1,1,0,0,0.0685561,11.0,0.613251,14
http://arxiv.org/abs/2205.03472v1,"When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",22,0.273183,0.5956,"Understanding longer narratives or participating in conversations requires
tracking of discourse entities that have been mentioned. Indefinite noun
phrases (NPs), such as 'a dog', frequently introduce discourse entities but
this behavior is modulated by sentential operators such as negation. For
example, 'a dog' in 'Arthur doesn't own a dog' does not introduce a discourse
entity due to the presence of negation. In this work, we adapt the
psycholinguistic assessment of language models paradigm to higher-level
linguistic phenomena and introduce an English evaluation suite that targets the
knowledge of the interactions between sentential operators and indefinite NPs.
We use this evaluation suite for a fine-grained investigation of the entity
tracking abilities of the Transformer-based models GPT-2 and GPT-3. We find
that while the models are to a certain extent sensitive to the interactions we
investigate, they are all challenged by the presence of multiple NPs and their
behavior is not systematic, which suggests that even models at the scale of
GPT-3 do not fully acquire basic entity tracking abilities.",1,0,0,0,0,0,0.728932,6.0,0.776177,42
http://arxiv.org/abs/2211.10057v1,Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic,37,0.620823,0.531621,"Propaganda is the expression of an opinion or an action by an individual or a
group deliberately designed to influence the opinions or the actions of other
individuals or groups with reference to predetermined ends, which is achieved
by means of well-defined rhetorical and psychological devices. Propaganda
techniques are commonly used in social media to manipulate or to mislead users.
Thus, there has been a lot of recent research on automatic detection of
propaganda techniques in text as well as in memes. However, so far the focus
has been primarily on English. With the aim to bridge this language gap, we ran
a shared task on detecting propaganda techniques in Arabic tweets as part of
the WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to
identify the set of propaganda techniques used in a tweet, which is a
multilabel classification problem, while Subtask~2 asks to detect the
propaganda techniques used in a tweet together with the exact span(s) of text
in which each propaganda technique appears. The task attracted 63 team
registrations, and eventually 14 and 3 teams made submissions for subtask 1 and
2, respectively. Finally, 11 teams submitted system description papers.",0,1,0,0,0,0,0.523037,5.0,0.617977,64
http://arxiv.org/abs/2211.00768v4,Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality,30,0.0896726,0.903804,"Recent visuolinguistic pre-trained models show promising progress on various
end tasks such as image retrieval and video captioning. Yet, they fail
miserably on the recently proposed Winoground dataset, which challenges models
to match paired images and English captions, with items constructed to overlap
lexically but differ in meaning (e.g., ""there is a mug in some grass"" vs.
""there is some grass in a mug""). By annotating the dataset using new
fine-grained tags, we show that solving the Winoground task requires not just
compositional language understanding, but a host of other abilities like
commonsense reasoning or locating small, out-of-focus objects in low-resolution
images. In this paper, we identify the dataset's main challenges through a
suite of experiments on related tasks (probing task, image retrieval task),
data augmentation, and manual inspection of the dataset. Our analysis suggests
that a main challenge in visuolinguistic models may lie in fusing visual and
textual representations, rather than in compositional language understanding.
We release our annotation and code at
https://github.com/ajd12342/why-winoground-hard .",1,0,0,0,0,0,0.302426,5.0,0.473864,48
http://arxiv.org/abs/2205.01625v1,Toward Robust Spiking Neural Network Against Adversarial Perturbation,6,0.0625324,0.408406,"As spiking neural networks (SNNs) are deployed increasingly in real-world
efficiency critical applications, the security concerns in SNNs attract more
attention. Currently, researchers have already demonstrated an SNN can be
attacked with adversarial examples. How to build a robust SNN becomes an urgent
issue. Recently, many studies apply certified training in artificial neural
networks (ANNs), which can improve the robustness of an NN model promisely.
However, existing certifications cannot transfer to SNNs directly because of
the distinct neuron behavior and input formats for SNNs. In this work, we first
design S-IBP and S-CROWN that tackle the non-linear functions in SNNs' neuron
modeling. Then, we formalize the boundaries for both digital and spike inputs.
Finally, we demonstrate the efficiency of our proposed robust training method
in different datasets and model architectures. Based on our experiment, we can
achieve a maximum $37.7\%$ attack error reduction with $3.7\%$ original
accuracy loss. To the best of our knowledge, this is the first analysis on
robust training of SNNs.",0,0,1,0,0,0,0.451971,6.0,0.647018,43
http://arxiv.org/abs/2201.06374v3,RestoreFormer: High-Quality Blind Face Restoration from Undegraded Key-Value Pairs,65,0.643821,0.855099,"Blind face restoration is to recover a high-quality face image from unknown
degradations. As face image contains abundant contextual information, we
propose a method, RestoreFormer, which explores fully-spatial attentions to
model contextual information and surpasses existing works that use local
operators. RestoreFormer has several benefits compared to prior arts. First,
unlike the conventional multi-head self-attention in previous Vision
Transformers (ViTs), RestoreFormer incorporates a multi-head cross-attention
layer to learn fully-spatial interactions between corrupted queries and
high-quality key-value pairs. Second, the key-value pairs in ResotreFormer are
sampled from a reconstruction-oriented high-quality dictionary, whose elements
are rich in high-quality facial features specifically aimed for face
reconstruction, leading to superior restoration results. Third, RestoreFormer
outperforms advanced state-of-the-art methods on one synthetic dataset and
three real-world datasets, as well as produces images with better visual
quality.",1,1,0,1,1,0,0.930248,7.0,0.909992,48
http://arxiv.org/abs/2202.10739v2,JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning,1,0.0325735,0.272866,"In online job marketplaces, it is important to establish a well-defined job
title taxonomy for various downstream tasks (e.g., job recommendation, users'
career analysis, and turnover prediction). Job Title Normalization (JTN) is
such a cleaning step to classify user-created non-standard job titles into
normalized ones. However, solving the JTN problem is non-trivial with
challenges: (1) semantic similarity of different job titles, (2) non-normalized
user-created job titles, and (3) large-scale and long-tailed job titles in
real-world applications. To this end, we propose a novel solution, named JAMES,
that constructs three unique embeddings (i.e., graph, contextual, and
syntactic) of a target job title to effectively capture its various traits. We
further propose a multi-aspect co-attention mechanism to attentively combine
these embeddings, and employ neural logical reasoning representations to
collaboratively estimate similarities between messy job titles and normalized
job titles in a reasoning space. To evaluate JAMES, we conduct comprehensive
experiments against ten competing models on a large-scale real-world dataset
with over 350,000 job titles. Our experimental results show that JAMES
significantly outperforms the best baseline by 10.06% in Precision@10 and by
17.52% in NDCG@10, respectively.",1,1,0,0,1,0,0.672442,7.0,0.78577,36
http://arxiv.org/abs/2208.10765v2,A Low-Cost Lane-Following Algorithm for Cyber-Physical Robots,1,0.0259705,0.0606273,"Duckiebots are low-cost mobile robots that are widely used in the fields of
research and education. Although there are existing self-driving algorithms for
the Duckietown platform, they are either too complex or perform too poorly to
navigate a multi-lane track. Moreover, it is essential to give memory and
computational resources to a Duckiebot so it can perform additional tasks such
as out-of-distribution input detection. In order to satisfy these constraints,
we built a low-cost autonomous driving algorithm capable of driving on a
two-lane track. The algorithm uses traditional computer vision techniques to
identify the central lane on the track and obtain the relevant steering angle.
The steering is then controlled by a PID controller that smoothens the movement
of the Duckiebot. The performance of the algorithm was compared to that of the
NeurIPS 2018 AI Driving Olympics (AIDO) finalists, and it outperformed all but
one finalists. The two main contributions of our algorithm are its low
computational requirements and very quick set-up, with ongoing efforts to make
it more reliable.",0,1,0,0,0,0,0.0989268,10.0,0.612882,9
http://arxiv.org/abs/2210.08901v1,Contrastive Language-Image Pre-Training with Knowledge Graphs,19,0.155102,0.584548,"Recent years have witnessed the fast development of large-scale pre-training
frameworks that can extract multi-modal representations in a unified form and
achieve promising performances when transferred to downstream tasks.
Nevertheless, existing approaches mainly focus on pre-training with simple
image-text pairs, while neglecting the semantic connections between concepts
from different modalities. In this paper, we propose a knowledge-based
pre-training framework, dubbed Knowledge-CLIP, which injects semantic
information into the widely used CLIP model. Through introducing
knowledge-based objectives in the pre-training process and utilizing different
types of knowledge graphs as training data, our model can semantically align
the representations in vision and language with higher quality, and enhance the
reasoning ability across scenarios and modalities. Extensive experiments on
various vision-language downstream tasks demonstrate the effectiveness of
Knowledge-CLIP compared with the original CLIP and competitive baselines.",0,1,0,0,0,0,0.713846,7.0,0.802098,82
http://arxiv.org/abs/2210.17440v1,Semantic Novelty Detection and Characterization in Factual Text Involving Named Entities,1,0.00668567,0.0613487,"Much of the existing work on text novelty detection has been studied at the
topic level, i.e., identifying whether the topic of a document or a sentence is
novel or not. Little work has been done at the fine-grained semantic level (or
contextual level). For example, given that we know Elon Musk is the CEO of a
technology company, the sentence ""Elon Musk acted in the sitcom The Big Bang
Theory"" is novel and surprising because normally a CEO would not be an actor.
Existing topic-based novelty detection methods work poorly on this problem
because they do not perform semantic reasoning involving relations between
named entities in the text and their background knowledge. This paper proposes
an effective model (called PAT-SND) to solve the problem, which can also
characterize the novelty. An annotated dataset is also created. Evaluation
shows that PAT-SND outperforms 10 baselines by large margins.",0,0,1,1,1,0,0.0302329,11.0,0.537004,104
http://arxiv.org/abs/2208.07240v1,Mono-surrogate vs Multi-surrogate in Multi-objective Bayesian Optimisation,3,0.073055,0.115205,"Bayesian optimisation (BO) has been widely used to solve problems with
expensive function evaluations. In multi-objective optimisation problems, BO
aims to find a set of approximated Pareto optimal solutions. There are
typically two ways to build surrogates in multi-objective BO: One surrogate by
aggregating objective functions (by using a scalarising function, also called
mono-surrogate approach) and multiple surrogates (for each objective function,
also called multi-surrogate approach). In both approaches, an acquisition
function (AF) is used to guide the search process. Mono-surrogate has the
advantage that only one model is used, however, the approach has two major
limitations. Firstly, the fitness landscape of the scalarising function and the
objective functions may not be similar. Secondly, the approach assumes that the
scalarising function distribution is Gaussian, and thus a closed-form
expression of the AF can be used. In this work, we overcome these limitations
by building a surrogate model for each objective function and show that the
scalarising function distribution is not Gaussian. We approximate the
distribution using Generalised extreme value distribution. The results and
comparison with existing approaches on standard benchmark and real-world
optimisation problems show the potential of the multi-surrogate approach.",0,1,0,0,0,0,0.153844,14.0,0.757222,30
http://arxiv.org/abs/2204.09041v1,Unsupervised detection of ash dieback disease (Hymenoscyphus fraxineus) using diffusion-based hyperspectral image clustering,4,0.130537,0.293011,"Ash dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is
causing the widespread death of ash trees across Europe. Remote sensing
hyperspectral images encode rich structure that has been exploited for the
detection of dieback disease in ash trees using supervised machine learning
techniques. However, to understand the state of forest health at
landscape-scale, accurate unsupervised approaches are needed. This article
investigates the use of the unsupervised Diffusion and VCA-Assisted Image
Segmentation (D-VIS) clustering algorithm for the detection of ash dieback
disease in a forest site near Cambridge, United Kingdom. The unsupervised
clustering presented in this work has high overlap with the supervised
classification of previous work on this scene (overall accuracy = 71%). Thus,
unsupervised learning may be used for the remote detection of ash dieback
disease without the need for expert labeling.",0,1,0,0,0,0,0.207403,11.0,0.72104,21
http://arxiv.org/abs/2206.07365v1,Modern Machine-Learning Predictive Models for Diagnosing Infectious Diseases,10,0.368581,0.449469,"Controlling infectious diseases is a major health priority because they can
spread and infect humans, thus evolving into epidemics or pandemics. Therefore,
early detection of infectious diseases is a significant need, and many
researchers have developed models to diagnose them in the early stages. This
paper reviewed research articles for recent machine-learning (ML) algorithms
applied to infectious disease diagnosis. We searched the Web of Science,
ScienceDirect, PubMed, Springer, and IEEE databases from 2015 to 2022,
identified the pros and cons of the reviewed ML models, and discussed the
possible recommendations to advance the studies in this field. We found that
most of the articles used small datasets, and few of them used real-time data.
Our results demonstrated that a suitable ML technique depends on the nature of
the dataset and the desired goal.",0,1,0,0,0,0,0.769903,6.0,0.795886,54
http://arxiv.org/abs/2210.07109v1,Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence,25,0.201252,0.961656,"AI researchers have posited Dungeons and Dragons (D&D) as a challenge problem
to test systems on various language-related capabilities. In this paper, we
frame D&D specifically as a dialogue system challenge, where the tasks are to
both generate the next conversational turn in the game and predict the state of
the game given the dialogue history. We create a gameplay dataset consisting of
nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns,
500,000 dice rolls, and 58 million words. We automatically annotate the data
with partial state information about the game play. We train a large language
model (LM) to generate the next game turn, conditioning it on different
information. The LM can respond as a particular character or as the player who
runs the game--i.e., the Dungeon Master (DM). It is trained to produce dialogue
that is either in-character (roleplaying in the fictional world) or
out-of-character (discussing rules or strategy). We perform a human evaluation
to determine what factors make the generated output plausible and interesting.
We further perform an automatic evaluation to determine how well the model can
predict the game state given the history and examine how well tracking the game
state improves its ability to produce plausible conversational output.",0,1,0,1,0,0,0.127509,7.0,0.485488,47
http://arxiv.org/abs/2209.02174v1,CNSNet: A Cleanness-Navigated-Shadow Network for Shadow Removal,6,0.240463,0.520938,"The key to shadow removal is recovering the contents of the shadow regions
with the guidance of the non-shadow regions. Due to the inadequate long-range
modeling, the CNN-based approaches cannot thoroughly investigate the
information from the non-shadow regions. To solve this problem, we propose a
novel cleanness-navigated-shadow network (CNSNet), with a shadow-oriented
adaptive normalization (SOAN) module and a shadow-aware aggregation with
transformer (SAAT) module based on the shadow mask. Under the guidance of the
shadow mask, the SOAN module formulates the statistics from the non-shadow
region and adaptively applies them to the shadow region for region-wise
restoration. The SAAT module utilizes the shadow mask to precisely guide the
restoration of each shadowed pixel by considering the highly relevant pixels
from the shadow-free regions for global pixel-wise restoration. Extensive
experiments on three benchmark datasets (ISTD, ISTD+, and SRD) show that our
method achieves superior de-shadowing performance.",0,1,0,0,1,0,0.940727,7.0,0.918469,54
http://arxiv.org/abs/2207.02063v2,RepMix: Representation Mixing for Robust Attribution of Synthesized Images,22,0.0705943,0.779171,"Rapid advances in Generative Adversarial Networks (GANs) raise new challenges
for image attribution; detecting whether an image is synthetic and, if so,
determining which GAN architecture created it. Uniquely, we present a solution
to this task capable of 1) matching images invariant to their semantic content;
2) robust to benign transformations (changes in quality, resolution, shape,
etc.) commonly encountered as images are re-shared online. In order to
formalize our research, a challenging benchmark, Attribution88, is collected
for robust and practical image attribution. We then propose RepMix, our GAN
fingerprinting technique based on representation mixing and a novel loss. We
validate its capability of tracing the provenance of GAN-generated images
invariant to the semantic content of the image and also robust to
perturbations. We show our approach improves significantly from existing GAN
fingerprinting works on both semantic generalization and robustness. Data and
code are available at https://github.com/TuBui/image_attribution.",1,1,0,1,0,0,0.221537,8.0,0.62575,65
http://arxiv.org/abs/2203.04172v2,Distributed Control using Reinforcement Learning with Temporal-Logic-Based Reward Shaping,2,0.0593398,0.18831,"We present a computational framework for synthesis of distributed control
strategies for a heterogeneous team of robots in a partially observable
environment. The goal is to cooperatively satisfy specifications given as
Truncated Linear Temporal Logic (TLTL) formulas. Our approach formulates the
synthesis problem as a stochastic game and employs a policy graph method to
find a control strategy with memory for each agent. We construct the stochastic
game on the product between the team transition system and a finite state
automaton (FSA) that tracks the satisfaction of the TLTL formula. We use the
quantitative semantics of TLTL as the reward of the game, and further reshape
it using the FSA to guide and accelerate the learning process. Simulation
results demonstrate the efficacy of the proposed solution under demanding task
specifications and the effectiveness of reward shaping in significantly
accelerating the speed of learning.",0,0,0,0,0,0,0.912756,11.0,0.934743,20
http://arxiv.org/abs/2203.09072v1,Gaussian Multi-head Attention for Simultaneous Machine Translation,16,0.138074,0.607292,"Simultaneous machine translation (SiMT) outputs translation while receiving
the streaming source inputs, and hence needs a policy to determine where to
start translating. The alignment between target and source words often implies
the most informative source word for each target word, and hence provides the
unified control over translation quality and latency, but unfortunately the
existing SiMT methods do not explicitly model the alignment to perform the
control. In this paper, we propose Gaussian Multi-head Attention (GMA) to
develop a new SiMT policy by modeling alignment and translation in a unified
manner. For SiMT policy, GMA models the aligned source position of each target
word, and accordingly waits until its aligned position to start translating. To
integrate the learning of alignment into the translation model, a Gaussian
distribution centered on predicted aligned position is introduced as an
alignment-related prior, which cooperates with translation-related soft
attention to determine the final attention. Experiments on En-Vi and De-En
tasks show that our method outperforms strong baselines on the trade-off
between translation and latency.",1,0,0,0,0,0,0.212511,6.0,0.493146,43
http://arxiv.org/abs/2210.12872v1,Socio-cognitive Optimization of Time-delay Control Problems using Evolutionary Metaheuristics,4,0.0781782,0.261135,"Metaheuristics are universal optimization algorithms which should be used for
solving difficult problems, unsolvable by classic approaches. In this paper we
aim at constructing novel socio-cognitive metaheuristic based on castes, and
apply several versions of this algorithm to optimization of time-delay system
model. Besides giving the background and the details of the proposed algorithms
we apply them to optimization of selected variants of the problem and discuss
the results.",0,0,0,0,0,0,0.00849269,42.0,0.848245,32
http://arxiv.org/abs/2202.01344v1,Formal Mathematics Statement Curriculum Learning,68,0.743172,0.999974,"We explore the use of expert iteration in the context of language modeling
applied to formal mathematics. We show that at same compute budget, expert
iteration, by which we mean proof search interleaved with learning,
dramatically outperforms proof search only. We also observe that when applied
to a collection of formal statements of sufficiently varied difficulty, expert
iteration is capable of finding and solving a curriculum of increasingly
difficult problems, without the need for associated ground-truth proofs.
Finally, by applying this expert iteration to a manually curated set of problem
statements, we achieve state-of-the-art on the miniF2F benchmark, automatically
solving multiple challenging problems drawn from high school olympiads.",0,0,0,0,1,0,0.836403,5.0,0.796816,46
http://arxiv.org/abs/2203.04440v1,Pointillism: Accurate 3D bounding box estimation with multi-radars,44,0.696553,0.933622,"Autonomous perception requires high-quality environment sensing in the form
of 3D bounding boxes of dynamic objects. The primary sensors used in automotive
systems are light-based cameras and LiDARs. However, they are known to fail in
adverse weather conditions. Radars can potentially solve this problem as they
are barely affected by adverse weather conditions. However, specular
reflections of wireless signals cause poor performance of radar point clouds.
We introduce Pointillism, a system that combines data from multiple spatially
separated radars with an optimal separation to mitigate these problems. We
introduce a novel concept of Cross Potential Point Clouds, which uses the
spatial diversity induced by multiple radars and solves the problem of noise
and sparsity in radar point clouds. Furthermore, we present the design of
RP-net, a novel deep learning architecture, designed explicitly for radar's
sparse data distribution, to enable accurate 3D bounding box estimation. The
spatial techniques designed and proposed in this paper are fundamental to
radars point cloud distribution and would benefit other radar sensing
applications.",1,1,0,0,0,0,0.60032,7.0,0.757716,64
http://arxiv.org/abs/2205.12475v1,Low Resource Style Transfer via Domain Adaptive Meta Learning,6,0.111883,0.164484,"Text style transfer (TST) without parallel data has achieved some practical
success. However, most of the existing unsupervised text style transfer methods
suffer from (i) requiring massive amounts of non-parallel data to guide
transferring different text styles. (ii) colossal performance degradation when
fine-tuning the model in new domains. In this work, we propose DAML-ATM (Domain
Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two
parts: DAML and ATM. DAML is a domain adaptive meta-learning approach to learn
general knowledge in multiple heterogeneous source domains, capable of adapting
to new unseen domains with a small amount of data. Moreover, we propose a new
unsupervised TST approach Adversarial Transfer Model (ATM), composed of a
sequence-to-sequence pre-trained language model and uses adversarial style
training for better content preservation and style transfer. Results on
multi-domain datasets demonstrate that our approach generalizes well on unseen
low-resource domains, achieving state-of-the-art results against ten strong
baselines.",0,1,0,0,1,0,0.59114,7.0,0.754134,62
http://arxiv.org/abs/2204.12749v2,"Control Globally, Understand Locally: A Global-to-Local Hierarchical Graph Network for Emotional Support Conversation",45,0.538726,0.99951,"Emotional support conversation aims at reducing the emotional distress of the
help-seeker, which is a new and challenging task. It requires the system to
explore the cause of help-seeker's emotional distress and understand their
psychological intention to provide supportive responses. However, existing
methods mainly focus on the sequential contextual information, ignoring the
hierarchical relationships with the global cause and local psychological
intention behind conversations, thus leads to a weak ability of emotional
support. In this paper, we propose a Global-to-Local Hierarchical Graph Network
to capture the multi-source information (global cause, local intentions and
dialog history) and model hierarchical relationships between them, which
consists of a multi-source encoder, a hierarchical graph reasoner, and a
global-guide decoder. Furthermore, a novel training objective is designed to
monitor semantic information of the global cause. Experimental results on the
emotional support conversation dataset, ESConv, confirm that the proposed GLHG
has achieved the state-of-the-art performance on the automatic and human
evaluations. The code will be released in here
\footnote{\small{~https://github.com/pengwei-iie/GLHG}}.",1,1,1,0,1,0,0.677796,6.0,0.752508,35
http://arxiv.org/abs/2203.11147v1,Teaching language models to support answers with verified quotes,160,0.984632,1.0,"Recent large language models often answer factual questions correctly. But
users can't trust any given claim a model makes without fact-checking, because
language models can hallucinate convincing nonsense. In this work we use
reinforcement learning from human preferences (RLHP) to train ""open-book"" QA
models that generate answers whilst also citing specific evidence for their
claims, which aids in the appraisal of correctness. Supporting evidence is
drawn from multiple documents found via a search engine, or from a single
user-provided document. Our 280 billion parameter model, GopherCite, is able to
produce answers with high quality supporting evidence and abstain from
answering when unsure. We measure the performance of GopherCite by conducting
human evaluation of answers to questions in a subset of the NaturalQuestions
and ELI5 datasets. The model's response is found to be high-quality 80\% of the
time on this Natural Questions subset, and 67\% of the time on the ELI5 subset.
Abstaining from the third of questions for which it is most unsure improves
performance to 90\% and 80\% respectively, approaching human baselines.
However, analysis on the adversarial TruthfulQA dataset shows why citation is
only one part of an overall strategy for safety and trustworthiness: not all
claims supported by evidence are true.",0,0,0,0,0,0,0.97742,5.0,0.944623,72
http://arxiv.org/abs/2210.06716v1,Low-resource Neural Machine Translation with Cross-modal Alignment,6,0.24201,0.279801,"How to achieve neural machine translation with limited parallel data?
Existing techniques often rely on large-scale monolingual corpora, which is
impractical for some low-resource languages. In this paper, we turn to connect
several low-resource languages to a particular high-resource one by additional
visual modality. Specifically, we propose a cross-modal contrastive learning
method to learn a shared space for all languages, where both a coarse-grained
sentence-level objective and a fine-grained token-level one are introduced.
Experimental results and further analysis show that our method can effectively
learn the cross-modal and cross-lingual alignment with a small amount of
image-text pairs and achieves significant improvements over the text-only
baseline under both zero-shot and few-shot scenarios.",0,1,0,0,0,0,0.900271,8.0,0.903222,57
http://arxiv.org/abs/2203.07060v2,MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic Environments,15,0.113484,0.484447,"This work addresses a gap in semantic scene completion (SSC) data by creating
a novel outdoor data set with accurate and complete dynamic scenes. Our data
set is formed from randomly sampled views of the world at each time step, which
supervises generalizability to complete scenes without occlusions or traces. We
create SSC baselines from state-of-the-art open source networks and construct a
benchmark real-time dense local semantic mapping algorithm, MotionSC, by
leveraging recent 3D deep learning architectures to enhance SSC with temporal
information. Our network shows that the proposed data set can quantify and
supervise accurate scene completion in the presence of dynamic objects, which
can lead to the development of improved dynamic mapping algorithms. All
software is available at https://github.com/UMich-CURLY/3DMapping.",1,1,1,1,0,0,0.265228,8.0,0.651692,62
http://arxiv.org/abs/2203.06898v1,Efficient universal shuffle attack for visual object tracking,26,0.134021,0.622087,"Recently, adversarial attacks have been applied in visual object tracking to
deceive deep trackers by injecting imperceptible perturbations into video
frames. However, previous work only generates the video-specific perturbations,
which restricts its application scenarios. In addition, existing attacks are
difficult to implement in reality due to the real-time of tracking and the
re-initialization mechanism. To address these issues, we propose an offline
universal adversarial attack called Efficient Universal Shuffle Attack. It
takes only one perturbation to cause the tracker malfunction on all videos. To
improve the computational efficiency and attack performance, we propose a
greedy gradient strategy and a triple loss to efficiently capture and attack
model-specific feature representations through the gradients. Experimental
results show that EUSA can significantly reduce the performance of
state-of-the-art trackers on OTB2015 and VOT2018.",0,1,0,0,0,0,0.453155,8.0,0.735713,18
http://arxiv.org/abs/2211.10163v1,Overview of the HASOC Subtrack at FIRE 2022: Offensive Language Identification in Marathi,12,0.258406,0.897191,"The widespread of offensive content online has become a reason for great
concern in recent years, motivating researchers to develop robust systems
capable of identifying such content automatically. With the goal of carrying
out a fair evaluation of these systems, several international competitions have
been organized, providing the community with important benchmark data and
evaluation methods for various languages. Organized since 2019, the HASOC (Hate
Speech and Offensive Content Identification) shared task is one of these
initiatives. In its fourth iteration, HASOC 2022 included three subtracks for
English, Hindi, and Marathi. In this paper, we report the results of the HASOC
2022 Marathi subtrack which provided participants with a dataset containing
data from Twitter manually annotated using the popular OLID taxonomy. The
Marathi track featured three additional subtracks, each corresponding to one
level of the taxonomy: Task A - offensive content identification (offensive vs.
non-offensive); Task B - categorization of offensive types (targeted vs.
untargeted), and Task C - offensive target identification (individual vs. group
vs. others). Overall, 59 runs were submitted by 10 teams. The best systems
obtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and
F1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of
traditional and deep learning approaches.",0,1,0,1,0,0,0.480666,7.0,0.70968,66
http://arxiv.org/abs/2210.07733v1,Fine-grained Category Discovery under Coarse-grained supervision with Hierarchical Weighted Self-contrastive Learning,10,0.111666,0.798809,"Novel category discovery aims at adapting models trained on known categories
to novel categories. Previous works only focus on the scenario where known and
novel categories are of the same granularity. In this paper, we investigate a
new practical scenario called Fine-grained Category Discovery under
Coarse-grained supervision (FCDC). FCDC aims at discovering fine-grained
categories with only coarse-grained labeled data, which can adapt models to
categories of different granularity from known ones and reduce significant
labeling cost. It is also a challenging task since supervised training on
coarse-grained categories tends to focus on inter-class distance (distance
between coarse-grained classes) but ignore intra-class distance (distance
between fine-grained sub-classes) which is essential for separating
fine-grained categories. Considering most current methods cannot transfer
knowledge from coarse-grained level to fine-grained level, we propose a
hierarchical weighted self-contrastive network by building a novel weighted
self-contrastive module and combining it with supervised learning in a
hierarchical manner. Extensive experiments on public datasets show both
effectiveness and efficiency of our model over compared methods. Code and data
are available at https://github.com/Lackel/Hierarchical_Weighted_SCL.",1,1,1,0,0,0,0.860938,6.0,0.845006,56
http://arxiv.org/abs/2207.13744v2,Lighting (In)consistency of Paint by Text,17,0.889989,0.389544,"Whereas generative adversarial networks are capable of synthesizing highly
realistic images of faces, cats, landscapes, or almost any other single
category, paint-by-text synthesis engines can -- from a single text prompt --
synthesize realistic images of seemingly endless categories with arbitrary
configurations and combinations. This powerful technology poses new challenges
to the photo-forensic community. Motivated by the fact that paint by text is
not based on explicit geometric or physical models, and the human visual
system's general insensitivity to lighting inconsistencies, we provide an
initial exploration of the lighting consistency of DALL-E-2 synthesized images
to determine if physics-based forensic analyses will prove fruitful in
detecting this new breed of synthetic media.",0,0,0,0,0,0,0.904382,24.0,0.968494,22
http://arxiv.org/abs/2209.03656v1,Saliency-based Multiple Region of Interest Detection from a Single 360° image,1,0.0693794,0.249849,"360{\deg} images are informative -- it contains omnidirectional visual
information around the camera. However, the areas that cover a 360{\deg} image
is much larger than the human's field of view, therefore important information
in different view directions is easily overlooked. To tackle this issue, we
propose a method for predicting the optimal set of Region of Interest (RoI)
from a single 360{\deg} image using the visual saliency as a clue. To deal with
the scarce, strongly biased training data of existing single 360{\deg} image
saliency prediction dataset, we also propose a data augmentation method based
on the spherical random data rotation. From the predicted saliency map and
redundant candidate regions, we obtain the optimal set of RoIs considering both
the saliency within a region and the Interaction-Over-Union (IoU) between
regions. We conduct the subjective evaluation to show that the proposed method
can select regions that properly summarize the input 360{\deg} image.",0,1,0,0,0,0,0.707677,11.0,0.872499,34
http://arxiv.org/abs/2211.10024v3,Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks,9,0.0317409,0.57359,"This paper considers the problem of helping humans exercise scalable
oversight over deep neural networks (DNNs). Adversarial examples can be useful
by helping to reveal weaknesses in DNNs, but they can be difficult to interpret
or draw actionable conclusions from. Some previous works have proposed using
human-interpretable adversarial attacks including copy/paste attacks in which
one natural image pasted into another causes an unexpected misclassification.
We build on these with two contributions. First, we introduce Search for
Natural Adversarial Features Using Embeddings (SNAFUE) which offers a fully
automated method for finding copy/paste attacks. Second, we use SNAFUE to red
team an ImageNet classifier. We reproduce copy/paste attacks from previous
works and find hundreds of other easily-describable vulnerabilities, all
without a human in the loop. Code is available at
https://github.com/thestephencasper/snafue",1,1,0,0,0,0,0.154098,8.0,0.575363,73
http://arxiv.org/abs/2209.05488v1,Deep Neural Networks as Complex Networks,3,0.0107731,0.348481,"Deep Neural Networks are, from a physical perspective, graphs whose `links`
and `vertices` iteratively process data and solve tasks sub-optimally. We use
Complex Network Theory (CNT) to represents Deep Neural Networks (DNNs) as
directed weighted graphs: within this framework, we introduce metrics to study
DNNs as dynamical systems, with a granularity that spans from weights to
layers, including neurons. CNT discriminates networks that differ in the number
of parameters and neurons, the type of hidden layers and activations, and the
objective task. We further show that our metrics discriminate low vs. high
performing networks. CNT is a comprehensive method to reason about DNNs and a
complementary approach to explain a model's behavior that is physically
grounded to networks theory and goes beyond the well-studied input-output
relation.",0,0,0,0,0,0,0.0196837,11.0,0.497502,16
http://arxiv.org/abs/2208.13954v1,Video-based Cross-modal Auxiliary Network for Multimodal Sentiment Analysis,6,0.0899742,0.365504,"Multimodal sentiment analysis has a wide range of applications due to its
information complementarity in multimodal interactions. Previous works focus
more on investigating efficient joint representations, but they rarely consider
the insufficient unimodal features extraction and data redundancy of multimodal
fusion. In this paper, a Video-based Cross-modal Auxiliary Network (VCAN) is
proposed, which is comprised of an audio features map module and a cross-modal
selection module. The first module is designed to substantially increase
feature diversity in audio feature extraction, aiming to improve classification
accuracy by providing more comprehensive acoustic representations. To empower
the model to handle redundant visual features, the second module is addressed
to efficiently filter the redundant visual frames during integrating
audiovisual data. Moreover, a classifier group consisting of several image
classification networks is introduced to predict sentiment polarities and
emotion categories. Extensive experimental results on RAVDESS, CMU-MOSI, and
CMU-MOSEI benchmarks indicate that VCAN is significantly superior to the
state-of-the-art methods for improving the classification accuracy of
multimodal sentiment analysis.",0,1,0,0,1,0,0.148644,8.0,0.570469,58
http://arxiv.org/abs/2204.12993v5,Counterfactual harm,16,0.168806,0.679612,"To act safely and ethically in the real world, agents must be able to reason
about harm and avoid harmful actions. However, to date there is no statistical
method for measuring harm and factoring it into algorithmic decisions. In this
paper we propose the first formal definition of harm and benefit using causal
models. We show that any factual definition of harm must violate basic
intuitions in certain scenarios, and show that standard machine learning
algorithms that cannot perform counterfactual reasoning are guaranteed to
pursue harmful policies following distributional shifts. We use our definition
of harm to devise a framework for harm-averse decision making using
counterfactual objective functions. We demonstrate this framework on the
problem of identifying optimal drug doses using a dose-response model learned
from randomized control trial data. We find that the standard method of
selecting doses using treatment effects results in unnecessarily harmful doses,
while our counterfactual approach allows us to identify doses that are
significantly less harmful without sacrificing efficacy.",0,0,1,0,0,0,0.288293,9.0,0.701335,128
