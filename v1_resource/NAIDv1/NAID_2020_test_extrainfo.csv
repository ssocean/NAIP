id,title,cites,TNCSI,TNCSI_SP,abstract,OA,is_practical,new_task,new_dataset,SOTA,is_broad,RQM,SMP,ARQ,Ref_num
7b090cb9-dfa5-4ed2-94d1-9be1768183b1,MT-Adapted Datasheets for Datasets: Template and Repository,11,0.0183772,0.206388,"In this report we are taking the standardized model proposed by Gebru et al.
(2018) for documenting the popular machine translation datasets of the EuroParl
(Koehn, 2005) and News-Commentary (Barrault et al., 2019). Within this
documentation process, we have adapted the original datasheet to the particular
case of data consumers within the Machine Translation area. We are also
proposing a repository for collecting the adapted datasheets in this research
area",0,1,0,0,0,0,0.608958,3.0,0.442519,17
42a39ada-10ed-4912-84f1-506b14c1bf7c,Universal linguistic inductive biases via meta-learning,23,0.0778299,0.403932,"How do learners acquire languages from the limited data available to them?
This process must involve some inductive biases - factors that affect how a
learner generalizes - but it is unclear which inductive biases can explain
observed patterns in language acquisition. To facilitate computational modeling
aimed at addressing this question, we introduce a framework for giving
particular linguistic inductive biases to a neural network model; such a model
can then be used to empirically explore the effects of those inductive biases.
This framework disentangles universal inductive biases, which are encoded in
the initial values of a neural network's parameters, from non-universal
factors, which the neural network must learn from data in a given language. The
initial state that encodes the inductive biases is found with meta-learning, a
technique through which a model discovers how to acquire new languages more
easily via exposure to many possible languages. By controlling the properties
of the languages that are used during meta-learning, we can control the
inductive biases that meta-learning imparts. We demonstrate this framework with
a case study based on syllable structure. First, we specify the inductive
biases that we intend to give our model, and then we translate those inductive
biases into a space of languages from which a model can meta-learn. Finally,
using existing analysis techniques, we verify that our approach has imparted
the linguistic inductive biases that it was intended to impart.",0,0,0,0,0,0,0.0142305,17.0,0.655609,37
6b390431-3927-4ea1-b66e-9648e8d40cb8,Distilling a Deep Neural Network into a Takagi-Sugeno-Kang Fuzzy Inference System,6,0.0591655,0.113084,"Deep neural networks (DNNs) demonstrate great success in classification
tasks. However, they act as black boxes and we don't know how they make
decisions in a particular classification task. To this end, we propose to
distill the knowledge from a DNN into a fuzzy inference system (FIS), which is
Takagi-Sugeno-Kang (TSK)-type in this paper. The model has the capability to
express the knowledge acquired by a DNN based on fuzzy rules, thus explaining a
particular decision much easier. Knowledge distillation (KD) is applied to
create a TSK-type FIS that generalizes better than one directly from the
training data, which is guaranteed through experiments in this paper. To
further improve the performances, we modify the baseline method of KD and
obtain good results.",0,0,0,0,0,0,0.754725,9.0,0.858985,25
d3f65134-153b-46e2-ab3a-845280dea5fb,Parallel Interactive Networks for Multi-Domain Dialogue State Generation,12,0.294149,0.336597,"The dependencies between system and user utterances in the same turn and
across different turns are not fully considered in existing multidomain
dialogue state tracking (MDST) models. In this study, we argue that the
incorporation of these dependencies is crucial for the design of MDST and
propose Parallel Interactive Networks (PIN) to model these dependencies.
Specifically, we integrate an interactive encoder to jointly model the in-turn
dependencies and cross-turn dependencies. The slot-level context is introduced
to extract more expressive features for different slots. And a distributed copy
mechanism is utilized to selectively copy words from historical system
utterances or historical user utterances. Empirical studies demonstrated the
superiority of the proposed PIN model.",0,1,0,0,0,0,0.839789,9.0,0.888397,37
14909bfe-7fd9-47f7-af3f-dd1c6b6f7be0,A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring of Answer Transcriptions in Video Job Interviews,3,0.00616166,0.0220961,"We address the task of automatically scoring the competency of candidates
based on textual features, from the automatic speech recognition (ASR)
transcriptions in the asynchronous video job interview (AVI). The key challenge
is how to construct the dependency relation between questions and answers, and
conduct the semantic level interaction for each question-answer (QA) pair.
However, most of the recent studies in AVI focus on how to represent questions
and answers better, but ignore the dependency information and interaction
between them, which is critical for QA evaluation. In this work, we propose a
Hierarchical Reasoning Graph Neural Network (HRGNN) for the automatic
assessment of question-answer pairs. Specifically, we construct a
sentence-level relational graph neural network to capture the dependency
information of sentences in or between the question and the answer. Based on
these graphs, we employ a semantic-level reasoning graph attention network to
model the interaction states of the current QA session. Finally, we propose a
gated recurrent unit encoder to represent the temporal question-answer pairs
for the final prediction. Empirical results conducted on CHNAT (a real-world
dataset) validate that our proposed model significantly outperforms
text-matching based benchmark models. Ablation studies and experimental results
with 10 random seeds also show the effectiveness and stability of our models.",0,0,0,0,1,0,0.158052,6.0,0.438419,45
2b044a83-bd31-4dfd-9739-d304ad984278,A Deep Ensemble Multi-Agent Reinforcement Learning Approach for Air Traffic Control,12,0.144825,0.533495,"Air traffic control is an example of a highly challenging operational problem
that is readily amenable to human expertise augmentation via decision support
technologies. In this paper, we propose a new intelligent decision making
framework that leverages multi-agent reinforcement learning (MARL) to
dynamically suggest adjustments of aircraft speeds in real-time. The goal of
the system is to enhance the ability of an air traffic controller to provide
effective guidance to aircraft to avoid air traffic congestion, near-miss
situations, and to improve arrival timeliness. We develop a novel deep ensemble
MARL method that can concisely capture the complexity of the air traffic
control problem by learning to efficiently arbitrate between the decisions of a
local kernel-based RL model and a wider-reaching deep MARL model. The proposed
method is trained and evaluated on an open-source air traffic management
simulator developed by Eurocontrol. Extensive empirical results on a real-world
dataset including thousands of aircraft demonstrate the feasibility of using
multi-agent RL for the problem of en-route air traffic control and show that
our proposed deep ensemble MARL method significantly outperforms three
state-of-the-art benchmark approaches.",1,1,0,0,1,0,0.287016,11.0,0.755157,43
ca14fb48-591e-4cb6-be9b-599de89eae5f,What Are People Asking About COVID-19? A Question Classification Dataset,33,0.104509,0.717213,"We present COVID-Q, a set of 1,690 questions about COVID-19 from 13 sources,
which we annotate into 15 question categories and 207 question clusters. The
most common questions in our dataset asked about transmission, prevention, and
societal effects of COVID, and we found that many questions that appeared in
multiple sources were not answered by any FAQ websites of reputable
organizations such as the CDC and FDA. We post our dataset publicly at
https://github.com/JerryWeiAI/COVID-Q. For classifying questions into 15
categories, a BERT baseline scored 58.1% accuracy when trained on 20 examples
per category, and for a question clustering task, a BERT + triplet loss
baseline achieved 49.5% accuracy. We hope COVID-Q can help either for direct
use in developing applied systems or as a domain-specific resource for model
evaluation.",0,1,0,1,0,0,0.939386,1.0,0.421332,17
37ae7be9-7b8f-4ab6-99bf-40c659bf4cec,NTIRE 2020 Challenge on Image and Video Deblurring,30,0.786945,0.696924,"Motion blur is one of the most common degradation artifacts in dynamic scene
photography. This paper reviews the NTIRE 2020 Challenge on Image and Video
Deblurring. In this challenge, we present the evaluation results from 3
competition tracks as well as the proposed solutions. Track 1 aims to develop
single-image deblurring methods focusing on restoration quality. On Track 2,
the image deblurring methods are executed on a mobile platform to find the
balance of the running speed and the restoration accuracy. Track 3 targets
developing video deblurring methods that exploit the temporal relation between
input frames. In each competition, there were 163, 135, and 102 registered
participants and in the final testing phase, 9, 4, and 7 teams competed. The
winning methods demonstrate the state-ofthe-art performance on image and video
deblurring tasks.",0,1,0,0,1,0,0.96978,5.0,0.928623,100
844913d2-a385-4bed-a8da-bd0267f26055,Multi-Plateau Ensemble for Endoscopic Artefact Segmentation and Detection,3,0.164475,0.123789,"Endoscopic artefact detection challenge consists of 1) Artefact detection, 2)
Semantic segmentation, and 3) Out-of-sample generalisation. For Semantic
segmentation task, we propose a multi-plateau ensemble of FPN (Feature Pyramid
Network) with EfficientNet as feature extractor/encoder. For Object detection
task, we used a three model ensemble of RetinaNet with Resnet50 Backbone and
FasterRCNN (FPN + DC5) with Resnext101 Backbone}. A PyTorch implementation to
our approach to the problem is available at
https://github.com/ubamba98/EAD2020.",1,1,0,0,0,0,0.992855,6.0,0.998034,15
5dfd31e1-b52f-42f4-9ab8-efdc971da33f,BioMegatron: Larger Biomedical Domain Language Model,118,0.775084,0.745951,"There has been an influx of biomedical domain-specific language models,
showing language models pre-trained on biomedical text perform better on
biomedical domain benchmarks than those trained on general domain text corpora
such as Wikipedia and Books. Yet, most works do not study the factors affecting
each domain language application deeply. Additionally, the study of model size
on domain-specific models has been mostly missing. We empirically study and
evaluate several factors that can affect performance on domain language
applications, such as the sub-word vocabulary set, model size, pre-training
corpus, and domain transfer. We show consistent improvements on benchmarks with
our larger BioMegatron model trained on a larger domain corpus, contributing to
our understanding of domain language model applications. We demonstrate
noticeable improvements over the previous state-of-the-art (SOTA) on standard
biomedical NLP benchmarks of named entity recognition, relation extraction, and
question answering. Model checkpoints and code are available at
[https://ngc.nvidia.com] and [https://github.com/NVIDIA/NeMo].",1,1,0,0,1,0,0.985082,4.0,0.95672,27
3f980e2b-6ced-4fa5-b407-70c40abf2ec4,Multi-Objective Evolutionary approach for the Performance Improvement of Learners using Ensembling Feature selection and Discretization Technique on Medical data,7,0.208641,0.174434,"Biomedical data is filled with continuous real values; these values in the
feature set tend to create problems like underfitting, the curse of
dimensionality and increase in misclassification rate because of higher
variance. In response, pre-processing techniques on dataset minimizes the side
effects and have shown success in maintaining the adequate accuracy. Feature
selection and discretization are the two necessary preprocessing steps that
were effectively employed to handle the data redundancies in the biomedical
data. However, in the previous works, the absence of unified effort by
integrating feature selection and discretization together in solving the data
redundancy problem leads to the disjoint and fragmented field. This paper
proposes a novel multi-objective based dimensionality reduction framework,
which incorporates both discretization and feature reduction as an ensemble
model for performing feature selection and discretization. Selection of optimal
features and the categorization of discretized and non-discretized features
from the feature subset is governed by the multi-objective genetic algorithm
(NSGA-II). The two objective, minimizing the error rate during the feature
selection and maximizing the information gain while discretization is
considered as fitness criteria.",0,1,0,0,0,0,0.105738,21.0,0.819006,58
d03b2b60-91bb-4fa4-97c9-15d113af30a2,Analysis and Prediction of Deforming 3D Shapes using Oriented Bounding Boxes and LSTM Autoencoders,6,0.0132951,0.202273,"For sequences of complex 3D shapes in time we present a general approach to
detect patterns for their analysis and to predict the deformation by making use
of structural components of the complex shape. We incorporate long short-term
memory (LSTM) layers into an autoencoder to create low dimensional
representations that allow the detection of patterns in the data and
additionally detect the temporal dynamics in the deformation behavior. This is
achieved with two decoders, one for reconstruction and one for prediction of
future time steps of the sequence. In a preprocessing step the components of
the studied object are converted to oriented bounding boxes which capture the
impact of plastic deformation and allow reducing the dimensionality of the data
describing the structure. The architecture is tested on the results of 196 car
crash simulations of a model with 133 different components, where material
properties are varied. In the latent representation we can detect patterns in
the plastic deformation for the different components. The predicted bounding
boxes give an estimate of the final simulation result and their quality is
improved in comparison to different baselines.",0,0,0,0,0,0,0.00764085,12.0,0.460012,31
30c7298a-44cd-4af1-82ca-edcb95db8364,An Application of Deep Reinforcement Learning to Algorithmic Trading,116,0.325194,0.977655,"This scientific research paper presents an innovative approach based on deep
reinforcement learning (DRL) to solve the algorithmic trading problem of
determining the optimal trading position at any point in time during a trading
activity in stock markets. It proposes a novel DRL trading strategy so as to
maximise the resulting Sharpe ratio performance indicator on a broad range of
stock markets. Denominated the Trading Deep Q-Network algorithm (TDQN), this
new trading strategy is inspired from the popular DQN algorithm and
significantly adapted to the specific algorithmic trading problem at hand. The
training of the resulting reinforcement learning (RL) agent is entirely based
on the generation of artificial trajectories from a limited set of stock market
historical data. In order to objectively assess the performance of trading
strategies, the research paper also proposes a novel, more rigorous performance
assessment methodology. Following this new performance assessment approach,
promising results are reported for the TDQN strategy.",1,1,0,0,0,0,0.18556,10.0,0.680706,48
4ebe3115-103b-4567-ba63-5aa313791623,PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning,487,0.860329,1.0,"Lifelong learning has attracted much attention, but existing works still
struggle to fight catastrophic forgetting and accumulate knowledge over long
stretches of incremental learning. In this work, we propose PODNet, a model
inspired by representation learning. By carefully balancing the compromise
between remembering the old classes and learning new ones, PODNet fights
catastrophic forgetting, even over very long runs of small incremental tasks
--a setting so far unexplored by current works. PODNet innovates on existing
art with an efficient spatial-based distillation-loss applied throughout the
model and a representation comprising multiple proxy vectors for each class. We
validate those innovations thoroughly, comparing PODNet with three
state-of-the-art models on three datasets: CIFAR100, ImageNet100, and
ImageNet1000. Our results showcase a significant advantage of PODNet over
existing art, with accuracy gains of 12.10, 6.51, and 2.85 percentage points,
respectively. Code is available at
https://github.com/arthurdouillard/incremental_learning.pytorch",1,0,0,0,1,0,0.915253,7.0,0.899143,40
f77ebbd3-6e10-4162-ab6f-cc3a17c57693,Complementary Network with Adaptive Receptive Fields for Melanoma Segmentation,13,0.387584,0.106923,"Automatic melanoma segmentation in dermoscopic images is essential in
computer-aided diagnosis of skin cancer. Existing methods may suffer from the
hole and shrink problems with limited segmentation performance. To tackle these
issues, we propose a novel complementary network with adaptive receptive filed
learning. Instead of regarding the segmentation task independently, we
introduce a foreground network to detect melanoma lesions and a background
network to mask non-melanoma regions. Moreover, we propose adaptive atrous
convolution (AAC) and knowledge aggregation module (KAM) to fill holes and
alleviate the shrink problems. AAC explicitly controls the receptive field at
multiple scales and KAM convolves shallow feature maps by dilated convolutions
with adaptive receptive fields, which are adjusted according to deep feature
maps. In addition, a novel mutual loss is proposed to utilize the dependency
between the foreground and background networks, thereby enabling the
reciprocally influence within these two networks. Consequently, this mutual
training strategy enables the semi-supervised learning and improve the
boundary-sensitivity. Training with Skin Imaging Collaboration (ISIC) 2018 skin
lesion segmentation dataset, our method achieves a dice co-efficient of 86.4%
and shows better performance compared with state-of-the-art melanoma
segmentation methods.",1,1,0,0,1,0,0.992662,6.0,0.997133,8
f0a0eca2-40f8-4f30-8b84-94985da9d1df,Response Selection for Multi-Party Conversations with Dynamic Topic Tracking,39,0.131214,0.831651,"While participants in a multi-party multi-turn conversation simultaneously
engage in multiple conversation topics, existing response selection methods are
developed mainly focusing on a two-party single-conversation scenario. Hence,
the prolongation and transition of conversation topics are ignored by current
methods. In this work, we frame response selection as a dynamic topic tracking
task to match the topic between the response and relevant conversation context.
With this new formulation, we propose a novel multi-task learning framework
that supports efficient encoding through large pretrained models with only two
utterances at once to perform dynamic topic disentanglement and response
selection. We also propose Topic-BERT an essential pretraining step to embed
topic information into BERT with self-supervised learning. Experimental results
on the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response
selection and topic disentanglement tasks outperforming existing methods by a
good margin.",1,1,1,0,1,0,0.229376,5.0,0.409124,44
dd053cac-0ead-478c-a3db-0f9947202a50,Optimal Neural Program Synthesis from Multimodal Specifications,17,0.142359,0.260493,"Multimodal program synthesis, which leverages different types of user input
to synthesize a desired program, is an attractive way to scale program
synthesis to challenging settings; however, it requires integrating noisy
signals from the user, like natural language, with hard constraints on the
program's behavior. This paper proposes an optimal neural synthesis approach
where the goal is to find a program that satisfies user-provided constraints
while also maximizing the program's score with respect to a neural model.
Specifically, we focus on multimodal synthesis tasks in which the user intent
is expressed using a combination of natural language (NL) and input-output
examples. At the core of our method is a top-down recurrent neural model that
places distributions over abstract syntax trees conditioned on the NL input.
This model not only allows for efficient search over the space of syntactically
valid programs, but it allows us to leverage automated program analysis
techniques for pruning the search space based on infeasibility of partial
programs with respect to the user's constraints. The experimental results on a
multimodal synthesis dataset (StructuredRegex) show that our method
substantially outperforms prior state-of-the-art techniques in terms of
accuracy and efficiency, and finds model-optimal programs more frequently.",0,0,0,0,1,0,0.441328,8.0,0.731201,48
4c87685d-9ce5-4806-a6d9-ffe763e4ae7b,Meta Learning Backpropagation And Improving It,52,0.192452,0.650729,"Many concepts have been proposed for meta learning with neural networks
(NNs), e.g., NNs that learn to reprogram fast weights, Hebbian plasticity,
learned learning rules, and meta recurrent NNs. Our Variable Shared Meta
Learning (VSML) unifies the above and demonstrates that simple weight-sharing
and sparsity in an NN is sufficient to express powerful learning algorithms
(LAs) in a reusable fashion. A simple implementation of VSML where the weights
of a neural network are replaced by tiny LSTMs allows for implementing the
backpropagation LA solely by running in forward-mode. It can even meta learn
new LAs that differ from online backpropagation and generalize to datasets
outside of the meta training distribution without explicit gradient
calculation. Introspection reveals that our meta learned LAs learn through fast
association in a way that is qualitatively different from gradient descent.",0,0,0,0,0,0,0.253018,7.0,0.594083,63
5e3246c6-1e46-49c1-822e-4d9664c256e2,Deep Metric Learning Meets Deep Clustering: An Novel Unsupervised Approach for Feature Embedding,10,0.042818,0.162289,"Unsupervised Deep Distance Metric Learning (UDML) aims to learn sample
similarities in the embedding space from an unlabeled dataset. Traditional UDML
methods usually use the triplet loss or pairwise loss which requires the mining
of positive and negative samples w.r.t. anchor data points. This is, however,
challenging in an unsupervised setting as the label information is not
available. In this paper, we propose a new UDML method that overcomes that
challenge. In particular, we propose to use a deep clustering loss to learn
centroids, i.e., pseudo labels, that represent semantic classes. During
learning, these centroids are also used to reconstruct the input samples. It
hence ensures the representativeness of centroids - each centroid represents
visually similar samples. Therefore, the centroids give information about
positive (visually similar) and negative (visually dissimilar) samples. Based
on pseudo labels, we propose a novel unsupervised metric loss which enforces
the positive concentration and negative separation of samples in the embedding
space. Experimental results on benchmarking datasets show that the proposed
approach outperforms other UDML methods.",0,0,0,0,0,0,0.640632,10.0,0.84137,55
57e63149-d6a3-42f0-87e6-043d12415747,Language Modelling for Source Code with Transformer-XL,8,0.0370432,0.100889,"It has been found that software, like natural language texts, exhibits
""naturalness"", which can be captured by statistical language models. In recent
years, neural language models have been proposed to represent the naturalness
of software through deep learning. In this paper, we conduct an experimental
evaluation of state-of-the-art neural language models for source code,
including RNN-based models and Transformer-XL based models. Through experiments
on a large-scale Python code corpus, we find that the Transformer-XL model
outperforms RNN-based models (including LSTM and GRU models) in capturing the
naturalness of software, with far less computational cost.",1,1,0,0,1,0,0.40259,9.0,0.747474,35
1582b110-12e5-4f35-a89d-d6d8274588eb,RoadText-1K: Text Detection & Recognition Dataset for Driving Videos,44,0.156411,0.72002,"Perceiving text is crucial to understand semantics of outdoor scenes and
hence is a critical requirement to build intelligent systems for driver
assistance and self-driving. Most of the existing datasets for text detection
and recognition comprise still images and are mostly compiled keeping text in
mind. This paper introduces a new ""RoadText-1K"" dataset for text in driving
videos. The dataset is 20 times larger than the existing largest dataset for
text in videos. Our dataset comprises 1000 video clips of driving without any
bias towards text and with annotations for text bounding boxes and
transcriptions in every frame. State of the art methods for text detection,
recognition and tracking are evaluated on the new dataset and the results
signify the challenges in unconstrained driving videos compared to existing
datasets. This suggests that RoadText-1K is suited for research and development
of reading systems, robust enough to be incorporated into more complex
downstream tasks like driver assistance and self-driving. The dataset can be
found at http://cvit.iiit.ac.in/research/projects/cvit-projects/roadtext-1k",0,1,1,1,0,0,0.0460388,9.0,0.481752,50
05050f34-0347-4e13-9b05-22276d76973c,Scalable and Customizable Benchmark Problems for Many-Objective Optimization,24,0.105648,0.633756,"Solving many-objective problems (MaOPs) is still a significant challenge in
the multi-objective optimization (MOO) field. One way to measure algorithm
performance is through the use of benchmark functions (also called test
functions or test suites), which are artificial problems with a well-defined
mathematical formulation, known solutions and a variety of features and
difficulties. In this paper we propose a parameterized generator of scalable
and customizable benchmark problems for MaOPs. It is able to generate problems
that reproduce features present in other benchmarks and also problems with some
new features. We propose here the concept of generative benchmarking, in which
one can generate an infinite number of MOO problems, by varying parameters that
control specific features that the problem should have: scalability in the
number of variables and objectives, bias, deceptiveness, multimodality, robust
and non-robust solutions, shape of the Pareto front, and constraints. The
proposed Generalized Position-Distance (GPD) tunable benchmark generator uses
the position-distance paradigm, a basic approach to building test functions,
used in other benchmarks such as Deb, Thiele, Laumanns and Zitzler (DTLZ),
Walking Fish Group (WFG) and others. It includes scalable problems in any
number of variables and objectives and it presents Pareto fronts with different
characteristics. The resulting functions are easy to understand and visualize,
easy to implement, fast to compute and their Pareto optimal solutions are
known.",0,0,0,1,0,0,0.162584,7.0,0.523059,60
9e5eaaaf-1503-4510-8e37-99518a4c6e9a,Explaining reputation assessments,5,0.0766586,0.120162,"Reputation is crucial to enabling human or software agents to select among
alternative providers. Although several effective reputation assessment methods
exist, they typically distil reputation into a numerical representation, with
no accompanying explanation of the rationale behind the assessment. Such
explanations would allow users or clients to make a richer assessment of
providers, and tailor selection according to their preferences and current
context. In this paper, we propose an approach to explain the rationale behind
assessments from quantitative reputation models, by generating arguments that
are combined to form explanations. Our approach adapts, extends and combines
existing approaches for explaining decisions made using multi-attribute
decision models in the context of reputation. We present example argument
templates, and describe how to select their parameters using explanation
algorithms. Our proposal was evaluated by means of a user study, which followed
an existing protocol. Our results give evidence that although explanations
present a subset of the information of trust scores, they are sufficient to
equally evaluate providers recommended based on their trust score. Moreover,
when explanation arguments reveal implicit model information, they are less
persuasive than scores.",0,0,0,0,0,0,0.0269448,25.0,0.791609,41
6a24a787-7d9c-4e67-8b31-48857e18dbd7,Image Captioning with Context-Aware Auxiliary Guidance,23,0.0873986,0.318292,"Image captioning is a challenging computer vision task, which aims to
generate a natural language description of an image. Most recent researches
follow the encoder-decoder framework which depends heavily on the previous
generated words for the current prediction. Such methods can not effectively
take advantage of the future predicted information to learn complete semantics.
In this paper, we propose Context-Aware Auxiliary Guidance (CAAG) mechanism
that can guide the captioning model to perceive global contexts. Upon the
captioning model, CAAG performs semantic attention that selectively
concentrates on useful information of the global predictions to reproduce the
current generation. To validate the adaptability of the method, we apply CAAG
to three popular captioners and our proposal achieves competitive performance
on the challenging Microsoft COCO image captioning benchmark, e.g. 132.2
CIDEr-D score on Karpathy split and 130.7 CIDEr-D (c40) score on official
online evaluation server.",0,1,0,0,0,1,0.490346,9.0,0.777341,44
998e7550-6b7b-4ebf-975e-8bd7de70cdec,Learning Omni-frequency Region-adaptive Representations for Real Image Super-Resolution,28,0.0899734,0.573891,"Traditional single image super-resolution (SISR) methods that focus on
solving single and uniform degradation (i.e., bicubic down-sampling), typically
suffer from poor performance when applied into real-world low-resolution (LR)
images due to the complicated realistic degradations. The key to solving this
more challenging real image super-resolution (RealSR) problem lies in learning
feature representations that are both informative and content-aware. In this
paper, we propose an Omni-frequency Region-adaptive Network (ORNet) to address
both challenges, here we call features of all low, middle and high frequencies
omni-frequency features. Specifically, we start from the frequency perspective
and design a Frequency Decomposition (FD) module to separate different
frequency components to comprehensively compensate the information lost for
real LR image. Then, considering the different regions of real LR image have
different frequency information lost, we further design a Region-adaptive
Frequency Aggregation (RFA) module by leveraging dynamic convolution and
spatial attention to adaptively restore frequency components for different
regions. The extensive experiments endorse the effective, and scenario-agnostic
nature of our OR-Net for RealSR.",0,0,0,0,0,0,0.659238,5.0,0.692869,40
9f1d9317-c385-4eac-a995-1c9e7742bf3f,Towards Gender-Neutral Face Descriptors for Mitigating Bias in Face Recognition,12,0.023074,0.283927,"State-of-the-art deep networks implicitly encode gender information while
being trained for face recognition. Gender is often viewed as an important
attribute with respect to identifying faces. However, the implicit encoding of
gender information in face descriptors has two major issues: (a.) It makes the
descriptors susceptible to privacy leakage, i.e. a malicious agent can be
trained to predict the face gender from such descriptors. (b.) It appears to
contribute to gender bias in face recognition, i.e. we find a significant
difference in the recognition accuracy of DCNNs on male and female faces.
Therefore, we present a novel `Adversarial Gender De-biasing algorithm
(AGENDA)' to reduce the gender information present in face descriptors obtained
from previously trained face recognition networks. We show that AGENDA
significantly reduces gender predictability of face descriptors. Consequently,
we are also able to reduce gender bias in face verification while maintaining
reasonable recognition performance.",0,1,0,0,0,0,0.237747,5.0,0.417337,47
ee903049-a7a8-4682-b29e-56e017b57df5,Learning Invariant Representations for Reinforcement Learning without Reconstruction,379,0.3532,0.89826,"We study how representation learning can accelerate reinforcement learning
from rich observations, such as images, without relying either on domain
knowledge or pixel-reconstruction. Our goal is to learn representations that
both provide for effective downstream control and invariance to task-irrelevant
details. Bisimulation metrics quantify behavioral similarity between states in
continuous MDPs, which we propose using to learn robust latent representations
which encode only the task-relevant information from observations. Our method
trains encoders such that distances in latent space equal bisimulation
distances in state space. We demonstrate the effectiveness of our method at
disregarding task-irrelevant information using modified visual MuJoCo tasks,
where the background is replaced with moving distractors and natural videos,
while achieving SOTA performance. We also test a first-person highway driving
task where our method learns invariance to clouds, weather, and time of day.
Finally, we provide generalization results drawn from properties of
bisimulation metrics, and links to causal inference.",0,1,0,0,1,0,0.26382,5.0,0.441462,39
285d507b-ecb8-4ab2-9742-9a733f0212d6,BoxE: A Box Embedding Model for Knowledge Base Completion,130,0.871713,0.998257,"Knowledge base completion (KBC) aims to automatically infer missing facts by
exploiting information already present in a knowledge base (KB). A promising
approach for KBC is to embed knowledge into latent spaces and make predictions
from learned embeddings. However, existing embedding models are subject to at
least one of the following limitations: (1) theoretical inexpressivity, (2)
lack of support for prominent inference patterns (e.g., hierarchies), (3) lack
of support for KBC over higher-arity relations, and (4) lack of support for
incorporating logical rules. Here, we propose a spatio-translational embedding
model, called BoxE, that simultaneously addresses all these limitations. BoxE
embeds entities as points, and relations as a set of hyper-rectangles (or
boxes), which spatially characterize basic logical properties. This seemingly
simple abstraction yields a fully expressive model offering a natural encoding
for many desired logical properties. BoxE can both capture and inject rules
from rich classes of rule languages, going well beyond individual inference
patterns. By design, BoxE naturally applies to higher-arity KBs. We conduct a
detailed experimental analysis, and show that BoxE achieves state-of-the-art
performance, both on benchmark knowledge graphs and on more general KBs, and we
empirically show the power of integrating logical rules.",0,0,0,0,1,0,0.815921,8.0,0.864588,49
38c58bbe-0e93-4d1b-a6e6-a4a822d5e0a1,Deep learning generates custom-made logistic regression models for explaining how breast cancer subtypes are classified,3,0.0691437,0.187778,"Differentiating the intrinsic subtypes of breast cancer is crucial for
deciding the best treatment strategy. Deep learning can predict the subtypes
from genetic information more accurately than conventional statistical methods,
but to date, deep learning has not been directly utilized to examine which
genes are associated with which subtypes. To clarify the mechanisms embedded in
the intrinsic subtypes, we developed an explainable deep learning model called
a point-wise linear (PWL) model that generates a custom-made logistic
regression for each patient. Logistic regression, which is familiar to both
physicians and medical informatics researchers, allows us to analyze the
importance of the feature variables, and the PWL model harnesses these
practical abilities of logistic regression. In this study, we show that
analyzing breast cancer subtypes is clinically beneficial for patients and one
of the best ways to validate the capability of the PWL model. First, we trained
the PWL model with RNA-seq data to predict PAM50 intrinsic subtypes and applied
it to the 41/50 genes of PAM50 through the subtype prediction task. Second, we
developed a deep enrichment analysis method to reveal the relationships between
the PAM50 subtypes and the copy numbers of breast cancer. Our findings showed
that the PWL model utilized genes relevant to the cell cycle-related pathways.
These preliminary successes in breast cancer subtype analysis demonstrate the
potential of our analysis strategy to clarify the mechanisms underlying breast
cancer and improve overall clinical outcomes.",0,1,0,0,0,0,0.759177,13.0,0.903371,63
3a701c31-7461-40a4-b16a-4412ef146077,"X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers",90,0.937006,0.72156,"Mirroring the success of masked language models, vision-and-language
counterparts like ViLBERT, LXMERT and UNITER have achieved state of the art
performance on a variety of multimodal discriminative tasks like visual
question answering and visual grounding. Recent work has also successfully
adapted such models towards the generative task of image captioning. This begs
the question: Can these models go the other way and generate images from pieces
of text? Our analysis of a popular representative from this model family -
LXMERT - finds that it is unable to generate rich and semantically meaningful
imagery with its current training setup. We introduce X-LXMERT, an extension to
LXMERT with training refinements including: discretizing visual
representations, using uniform masking with a large range of masking ratios and
aligning the right pre-training datasets to the right objectives which enables
it to paint. X-LXMERT's image generation capabilities rival state of the art
generative models while its question answering and captioning abilities remains
comparable to LXMERT. Finally, we demonstrate the generality of these training
refinements by adding image generation capabilities into UNITER to produce
X-UNITER.",1,1,0,0,0,0,0.987632,5.0,0.974099,74
23478748-9519-408a-9c44-ccc4dd124d6f,Light Field View Synthesis via Aperture Disparity and Warping Confidence Map,19,0.196013,0.48776,"This paper presents a learning-based approach to synthesize the view from an
arbitrary camera position given a sparse set of images. A key challenge for
this novel view synthesis arises from the reconstruction process, when the
views from different input images may not be consistent due to obstruction in
the light path. We overcome this by jointly modeling the epipolar property and
occlusion in designing a convolutional neural network. We start by defining and
computing the aperture disparity map, which approximates the parallax and
measures the pixel-wise shift between two views. While this relates to
free-space rendering and can fail near the object boundaries, we further
develop a warping confidence map to address pixel occlusion in these
challenging regions. The proposed method is evaluated on diverse real-world and
synthetic light field scenes, and it shows better performance over several
state-of-the-art techniques.",0,1,0,0,1,0,0.33895,9.0,0.723166,67
46b31606-9d3d-4657-bb95-94ca332230bb,Assessing the Bilingual Knowledge Learned by Neural Machine Translation Models,5,0.0123388,0.124167,"Machine translation (MT) systems translate text between different languages
by automatically learning in-depth knowledge of bilingual lexicons, grammar and
semantics from the training examples. Although neural machine translation (NMT)
has led the field of MT, we have a poor understanding on how and why it works.
In this paper, we bridge the gap by assessing the bilingual knowledge learned
by NMT models with phrase table -- an interpretable table of bilingual
lexicons. We extract the phrase table from the training examples that an NMT
model correctly predicts. Extensive experiments on widely-used datasets show
that the phrase table is reasonable and consistent against language pairs and
random seeds. Equipped with the interpretable phrase table, we find that NMT
models learn patterns from simple to complex and distill essential bilingual
knowledge from the training examples. We also revisit some advances that
potentially affect the learning of bilingual knowledge (e.g.,
back-translation), and report some interesting findings. We believe this work
opens a new angle to interpret NMT with statistic models, and provides
empirical supports for recent advances in improving NMT models.",0,0,0,0,0,0,0.283287,7.0,0.613027,54
8dc21828-1e6e-458f-9f59-eafff5f8b8d9,Graph-based Topic Extraction from Vector Embeddings of Text Documents: Application to a Corpus of News Articles,7,0.0186994,0.243558,"Production of news content is growing at an astonishing rate. To help manage
and monitor the sheer amount of text, there is an increasing need to develop
efficient methods that can provide insights into emerging content areas, and
stratify unstructured corpora of text into `topics' that stem intrinsically
from content similarity. Here we present an unsupervised framework that brings
together powerful vector embeddings from natural language processing with tools
from multiscale graph partitioning that can reveal natural partitions at
different resolutions without making a priori assumptions about the number of
clusters in the corpus. We show the advantages of graph-based clustering
through end-to-end comparisons with other popular clustering and topic
modelling methods, and also evaluate different text vector embeddings, from
classic Bag-of-Words to Doc2Vec to the recent transformers based model Bert.
This comparative work is showcased through an analysis of a corpus of US news
coverage during the presidential election year of 2016.",0,1,0,0,0,1,0.0394307,15.0,0.678493,27
376f95de-0545-4c15-b5e3-4eef4d88a450,Mention Extraction and Linking for SQL Query Generation,25,0.264173,0.67589,"On the WikiSQL benchmark, state-of-the-art text-to-SQL systems typically take
a slot-filling approach by building several dedicated models for each type of
slots. Such modularized systems are not only complex butalso of limited
capacity for capturing inter-dependencies among SQL clauses. To solve these
problems, this paper proposes a novel extraction-linking approach, where a
unified extractor recognizes all types of slot mentions appearing in the
question sentence before a linker maps the recognized columns to the table
schema to generate executable SQL queries. Trained with automatically generated
annotations, the proposed method achieves the first place on the WikiSQL
benchmark.",0,1,0,0,1,0,0.942939,6.0,0.907109,30
8e323d9a-e973-4c70-904b-e1b374ef5bd9,FedNER: Privacy-preserving Medical Named Entity Recognition with Federated Learning,49,0.520303,0.847974,"Medical named entity recognition (NER) has wide applications in intelligent
healthcare. Sufficient labeled data is critical for training accurate medical
NER model. However, the labeled data in a single medical platform is usually
limited. Although labeled datasets may exist in many different medical
platforms, they cannot be directly shared since medical data is highly
privacy-sensitive. In this paper, we propose a privacy-preserving medical NER
method based on federated learning, which can leverage the labeled data in
different platforms to boost the training of medical NER model and remove the
need of exchanging raw data among different platforms. Since the labeled data
in different platforms usually has some differences in entity type and
annotation criteria, instead of constraining different platforms to share the
same model, we decompose the medical NER model in each platform into a shared
module and a private module. The private module is used to capture the
characteristics of the local data in each platform, and is updated using local
labeled data. The shared module is learned across different medical platform to
capture the shared NER knowledge. Its local gradients from different platforms
are aggregated to update the global shared module, which is further delivered
to each platform to update their local shared modules. Experiments on three
publicly available datasets validate the effectiveness of our method.",0,1,0,0,0,0,0.603368,9.0,0.812481,36
6bd601b9-57f9-455b-b85c-43297556b189,Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations,40,0.34715,0.48802,"Neural implicit functions have emerged as a powerful representation for
surfaces in 3D. Such a function can encode a high quality surface with
intricate details into the parameters of a deep neural network. However,
optimizing for the parameters for accurate and robust reconstructions remains a
challenge, especially when the input data is noisy or incomplete. In this work,
we develop a hybrid neural surface representation that allows us to impose
geometry-aware sampling and regularization, which significantly improves the
fidelity of reconstructions. We propose to use \emph{iso-points} as an explicit
representation for a neural implicit function. These points are computed and
updated on-the-fly during training to capture important geometric features and
impose geometric constraints on the optimization. We demonstrate that our
method can be adopted to improve state-of-the-art techniques for reconstructing
neural implicit surfaces from multi-view images or point clouds. Quantitative
and qualitative evaluations show that, compared with existing sampling and
optimization methods, our approach allows faster convergence, better
generalization, and accurate recovery of details and topology.",0,1,0,0,0,0,0.909358,5.0,0.853276,55
fbd8be40-369e-43f4-8dd9-b8fdffdc6876,NeuSpell: A Neural Spelling Correction Toolkit,55,0.820103,0.832819,"We introduce NeuSpell, an open-source toolkit for spelling correction in
English. Our toolkit comprises ten different models, and benchmarks them on
naturally occurring misspellings from multiple sources. We find that many
systems do not adequately leverage the context around the misspelt token. To
remedy this, (i) we train neural models using spelling errors in context,
synthetically constructed by reverse engineering isolated misspellings; and
(ii) use contextual representations. By training on our synthetic examples,
correction rates improve by 9% (absolute) compared to the case when models are
trained on randomly sampled character perturbations. Using richer contextual
representations boosts the correction rate by another 3%. Our toolkit enables
practitioners to use our proposed and existing spelling correction systems,
both via a unified command line, as well as a web interface. Among many
potential applications, we demonstrate the utility of our spell-checkers in
combating adversarial misspellings. The toolkit can be accessed at
neuspell.github.io. Code and pretrained models are available at
http://github.com/neuspell/neuspell.",1,1,0,0,1,0,0.944829,9.0,0.939372,25
360c6512-93c8-4bbe-8990-21e38f94207f,Adversarial Learning for Debiasing Knowledge Graph Embeddings,29,0.24269,0.54722,"Knowledge Graphs (KG) are gaining increasing attention in both academia and
industry. Despite their diverse benefits, recent research have identified
social and cultural biases embedded in the representations learned from KGs.
Such biases can have detrimental consequences on different population and
minority groups as applications of KG begin to intersect and interact with
social spheres. This paper aims at identifying and mitigating such biases in
Knowledge Graph (KG) embeddings. As a first step, we explore popularity bias --
the relationship between node popularity and link prediction accuracy. In case
of node2vec graph embeddings, we find that prediction accuracy of the embedding
is negatively correlated with the degree of the node. However, in case of
knowledge-graph embeddings (KGE), we observe an opposite trend. As a second
step, we explore gender bias in KGE, and a careful examination of popular KGE
algorithms suggest that sensitive attribute like the gender of a person can be
predicted from the embedding. This implies that such biases in popular KGs is
captured by the structural properties of the embedding. As a preliminary
solution to debiasing KGs, we introduce a novel framework to filter out the
sensitive attribute information from the KG embeddings, which we call FAN
(Filtering Adversarial Network). We also suggest the applicability of FAN for
debiasing other network embeddings which could be explored in future work.",0,0,0,0,0,0,0.33315,11.0,0.77156,29
ef9f2f2e-41bb-40c3-af78-ac9bf9b5e0eb,Explainable Artificial Intelligence Recommendation System by Leveraging the Semantics of Adverse Childhood Experiences: Proof-of-Concept Prototype Development,27,0.151385,0.542446,"The study of adverse childhood experiences and their consequences has emerged
over the past 20 years. In this study, we aimed to leverage explainable
artificial intelligence, and propose a proof-of-concept prototype for a
knowledge-driven evidence-based recommendation system to improve surveillance
of adverse childhood experiences. We used concepts from an ontology that we
have developed to build and train a question-answering agent using the Google
DialogFlow engine. In addition to the question-answering agent, the initial
prototype includes knowledge graph generation and recommendation components
that leverage third-party graph technology. To showcase the framework
functionalities, we here present a prototype design and demonstrate the main
features through four use case scenarios motivated by an initiative currently
implemented at a children hospital in Memphis, Tennessee. Ongoing development
of the prototype requires implementing an optimization algorithm of the
recommendations, incorporating a privacy layer through a personal health
library, and conducting a clinical trial to assess both usability and
usefulness of the implementation. This semantic-driven explainable artificial
intelligence prototype can enhance health care practitioners ability to provide
explanations for the decisions they make.",0,1,0,0,0,0,0.28032,5.0,0.455742,25
65fdcbc0-ffa1-4baf-9837-c7856e12e1cf,PLAS: Latent Action Space for Offline Reinforcement Learning,123,0.90137,0.881189,"The goal of offline reinforcement learning is to learn a policy from a fixed
dataset, without further interactions with the environment. This setting will
be an increasingly more important paradigm for real-world applications of
reinforcement learning such as robotics, in which data collection is slow and
potentially dangerous. Existing off-policy algorithms have limited performance
on static datasets due to extrapolation errors from out-of-distribution
actions. This leads to the challenge of constraining the policy to select
actions within the support of the dataset during training. We propose to simply
learn the Policy in the Latent Action Space (PLAS) such that this requirement
is naturally satisfied. We evaluate our method on continuous control benchmarks
in simulation and a deformable object manipulation task with a physical robot.
We demonstrate that our method provides competitive performance consistently
across various continuous control tasks and different types of datasets,
outperforming existing offline reinforcement learning methods with explicit
constraints. Videos and code are available at
https://sites.google.com/view/latent-policy.",1,1,0,0,0,0,0.967359,6.0,0.936807,26
7bfc71c5-a254-4d52-a521-782cb7280f0e,ENTMOOT: A Framework for Optimization over Ensemble Tree Models,37,0.0678172,0.416516,"Gradient boosted trees and other regression tree models perform well in a
wide range of real-world, industrial applications. These tree models (i) offer
insight into important prediction features, (ii) effectively manage sparse
data, and (iii) have excellent prediction capabilities. Despite their
advantages, they are generally unpopular for decision-making tasks and
black-box optimization, which is due to their difficult-to optimize structure
and the lack of a reliable uncertainty measure. ENTMOOT is our new framework
for integrating (already trained) tree models into larger optimization
problems. The contributions of ENTMOOT include: (i) explicitly introducing a
reliable uncertainty measure that is compatible with tree models, (ii) solving
the larger optimization problems that incorporate these uncertainty aware tree
models, (iii) proving that the solutions are globally optimal, i.e. no better
solution exists. In particular, we show how the ENTMOOT approach allows a
simple integration of tree models into decision-making and black-box
optimization, where it proves as a strong competitor to commonly-used
frameworks.",0,1,0,0,0,0,0.014636,13.0,0.55182,83
33575774-c895-4eac-ac73-b1c2e0d4d230,"Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation",16,0.407872,0.369851,"AMR-to-text generation is used to transduce Abstract Meaning Representation
structures (AMR) into text. A key challenge in this task is to efficiently
learn effective graph representations. Previously, Graph Convolution Networks
(GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to
capture non-local information and additionally, they follow a local
(first-order) information aggregation scheme. To account for these issues,
larger and deeper GCN models are required to capture more complex interactions.
In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight
Dynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local
interactions by synthesizing higher order information from the input graphs. We
further develop two novel parameter saving strategies based on the group graph
convolutions and weight tied convolutions to reduce memory usage and model
complexity. With the help of these strategies, we are able to train a model
with fewer parameters while maintaining the model capacity. Experiments
demonstrate that LDGCNs outperform state-of-the-art models on two benchmark
datasets for AMR-to-text generation with significantly fewer parameters.",1,1,0,0,1,0,0.981553,5.0,0.955013,49
7e3cbb1d-27ba-4ca3-b103-bacfd92ad809,How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking,74,0.0554707,0.453702,"Attribution methods assess the contribution of inputs to the model
prediction. One way to do so is erasure: a subset of inputs is considered
irrelevant if it can be removed without affecting the prediction. Though
conceptually simple, erasure's objective is intractable and approximate search
remains expensive with modern deep NLP models. Erasure is also susceptible to
the hindsight bias: the fact that an input can be dropped does not mean that
the model `knows' it can be dropped. The resulting pruning is over-aggressive
and does not reflect how the model arrives at the prediction. To deal with
these challenges, we introduce Differentiable Masking. DiffMask learns to
mask-out subsets of the input while maintaining differentiability. The decision
to include or disregard an input token is made with a simple model based on
intermediate hidden layers of the analyzed model. First, this makes the
approach efficient because we predict rather than search. Second, as with
probing classifiers, this reveals what the network `knows' at the corresponding
layers. This lets us not only plot attribution heatmaps but also analyze how
decisions are formed across network layers. We use DiffMask to study BERT
models on sentiment classification and question answering.",1,1,0,0,0,1,0.517674,4.0,0.518666,70
15d2408f-836f-45d6-a6fe-bf5f4100132a,Supermasks in Superposition,229,0.87179,0.806673,"We present the Supermasks in Superposition (SupSup) model, capable of
sequentially learning thousands of tasks without catastrophic forgetting. Our
approach uses a randomly initialized, fixed base network and for each task
finds a subnetwork (supermask) that achieves good performance. If task identity
is given at test time, the correct subnetwork can be retrieved with minimal
memory usage. If not provided, SupSup can infer the task using gradient-based
optimization to find a linear superposition of learned supermasks which
minimizes the output entropy. In practice we find that a single gradient step
is often sufficient to identify the correct mask, even among 2500 tasks. We
also showcase two promising extensions. First, SupSup models can be trained
entirely without task identity information, as they may detect when they are
uncertain about new data and allocate an additional supermask for the new
training distribution. Finally the entire, growing set of supermasks can be
stored in a constant-sized reservoir by implicitly storing them as attractors
in a fixed-sized Hopfield network.",0,0,0,0,0,0,0.94087,6.0,0.905023,64
a4f8da5d-5a6f-4a2a-9b5f-3edd3e25dfe9,Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback,57,0.862453,0.866089,"We study the task of semantic parse correction with natural language
feedback. Given a natural language utterance, most semantic parsing systems
pose the problem as one-shot translation where the utterance is mapped to a
corresponding logical form. In this paper, we investigate a more interactive
scenario where humans can further interact with the system by providing
free-form natural language feedback to correct the system when it generates an
inaccurate interpretation of an initial utterance. We focus on natural language
to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL
interpretations and the corresponding natural language feedback. We compare
various reference models for the correction task and show that incorporating
such a rich form of feedback can significantly improve the overall semantic
parsing accuracy while retaining the flexibility of natural language
interaction. While we estimated human correction accuracy is 81.5%, our best
model achieves only 25.1%, which leaves a large gap for improvement in future
research. SPLASH is publicly available at https://aka.ms/Splash_dataset.",1,1,0,1,0,0,0.938434,6.0,0.902626,61
f36eb0c3-fd8d-4875-a706-9bc79d7cd093,Anomalous Motion Detection on Highway Using Deep Learning,9,0.080419,0.249481,"Research in visual anomaly detection draws much interest due to its
applications in surveillance. Common datasets for evaluation are constructed
using a stationary camera overlooking a region of interest. Previous research
has shown promising results in detecting spatial as well as temporal anomalies
in these settings. The advent of self-driving cars provides an opportunity to
apply visual anomaly detection in a more dynamic application yet no dataset
exists in this type of environment. This paper presents a new anomaly detection
dataset - the Highway Traffic Anomaly (HTA) dataset - for the problem of
detecting anomalous traffic patterns from dash cam videos of vehicles on
highways. We evaluate state-of-the-art deep learning anomaly detection models
and propose novel variations to these methods. Our results show that
state-of-the-art models built for settings with a stationary camera do not
translate well to a more dynamic environment. The proposed variations to these
SoTA methods show promising results on the new HTA dataset.",1,1,1,1,0,0,0.640479,8.0,0.80166,17
f7261054-0a3a-47e3-a748-2325c0bd9530,Neural Rough Differential Equations for Long Time Series,94,0.610967,0.940683,"Neural controlled differential equations (CDEs) are the continuous-time
analogue of recurrent neural networks, as Neural ODEs are to residual networks,
and offer a memory-efficient continuous-time way to model functions of
potentially irregular time series. Existing methods for computing the forward
pass of a Neural CDE involve embedding the incoming time series into path
space, often via interpolation, and using evaluations of this path to drive the
hidden state. Here, we use rough path theory to extend this formulation.
Instead of directly embedding into path space, we instead represent the input
signal over small time intervals through its \textit{log-signature}, which are
statistics describing how the signal drives a CDE. This is the approach for
solving \textit{rough differential equations} (RDEs), and correspondingly we
describe our main contribution as the introduction of Neural RDEs. This
extension has a purpose: by generalising the Neural CDE approach to a broader
class of driving signals, we demonstrate particular advantages for tackling
long time series. In this regime, we demonstrate efficacy on problems of length
up to 17k observations and observe significant training speed-ups, improvements
in model performance, and reduced memory requirements compared to existing
approaches.",1,0,0,0,0,0,0.77933,6.0,0.800565,40
d57fd3f3-5f94-47e1-87a7-b3242c04d81c,Incorporating Effective Global Information via Adaptive Gate Attention for Text Classification,4,0.00708466,0.057667,"The dominant text classification studies focus on training classifiers using
textual instances only or introducing external knowledge (e.g., hand-craft
features and domain expert knowledge). In contrast, some corpus-level
statistical features, like word frequency and distribution, are not well
exploited. Our work shows that such simple statistical information can enhance
classification performance both efficiently and significantly compared with
several baseline models. In this paper, we propose a classifier with gate
mechanism named Adaptive Gate Attention model with Global Information (AGA+GI),
in which the adaptive gate mechanism incorporates global statistical features
into latent semantic features and the attention layer captures dependency
relationship within the sentence. To alleviate the overfitting issue, we
propose a novel Leaky Dropout mechanism to improve generalization ability and
performance stability. Our experiments show that the proposed method can
achieve better accuracy than CNN-based and RNN-based approaches without global
information on several benchmarks.",0,1,0,0,1,1,0.0886429,12.0,0.667789,30
5daf5563-678a-4f03-82a1-1d3ad5e99cb6,Q-Learning in enormous action spaces via amortized approximate maximization,51,0.068462,0.336256,"Applying Q-learning to high-dimensional or continuous action spaces can be
difficult due to the required maximization over the set of possible actions.
Motivated by techniques from amortized inference, we replace the expensive
maximization over all actions with a maximization over a small subset of
possible actions sampled from a learned proposal distribution. The resulting
approach, which we dub Amortized Q-learning (AQL), is able to handle discrete,
continuous, or hybrid action spaces while maintaining the benefits of
Q-learning. Our experiments on continuous control tasks with up to 21
dimensional actions show that AQL outperforms D3PG (Barth-Maron et al, 2018)
and QT-Opt (Kalashnikov et al, 2018). Experiments on structured discrete action
spaces demonstrate that AQL can efficiently learn good policies in spaces with
thousands of discrete actions.",0,1,0,0,1,0,0.377504,6.0,0.607342,42
a1e5a5c5-9192-4cc4-b8e3-cb65f0914698,Learning to Transfer Texture from Clothing Images to 3D Humans,93,0.718506,0.703734,"In this paper, we present a simple yet effective method to automatically
transfer textures of clothing images (front and back) to 3D garments worn on
top SMPL, in real time. We first automatically compute training pairs of images
with aligned 3D garments using a custom non-rigid 3D to 2D registration method,
which is accurate but slow. Using these pairs, we learn a mapping from pixels
to the 3D garment surface. Our idea is to learn dense correspondences from
garment image silhouettes to a 2D-UV map of a 3D garment surface using shape
information alone, completely ignoring texture, which allows us to generalize
to the wide range of web images. Several experiments demonstrate that our model
is more accurate than widely used baselines such as thin-plate-spline warping
and image-to-image translation networks while being orders of magnitude faster.
Our model opens the door for applications such as virtual try-on, and allows
for generation of 3D humans with varied textures which is necessary for
learning.",0,1,0,0,0,0,0.85734,5.0,0.8114,89
8f9e3fa8-e8b3-4995-810a-3ca89cc7b2b4,Frequency-based Search-control in Dyna,14,0.0509304,0.218439,"Model-based reinforcement learning has been empirically demonstrated as a
successful strategy to improve sample efficiency. In particular, Dyna is an
elegant model-based architecture integrating learning and planning that
provides huge flexibility of using a model. One of the most important
components in Dyna is called search-control, which refers to the process of
generating state or state-action pairs from which we query the model to acquire
simulated experiences. Search-control is critical in improving learning
efficiency. In this work, we propose a simple and novel search-control strategy
by searching high frequency regions of the value function. Our main intuition
is built on Shannon sampling theorem from signal processing, which indicates
that a high frequency signal requires more samples to reconstruct. We
empirically show that a high frequency function is more difficult to
approximate. This suggests a search-control strategy: we should use states from
high frequency regions of the value function to query the model to acquire more
samples. We develop a simple strategy to locally measure the frequency of a
function by gradient and hessian norms, and provide theoretical justification
for this approach. We then apply our strategy to search-control in Dyna, and
conduct experiments to show its property and effectiveness on benchmark
domains.",0,0,0,0,0,0,0.0306543,16.0,0.682569,50
45bf6634-692d-422e-81c0-75082a3dac9d,An Analysis of Regularized Approaches for Constrained Machine Learning,2,0.0182012,0.0307758,"Regularization-based approaches for injecting constraints in Machine Learning
(ML) were introduced to improve a predictive model via expert knowledge. We
tackle the issue of finding the right balance between the loss (the accuracy of
the learner) and the regularization term (the degree of constraint
satisfaction). The key results of this paper is the formal demonstration that
this type of approach cannot guarantee to find all optimal solutions. In
particular, in the non-convex case there might be optima for the constrained
problem that do not correspond to any multiplier value.",0,0,0,0,0,0,0.690964,4.0,0.637808,9
0a4b1215-1abd-4279-89dd-5f7275a8cd74,Deep Learning for Hindi Text Classification: A Comparison,39,0.0669731,0.40874,"Natural Language Processing (NLP) and especially natural language text
analysis have seen great advances in recent times. Usage of deep learning in
text processing has revolutionized the techniques for text processing and
achieved remarkable results. Different deep learning architectures like CNN,
LSTM, and very recent Transformer have been used to achieve state of the art
results variety on NLP tasks. In this work, we survey a host of deep learning
architectures for text classification tasks. The work is specifically concerned
with the classification of Hindi text. The research in the classification of
morphologically rich and low resource Hindi language written in Devanagari
script has been limited due to the absence of large labeled corpus. In this
work, we used translated versions of English data-sets to evaluate models based
on CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based
on BERT and LASER are also compared to evaluate their effectiveness for the
Hindi language. The paper also serves as a tutorial for popular text
classification techniques.",0,1,0,0,0,0,0.609446,7.0,0.76127,11
f8401930-1db6-4a46-b1dc-6e4ab23a2db1,Belief Propagation Reloaded: Learning BP-Layers for Labeling Problems,19,0.101267,0.362843,"It has been proposed by many researchers that combining deep neural networks
with graphical models can create more efficient and better regularized
composite models. The main difficulties in implementing this in practice are
associated with a discrepancy in suitable learning objectives as well as with
the necessity of approximations for the inference. In this work we take one of
the simplest inference methods, a truncated max-product Belief Propagation, and
add what is necessary to make it a proper component of a deep learning model:
We connect it to learning formulations with losses on marginals and compute the
backprop operation. This BP-Layer can be used as the final or an intermediate
block in convolutional neural networks (CNNs), allowing us to design a
hierarchical model composing BP inference and CNNs at different scale levels.
The model is applicable to a range of dense prediction problems, is
well-trainable and provides parameter-efficient and robust solutions in stereo,
optical flow and semantic segmentation.",1,1,0,0,0,0,0.165056,9.0,0.630881,56
41e10a0b-b3f2-4478-82e5-c6ad0e8a164d,Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem,63,0.28653,0.703971,"The celebrated Seq2Seq technique and its numerous variants achieve excellent
performance on many tasks such as neural machine translation, semantic parsing,
and math word problem solving. However, these models either only consider input
objects as sequences while ignoring the important structural information for
encoding, or they simply treat output objects as sequence outputs instead of
structural objects for decoding. In this paper, we present a novel
Graph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder
and a hierarchical tree decoder, that encodes an augmented graph-structured
input and decodes a tree-structured output. In particular, we investigated our
model for solving two problems, neural semantic parsing and math word problem.
Our extensive experiments demonstrate that our Graph2Tree model outperforms or
matches the performance of other state-of-the-art models on these tasks.",0,0,0,0,1,0,0.492373,6.0,0.666995,56
1cf548f5-8d47-4c8f-ad9d-26727cf72485,Image-based underwater 3D reconstruction for Cultural Heritage: from image collection to 3D. Critical steps and considerations,4,0.0898142,0.0967494,"Underwater Cultural Heritage (CH) sites are widely spread; from ruins in
coastlines up to shipwrecks in deep. The documentation and preservation of this
heritage is an obligation of the mankind, dictated also by the international
treaties like the Convention on the Protection of the Underwater Cultural
Her-itage which fosters the use of ""non-destructive techniques and survey
meth-ods in preference over the recovery of objects"". However, submerged CH
lacks in protection and monitoring in regards to the land CH and nowadays
recording and documenting, for digital preservation as well as dissemination
through VR to wide public, is of most importance. At the same time, it is most
difficult to document it, due to inherent restrictions posed by the
environ-ment. In order to create high detailed textured 3D models, optical
sensors and photogrammetric techniques seems to be the best solution. This
chapter dis-cusses critical aspects of all phases of image based underwater 3D
reconstruc-tion process, from data acquisition and data preparation using
colour restora-tion and colour enhancement algorithms to Structure from Motion
(SfM) and Multi-View Stereo (MVS) techniques to produce an accurate, precise
and complete 3D model for a number of applications.",0,1,0,0,0,0,0.0506852,14.0,0.673881,71
3991c1a1-4a41-41e6-892d-bbec01047a71,RankPose: Learning Generalised Feature with Rank Supervision for Head Pose Estimation,12,0.201377,0.254886,"We address the challenging problem of RGB image-based head pose estimation.
We first reformulate head pose representation learning to constrain it to a
bounded space. Head pose represented as vector projection or vector angles
shows helpful to improving performance. Further, a ranking loss combined with
MSE regression loss is proposed. The ranking loss supervises a neural network
with paired samples of the same person and penalises incorrect ordering of pose
prediction. Analysis on this new loss function suggests it contributes to a
better local feature extractor, where features are generalised to Abstract
Landmarks which are pose-related features instead of pose-irrelevant
information such as identity, age, and lighting. Extensive experiments show
that our method significantly outperforms the current state-of-the-art schemes
on public datasets: AFLW2000 and BIWI. Our model achieves significant
improvements over previous SOTA MAE on AFLW2000 and BIWI from 4.50 to 3.66 and
from 4.0 to 3.71 respectively. Source code will be made available at:
https://github.com/seathiefwang/RankHeadPose.",1,1,0,0,1,0,0.949834,10.0,0.948664,25
f7ff1b77-6724-4d59-8077-11d0f5378c16,Verifying Tree Ensembles by Reasoning about Potential Instances,8,0.0343709,0.114256,"Imagine being able to ask questions to a black box model such as ""Which
adversarial examples exist?"", ""Does a specific attribute have a
disproportionate effect on the model's prediction?"" or ""What kind of
predictions could possibly be made for a partially described example?"" This
last question is particularly important if your partial description does not
correspond to any observed example in your data, as it provides insight into
how the model will extrapolate to unseen data. These capabilities would be
extremely helpful as they would allow a user to better understand the model's
behavior, particularly as it relates to issues such as robustness, fairness,
and bias. In this paper, we propose such an approach for an ensemble of trees.
Since, in general, this task is intractable we present a strategy that (1) can
prune part of the input space given the question asked to simplify the problem;
and (2) follows a divide and conquer approach that is incremental and can
always return some answers and indicates which parts of the input domains are
still uncertain. The usefulness of our approach is shown on a diverse set of
use cases.",0,0,0,0,0,0,0.542232,5.0,0.628777,28
18274ac5-8470-4d85-9e43-4c20e730f091,Positional Encoding as Spatial Inductive Bias in GANs,78,0.170017,0.759816,"SinGAN shows impressive capability in learning internal patch distribution
despite its limited effective receptive field. We are interested in knowing how
such a translation-invariant convolutional generator could capture the global
structure with just a spatially i.i.d. input. In this work, taking SinGAN and
StyleGAN2 as examples, we show that such capability, to a large extent, is
brought by the implicit positional encoding when using zero padding in the
generators. Such positional encoding is indispensable for generating images
with high fidelity. The same phenomenon is observed in other generative
architectures such as DCGAN and PGGAN. We further show that zero padding leads
to an unbalanced spatial bias with a vague relation between locations. To offer
a better spatial inductive bias, we investigate alternative positional
encodings and analyze their effects. Based on a more flexible positional
encoding explicitly, we propose a new multi-scale training strategy and
demonstrate its effectiveness in the state-of-the-art unconditional generator
StyleGAN2. Besides, the explicit spatial inductive bias substantially improve
SinGAN for more versatile image manipulation.",0,0,0,0,0,0,0.76987,6.0,0.79587,57
ede50b7f-6919-441f-b4e7-71275452544d,Multi-task Language Modeling for Improving Speech Recognition of Rare Words,26,0.0429296,0.405201,"End-to-end automatic speech recognition (ASR) systems are increasingly
popular due to their relative architectural simplicity and competitive
performance. However, even though the average accuracy of these systems may be
high, the performance on rare content words often lags behind hybrid ASR
systems. To address this problem, second-pass rescoring is often applied
leveraging upon language modeling. In this paper, we propose a second-pass
system with multi-task learning, utilizing semantic targets (such as intent and
slot prediction) to improve speech recognition performance. We show that our
rescoring model trained with these additional tasks outperforms the baseline
rescoring model, trained with only the language modeling task, by 1.4% on a
general test and by 2.6% on a rare word test set in terms of word-error-rate
relative (WERR). Our best ASR system with multi-task LM shows 4.6% WERR
deduction compared with RNN Transducer only ASR baseline for rare words
recognition.",0,1,0,0,0,0,0.106962,6.0,0.368551,34
34b27b76-8939-4a37-880a-3d240c43a1cb,Deep Image Compression using Decoder Side Information,22,0.0586719,0.554671,"We present a Deep Image Compression neural network that relies on side
information, which is only available to the decoder. We base our algorithm on
the assumption that the image available to the encoder and the image available
to the decoder are correlated, and we let the network learn these correlations
in the training phase.
  Then, at run time, the encoder side encodes the input image without knowing
anything about the decoder side image and sends it to the decoder. The decoder
then uses the encoded input image and the side information image to reconstruct
the original image.
  This problem is known as Distributed Source Coding in Information Theory, and
we discuss several use cases for this technology. We compare our algorithm to
several image compression algorithms and show that adding decoder-only side
information does indeed improve results. Our code is publicly available at
https://github.com/ayziksha/DSIN.",1,1,0,0,0,0,0.0402832,13.0,0.63071,39
347d63e8-9627-40f8-84dc-61b9b150c3b6,FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity Annotation,7,0.0245547,0.457616,"Sentiment analysis and opinion mining is an important task with obvious
application areas in social media, e.g. when indicating hate speech and fake
news. In our survey of previous work, we note that there is no large-scale
social media data set with sentiment polarity annotations for Finnish. This
publications aims to remedy this shortcoming by introducing a 27,000 sentence
data set annotated independently with sentiment polarity by three native
annotators. We had the same three annotators for the whole data set, which
provides a unique opportunity for further studies of annotator behaviour over
time. We analyse their inter-annotator agreement and provide two baselines to
validate the usefulness of the data set.",0,1,1,1,0,0,0.00517202,13.0,0.471436,81
d219ed38-566e-4a7d-bcdd-f0c8c830a24c,AutoAssign: Differentiable Label Assignment for Dense Object Detection,167,0.686328,0.767573,"Determining positive/negative samples for object detection is known as label
assignment. Here we present an anchor-free detector named AutoAssign. It
requires little human knowledge and achieves appearance-aware through a fully
differentiable weighting mechanism. During training, to both satisfy the prior
distribution of data and adapt to category characteristics, we present Center
Weighting to adjust the category-specific prior distributions. To adapt to
object appearances, Confidence Weighting is proposed to adjust the specific
assign strategy of each instance. The two weighting modules are then combined
to generate positive and negative weights to adjust each location's confidence.
Extensive experiments on the MS COCO show that our method steadily surpasses
other best sampling strategies by large margins with various backbones.
Moreover, our best model achieves 52.1% AP, outperforming all existing
one-stage detectors. Besides, experiments on other datasets, e.g., PASCAL VOC,
Objects365, and WiderFace, demonstrate the broad applicability of AutoAssign.",0,1,0,0,1,0,0.981771,4.0,0.94451,34
3b44970b-2bb7-4339-9a41-a96d0af0ee86,RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling,48,0.854666,0.869778,"In order to alleviate the shortage of multi-domain data and to capture
discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a
large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic
Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn
semantically annotated dialogues, with more than 150K utterances spanning over
12 domains, which is larger than all previous annotated H2H conversational
datasets. Both single- and multi-domain dialogues are constructed, accounting
for 65% and 35%, respectively. Each dialogue is labeled with comprehensive
dialogue annotations, including dialogue goal in the form of natural language
description, domain, dialogue states and acts at both the user and system side.
In addition to traditional dialogue annotations, we especially provide
linguistic annotations on discourse phenomena, e.g., ellipsis and coreference,
in dialogues, which are useful for dialogue coreference and ellipsis resolution
tasks. Apart from the fully annotated dataset, we also present a detailed
description of the data collection procedure, statistics and analysis of the
dataset. A series of benchmark models and results are reported, including
natural language understanding (intent detection & slot filling), dialogue
state tracking and dialogue context-to-text generation, as well as coreference
and ellipsis resolution, which facilitate the baseline comparison for future
research on this corpus.",1,1,0,1,0,0,0.962463,5.0,0.91583,34
77c44741-ee85-49aa-898e-18cfb772718a,VideoMix: Rethinking Data Augmentation for Video Classification,61,0.18851,0.718393,"State-of-the-art video action classifiers often suffer from overfitting. They
tend to be biased towards specific objects and scene cues, rather than the
foreground action content, leading to sub-optimal generalization performances.
Recent data augmentation strategies have been reported to address the
overfitting problems in static image classifiers. Despite the effectiveness on
the static image classifiers, data augmentation has rarely been studied for
videos. For the first time in the field, we systematically analyze the efficacy
of various data augmentation strategies on the video classification task. We
then propose a powerful augmentation strategy VideoMix. VideoMix creates a new
training video by inserting a video cuboid into another video. The ground truth
labels are mixed proportionally to the number of voxels from each video. We
show that VideoMix lets a model learn beyond the object and scene biases and
extract more robust cues for action recognition. VideoMix consistently
outperforms other augmentation baselines on Kinetics and the challenging
Something-Something-V2 benchmarks. It also improves the weakly-supervised
action localization performance on THUMOS'14. VideoMix pretrained models
exhibit improved accuracies on the video detection task (AVA).",1,1,0,0,1,0,0.765072,7.0,0.823011,42
84516a6f-c3cb-4481-91c3-6ce37d160463,Building Interpretable Interaction Trees for Deep NLP Models,32,0.158535,0.627721,"This paper proposes a method to disentangle and quantify interactions among
words that are encoded inside a DNN for natural language processing. We
construct a tree to encode salient interactions extracted by the DNN. Six
metrics are proposed to analyze properties of interactions between constituents
in a sentence. The interaction is defined based on Shapley values of words,
which are considered as an unbiased estimation of word contributions to the
network prediction. Our method is used to quantify word interactions encoded
inside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental
results have provided a new perspective to understand these DNNs, and have
demonstrated the effectiveness of our method.",0,0,0,0,0,0,0.261562,7.0,0.599608,52
4a35d4d9-5562-42cb-b0cb-076268485bc1,Challenges and Countermeasures for Adversarial Attacks on Deep Reinforcement Learning,100,0.641102,0.94202,"Deep Reinforcement Learning (DRL) has numerous applications in the real world
thanks to its outstanding ability in quickly adapting to the surrounding
environments. Despite its great advantages, DRL is susceptible to adversarial
attacks, which precludes its use in real-life critical systems and applications
(e.g., smart grids, traffic controls, and autonomous vehicles) unless its
vulnerabilities are addressed and mitigated. Thus, this paper provides a
comprehensive survey that discusses emerging attacks in DRL-based systems and
the potential countermeasures to defend against these attacks. We first cover
some fundamental backgrounds about DRL and present emerging adversarial attacks
on machine learning techniques. We then investigate more details of the
vulnerabilities that the adversary can exploit to attack DRL along with the
state-of-the-art countermeasures to prevent such attacks. Finally, we highlight
open issues and research challenges for developing solutions to deal with
attacks for DRL-based intelligent systems.",0,1,0,0,0,0,0.795302,4.0,0.712979,141
0632f7fa-b61d-4634-85c8-ce1c5d55fe5d,Breaking Batch Normalization for better explainability of Deep Neural Networks through Layer-wise Relevance Propagation,17,0.119974,0.378995,"The lack of transparency of neural networks stays a major break for their
use. The Layerwise Relevance Propagation technique builds heat-maps
representing the relevance of each input in the model s decision. The relevance
spreads backward from the last to the first layer of the Deep Neural Network.
Layer-wise Relevance Propagation does not manage normalization layers, in this
work we suggest a method to include normalization layers. Specifically, we
build an equivalent network fusing normalization layers and convolutional or
fully connected layers. Heatmaps obtained with our method on MNIST and CIFAR 10
datasets are more accurate for convolutional layers. Our study also prevents
from using Layerwise Relevance Propagation with networks including a
combination of connected layers and normalization layer.",0,1,0,0,0,0,0.919181,9.0,0.923672,38
d7144b3d-c086-4d66-a0f1-21fb215cbc48,Neural Machine Translation with Error Correction,64,0.146934,0.894663,"Neural machine translation (NMT) generates the next target token given as
input the previous ground truth target tokens during training while the
previous generated target tokens during inference, which causes discrepancy
between training and inference as well as error propagation, and affects the
translation accuracy. In this paper, we introduce an error correction mechanism
into NMT, which corrects the error information in the previous generated tokens
to better predict the next token. Specifically, we introduce two-stream
self-attention from XLNet into NMT decoder, where the query stream is used to
predict the next token, and meanwhile the content stream is used to correct the
error information from the previous predicted tokens. We leverage scheduled
sampling to simulate the prediction errors during training. Experiments on
three IWSLT translation datasets and two WMT translation datasets demonstrate
that our method achieves improvements over Transformer baseline and scheduled
sampling. Further experimental analyses also verify the effectiveness of our
proposed error correction mechanism to improve the translation quality.",1,1,0,0,0,0,0.512001,5.0,0.611699,29
eb96b781-29e2-430e-827a-a323e35aaba1,"Massive Choice, Ample Tasks (MaChAmp): A Toolkit for Multi-task Learning in NLP",100,0.204121,0.676639,"Transfer learning, particularly approaches that combine multi-task learning
with pre-trained contextualized embeddings and fine-tuning, have advanced the
field of Natural Language Processing tremendously in recent years. In this
paper we present MaChAmp, a toolkit for easy fine-tuning of contextualized
embeddings in multi-task settings. The benefits of MaChAmp are its flexible
configuration options, and the support of a variety of natural language
processing tasks in a uniform toolkit, from text classification and sequence
labeling to dependency parsing, masked language modeling, and text generation.",0,1,0,0,0,1,0.0734251,6.0,0.302827,200
3a95f5a7-c4df-434c-bd1a-15083c308331,Audio-Visual Understanding of Passenger Intents for In-Cabin Conversational Agents,6,0.180861,0.127283,"Building multimodal dialogue understanding capabilities situated in the
in-cabin context is crucial to enhance passenger comfort in autonomous vehicle
(AV) interaction systems. To this end, understanding passenger intents from
spoken interactions and vehicle vision systems is a crucial component for
developing contextual and visually grounded conversational agents for AV.
Towards this goal, we explore AMIE (Automated-vehicle Multimodal In-cabin
Experience), the in-cabin agent responsible for handling multimodal
passenger-vehicle interactions. In this work, we discuss the benefits of a
multimodal understanding of in-cabin utterances by incorporating
verbal/language input together with the non-verbal/acoustic and visual clues
from inside and outside the vehicle. Our experimental results outperformed
text-only baselines as we achieved improved performances for intent detection
with a multimodal approach.",0,1,0,1,0,0,0.820668,7.0,0.847432,28
23502afa-a4ab-40a1-8d8d-1f761f7cc033,Fuzzy Commitments Offer Insufficient Protection to Biometric Templates Produced by Deep Learning,8,0.299183,0.677118,"In this work, we study the protection that fuzzy commitments offer when they
are applied to facial images, processed by the state of the art deep learning
facial recognition systems. We show that while these systems are capable of
producing great accuracy, they produce templates of too little entropy. As a
result, we present a reconstruction attack that takes a protected template, and
reconstructs a facial image. The reconstructed facial images greatly resemble
the original ones. In the simplest attack scenario, more than 78% of these
reconstructed templates succeed in unlocking an account (when the system is
configured to 0.1% FAR). Even in the ""hardest"" settings (in which we take a
reconstructed image from one system and use it in a different system, with
different feature extraction process) the reconstructed image offers 50 to 120
times higher success rates than the system's FAR.",0,1,0,0,0,0,0.473538,18.0,0.88593,55
2021edbd-e3db-4236-abe5-31d3a10e08b4,Hierarchical Conditional Relation Networks for Video Question Answering,223,0.917839,0.836393,"Video question answering (VideoQA) is challenging as it requires modeling
capacity to distill dynamic visual artifacts and distant relations and to
associate them with linguistic concepts. We introduce a general-purpose
reusable neural unit called Conditional Relation Network (CRN) that serves as a
building block to construct more sophisticated structures for representation
and reasoning over video. CRN takes as input an array of tensorial objects and
a conditioning feature, and computes an array of encoded output objects. Model
building becomes a simple exercise of replication, rearrangement and stacking
of these reusable units for diverse modalities and contextual information. This
design thus supports high-order relational and multi-step reasoning. The
resulting architecture for VideoQA is a CRN hierarchy whose branches represent
sub-videos or clips, all sharing the same question as the contextual condition.
Our evaluations on well-known datasets achieved new SoTA results, demonstrating
the impact of building a general-purpose reasoning unit on complex domains such
as VideoQA.",0,0,0,0,1,0,0.667044,5.0,0.697128,51
3d9a356a-9790-4826-adb5-58ddcf3a5a38,Interactive Extractive Search over Biomedical Corpora,27,0.475519,0.681742,"We present a system that allows life-science researchers to search a
linguistically annotated corpus of scientific texts using patterns over
dependency graphs, as well as using patterns over token sequences and a
powerful variant of boolean keyword queries. In contrast to previous attempts
to dependency-based search, we introduce a light-weight query language that
does not require the user to know the details of the underlying linguistic
representations, and instead to query the corpus by providing an example
sentence coupled with simple markup. Search is performed at an interactive
speed due to efficient linguistic graph-indexing and retrieval engine. This
allows for rapid exploration, development and refinement of user queries. We
demonstrate the system using example workflows over two corpora: the PubMed
corpus including 14,446,243 PubMed abstracts and the CORD-19 dataset, a
collection of over 45,000 research papers focused on COVID-19 research. The
system is publicly available at https://allenai.github.io/spike",0,1,0,0,0,0,0.392448,7.0,0.670578,23
3d3b9514-c936-47fe-8d2b-6eb36e4e99a8,Mind The Facts: Knowledge-Boosted Coherent Abstractive Text Summarization,38,0.442394,0.616702,"Neural models have become successful at producing abstractive summaries that
are human-readable and fluent. However, these models have two critical
shortcomings: they often don't respect the facts that are either included in
the source article or are known to humans as commonsense knowledge, and they
don't produce coherent summaries when the source article is long. In this work,
we propose a novel architecture that extends Transformer encoder-decoder
architecture in order to improve on these shortcomings. First, we incorporate
entity-level knowledge from the Wikidata knowledge graph into the
encoder-decoder architecture. Injecting structural world knowledge from
Wikidata helps our abstractive summarization model to be more fact-aware.
Second, we utilize the ideas used in Transformer-XL language model in our
proposed encoder-decoder architecture. This helps our model with producing
coherent summaries even when the source article is long. We test our model on
CNN/Daily Mail summarization dataset and show improvements on ROUGE scores over
the baseline Transformer model. We also include model predictions for which our
model accurately conveys the facts, while the baseline Transformer model
doesn't.",0,0,0,0,0,0,0.992927,7.0,0.998606,16
9e512a50-a716-47c9-b83b-7c78188f7d5a,Consistent Transcription and Translation of Speech,17,0.116121,0.417627,"The conventional paradigm in speech translation starts with a speech
recognition step to generate transcripts, followed by a translation step with
the automatic transcripts as input. To address various shortcomings of this
paradigm, recent work explores end-to-end trainable direct models that
translate without transcribing. However, transcripts can be an indispensable
output in practical applications, which often display transcripts alongside the
translations to users.
  We make this common requirement explicit and explore the task of jointly
transcribing and translating speech. While high accuracy of transcript and
translation are crucial, even highly accurate systems can suffer from
inconsistencies between both outputs that degrade the user experience. We
introduce a methodology to evaluate consistency and compare several modeling
approaches, including the traditional cascaded approach and end-to-end models.
We find that direct models are poorly suited to the joint
transcription/translation task, but that end-to-end models that feature a
coupled inference procedure are able to achieve strong consistency. We further
introduce simple techniques for directly optimizing for consistency, and
analyze the resulting trade-offs between consistency, transcription accuracy,
and translation accuracy.",0,1,0,0,0,0,0.162874,10.0,0.666336,44
9459be41-d93d-4a03-af9e-e9375d4ede40,Noise-Aware Texture-Preserving Low-Light Enhancement,6,0.122836,0.139189,"A simple and effective low-light image enhancement method based on a
noise-aware texture-preserving retinex model is proposed in this work. The new
method, called NATLE, attempts to strike a balance between noise removal and
natural texture preservation through a low-complexity solution. Its cost
function includes an estimated piece-wise smooth illumination map and a
noise-free texture-preserving reflectance map. Afterwards, illumination is
adjusted to form the enhanced image together with the reflectance map.
Extensive experiments are conducted on common low-light image enhancement
datasets to demonstrate the superior performance of NATLE.",0,1,0,0,0,0,0.985334,6.0,0.97182,17
d317c18c-0c86-47ab-9291-c425ee64c31d,Boosting rare benthic macroinvertebrates taxa identification with one-class classification,12,0.442736,0.508268,"Insect monitoring is crucial for understanding the consequences of rapid
ecological changes, but taxa identification currently requires tedious manual
expert work and cannot be scaled-up efficiently. Deep convolutional neural
networks (CNNs), provide a viable way to significantly increase the
biomonitoring volumes. However, taxa abundances are typically very imbalanced
and the amounts of training images for the rarest classes are simply too low
for deep CNNs. As a result, the samples from the rare classes are often
completely missed, while detecting them has biological importance. In this
paper, we propose combining the trained deep CNN with one-class classifiers to
improve the rare species identification. One-class classification models are
traditionally trained with much fewer samples and they can provide a mechanism
to indicate samples potentially belonging to the rare classes for human
inspection. Our experiments confirm that the proposed approach may indeed
support moving towards partial automation of the taxa identification task.",0,1,0,0,0,0,0.615565,5.0,0.669109,28
a4f45a98-f5c8-4a87-91a2-6b18579840da,Extended Markov Games to Learn Multiple Tasks in Multi-Agent Reinforcement Learning,15,0.12313,0.274831,"The combination of Formal Methods with Reinforcement Learning (RL) has
recently attracted interest as a way for single-agent RL to learn multiple-task
specifications. In this paper we extend this convergence to multi-agent
settings and formally define Extended Markov Games as a general mathematical
model that allows multiple RL agents to concurrently learn various
non-Markovian specifications. To introduce this new model we provide formal
definitions and proofs as well as empirical tests of RL algorithms running on
this framework. Specifically, we use our model to train two different
logic-based multi-agent RL algorithms to solve diverse settings of
non-Markovian co-safe LTL specifications.",1,0,0,0,0,0,0.556915,7.0,0.74068,37
db738bc6-2997-42f2-9a24-3cf3aee442ff,Rotation-Invariant Autoencoders for Signals on Spheres,5,0.0233624,0.317525,"Omnidirectional images and spherical representations of $3D$ shapes cannot be
processed with conventional 2D convolutional neural networks (CNNs) as the
unwrapping leads to large distortion. Using fast implementations of spherical
and $SO(3)$ convolutions, researchers have recently developed deep learning
methods better suited for classifying spherical images. These newly proposed
convolutional layers naturally extend the notion of convolution to functions on
the unit sphere $S^2$ and the group of rotations $SO(3)$ and these layers are
equivariant to 3D rotations. In this paper, we consider the problem of
unsupervised learning of rotation-invariant representations for spherical
images. In particular, we carefully design an autoencoder architecture
consisting of $S^2$ and $SO(3)$ convolutional layers. As 3D rotations are often
a nuisance factor, the latent space is constrained to be exactly invariant to
these input transformations. As the rotation information is discarded in the
latent space, we craft a novel rotation-invariant loss function for training
the network. Extensive experiments on multiple datasets demonstrate the
usefulness of the learned representations on clustering, retrieval and
classification applications.",0,0,0,0,0,0,0.389148,7.0,0.669016,48
8cbf70e6-a377-4704-872b-a314d88f52ac,An IoT Framework for Heart Disease Prediction based on MDCNN Classifier,154,0.841027,0.998481,"Nowadays, heart disease is the leading cause of death worldwide. Predicting
heart disease is a complex task since it requires experience along with
advanced knowledge. Internet of Things (IoT) technology has lately been adopted
in healthcare systems to collect sensor values for heart disease diagnosis and
prediction. Many researchers have focused on the diagnosis of heart disease,
yet the accuracy of the diagnosis results is low. To address this issue, an IoT
framework is proposed to evaluate heart disease more accurately using a
Modified Deep Convolutional Neural Network (MDCNN). The smartwatch and heart
monitor device that is attached to the patient monitors the blood pressure and
electrocardiogram (ECG). The MDCNN is utilized for classifying the received
sensor data into normal and abnormal. The performance of the system is analyzed
by comparing the proposed MDCNN with existing deep learning neural networks and
logistic regression. The results demonstrate that the proposed MDCNN based
heart disease prediction system performs better than other methods. The
proposed method shows that for the maximum number of records, the MDCNN
achieves an accuracy of 98.2 which is better than existing classifiers.",0,1,0,0,1,0,0.543906,5.0,0.629712,47
75b41e1f-01a4-4bda-a038-cea437384eab,Frame-To-Frame Consistent Semantic Segmentation,7,0.073522,0.083668,"In this work, we aim for temporally consistent semantic segmentation
throughout frames in a video. Many semantic segmentation algorithms process
images individually which leads to an inconsistent scene interpretation due to
illumination changes, occlusions and other variations over time. To achieve a
temporally consistent prediction, we train a convolutional neural network (CNN)
which propagates features through consecutive frames in a video using a
convolutional long short term memory (ConvLSTM) cell. Besides the temporal
feature propagation, we penalize inconsistencies in our loss function. We show
in our experiments that the performance improves when utilizing video
information compared to single frame prediction. The mean intersection over
union (mIoU) metric on the Cityscapes validation set increases from 45.2 % for
the single frames to 57.9 % for video data after implementing the ConvLSTM to
propagate features trough time on the ESPNet. Most importantly, inconsistency
decreases from 4.5 % to 1.3 % which is a reduction by 71.1 %. Our results
indicate that the added temporal information produces a frame-to-frame
consistent and more accurate image understanding compared to single frame
processing. Code and videos are available at
https://github.com/mrebol/f2f-consistent-semantic-segmentation",1,1,0,0,0,0,0.951138,9.0,0.943934,29
525a3bf2-c900-44f8-bab4-456adf6828b2,Unravelling Small Sample Size Problems in the Deep Learning World,26,0.141484,0.525289,"The growth and success of deep learning approaches can be attributed to two
major factors: availability of hardware resources and availability of large
number of training samples. For problems with large training databases, deep
learning models have achieved superlative performances. However, there are a
lot of \textit{small sample size or $S^3$} problems for which it is not
feasible to collect large training databases. It has been observed that deep
learning models do not generalize well on $S^3$ problems and specialized
solutions are required. In this paper, we first present a review of deep
learning algorithms for small sample size problems in which the algorithms are
segregated according to the space in which they operate, i.e. input space,
model space, and feature space. Secondly, we present Dynamic Attention Pooling
approach which focuses on extracting global information from the most
discriminative sub-part of the feature map. The performance of the proposed
dynamic attention pooling is analyzed with state-of-the-art ResNet model on
relatively small publicly available datasets such as SVHN, C10, C100, and
TinyImageNet.",0,1,0,0,0,0,0.42484,8.0,0.724795,100
adfd8e8b-5b6d-4e7b-8168-c0b7320bbf5c,An Optimal Procedure to Check Pareto-Optimality in House Markets with Single-Peaked Preferences,2,0.0635063,0.0430604,"Recently, the problem of allocating one resource per agent with initial
endowments (house markets) has seen a renewed interest: indeed, while in the
domain of strict preferences the Top Trading Cycle algorithm is known to be the
only procedure guaranteeing Pareto-optimality, individual rationality, and
strategy proofness. However, the situation differs in the single-peaked domain.
Indeed, Bade presented the Crawler, an alternative procedure enjoying the same
properties, with the additional advantage of being implementable in obviously
dominant strategies. In this paper we further investigate the Crawler and
propose the Diver, a variant which checks optimally whether an allocation is
Pareto-optimal for single-peaked preferences, thus improving over known
techniques used for checking Pareto-optimality in more general domains. We also
prove that the Diver is asymptotically optimal in terms of communication
complexity.",0,0,0,0,0,0,0.0470195,29.0,0.839909,23
6f989f48-94f2-45ee-a205-7712ab0a9d62,Interactive Robot Training for Non-Markov Tasks,15,0.0574962,0.292294,"Defining sound and complete specifications for robots using formal languages
is challenging, while learning formal specifications directly from
demonstrations can lead to over-constrained task policies. In this paper, we
propose a Bayesian interactive robot training framework that allows the robot
to learn from both demonstrations provided by a teacher, and that teacher's
assessments of the robot's task executions. We also present an active learning
approach -- inspired by uncertainty sampling -- to identify the task execution
with the most uncertain degree of acceptability. Through a simulated
experiment, we demonstrate that our active learning approach identifies a
teacher's intended task specification with an equivalent or greater similarity
when compared to an approach that learns purely from demonstrations. Finally,
we demonstrate the efficacy of our approach in a real-world setting through a
user-study based on teaching a robot to set a dinner table.",0,0,0,0,0,0,0.335886,5.0,0.499452,40
26902243-4a84-47f8-9e70-97b7aa05f8ba,Multimodal Future Localization and Emergence Prediction for Objects in Egocentric View with a Reachability Prior,29,0.247413,0.708708,"In this paper, we investigate the problem of anticipating future dynamics,
particularly the future location of other vehicles and pedestrians, in the view
of a moving vehicle. We approach two fundamental challenges: (1) the partial
visibility due to the egocentric view with a single RGB camera and considerable
field-of-view change due to the egomotion of the vehicle; (2) the multimodality
of the distribution of future states. In contrast to many previous works, we do
not assume structural knowledge from maps. We rather estimate a reachability
prior for certain classes of objects from the semantic map of the present image
and propagate it into the future using the planned egomotion. Experiments show
that the reachability prior combined with multi-hypotheses learning improves
multimodal prediction of the future location of tracked objects and, for the
first time, the emergence of new objects. We also demonstrate promising
zero-shot transfer to unseen datasets. Source code is available at
$\href{https://github.com/lmb-freiburg/FLN-EPN-RPN}{\text{this https URL.}}$",1,1,0,0,0,0,0.786484,5.0,0.764993,68
1906dc34-60c8-4bc1-9dd7-b1f6b83fb586,Shape-Texture Debiased Neural Network Training,94,0.434608,0.994214,"Shape and texture are two prominent and complementary cues for recognizing
objects. Nonetheless, Convolutional Neural Networks are often biased towards
either texture or shape, depending on the training dataset. Our ablation shows
that such bias degenerates model performance. Motivated by this observation, we
develop a simple algorithm for shape-texture debiased learning. To prevent
models from exclusively attending on a single cue in representation learning,
we augment training data with images with conflicting shape and texture
information (eg, an image of chimpanzee shape but with lemon texture) and, most
importantly, provide the corresponding supervisions from shape and texture
simultaneously.
  Experiments show that our method successfully improves model performance on
several image recognition benchmarks and adversarial robustness. For example,
by training on ImageNet, it helps ResNet-152 achieve substantial improvements
on ImageNet (+1.2%), ImageNet-A (+5.2%), ImageNet-C (+8.3%) and
Stylized-ImageNet (+11.1%), and on defending against FGSM adversarial attacker
on ImageNet (+14.4%). Our method also claims to be compatible with other
advanced data augmentation strategies, eg, Mixup, and CutMix. The code is
available here: https://github.com/LiYingwei/ShapeTextureDebiasedTraining.",0,1,0,0,1,1,0.925859,8.0,0.918345,48
8f0a1e55-8b3e-4eba-9e19-880c124ccc4f,Fair Transfer of Multiple Style Attributes in Text,2,0.0143097,0.015396,"To preserve anonymity and obfuscate their identity on online platforms users
may morph their text and portray themselves as a different gender or
demographic. Similarly, a chatbot may need to customize its communication style
to improve engagement with its audience. This manner of changing the style of
written text has gained significant attention in recent years. Yet these past
research works largely cater to the transfer of single style attributes. The
disadvantage of focusing on a single style alone is that this often results in
target text where other existing style attributes behave unpredictably or are
unfairly dominated by the new style. To counteract this behavior, it would be
nice to have a style transfer mechanism that can transfer or control multiple
styles simultaneously and fairly. Through such an approach, one could obtain
obfuscated or written text incorporated with a desired degree of multiple soft
styles such as female-quality, politeness, or formalness.
  In this work, we demonstrate that the transfer of multiple styles cannot be
achieved by sequentially performing multiple single-style transfers. This is
because each single style-transfer step often reverses or dominates over the
style incorporated by a previous transfer step. We then propose a neural
network architecture for fairly transferring multiple style attributes in a
given text. We test our architecture on the Yelp data set to demonstrate our
superior performance as compared to existing one-style transfer steps performed
in a sequence.",0,0,0,0,0,0,0.775643,6.0,0.798728,18
db6132b4-5328-439a-ae0a-7e03f4cc00e0,Data science and AI in FinTech: An overview,48,0.273133,0.78638,"Financial technology (FinTech) has been playing an increasingly critical role
in driving modern economies, society, technology, and many other areas. Smart
FinTech is the new-generation FinTech, largely inspired and empowered by data
science and new-generation AI and (DSAI) techniques. Smart FinTech synthesizes
broad DSAI and transforms finance and economies to drive intelligent,
automated, whole-of-business and personalized economic and financial
businesses, services and systems. The research on data science and AI in
FinTech involves many latest progress made in smart FinTech for BankingTech,
TradeTech, LendTech, InsurTech, WealthTech, PayTech, RiskTech,
cryptocurrencies, and blockchain, and the DSAI techniques including complex
system methods, quantitative methods, intelligent interactions, recognition and
responses, data analytics, deep learning, federated learning,
privacy-preserving processing, augmentation, optimization, and system
intelligence enhancement. Here, we present a highly dense research overview of
smart financial businesses and their challenges, the smart FinTech ecosystem,
the DSAI techniques to enable smart FinTech, and some research directions of
smart FinTech futures to the DSAI communities.",0,0,0,0,0,0,0.632656,3.0,0.464006,66
b3ffe06a-6507-4321-bc51-18c6c764308a,Logistic Q-Learning,36,0.0488276,0.298355,"We propose a new reinforcement learning algorithm derived from a regularized
linear-programming formulation of optimal control in MDPs. The method is
closely related to the classic Relative Entropy Policy Search (REPS) algorithm
of Peters et al. (2010), with the key difference that our method introduces a
Q-function that enables efficient exact model-free implementation. The main
feature of our algorithm (called QREPS) is a convex loss function for policy
evaluation that serves as a theoretically sound alternative to the widely used
squared Bellman error. We provide a practical saddle-point optimization method
for minimizing this loss function and provide an error-propagation analysis
that relates the quality of the individual updates to the performance of the
output policy. Finally, we demonstrate the effectiveness of our method on a
range of benchmark problems.",1,0,0,0,0,0,0.0278019,10.0,0.482198,69
46ec8fe4-442e-42bd-9dba-dd58d6bebb1c,Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers,32,0.277667,0.472721,"With the growth of computing power neural machine translation (NMT) models
also grow accordingly and become better. However, they also become harder to
deploy on edge devices due to memory constraints. To cope with this problem, a
common practice is to distill knowledge from a large and accurately-trained
teacher network (T) into a compact student network (S). Although knowledge
distillation (KD) is useful in most cases, our study shows that existing KD
techniques might not be suitable enough for deep NMT engines, so we propose a
novel alternative. In our model, besides matching T and S predictions we have a
combinatorial mechanism to inject layer-level supervision from T to S. In this
paper, we target low-resource settings and evaluate our translation engines for
Portuguese--English, Turkish--English, and English--German directions. Students
trained using our technique have 50% fewer parameters and can still deliver
comparable results to those of 12-layer teachers.",1,1,0,0,0,0,0.97133,6.0,0.943008,21
fde8fc29-dcf5-4611-90cf-ebf7d56f34ea,STAR: A Schema-Guided Dialog Dataset for Transfer Learning,35,0.493849,0.703862,"We present STAR, a schema-guided task-oriented dialog dataset consisting of
127,833 utterances and knowledge base queries across 5,820 task-oriented
dialogs in 13 domains that is especially designed to facilitate task and domain
transfer learning in task-oriented dialog. Furthermore, we propose a scalable
crowd-sourcing paradigm to collect arbitrarily large datasets of the same
quality as STAR. Moreover, we introduce novel schema-guided dialog models that
use an explicit description of the task(s) to generalize from known to unknown
tasks. We demonstrate the effectiveness of these models, particularly for
zero-shot generalization across tasks and domains.",1,1,1,1,0,0,0.981902,3.0,0.926614,41
9b268136-3a0f-4951-9afa-78d626ca20d5,Investigating the Impact of Pre-processing and Prediction Aggregation on the DeepFake Detection Task,21,0.553879,0.0958762,"Recent advances in content generation technologies (widely known as
DeepFakes) along with the online proliferation of manipulated media content
render the detection of such manipulations a task of increasing importance.
Even though there are many DeepFake detection methods, only a few focus on the
impact of dataset preprocessing and the aggregation of frame-level to
video-level prediction on model performance. In this paper, we propose a
pre-processing step to improve the training data quality and examine its effect
on the performance of DeepFake detection. We also propose and evaluate the
effect of video-level prediction aggregation approaches. Experimental results
show that the proposed pre-processing approach leads to considerable
improvements in the performance of detection models, and the proposed
prediction aggregation scheme further boosts the detection efficiency in cases
where there are multiple faces in a video.",0,1,0,0,0,0,0.987315,4.0,0.966181,41
5be78017-dd8f-4059-8617-1785d491b83c,Visualizing Classification Structure of Large-Scale Classifiers,1,0.00122585,0.0120767,"We propose a measure to compute class similarity in large-scale
classification based on prediction scores. Such measure has not been formally
pro-posed in the literature. We show how visualizing the class similarity
matrix can reveal hierarchical structures and relationships that govern the
classes. Through examples with various classifiers, we demonstrate how such
structures can help in analyzing the classification behavior and in inferring
potential corner cases. The source code for one example is available as a
notebook at https://github.com/bilalsal/blocks",1,0,1,0,0,0,0.0221376,9.0,0.399029,38
2490efe1-b21b-4258-85e7-012d9f0ce042,The two-echelon routing problem with truck and drones,14,0.250983,0.436881,"In this paper, we study novel variants of the well-known two-echelon vehicle
routing problem in which a truck works on the first echelon to transport
parcels and a fleet of drones to intermediate depots while in the second
echelon, the drones are used to deliver parcels from intermediate depots to
customers. The objective is to minimize the completion time instead of the
transportation cost as in classical 2-echelon vehicle routing problems.
Depending on the context, a drone can be launched from the truck at an
intermediate depot once (single trip drone) or several times (multiple trip
drone). Mixed Integer Linear Programming (MILP) models are first proposed to
formulate mathematically the problems and solve to optimality small-size
instances. To handle larger instances, a metaheuristic based on the idea of
Greedy Randomized Adaptive Search Procedure (GRASP) is introduced. Experimental
results obtained on instances of different contexts are reported and analyzed.",0,1,1,0,0,0,0.812762,8.0,0.863325,41
468ded75-fe92-4cef-a143-ebe9148b08d1,Deep Learning for Content-based Personalized Viewport Prediction of 360-Degree VR Videos,24,0.844957,0.797673,"In this paper, the problem of head movement prediction for virtual reality
videos is studied. In the considered model, a deep learning network is
introduced to leverage position data as well as video frame content to predict
future head movement. For optimizing data input into this neural network, data
sample rate, reduced data, and long-period prediction length are also explored
for this model. Simulation results show that the proposed approach yields
16.1\% improvement in terms of prediction accuracy compared to a baseline
approach that relies only on the position data.",0,1,0,0,0,0,0.984113,6.0,0.968634,17
87541d22-dc70-4315-9129-d936b296a402,Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking,67,0.694498,0.920875,"The rapid advancement of technology in online communication via social media
platforms has led to a prolific rise in the spread of misinformation and fake
news. Fake news is especially rampant in the current COVID-19 pandemic, leading
to people believing in false and potentially harmful claims and stories.
Detecting fake news quickly can alleviate the spread of panic, chaos and
potential health hazards. We developed a two stage automated pipeline for
COVID-19 fake news detection using state of the art machine learning models for
natural language processing. The first model leverages a novel fact checking
algorithm that retrieves the most relevant facts concerning user claims about
particular COVID-19 claims. The second model verifies the level of truth in the
claim by computing the textual entailment between the claim and the true facts
retrieved from a manually curated COVID-19 dataset. The dataset is based on a
publicly available knowledge source consisting of more than 5000 COVID-19 false
claims and verified explanations, a subset of which was internally annotated
and cross-validated to train and evaluate our models. We evaluate a series of
models based on classical text-based features to more contextual Transformer
based models and observe that a model pipeline based on BERT and ALBERT for the
two stages respectively yields the best results.",0,1,0,1,0,0,0.885453,6.0,0.860633,28
523a99e2-652c-4911-bc5f-e96568d76745,ShapeFlow: Learnable Deformations Among 3D Shapes,43,0.472635,0.610527,"We present ShapeFlow, a flow-based model for learning a deformation space for
entire classes of 3D shapes with large intra-class variations. ShapeFlow allows
learning a multi-template deformation space that is agnostic to shape topology,
yet preserves fine geometric details. Different from a generative space where a
latent vector is directly decoded into a shape, a deformation space decodes a
vector into a continuous flow that can advect a source shape towards a target.
Such a space naturally allows the disentanglement of geometric style (coming
from the source) and structural pose (conforming to the target). We parametrize
the deformation between geometries as a learned continuous flow field via a
neural network and show that such deformations can be guaranteed to have
desirable properties, such as be bijectivity, freedom from self-intersections,
or volume preservation. We illustrate the effectiveness of this learned
deformation space for various downstream applications, including shape
generation via deformation, geometric style transfer, unsupervised learning of
a consistent parameterization for entire classes of shapes, and shape
interpolation.",0,0,0,0,0,0,0.942451,5.0,0.887935,68
5fae10b8-2b68-465b-a72b-0a730b9bff45,K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters,469,0.836952,1.0,"We study the problem of injecting knowledge into large pre-trained models
like BERT and RoBERTa. Existing methods typically update the original
parameters of pre-trained models when injecting knowledge. However, when
multiple kinds of knowledge are injected, the historically injected knowledge
would be flushed away. To address this, we propose K-Adapter, a framework that
retains the original parameters of the pre-trained model fixed and supports the
development of versatile knowledge-infused model. Taking RoBERTa as the
backbone model, K-Adapter has a neural adapter for each kind of infused
knowledge, like a plug-in connected to RoBERTa. There is no information flow
between different adapters, thus multiple adapters can be efficiently trained
in a distributed way. As a case study, we inject two kinds of knowledge in this
work, including (1) factual knowledge obtained from automatically aligned
text-triplets on Wikipedia and Wikidata and (2) linguistic knowledge obtained
via dependency parsing. Results on three knowledge-driven tasks, including
relation classification, entity typing, and question answering, demonstrate
that each adapter improves the performance and the combination of both adapters
brings further improvements. Further analysis indicates that K-Adapter captures
versatile knowledge than RoBERTa.",1,1,0,1,0,0,0.895857,3.0,0.735603,53
3766dc3d-9b54-4787-8bce-c1694d0c82ef,Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing,80,0.582316,0.949082,"Task-oriented semantic parsing is a critical component of virtual assistants,
which is responsible for understanding the user's intents (set reminder, play
music, etc.). Recent advances in deep learning have enabled several approaches
to successfully parse more complex queries (Gupta et al., 2018; Rongali et
al.,2020), but these models require a large amount of annotated training data
to parse queries on new domains (e.g. reminder, music).
  In this paper, we focus on adapting task-oriented semantic parsers to
low-resource domains, and propose a novel method that outperforms a supervised
neural model at a 10-fold data reduction. In particular, we identify two
fundamental factors for low-resource domain adaptation: better representation
learning and better training techniques. Our representation learning uses BART
(Lewis et al., 2019) to initialize our model which outperforms encoder-only
pre-trained representations used in previous work. Furthermore, we train with
optimization-based meta-learning (Finn et al., 2017) to improve generalization
to low-resource domains. This approach significantly outperforms all baseline
methods in the experiments on a newly collected multi-domain task-oriented
semantic parsing dataset (TOPv2), which we release to the public.",0,1,0,1,1,0,0.868294,5.0,0.819442,33
f046103e-6aab-4145-87d0-3d0d0be1cdf8,Fast top-K Cosine Similarity Search through XOR-Friendly Binary Quantization on GPUs,5,0.0590937,0.218792,"We explore the use of GPU for accelerating large scale nearest neighbor
search and we propose a fast vector-quantization-based exhaustive nearest
neighbor search algorithm that can achieve high accuracy without any indexing
construction specifically designed for cosine similarity. This algorithm uses a
novel XOR-friendly binary quantization method to encode floating-point numbers
such that high-complexity multiplications can be optimized as low-complexity
bitwise operations. Experiments show that, our quantization method takes short
preprocessing time, and helps make the search speed of our exhaustive search
method much more faster than that of popular approximate nearest neighbor
algorithms when high accuracy is needed.",0,1,0,0,1,0,0.789585,18.0,0.935244,28
d688ec5b-834d-4672-8c76-b4252eeef94b,A High-Level Description and Performance Evaluation of Pupil Invisible,32,0.54106,0.436994,"Head-mounted eye trackers promise convenient access to reliable gaze data in
unconstrained environments. Due to several limitations, however, often they can
only partially deliver on this promise.
  Among those are the following: (i) the necessity of performing a device setup
and calibration prior to every use of the eye tracker, (ii) a lack of
robustness of gaze-estimation results against perturbations, such as outdoor
lighting conditions and unavoidable slippage of the eye tracker on the head of
the subject, and (iii) behavioral distortion resulting from social awkwardness,
due to the unnatural appearance of current head-mounted eye trackers.
  Recently, Pupil Labs released Pupil Invisible glasses, a head-mounted eye
tracker engineered to tackle these limitations. Here, we present an extensive
evaluation of its gaze-estimation capabilities. To this end, we designed a
data-collection protocol and evaluation scheme geared towards providing a
faithful portrayal of the real-world usage of Pupil Invisible glasses.
  In particular, we develop a geometric framework for gauging gaze-estimation
accuracy that goes beyond reporting mean angular accuracy. We demonstrate that
Pupil Invisible glasses, without the need of a calibration, provide gaze
estimates which are robust to perturbations, including outdoor lighting
conditions and slippage of the headset.",0,1,1,0,0,0,0.578471,8.0,0.780528,62
7f0c56c2-fc99-4ed7-a9b3-d97442d0b7c9,Meta-DRN: Meta-Learning for 1-Shot Image Segmentation,5,0.0042763,0.0432955,"Modern deep learning models have revolutionized the field of computer vision.
But, a significant drawback of most of these models is that they require a
large number of labelled examples to generalize properly. Recent developments
in few-shot learning aim to alleviate this requirement. In this paper, we
propose a novel lightweight CNN architecture for 1-shot image segmentation. The
proposed model is created by taking inspiration from well-performing
architectures for semantic segmentation and adapting it to the 1-shot domain.
We train our model using 4 meta-learning algorithms that have worked well for
image classification and compare the results. For the chosen dataset, our
proposed model has a 70% lower parameter count than the benchmark, while having
better or comparable mean IoU scores using all 4 of the meta-learning
algorithms.",0,1,0,0,0,0,0.439093,5.0,0.568545,33
87836eb1-9d6e-4dea-b2c3-b378e7bca608,Procrustean Regression Networks: Learning 3D Structure of Non-Rigid Objects from 2D Annotations,16,0.113129,0.30304,"We propose a novel framework for training neural networks which is capable of
learning 3D information of non-rigid objects when only 2D annotations are
available as ground truths. Recently, there have been some approaches that
incorporate the problem setting of non-rigid structure-from-motion (NRSfM) into
deep learning to learn 3D structure reconstruction. The most important
difficulty of NRSfM is to estimate both the rotation and deformation at the
same time, and previous works handle this by regressing both of them. In this
paper, we resolve this difficulty by proposing a loss function wherein the
suitable rotation is automatically determined. Trained with the cost function
consisting of the reprojection error and the low-rank term of aligned shapes,
the network learns the 3D structures of such objects as human skeletons and
faces during the training, whereas the testing is done in a single-frame basis.
The proposed method can handle inputs with missing entries and experimental
results validate that the proposed framework shows superior reconstruction
performance to the state-of-the-art method on the Human 3.6M, 300-VW, and
SURREAL datasets, even though the underlying network structure is very simple.",0,1,0,0,1,0,0.352027,9.0,0.728404,48
cdd8a6c0-4b60-4018-8c7d-a5a0ff5fb3a1,RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments,145,0.182603,0.692327,"Exploration in sparse reward environments remains one of the key challenges
of model-free reinforcement learning. Instead of solely relying on extrinsic
rewards provided by the environment, many state-of-the-art methods use
intrinsic rewards to encourage exploration. However, we show that existing
methods fall short in procedurally-generated environments where an agent is
unlikely to visit a state more than once. We propose a novel type of intrinsic
reward which encourages the agent to take actions that lead to significant
changes in its learned state representation. We evaluate our method on multiple
challenging procedurally-generated tasks in MiniGrid, as well as on tasks with
high-dimensional observations used in prior work. Our experiments demonstrate
that this approach is more sample efficient than existing exploration methods,
particularly for procedurally-generated MiniGrid environments. Furthermore, we
analyze the learned behavior as well as the intrinsic reward received by our
agent. In contrast to previous approaches, our intrinsic reward does not
diminish during the course of training and it rewards the agent substantially
more for interacting with objects that it can control.",0,1,0,0,0,0,0.154096,6.0,0.433815,67
224b2214-883a-4f24-9fc3-5c951eeca9aa,Modular Multi Target Tracking Using LSTM Networks,6,0.0581373,0.212897,"The process of association and tracking of sensor detections is a key element
in providing situational awareness. When the targets in the scenario are dense
and exhibit high maneuverability, Multi-Target Tracking (MTT) becomes a
challenging task. The conventional techniques to solve such NP-hard
combinatorial optimization problem involves multiple complex models and
requires tedious tuning of parameters, failing to provide an acceptable
performance within the computational constraints. This paper proposes a model
free end-to-end approach for airborne target tracking system using sensor
measurements, integrating all the key elements of multi target tracking --
association, prediction and filtering using deep learning with memory. The
challenging task of association is performed using the Bi-Directional Long
short-term memory (LSTM) whereas filtering and prediction are done using LSTM
models. The proposed modular blocks can be independently trained and used in
multitude of tracking applications including non co-operative (e.g., radar) and
co-operative sensors (e.g., AIS, IFF, ADS-B). Such modular blocks also enhances
the interpretability of the deep learning application. It is shown that
performance of the proposed technique outperforms conventional state of the art
technique Joint Probabilistic Data Association with Interacting Multiple Model
(JPDA-IMM) filter.",0,1,0,0,1,0,0.176066,12.0,0.729078,23
22e3b2fe-4038-4282-8f21-8ac6616f3885,Synthesizer: Rethinking Self-Attention in Transformer Models,69,0.228739,0.640444,"The dot product self-attention is known to be central and indispensable to
state-of-the-art Transformer models. But is it really required? This paper
investigates the true importance and contribution of the dot product-based
self-attention mechanism on the performance of Transformer models. Via
extensive experiments, we find that (1) random alignment matrices surprisingly
perform quite competitively and (2) learning attention weights from token-token
(query-key) interactions is useful but not that important after all. To this
end, we propose \textsc{Synthesizer}, a model that learns synthetic attention
weights without token-token interactions. In our experiments, we first show
that simple Synthesizers achieve highly competitive performance when compared
against vanilla Transformer models across a range of tasks, including machine
translation, language modeling, text generation and GLUE/SuperGLUE benchmarks.
When composed with dot product attention, we find that Synthesizers
consistently outperform Transformers. Moreover, we conduct additional
comparisons of Synthesizers against Dynamic Convolutions, showing that simple
Random Synthesizer is not only $60\%$ faster but also improves perplexity by a
relative $3.5\%$. Finally, we show that simple factorized Synthesizers can
outperform Linformers on encoding only tasks.",0,0,0,0,0,0,0.929446,5.0,0.873128,29
c943a74b-26c5-4f47-876b-851820b9e58b,AAG: Self-Supervised Representation Learning by Auxiliary Augmentation with GNT-Xent Loss,1,0.00755032,0.00963709,"Self-supervised representation learning is an emerging research topic for its
powerful capacity in learning with unlabeled data. As a mainstream
self-supervised learning method, augmentation-based contrastive learning has
achieved great success in various computer vision tasks that lack manual
annotations. Despite current progress, the existing methods are often limited
by extra cost on memory or storage, and their performance still has large room
for improvement. Here we present a self-supervised representation learning
method, namely AAG, which is featured by an auxiliary augmentation strategy and
GNT-Xent loss. The auxiliary augmentation is able to promote the performance of
contrastive learning by increasing the diversity of images. The proposed
GNT-Xent loss enables a steady and fast training process and yields competitive
accuracy. Experiment results demonstrate the superiority of AAG to previous
state-of-the-art methods on CIFAR10, CIFAR100, and SVHN. Especially, AAG
achieves 94.5% top-1 accuracy on CIFAR10 with batch size 64, which is 0.5%
higher than the best result of SimCLR with batch size 1024.",0,1,0,0,1,1,0.911092,7.0,0.896342,33
2352ac7e-52d2-4b96-8938-67c69ffb2c0f,Archimedean Choice Functions: an Axiomatic Foundation for Imprecise Decision Making,10,0.0181905,0.218668,"If uncertainty is modelled by a probability measure, decisions are typically
made by choosing the option with the highest expected utility. If an imprecise
probability model is used instead, this decision rule can be generalised in
several ways. We here focus on two such generalisations that apply to sets of
probability measures: E-admissibility and maximality. Both of them can be
regarded as special instances of so-called choice functions, a very general
mathematical framework for decision making. For each of these two decision
rules, we provide a set of necessary and sufficient conditions on choice
functions that uniquely characterises this rule, thereby providing an axiomatic
foundation for imprecise decision making with sets of probabilities. A
representation theorem for Archimedean choice functions in terms of coherent
lower previsions lies at the basis of both results.",0,0,0,0,0,0,8.08876e-05,17.0,0.351068,16
9cb3531a-db40-4259-b97b-1824deeea86e,Improving Domain-Adapted Sentiment Classification by Deep Adversarial Mutual Learning,35,0.151236,0.722962,"Domain-adapted sentiment classification refers to training on a labeled
source domain to well infer document-level sentiment on an unlabeled target
domain. Most existing relevant models involve a feature extractor and a
sentiment classifier, where the feature extractor works towards learning
domain-invariant features from both domains, and the sentiment classifier is
trained only on the source domain to guide the feature extractor. As such, they
lack a mechanism to use sentiment polarity lying in the target domain. To
improve domain-adapted sentiment classification by learning sentiment from the
target domain as well, we devise a novel deep adversarial mutual learning
approach involving two groups of feature extractors, domain discriminators,
sentiment classifiers, and label probers. The domain discriminators enable the
feature extractors to obtain domain-invariant features. Meanwhile, the label
prober in each group explores document sentiment polarity of the target domain
through the sentiment prediction generated by the classifier in the peer group,
and guides the learning of the feature extractor in its own group. The proposed
approach achieves the mutual learning of the two groups in an end-to-end
manner. Experiments on multiple public datasets indicate our method obtains the
state-of-the-art performance, validating the effectiveness of mutual learning
through label probers.",1,1,0,0,1,0,0.449122,10.0,0.787345,35
93639571-0bb5-4164-99b3-17cc12ae85ac,1st Place Solution to Google Landmark Retrieval 2020,9,0.0635623,0.143634,"This paper presents the 1st place solution to the Google Landmark Retrieval
2020 Competition on Kaggle. The solution is based on metric learning to
classify numerous landmark classes, and uses transfer learning with two train
datasets, fine-tuning on bigger images, adjusting loss weight for cleaner
samples, and esemble to enhance the model's performance further. Finally, it
scored 0.38677 mAP@100 on the private leaderboard.",0,1,0,0,0,0,0.914391,3.0,0.763299,5
6908ffff-d433-4406-8d07-0156163aa4e8,A Clarifying Question Selection System from NTES_ALONG in Convai3 Challenge,7,0.0520949,0.227139,"This paper presents the participation of NetEase Game AI Lab team for the
ClariQ challenge at Search-oriented Conversational AI (SCAI) EMNLP workshop in
2020. The challenge asks for a complete conversational information retrieval
system that can understanding and generating clarification questions. We
propose a clarifying question selection system which consists of response
understanding, candidate question recalling and clarifying question ranking. We
fine-tune a RoBERTa model to understand user's responses and use an enhanced
BM25 model to recall the candidate questions. In clarifying question ranking
stage, we reconstruct the training dataset and propose two models based on
ELECTRA. Finally we ensemble the models by summing up their output
probabilities and choose the question with the highest probability as the
clarification question. Experiments show that our ensemble ranking model
outperforms in the document relevance task and achieves the best recall@[20,30]
metrics in question relevance task. And in multi-turn conversation evaluation
in stage2, our system achieve the top score of all document relevance metrics.",0,1,0,0,0,0,0.975882,3.0,0.90186,7
3fe18da2-fdc1-4fab-b120-bdda99b8d212,Reducing Drift in Structure From Motion Using Extended Features,8,0.0356477,0.355992,"Low-frequency long-range errors (drift) are an endemic problem in 3D
structure from motion, and can often hamper reasonable reconstructions of the
scene. In this paper, we present a method to dramatically reduce scale and
positional drift by using extended structural features such as planes and
vanishing points. Unlike traditional feature matches, our extended features are
able to span non-overlapping input images, and hence provide long-range
constraints on the scale and shape of the reconstruction. We add these features
as additional constraints to a state-of-the-art global structure from motion
algorithm and demonstrate that the added constraints enable the reconstruction
of particularly drift-prone sequences such as long, low field-of-view videos
without inertial measurements. Additionally, we provide an analysis of the
drift-reducing capabilities of these constraints by evaluating on a synthetic
dataset. Our structural features are able to significantly reduce drift for
scenes that contain long-spanning man-made structures, such as aligned rows of
windows or planar building facades.",1,1,0,0,0,0,0.0112254,16.0,0.619164,62
3163cff1-ef80-4b86-8cf0-5dda2ee352b1,Language Models not just for Pre-training: Fast Online Neural Noisy Channel Modeling,7,0.0172315,0.249138,"Pre-training models on vast quantities of unlabeled data has emerged as an
effective approach to improving accuracy on many NLP tasks. On the other hand,
traditional machine translation has a long history of leveraging unlabeled data
through noisy channel modeling. The same idea has recently been shown to
achieve strong improvements for neural machine translation. Unfortunately,
na\""{i}ve noisy channel modeling with modern sequence to sequence models is up
to an order of magnitude slower than alternatives. We address this issue by
introducing efficient approximations to make inference with the noisy channel
approach as fast as strong ensembles while increasing accuracy. We also show
that the noisy channel approach can outperform strong pre-training results by
achieving a new state of the art on WMT Romanian-English translation.",0,1,0,0,1,0,0.522115,5.0,0.617454,37
16e564eb-94f7-42a1-b5e3-33cc25232707,Do you comply with AI? -- Personalized explanations of learning algorithms and their impact on employees' compliance behavior,28,0.156529,0.451108,"Machine Learning algorithms are technological key enablers for artificial
intelligence (AI). Due to the inherent complexity, these learning algorithms
represent black boxes and are difficult to comprehend, therefore influencing
compliance behavior. Hence, compliance with the recommendations of such
artifacts, which can impact employees' task performance significantly, is still
subject to research - and personalization of AI explanations seems to be a
promising concept in this regard. In our work, we hypothesize that, based on
varying backgrounds like training, domain knowledge and demographic
characteristics, individuals have different understandings and hence mental
models about the learning algorithm. Personalization of AI explanations,
related to the individuals' mental models, may thus be an instrument to affect
compliance and therefore employee task performance. Our preliminary results
already indicate the importance of personalized explanations in industry
settings and emphasize the importance of this research endeavor.",0,0,0,0,0,0,0.0352168,12.0,0.588517,30
4063edb6-b708-4adb-b50f-f49eb573d1ba,TAVAT: Token-Aware Virtual Adversarial Training for Language Understanding,23,0.0326136,0.145442,"Gradient-based adversarial training is widely used in improving the
robustness of neural networks, while it cannot be easily adapted to natural
language processing tasks since the embedding space is discrete. In natural
language processing fields, virtual adversarial training is introduced since
texts are discrete and cannot be perturbed by gradients directly.
Alternatively, virtual adversarial training, which generates perturbations on
the embedding space, is introduced in NLP tasks. Despite its success, existing
virtual adversarial training methods generate perturbations roughly constrained
by Frobenius normalization balls. To craft fine-grained perturbations, we
propose a Token-Aware Virtual Adversarial Training method. We introduce a
token-level accumulated perturbation vocabulary to initialize the perturbations
better and use a token-level normalization ball to constrain these
perturbations pertinently. Experiments show that our method improves the
performance of pre-trained models such as BERT and ALBERT in various tasks by a
considerable margin. The proposed method improves the score of the GLUE
benchmark from 78.3 to 80.9 using BERT model and it also enhances the
performance of sequence labeling and text classification tasks.",0,1,0,0,0,0,0.782563,6.0,0.802185,29
2bf6d829-f593-402f-8a8a-7fe3ee3c1f7d,Automated Measurements of Key Morphological Features of Human Embryos for IVF,19,0.176421,0.62351,"A major challenge in clinical In-Vitro Fertilization (IVF) is selecting the
highest quality embryo to transfer to the patient in the hopes of achieving a
pregnancy. Time-lapse microscopy provides clinicians with a wealth of
information for selecting embryos. However, the resulting movies of embryos are
currently analyzed manually, which is time consuming and subjective. Here, we
automate feature extraction of time-lapse microscopy of human embryos with a
machine-learning pipeline of five convolutional neural networks (CNNs). Our
pipeline consists of (1) semantic segmentation of the regions of the embryo,
(2) regression predictions of fragment severity, (3) classification of the
developmental stage, and object instance segmentation of (4) cells and (5)
pronuclei. Our approach greatly speeds up the measurement of quantitative,
biologically relevant features that may aid in embryo selection.",0,1,0,0,0,0,0.239972,10.0,0.709739,35
bd652628-f907-49ea-a69c-7ff4e7445047,I'm Sorry for Your Loss: Spectrally-Based Audio Distances Are Bad at Pitch,27,0.422114,0.440072,"Growing research demonstrates that synthetic failure modes imply poor
generalization. We compare commonly used audio-to-audio losses on a synthetic
benchmark, measuring the pitch distance between two stationary sinusoids. The
results are surprising: many have poor sense of pitch direction. These
shortcomings are exposed using simple rank assumptions. Our task is trivial for
humans but difficult for these audio distances, suggesting significant progress
can be made in self-supervised audio learning by improving current losses.",0,0,0,0,0,0,0.891843,6.0,0.864991,76
3c76dd69-4bd3-4064-9822-9c75b70e186b,From Data to Actions in Intelligent Transportation Systems: a Prescription of Functional Requirements for Model Actionability,34,0.233672,0.738571,"Advances in Data Science permeate every field of Transportation Science and
Engineering, resulting in developments in the transportation sector that {are}
data-driven. Nowadays, Intelligent Transportation Systems (ITS) could be
arguably approached as a ``story'' intensively producing and consuming large
amounts of data. A~diversity of sensing devices densely spread over the
infrastructure, vehicles or the travelers' personal devices act as sources of
data flows that are eventually fed {into} software running on automatic
devices, actuators or control systems producing, in~turn, complex information
flows {among} users, traffic managers, data analysts, traffic modeling
scientists, etc. These~information flows provide enormous opportunities to
improve model development and decision-making. This work aims to describe how
data, coming from diverse ITS sources, can be used to learn and adapt
data-driven models for efficiently operating ITS assets, systems and processes;
in~other words, for data-based models to fully become \emph{actionable}.
Grounded in this described data modeling pipeline for ITS, we~define the
characteristics, engineering requisites and challenges intrinsic to its three
compounding stages, namely, data fusion, adaptive learning and model
evaluation. We~deliberately generalize model learning to be adaptive, since,
in~the core of our paper is the firm conviction that most learners will have to
adapt to the ever-changing phenomenon scenario underlying the majority of ITS
applications. Finally, we~provide a prospect of current research lines within
Data Science that can bring notable advances to data-based ITS modeling, which
will eventually bridge the gap towards the practicality and actionability of
such models.",0,0,0,0,0,0,0.0601857,10.0,0.561112,234
c83c12e1-1786-4c42-aabe-91f03b0a00e6,Forensic Scanner Identification Using Machine Learning,7,0.184159,0.271064,"Due to the increasing availability and functionality of image editing tools,
many forensic techniques such as digital image authentication, source
identification and tamper detection are important for forensic image analysis.
In this paper, we describe a machine learning based system to address the
forensic analysis of scanner devices. The proposed system uses deep-learning to
automatically learn the intrinsic features from various scanned images. Our
experimental results show that high accuracy can be achieved for source scanner
identification. The proposed system can also generate a reliability map that
indicates the manipulated regions in an scanned image.",0,1,0,0,0,0,0.846931,22.0,0.955462,20
3afce73a-acfc-4195-9f92-c27dee2734c2,Discovering Pattern Structure Using Differentiable Compositing,25,0.2013,0.422503,"Patterns, which are collections of elements arranged in regular or
near-regular arrangements, are an important graphic art form and widely used
due to their elegant simplicity and aesthetic appeal. When a pattern is encoded
as a flat image without the underlying structure, manually editing the pattern
is tedious and challenging as one has to both preserve the individual element
shapes and their original relative arrangements. State-of-the-art deep learning
frameworks that operate at the pixel level are unsuitable for manipulating such
patterns. Specifically, these methods can easily disturb the shapes of the
individual elements or their arrangement, and thus fail to preserve the latent
structures of the input patterns. We present a novel differentiable compositing
operator using pattern elements and use it to discover structures, in the form
of a layered representation of graphical objects, directly from raw pattern
images. This operator allows us to adapt current deep learning based image
methods to effectively handle patterns. We evaluate our method on a range of
patterns and demonstrate superiority in the context of pattern manipulations
when compared against state-of-the-art",0,1,0,0,0,0,0.271208,10.0,0.723971,69
5dfaad35-6138-402d-a023-f76325c8b672,Analysis of Bayesian Networks via Prob-Solvable Loops,12,0.0287358,0.284374,"Prob-solvable loops are probabilistic programs with polynomial assignments
over random variables and parametrised distributions, for which the full
automation of moment-based invariant generation is decidable. In this paper we
extend Prob-solvable loops with new features essential for encoding Bayesian
networks (BNs). We show that various BNs, such as discrete, Gaussian,
conditional linear Gaussian and dynamic BNs, can be naturally encoded as
Prob-solvable loops. Thanks to these encodings, we can automatically solve
several BN related problems, including exact inference, sensitivity analysis,
filtering and computing the expected number of rejecting samples in
sampling-based procedures. We evaluate our work on a number of BN benchmarks,
using automated invariant generation within Prob-solvable loop analysis.",0,0,0,0,0,0,7.35542e-05,21.0,0.470148,47
6d849d87-82be-41a4-af15-0137cd2f463e,On Learning Text Style Transfer with Direct Rewards,38,0.430842,0.444886,"In most cases, the lack of parallel corpora makes it impossible to directly
train supervised models for the text style transfer task. In this paper, we
explore training algorithms that instead optimize reward functions that
explicitly consider different aspects of the style-transferred outputs. In
particular, we leverage semantic similarity metrics originally used for
fine-tuning neural machine translation models to explicitly assess the
preservation of content between system outputs and input texts. We also
investigate the potential weaknesses of the existing automatic metrics and
propose efficient strategies of using these metrics for training. The
experimental results show that our model provides significant gains in both
automatic and human evaluation over strong baselines, indicating the
effectiveness of our proposed methods and training strategies.",1,0,0,0,0,0,0.909346,5.0,0.853265,45
50c741f4-c0e3-4f3f-88af-e531eb8502aa,Towards an Argument Mining Pipeline Transforming Texts to Argument Graphs,19,0.334101,0.365927,"This paper targets the automated extraction of components of argumentative
information and their relations from natural language text. Moreover, we
address a current lack of systems to provide complete argumentative structure
from arbitrary natural language text for general usage. We present an argument
mining pipeline as a universally applicable approach for transforming German
and English language texts to graph-based argument representations. We also
introduce new methods for evaluating the results based on existing benchmark
argument structures. Our results show that the generated argument graphs can be
beneficial to detect new connections between different statements of an
argumentative text. Our pipeline implementation is publicly available on
GitHub.",1,0,0,1,0,0,0.549223,9.0,0.795932,28
37fb4fe3-eabc-43fb-bb93-6098f998747e,Relevance Transformer: Generating Concise Code Snippets with Relevance Feedback,11,0.0276489,0.18938,"Tools capable of automatic code generation have the potential to augment
programmer's capabilities. While straightforward code retrieval is incorporated
into many IDEs, an emerging area is explicit code generation. Code generation
is currently approached as a Machine Translation task, with Recurrent Neural
Network (RNN) based encoder-decoder architectures trained on code-description
pairs. In this work we introduce and study modern Transformer architectures for
this task. We further propose a new model called the Relevance Transformer that
incorporates external knowledge using pseudo-relevance feedback. The Relevance
Transformer biases the decoding process to be similar to existing retrieved
code while enforcing diversity. We perform experiments on multiple standard
benchmark datasets for code generation including Django, Hearthstone, and
CoNaLa. The results show improvements over state-of-the-art methods based on
BLEU evaluation. The Relevance Transformer model shows the potential of
Transformer-based architectures for code generation and introduces a method of
incorporating pseudo-relevance feedback during inference.",0,1,0,0,1,0,0.0664776,10.0,0.571387,19
667e1166-4186-4e59-bb7c-4a588b3c75c3,Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning,118,0.281708,0.716815,"Learning a good representation is an essential component for deep
reinforcement learning (RL). Representation learning is especially important in
multitask and partially observable settings where building a representation of
the unknown environment is crucial to solve the tasks. Here we introduce
Prediction of Bootstrap Latents (PBL), a simple and flexible self-supervised
representation learning algorithm for multitask deep RL. PBL builds on
multistep predictive representations of future observations, and focuses on
capturing structured information about environment dynamics. Specifically, PBL
trains its representation by predicting latent embeddings of future
observations. These latent embeddings are themselves trained to be predictive
of the aforementioned representations. These predictions form a bootstrapping
effect, allowing the agent to learn more about the key aspects of the
environment dynamics. In addition, by defining prediction tasks completely in
latent space, PBL provides the flexibility of using multimodal observations
involving pixel images, language instructions, rewards and more. We show in our
experiments that PBL delivers across-the-board improved performance over state
of the art deep RL agents in the DMLab-30 and Atari-57 multitask setting.",1,1,0,0,1,0,0.606288,6.0,0.720047,53
85d1b937-0749-4440-a950-9a3f417ea08f,Action2Motion: Conditioned Generation of 3D Human Motions,262,0.991055,1.0,"Action recognition is a relatively established task, where givenan input
sequence of human motion, the goal is to predict its ac-tion category. This
paper, on the other hand, considers a relativelynew problem, which could be
thought of as an inverse of actionrecognition: given a prescribed action type,
we aim to generateplausible human motion sequences in 3D. Importantly, the set
ofgenerated motions are expected to maintain itsdiversityto be ableto explore
the entire action-conditioned motion space; meanwhile,each sampled sequence
faithfully resembles anaturalhuman bodyarticulation dynamics. Motivated by
these objectives, we followthe physics law of human kinematics by adopting the
Lie Algebratheory to represent thenaturalhuman motions; we also propose
atemporal Variational Auto-Encoder (VAE) that encourages adiversesampling of
the motion space. A new 3D human motion dataset, HumanAct12, is also
constructed. Empirical experiments overthree distinct human motion datasets
(including ours) demonstratethe effectiveness of our approach.",0,0,0,1,0,0,0.895205,6.0,0.867341,38
e086f58f-121d-4b73-b066-b2a22fd82aaa,"Unified Models of Human Behavioral Agents in Bandits, Contextual Bandits and RL",24,0.204336,0.574901,"Artificial behavioral agents are often evaluated based on their consistent
behaviors and performance to take sequential actions in an environment to
maximize some notion of cumulative reward. However, human decision making in
real life usually involves different strategies and behavioral trajectories
that lead to the same empirical outcome. Motivated by clinical literature of a
wide range of neurological and psychiatric disorders, we propose here a more
general and flexible parametric framework for sequential decision making that
involves a two-stream reward processing mechanism. We demonstrated that this
framework is flexible and unified enough to incorporate a family of problems
spanning multi-armed bandits (MAB), contextual bandits (CB) and reinforcement
learning (RL), which decompose the sequential decision making process in
different levels. Inspired by the known reward processing abnormalities of many
mental disorders, our clinically-inspired agents demonstrated interesting
behavioral trajectories and comparable performance on simulated tasks with
particular reward distributions, a real-world dataset capturing human
decision-making in gambling tasks, and the PacMan game across different reward
stationarities in a lifelong learning setting.",1,0,0,0,0,0,0.015545,19.0,0.696546,48
fc0d7e03-2c21-4d47-9ebc-7ee38d673f3b,Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective Learning,17,0.399434,0.617107,"Human society had a long history of suffering from cognitive biases leading
to social prejudices and mass injustice. The prevalent existence of cognitive
biases in large volumes of historical data can pose a threat of being
manifested as unethical and seemingly inhuman predictions as outputs of AI
systems trained on such data. To alleviate this problem, we propose a
bias-aware multi-objective learning framework that given a set of identity
attributes (e.g. gender, ethnicity etc.) and a subset of sensitive categories
of the possible classes of prediction outputs, learns to reduce the frequency
of predicting certain combinations of them, e.g. predicting stereotypes such as
`most blacks use abusive language', or `fear is a virtue of women'. Our
experiments conducted on an emotion prediction task with balanced class priors
shows that a set of baseline bias-agnostic models exhibit cognitive biases with
respect to gender, such as women are prone to be afraid whereas men are more
prone to be angry. In contrast, our proposed bias-aware multi-objective
learning methodology is shown to reduce such biases in the predictied emotions.",0,0,0,0,0,0,0.985391,3.0,0.943947,32
ee59fc2e-722c-4142-83f5-2ad1e2e97662,Attribute Adaptive Margin Softmax Loss using Privileged Information,5,0.228939,0.565402,"We present a novel framework to exploit privileged information for
recognition which is provided only during the training phase. Here, we focus on
recognition task where images are provided as the main view and soft biometric
traits (attributes) are provided as the privileged data (only available during
training phase). We demonstrate that more discriminative feature space can be
learned by enforcing a deep network to adjust adaptive margins between classes
utilizing attributes. This tight constraint also effectively reduces the class
imbalance inherent in the local data neighborhood, thus carving more balanced
class boundaries locally and using feature space more efficiently. Extensive
experiments are performed on five different datasets and the results show the
superiority of our method compared to the state-of-the-art models in both tasks
of face recognition and person re-identification.",0,1,0,0,1,0,0.991389,9.0,0.994411,37
6fb1f164-0f01-4435-b4eb-60cd7f267fe3,Circumventing Outliers of AutoAugment with Knowledge Distillation,53,0.141869,0.384668,"AutoAugment has been a powerful algorithm that improves the accuracy of many
vision tasks, yet it is sensitive to the operator space as well as
hyper-parameters, and an improper setting may degenerate network optimization.
This paper delves deep into the working mechanism, and reveals that AutoAugment
may remove part of discriminative information from the training image and so
insisting on the ground-truth label is no longer the best option. To relieve
the inaccuracy of supervision, we make use of knowledge distillation that
refers to the output of a teacher model to guide network training. Experiments
are performed in standard image classification benchmarks, and demonstrate the
effectiveness of our approach in suppressing noise of data augmentation and
stabilizing training. Upon the cooperation of knowledge distillation and
AutoAugment, we claim the new state-of-the-art on ImageNet classification with
a top-1 accuracy of 85.8%.",0,1,0,0,1,1,0.874988,6.0,0.853769,60
34f5ee7d-b69b-4ac8-9c05-042cd3f4f850,Robust Tracking against Adversarial Attacks,37,0.178965,0.715763,"While deep convolutional neural networks (CNNs) are vulnerable to adversarial
attacks, considerably few efforts have been paid to construct robust deep
tracking algorithms against adversarial attacks. Current studies on adversarial
attack and defense mainly reside in a single image. In this work, we first
attempt to generate adversarial examples on top of video sequences to improve
the tracking robustness against adversarial attacks. To this end, we take
temporal motion into consideration when generating lightweight perturbations
over the estimated tracking results frame-by-frame. On one hand, we add the
temporal perturbations into the original video sequences as adversarial
examples to greatly degrade the tracking performance. On the other hand, we
sequentially estimate the perturbations from input sequences and learn to
eliminate their effect for performance restoration. We apply the proposed
adversarial attack and defense approaches to state-of-the-art deep tracking
algorithms. Extensive evaluations on the benchmark datasets demonstrate that
our defense method not only eliminates the large performance drops caused by
adversarial attacks, but also achieves additional performance gains when deep
trackers are not under adversarial attacks.",1,1,0,0,0,0,0.910856,6.0,0.878883,48
5f4f137e-8da8-4343-8cc8-1e660692013a,On the Sparsity of Neural Machine Translation Models,11,0.0269445,0.349342,"Modern neural machine translation (NMT) models employ a large number of
parameters, which leads to serious over-parameterization and typically causes
the underutilization of computational resources. In response to this problem,
we empirically investigate whether the redundant parameters can be reused to
achieve better performance. Experiments and analyses are systematically
conducted on different datasets and NMT architectures. We show that: 1) the
pruned parameters can be rejuvenated to improve the baseline model by up to
+0.8 BLEU points; 2) the rejuvenated parameters are reallocated to enhance the
ability of modeling low-level lexical information.",0,1,0,0,0,0,0.294097,7.0,0.619401,29
2dc6d2ea-9115-41c9-a3f0-fa659db0d2a3,An Explainable Machine Learning Model for Early Detection of Parkinson's Disease using LIME on DaTscan Imagery,134,0.246347,0.771375,"Parkinson's disease (PD) is a degenerative and progressive neurological
condition. Early diagnosis can improve treatment for patients and is performed
through dopaminergic imaging techniques like the SPECT DaTscan. In this study,
we propose a machine learning model that accurately classifies any given
DaTscan as having Parkinson's disease or not, in addition to providing a
plausible reason for the prediction. This is kind of reasoning is done through
the use of visual indicators generated using Local Interpretable Model-Agnostic
Explainer (LIME) methods. DaTscans were drawn from the Parkinson's Progression
Markers Initiative database and trained on a CNN (VGG16) using transfer
learning, yielding an accuracy of 95.2%, a sensitivity of 97.5%, and a
specificity of 90.9%. Keeping model interpretability of paramount importance,
especially in the healthcare field, this study utilises LIME explanations to
distinguish PD from non-PD, using visual superpixels on the DaTscans. It could
be concluded that the proposed system, in union with its measured
interpretability and accuracy may effectively aid medical workers in the early
diagnosis of Parkinson's Disease.",0,1,0,0,1,0,0.196982,7.0,0.553372,36
4127f8ee-d74f-4aba-992e-44115ea061d9,Training Keyword Spotting Models on Non-IID Data with Federated Learning,59,0.249901,0.522181,"We demonstrate that a production-quality keyword-spotting model can be
trained on-device using federated learning and achieve comparable false accept
and false reject rates to a centrally-trained model. To overcome the
algorithmic constraints associated with fitting on-device data (which are
inherently non-independent and identically distributed), we conduct thorough
empirical studies of optimization algorithms and hyperparameter configurations
using large-scale federated simulations. To overcome resource constraints, we
replace memory intensive MTR data augmentation with SpecAugment, which reduces
the false reject rate by 56%. Finally, to label examples (given the zero
visibility into on-device data), we explore teacher-student training.",0,1,0,0,0,0,0.81732,4.0,0.7303,44
bfd01842-93ee-4891-a1ab-05c42b37bc8c,Few-Shot Named Entity Recognition: A Comprehensive Study,74,0.991026,0.914388,"This paper presents a comprehensive study to efficiently build named entity
recognition (NER) systems when a small number of in-domain labeled data is
available. Based upon recent Transformer-based self-supervised pre-trained
language models (PLMs), we investigate three orthogonal schemes to improve the
model generalization ability for few-shot settings: (1) meta-learning to
construct prototypes for different entity types, (2) supervised pre-training on
noisy web data to extract entity-related generic representations and (3)
self-training to leverage unlabeled in-domain data. Different combinations of
these schemes are also considered. We perform extensive empirical comparisons
on 10 public NER datasets with various proportions of labeled data, suggesting
useful insights for future research. Our experiments show that (i) in the
few-shot learning setting, the proposed NER schemes significantly improve or
outperform the commonly used baseline, a PLM-based linear classifier fine-tuned
on domain labels; (ii) We create new state-of-the-art results on both few-shot
and training-free settings compared with existing methods. We will release our
code and pre-trained models for reproducible research.",0,1,0,0,1,0,0.987525,5.0,0.973704,69
cdec038b-3491-42e1-a4db-be4df90c7356,An anytime tree search algorithm for the 2018 ROADEF/EURO challenge glass cutting problem,20,0.0525744,0.732202,"In this article, we present the anytime tree search algorithm we designed for
the 2018 ROADEF/EURO challenge glass cutting problem proposed by the French
company Saint-Gobain. The resulting program was ranked first among 64
participants. Its key components are: a new search algorithm called Memory
Bounded A* (MBA*) with guide functions, a symmetry breaking strategy, and a
pseudo-dominance rule. We perform a comprehensive study of these components
showing that each of them contributes to the algorithm global performances. In
addition, we designed a second tree search algorithm fully based on the
pseudo-dominance rule and dedicated to some of the challenge instances with
strong precedence constraints. On these instances, it finds the best-known
solutions very quickly.",0,1,0,0,0,0,1.29799e-05,15.0,0.142564,42
cffc9676-04c2-4cdf-9753-eed07d800782,Augmenting BERT Carefully with Underrepresented Linguistic Features,2,0.0521459,0.0512443,"Fine-tuned Bidirectional Encoder Representations from Transformers
(BERT)-based sequence classification models have proven to be effective for
detecting Alzheimer's Disease (AD) from transcripts of human speech. However,
previous research shows it is possible to improve BERT's performance on various
tasks by augmenting the model with additional information. In this work, we use
probing tasks as introspection techniques to identify linguistic information
not well-represented in various layers of BERT, but important for the AD
detection task. We supplement these linguistic features in which
representations from BERT are found to be insufficient with hand-crafted
features externally, and show that jointly fine-tuning BERT in combination with
these features improves the performance of AD classification by upto 5\% over
fine-tuned BERT alone.",0,1,0,0,0,0,0.890493,5.0,0.83687,21
1fdf9f96-91a3-40b7-8fa6-93288076e47f,Neural Topic Modeling with Bidirectional Adversarial Training,72,0.361736,0.67637,"Recent years have witnessed a surge of interests of using neural topic models
for automatic topic extraction from text, since they avoid the complicated
mathematical derivations for model inference as in traditional topic models
such as Latent Dirichlet Allocation (LDA). However, these models either
typically assume improper prior (e.g. Gaussian or Logistic Normal) over latent
topic space or could not infer topic distribution for a given document. To
address these limitations, we propose a neural topic modeling approach, called
Bidirectional Adversarial Topic (BAT) model, which represents the first attempt
of applying bidirectional adversarial training for neural topic modeling. The
proposed BAT builds a two-way projection between the document-topic
distribution and the document-word distribution. It uses a generator to capture
the semantic patterns from texts and an encoder for topic inference.
Furthermore, to incorporate word relatedness information, the Bidirectional
Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To
verify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are
used in our experiments. The experimental results show that BAT and
Gaussian-BAT obtain more coherent topics, outperforming several competitive
baselines. Moreover, when performing text clustering based on the extracted
topics, our models outperform all the baselines, with more significant
improvements achieved by Gaussian-BAT where an increase of near 6\% is observed
in accuracy.",0,0,0,0,0,0,0.776985,9.0,0.866264,35
8c943540-1f14-46bd-8d34-3a54427fd561,Remarks on Optimal Scores for Speaker Recognition,8,0.0377316,0.20812,"In this article, we first establish the theory of optimal scores for speaker
recognition. Our analysis shows that the minimum Bayes risk (MBR) decisions for
both the speaker identification and speaker verification tasks can be based on
a normalized likelihood (NL). When the underlying generative model is a linear
Gaussian, the NL score is mathematically equivalent to the PLDA likelihood
ratio, and the empirical scores based on cosine distance and Euclidean distance
can be seen as approximations of this linear Gaussian NL score under some
conditions. We discuss a number of properties of the NL score and perform a
simple simulation experiment to demonstrate the properties of the NL score.",0,0,0,0,0,0,0.0543936,11.0,0.591535,34
8244be31-1168-4dc4-9676-a2185f4fe548,CryptoGRU: Low Latency Privacy-Preserving Text Analysis With GRU,12,0.120118,0.503716,"Billions of text analysis requests containing private emails, personal text
messages, and sensitive online reviews, are processed by recurrent neural
networks (RNNs) deployed on public clouds every day. Although prior secure
networks combine homomorphic encryption (HE) and garbled circuit (GC) to
preserve users' privacy, naively adopting the HE and GC hybrid technique to
implement RNNs suffers from long inference latency due to slow activation
functions. In this paper, we present a HE and GC hybrid gated recurrent unit
(GRU) network, CryptoGRU, for low-latency secure inferences. CryptoGRU replaces
computationally expensive GC-based $tanh$ with fast GC-based $ReLU$, and then
quantizes $sigmoid$ and $ReLU$ with a smaller bit length to accelerate
activations in a GRU. We evaluate CryptoGRU with multiple GRU models trained on
4 public datasets. Experimental results show CryptoGRU achieves top-notch
accuracy and improves the secure inference latency by up to $138\times$ over
one of state-of-the-art secure networks on the Penn Treebank dataset.",1,1,0,0,1,0,0.743536,9.0,0.855401,25
a25de796-80d3-4a53-8541-dec129ed067c,Does syntax need to grow on trees? Sources of hierarchical inductive bias in sequence-to-sequence networks,87,0.0873274,0.611458,"Learners that are exposed to the same training data might generalize
differently due to differing inductive biases. In neural network models,
inductive biases could in theory arise from any aspect of the model
architecture. We investigate which architectural factors affect the
generalization behavior of neural sequence-to-sequence models trained on two
syntactic tasks, English question formation and English tense reinflection. For
both tasks, the training set is consistent with a generalization based on
hierarchical structure and a generalization based on linear order. All
architectural factors that we investigated qualitatively affected how models
generalized, including factors with no clear connection to hierarchical
structure. For example, LSTMs and GRUs displayed qualitatively different
inductive biases. However, the only factor that consistently contributed a
hierarchical bias across tasks was the use of a tree-structured model rather
than a model with sequential recurrence, suggesting that human-like syntactic
generalization requires architectural syntactic structure.",1,0,0,0,0,0,0.000462729,16.0,0.419527,55
a73ea912-abe7-4609-a4e8-c532d07d99b1,Sequence-Level Mixed Sample Data Augmentation,82,0.210784,0.648983,"Despite their empirical success, neural networks still have difficulty
capturing compositional aspects of natural language. This work proposes a
simple data augmentation approach to encourage compositional behavior in neural
models for sequence-to-sequence problems. Our approach, SeqMix, creates new
synthetic examples by softly combining input/output sequences from the training
set. We connect this approach to existing techniques such as SwitchOut and word
dropout, and show that these techniques are all approximating variants of a
single objective. SeqMix consistently yields approximately 1.0 BLEU improvement
on five different translation datasets over strong Transformer baselines. On
tasks that require strong compositional generalization such as SCAN and
semantic parsing, SeqMix also offers further improvements.",1,1,0,0,0,1,0.443612,7.0,0.693803,22
04382217-996c-4d3f-9421-e06e270355cf,Don't Neglect the Obvious: On the Role of Unambiguous Words in Word Sense Disambiguation,11,0.0974426,0.669189,"State-of-the-art methods for Word Sense Disambiguation (WSD) combine two
different features: the power of pre-trained language models and a propagation
method to extend the coverage of such models. This propagation is needed as
current sense-annotated corpora lack coverage of many instances in the
underlying sense inventory (usually WordNet). At the same time, unambiguous
words make for a large portion of all words in WordNet, while being poorly
covered in existing sense-annotated corpora. In this paper, we propose a simple
method to provide annotations for most unambiguous words in a large corpus. We
introduce the UWA (Unambiguous Word Annotations) dataset and show how a
state-of-the-art propagation-based model can use it to extend the coverage and
quality of its word sense embeddings by a significant margin, improving on its
original results on WSD.",0,1,0,1,0,0,0.423958,7.0,0.685083,33
8e1db7ff-6d22-4ff4-8a61-9a1d16f2b444,Altruist: Argumentative Explanations through Local Interpretations of Predictive Models,9,0.0817951,0.247979,"Explainable AI is an emerging field providing solutions for acquiring
insights into automated systems' rationale. It has been put on the AI map by
suggesting ways to tackle key ethical and societal issues. Existing explanation
techniques are often not comprehensible to the end user. Lack of evaluation and
selection criteria also makes it difficult for the end user to choose the most
suitable technique. In this study, we combine logic-based argumentation with
Interpretable Machine Learning, introducing a preliminary meta-explanation
methodology that identifies the truthful parts of feature importance oriented
interpretations. This approach, in addition to being used as a meta-explanation
technique, can be used as an evaluation or selection tool for multiple feature
importance techniques. Experimentation strongly indicates that an ensemble of
multiple interpretation techniques yields considerably more truthful
explanations.",1,0,0,0,0,0,0.16809,9.0,0.633101,47
b3b393d6-5f16-4d79-a06d-f3fd3730cf13,Cross-Spectral Periocular Recognition with Conditional Adversarial Networks,10,0.459935,0.47334,"This work addresses the challenge of comparing periocular images captured in
different spectra, which is known to produce significant drops in performance
in comparison to operating in the same spectrum. We propose the use of
Conditional Generative Adversarial Networks, trained to con-vert periocular
images between visible and near-infrared spectra, so that biometric
verification is carried out in the same spectrum. The proposed setup allows the
use of existing feature methods typically optimized to operate in a single
spectrum. Recognition experiments are done using a number of off-the-shelf
periocular comparators based both on hand-crafted features and CNN descriptors.
Using the Hong Kong Polytechnic University Cross-Spectral Iris Images Database
(PolyU) as benchmark dataset, our experiments show that cross-spectral
performance is substantially improved if both images are converted to the same
spectrum, in comparison to matching features extracted from images in different
spectra. In addition to this, we fine-tune a CNN based on the ResNet50
architecture, obtaining a cross-spectral periocular performance of EER=1%, and
GAR>99% @ FAR=1%, which is comparable to the state-of-the-art with the PolyU
database.",1,1,0,0,1,0,0.906846,9.0,0.917214,34
cf6a03d1-972c-4752-b95b-8389bccdda13,Simultaneously Learning Corrections and Error Models for Geometry-based Visual Odometry Methods,8,0.070393,0.322954,"This paper fosters the idea that deep learning methods can be used to
complement classical visual odometry pipelines to improve their accuracy and to
associate uncertainty models to their estimations. We show that the biases
inherent to the visual odometry process can be faithfully learned and
compensated for, and that a learning architecture associated with a
probabilistic loss function can jointly estimate a full covariance matrix of
the residual errors, defining an error model capturing the heteroscedasticity
of the process. Experiments on autonomous driving image sequences assess the
possibility to concurrently improve visual odometry and estimate an error
associated with its outputs.",0,1,0,0,0,0,0.518883,9.0,0.786456,19
b24b599e-d319-4b1e-bd19-3d6bbc9ced71,Learning Motion Flows for Semi-supervised Instrument Segmentation from Robotic Surgical Video,30,0.108425,0.463466,"Performing low hertz labeling for surgical videos at intervals can greatly
releases the burden of surgeons. In this paper, we study the semi-supervised
instrument segmentation from robotic surgical videos with sparse annotations.
Unlike most previous methods using unlabeled frames individually, we propose a
dual motion based method to wisely learn motion flows for segmentation
enhancement by leveraging temporal dynamics. We firstly design a flow predictor
to derive the motion for jointly propagating the frame-label pairs given the
current labeled frame. Considering the fast instrument motion, we further
introduce a flow compensator to estimate intermediate motion within continuous
frames, with a novel cycle learning strategy. By exploiting generated data
pairs, our framework can recover and even enhance temporal consistency of
training sequences to benefit segmentation. We validate our framework with
binary, part, and type tasks on 2017 MICCAI EndoVis Robotic Instrument
Segmentation Challenge dataset. Results show that our method outperforms the
state-of-the-art semi-supervised methods by a large margin, and even exceeds
fully supervised training on two tasks.",1,1,0,0,1,0,0.384068,5.0,0.533234,27
e41f0060-ae27-4e2a-a060-0439017f225c,The Frankfurt Latin Lexicon: From Morphological Expansion and Word Embeddings to SemioGraphs,5,0.538576,0.441679,"In this article we present the Frankfurt Latin Lexicon (FLL), a lexical
resource for Medieval Latin that is used both for the lemmatization of Latin
texts and for the post-editing of lemmatizations. We describe recent advances
in the development of lemmatizers and test them against the Capitularies corpus
(comprising Frankish royal edicts, mid-6th to mid-9th century), a corpus
created as a reference for processing Medieval Latin. We also consider the
post-correction of lemmatizations using a limited crowdsourcing process aimed
at continuous review and updating of the FLL. Starting from the texts resulting
from this lemmatization process, we describe the extension of the FLL by means
of word embeddings, whose interactive traversing by means of SemioGraphs
completes the digital enhanced hermeneutic circle. In this way, the article
argues for a more comprehensive understanding of lemmatization, encompassing
classical machine learning as well as intellectual post-corrections and, in
particular, human computation in the form of interpretation processes based on
graph representations of the underlying lexical resources.",0,0,0,0,0,0,0.89253,9.0,0.910312,61
cd4ecd63-a6e3-426a-9a05-beeed60b67a2,Fashion-IQ 2020 Challenge 2nd Place Team's Solution,7,0.0616175,0.237346,"This paper is dedicated to team VAA's approach submitted to the Fashion-IQ
challenge in CVPR 2020. Given a pair of the image and the text, we present a
novel multimodal composition method, RTIC, that can effectively combine the
text and the image modalities into a semantic space. We extract the image and
the text features that are encoded by the CNNs and the sequential models (e.g.,
LSTM or GRU), respectively. To emphasize the meaning of the residual of the
feature between the target and candidate, the RTIC is composed of N-blocks with
channel-wise attention modules. Then, we add the encoded residual to the
feature of the candidate image to obtain a synthesized feature. We also
explored an ensemble strategy with variants of models and achieved a
significant boost in performance comparing to the best single model. Finally,
our approach achieved 2nd place in the Fashion-IQ 2020 Challenge with a test
score of 48.02 on the leaderboard.",0,1,0,0,0,0,0.938007,7.0,0.916182,25
8cbabae7-1040-41ef-be7e-1b55f3177797,CD-UAP: Class Discriminative Universal Adversarial Perturbation,55,0.269122,0.710065,"A single universal adversarial perturbation (UAP) can be added to all natural
images to change most of their predicted class labels. It is of high practical
relevance for an attacker to have flexible control over the targeted classes to
be attacked, however, the existing UAP method attacks samples from all classes.
In this work, we propose a new universal attack method to generate a single
perturbation that fools a target network to misclassify only a chosen group of
classes, while having limited influence on the remaining classes. Since the
proposed attack generates a universal adversarial perturbation that is
discriminative to targeted and non-targeted classes, we term it class
discriminative universal adversarial perturbation (CD-UAP). We propose one
simple yet effective algorithm framework, under which we design and compare
various loss function configurations tailored for the class discriminative
universal attack. The proposed approach has been evaluated with extensive
experiments on various benchmark datasets. Additionally, our proposed approach
achieves state-of-the-art performance for the original task of UAP attacking
all classes, which demonstrates the effectiveness of our approach.",0,1,1,0,1,0,0.872232,6.0,0.852012,30
05e2bbff-5bb7-4b19-9595-76501a643009,IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding,212,0.73238,0.992581,"Although Indonesian is known to be the fourth most frequently used language
over the internet, the research progress on this language in the natural
language processing (NLP) is slow-moving due to a lack of available resources.
In response, we introduce the first-ever vast resource for the training,
evaluating, and benchmarking on Indonesian natural language understanding
(IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence
classification to pair-sentences sequence labeling with different levels of
complexity. The datasets for the tasks lie in different domains and styles to
ensure task diversity. We also provide a set of Indonesian pre-trained models
(IndoBERT) trained from a large and clean Indonesian dataset Indo4B collected
from publicly available sources such as social media texts, blogs, news, and
websites. We release baseline models for all twelve tasks, as well as the
framework for benchmark evaluation, and thus it enables everyone to benchmark
their system performances.",0,1,1,1,1,0,0.607656,4.0,0.581003,39
74281182-553a-4ec4-a794-f3d143f3e23d,Measuring and Harnessing Transference in Multi-Task Learning,13,0.0292439,0.15222,"Multi-task learning can leverage information learned by one task to benefit
the training of other tasks. Despite this capacity, naive formulations often
degrade performance and in particular, identifying the tasks that would benefit
from co-training remains a challenging design question. In this paper, we
analyze the dynamics of information transfer, or transference, across tasks
throughout training. Specifically, we develop a similarity measure that can
quantify transference among tasks and use this quantity to both better
understand the optimization dynamics of multi-task learning as well as improve
overall learning performance. In the latter case, we propose two methods to
leverage our transference metric. The first operates at a macro-level by
selecting which tasks should train together while the second functions at a
micro-level by determining how to combine task gradients at each training step.
We find these methods can lead to significant improvement over prior work on
three supervised multi-task learning benchmarks and one multi-task
reinforcement learning paradigm.",0,0,0,0,0,0,0.514902,6.0,0.677796,62
236f8803-0a8b-4820-b5f1-1039e20f6086,Compositionality and Generalization in Emergent Languages,110,0.820262,0.329889,"Natural language allows us to refer to novel composite concepts by combining
expressions denoting their parts according to systematic rules, a property
known as \emph{compositionality}. In this paper, we study whether the language
emerging in deep multi-agent simulations possesses a similar ability to refer
to novel primitive combinations, and whether it accomplishes this feat by
strategies akin to human-language compositionality. Equipped with new ways to
measure compositionality in emergent languages inspired by disentanglement in
representation learning, we establish three main results. First, given
sufficiently large input spaces, the emergent language will naturally develop
the ability to refer to novel composite concepts. Second, there is no
correlation between the degree of compositionality of an emergent language and
its ability to generalize. Third, while compositionality is not necessary for
generalization, it provides an advantage in terms of language transmission: The
more compositional a language is, the more easily it will be picked up by new
learners, even when the latter differ in architecture from the original agents.
We conclude that compositionality does not arise from simple generalization
pressure, but if an emergent language does chance upon it, it will be more
likely to survive and thrive.",0,0,0,0,0,0,0.772957,5.0,0.756874,51
c66ec45d-bff4-4460-95be-34a6f172f3f0,A Summary of the First Workshop on Language Technology for Language Documentation and Revitalization,6,0.0163376,0.152436,"Despite recent advances in natural language processing and other language
technology, the application of such technology to language documentation and
conservation has been limited. In August 2019, a workshop was held at Carnegie
Mellon University in Pittsburgh to attempt to bring together language community
members, documentary linguists, and technologists to discuss how to bridge this
gap and create prototypes of novel and practical language revitalization
technologies. This paper reports the results of this workshop, including issues
discussed, and various conceived and implemented technologies for nine
languages: Arapaho, Cayuga, Inuktitut, Irish Gaelic, Kidaw'ida, Kwak'wala,
Ojibwe, San Juan Quiahije Chatino, and Seneca.",0,0,0,0,0,0,0.0117234,12.0,0.495857,56
019cb001-063c-4eec-b498-ca9c98f13b2e,Deflating Dataset Bias Using Synthetic Data Augmentation,45,0.660217,0.402041,"Deep Learning has seen an unprecedented increase in vision applications since
the publication of large-scale object recognition datasets and introduction of
scalable compute hardware. State-of-the-art methods for most vision tasks for
Autonomous Vehicles (AVs) rely on supervised learning and often fail to
generalize to domain shifts and/or outliers. Dataset diversity is thus key to
successful real-world deployment. No matter how big the size of the dataset,
capturing long tails of the distribution pertaining to task-specific
environmental factors is impractical. The goal of this paper is to investigate
the use of targeted synthetic data augmentation - combining the benefits of
gaming engine simulations and sim2real style transfer techniques - for filling
gaps in real datasets for vision tasks. Empirical studies on three different
computer vision tasks of practical use to AVs - parking slot detection, lane
detection and monocular depth estimation - consistently show that having
synthetic data in the training mix provides a significant boost in
cross-dataset generalization performance as compared to training on real data
only, for the same size of the training set.",0,1,0,0,0,0,0.986176,6.0,0.97414,47
5b891a7a-d81c-4580-a327-0a51502029d7,Multi-Domain Dialogue Acts and Response Co-Generation,54,0.736863,0.984547,"Generating fluent and informative responses is of critical importance for
task-oriented dialogue systems. Existing pipeline approaches generally predict
multiple dialogue acts first and use them to assist response generation. There
are at least two shortcomings with such approaches. First, the inherent
structures of multi-domain dialogue acts are neglected. Second, the semantic
associations between acts and responses are not taken into account for response
generation. To address these issues, we propose a neural co-generation model
that generates dialogue acts and responses concurrently. Unlike those pipeline
approaches, our act generation module preserves the semantic structures of
multi-domain dialogue acts and our response generation module dynamically
attends to different acts as needed. We train the two modules jointly using an
uncertainty loss to adjust their task weights adaptively. Extensive experiments
are conducted on the large-scale MultiWOZ dataset and the results show that our
model achieves very favorable improvement over several state-of-the-art models
in both automatic and human evaluations.",1,1,0,0,1,0,0.934931,6.0,0.899285,32
daf94391-693b-4f33-af0f-263defac65ca,Composed Variational Natural Language Generation for Few-shot Intents,31,0.158536,0.429035,"In this paper, we focus on generating training examples for few-shot intents
in the realistic imbalanced scenario. To build connections between existing
many-shot intents and few-shot intents, we consider an intent as a combination
of a domain and an action, and propose a composed variational natural language
generator (CLANG), a transformer-based conditional variational autoencoder.
CLANG utilizes two latent variables to represent the utterances corresponding
to two different independent parts (domain and action) in the intent, and the
latent variables are composed together to generate natural examples.
Additionally, to improve the generator learning, we adopt the contrastive
regularization loss that contrasts the in-class with the out-of-class utterance
generation given the intent. To evaluate the quality of the generated
utterances, experiments are conducted on the generalized few-shot intent
detection task. Empirical results show that our proposed model achieves
state-of-the-art performances on two real-world intent detection datasets.",0,1,0,0,1,0,0.725034,8.0,0.830758,36
09eb5aa1-4677-437d-a341-48775373a854,Measuring Happiness Around the World Through Artificial Intelligence,1,0.00893793,0.101103,"In this work, we analyze the happiness levels of countries using an unbiased
emotion detector, artificial intelligence (AI). To date, researchers proposed
many factors that may affect happiness such as wealth, health and safety. Even
though these factors all seem relevant, there is no clear consensus between
sociologists on how to interpret these, and the models to estimate the cost of
these utilities include some assumptions. Researchers in social sciences have
been working on determination of the happiness levels in society and
exploration of the factors correlated with it through polls and different
statistical methods. In our work, by using artificial intelligence, we
introduce a different and relatively unbiased approach to this problem. By
using AI, we make no assumption about what makes a person happy, and leave the
decision to AI to detect the emotions from the faces of people collected from
publicly available street footages. We analyzed the happiness levels in eight
different cities around the world through available footage on the Internet and
found out that there is no statistically significant difference between
countries in terms of happiness.",0,1,0,0,0,1,0.449272,23.0,0.907561,29
25e4f7e6-60df-4cb7-b6ed-1857ac7a1bc4,Learning from others' mistakes: Avoiding dataset biases without modeling them,94,0.126732,0.567241,"State-of-the-art natural language processing (NLP) models often learn to
model dataset biases and surface form correlations instead of features that
target the intended underlying task. Previous work has demonstrated effective
methods to circumvent these issues when knowledge of the bias is available. We
consider cases where the bias issues may not be explicitly identified, and show
a method for training models that learn to ignore these problematic
correlations. Our approach relies on the observation that models with limited
capacity primarily learn to exploit biases in the dataset. We can leverage the
errors of such limited capacity models to train a more robust model in a
product of experts, thus bypassing the need to hand-craft a biased model. We
show the effectiveness of this method to retain improvements in
out-of-distribution settings even if no particular bias is targeted by the
biased model.",0,0,0,0,0,1,0.405974,5.0,0.547647,58
0fa3378c-166f-4791-ace4-743893ea930f,COVID-19 Knowledge Graph: Accelerating Information Retrieval and Discovery for Scientific Literature,68,0.782939,0.822422,"The coronavirus disease (COVID-19) has claimed the lives of over 350,000
people and infected more than 6 million people worldwide. Several search
engines have surfaced to provide researchers with additional tools to find and
retrieve information from the rapidly growing corpora on COVID-19. These
engines lack extraction and visualization tools necessary to retrieve and
interpret complex relations inherent to scientific literature. Moreover,
because these engines mainly rely upon semantic information, their ability to
capture complex global relationships across documents is limited, which reduces
the quality of similarity-based article recommendations for users. In this
work, we present the COVID-19 Knowledge Graph (CKG), a heterogeneous graph for
extracting and visualizing complex relationships between COVID-19 scientific
articles. The CKG combines semantic information with document topological
information for the application of similar document retrieval. The CKG is
constructed using the latent schema of the data, and then enriched with
biomedical entity information extracted from the unstructured text of articles
using scalable AWS technologies to form relations in the graph. Finally, we
propose a document similarity engine that leverages low-dimensional graph
embeddings from the CKG with semantic embeddings for similar article retrieval.
Analysis demonstrates the quality of relationships in the CKG and shows that it
can be used to uncover meaningful information in COVID-19 scientific articles.
The CKG helps power www.cord19.aws and is publicly available.",0,1,0,0,0,0,0.950242,7.0,0.927053,30
3c1eb8b3-06a0-41e4-8cf7-ff7e827bca47,Prototype-based Incremental Few-Shot Semantic Segmentation,17,0.164695,0.338661,"Semantic segmentation models have two fundamental weaknesses: i) they require
large training sets with costly pixel-level annotations, and ii) they have a
static output space, constrained to the classes of the training set. Toward
addressing both problems, we introduce a new task, Incremental Few-Shot
Segmentation (iFSS). The goal of iFSS is to extend a pretrained segmentation
model with new classes from few annotated images and without access to old
training data. To overcome the limitations of existing models iniFSS, we
propose Prototype-based Incremental Few-Shot Segmentation (PIFS) that couples
prototype learning and knowledge distillation. PIFS exploits prototypes to
initialize the classifiers of new classes, fine-tuning the network to refine
its features representation. We design a prototype-based distillation loss on
the scores of both old and new class prototypes to avoid overfitting and
forgetting, and batch-renormalization to cope with non-i.i.d.few-shot data. We
create an extensive benchmark for iFSS showing that PIFS outperforms several
few-shot and incremental learning methods in all scenarios.",1,1,1,0,0,0,0.965561,6.0,0.934175,60
1224a5f3-b8ef-49ab-b5a5-b2d175e49be2,Meaningful Answer Generation of E-Commerce Question-Answering,31,0.378941,0.982855,"In e-commerce portals, generating answers for product-related questions has
become a crucial task. In this paper, we focus on the task of product-aware
answer generation, which learns to generate an accurate and complete answer
from large-scale unlabeled e-commerce reviews and product attributes. However,
safe answer problems pose significant challenges to text generation tasks, and
e-commerce question-answering task is no exception. To generate more meaningful
answers, in this paper, we propose a novel generative neural model, called the
Meaningful Product Answer Generator (MPAG), which alleviates the safe answer
problem by taking product reviews, product attributes, and a prototype answer
into consideration. Product reviews and product attributes are used to provide
meaningful content, while the prototype answer can yield a more diverse answer
pattern. To this end, we propose a novel answer generator with a review
reasoning module and a prototype answer reader. Our key idea is to obtain the
correct question-aware information from a large scale collection of reviews and
learn how to write a coherent and meaningful answer from an existing prototype
answer. To be more specific, we propose a read-and-write memory consisting of
selective writing units to conduct reasoning among these reviews. We then
employ a prototype reader consisting of comprehensive matching to extract the
answer skeleton from the prototype answer. Finally, we propose an answer editor
to generate the final answer by taking the question and the above parts as
input. Conducted on a real-world dataset collected from an e-commerce platform,
extensive experimental results show that our model achieves state-of-the-art
performance in terms of both automatic metrics and human evaluations. Human
evaluation also demonstrates that our model can consistently generate specific
and proper answers.",0,1,0,0,1,0,0.652163,6.0,0.740845,90
58bfe24f-01cb-4944-8fc1-3559df1f956b,Improving auto-encoder novelty detection using channel attention and entropy minimization,2,0.0112722,0.0270327,"Novelty detection is a important research area which mainly solves the
classification problem of inliers which usually consists of normal samples and
outliers composed of abnormal samples. Auto-encoder is often used for novelty
detection. However, the generalization ability of the auto-encoder may cause
the undesirable reconstruction of abnormal elements and reduce the
identification ability of the model. To solve the problem, we focus on the
perspective of better reconstructing the normal samples as well as retaining
the unique information of normal samples to improve the performance of
auto-encoder for novelty detection. Firstly, we introduce attention mechanism
into the task. Under the action of attention mechanism, auto-encoder can pay
more attention to the representation of inlier samples through adversarial
training. Secondly, we apply the information entropy into the latent layer to
make it sparse and constrain the expression of diversity. Experimental results
on three public datasets show that the proposed method achieves comparable
performance compared with previous popular approaches.",0,1,0,0,0,0,0.957367,5.0,0.907918,31
dafad73d-25c0-4c75-b991-8577010b1784,Multi-Task Reinforcement Learning with Soft Modularization,141,0.751804,0.832122,"Multi-task learning is a very challenging problem in reinforcement learning.
While training multiple tasks jointly allow the policies to share parameters
across different tasks, the optimization problem becomes non-trivial: It
remains unclear what parameters in the network should be reused across tasks,
and how the gradients from different tasks may interfere with each other. Thus,
instead of naively sharing parameters across tasks, we introduce an explicit
modularization technique on policy representation to alleviate this
optimization issue. Given a base policy network, we design a routing network
which estimates different routing strategies to reconfigure the base network
for each task. Instead of directly selecting routes for each task, our
task-specific policy uses a method called soft modularization to softly combine
all the possible routes, which makes it suitable for sequential tasks. We
experiment with various robotics manipulation tasks in simulation and show our
method improves both sample efficiency and performance over strong baselines by
a large margin.",1,1,0,0,0,0,0.856552,6.0,0.842361,48
3f1dd5cd-c016-4981-a2ae-d9b0b5bc3a4a,Construction and Application of Teaching System Based on Crowdsourcing Knowledge Graph,10,0.0290889,0.143958,"Through the combination of crowdsourcing knowledge graph and teaching system,
research methods to generate knowledge graph and its applications. Using two
crowdsourcing approaches, crowdsourcing task distribution and reverse captcha
generation, to construct knowledge graph in the field of teaching system.
Generating a complete hierarchical knowledge graph of the teaching domain by
nodes of school, student, teacher, course, knowledge point and exercise type.
The knowledge graph constructed in a crowdsourcing manner requires many users
to participate collaboratively with fully consideration of teachers' guidance
and users' mobilization issues. Based on the three subgraphs of knowledge
graph, prominent teacher, student learning situation and suitable learning
route could be visualized. Personalized exercises recommendation model is used
to formulate the personalized exercise by algorithm based on the knowledge
graph. Collaborative creation model is developed to realize the crowdsourcing
construction mechanism. Though unfamiliarity with the learning mode of
knowledge graph and learners' less attention to the knowledge structure, system
based on Crowdsourcing Knowledge Graph can still get high acceptance around
students and teachers",0,1,0,0,0,0,0.000121186,33.0,0.677953,15
2cd22e32-aeed-4c14-abd7-b85ca1360d8e,Deep Frequent Spatial Temporal Learning for Face Anti-Spoofing,11,0.259763,0.526318,"Face anti-spoofing is crucial for the security of face recognition system, by
avoiding invaded with presentation attack. Previous works have shown the
effectiveness of using depth and temporal supervision for this task. However,
depth supervision is often considered only in a single frame, and temporal
supervision is explored by utilizing certain signals which is not robust to the
change of scenes. In this work, motivated by two stream ConvNets, we propose a
novel two stream FreqSaptialTemporalNet for face anti-spoofing which
simultaneously takes advantage of frequent, spatial and temporal information.
Compared with existing methods which mine spoofing cues in multi-frame RGB
image, we make multi-frame spectrum image as one input stream for the
discriminative deep neural network, encouraging the primary difference between
live and fake video to be automatically unearthed. Extensive experiments show
promising improvement results using the proposed architecture. Meanwhile, we
proposed a concise method to obtain a large amount of spoofing training data by
utilizing a frequent augmentation pipeline, which contributes detail
visualization between live and fake images as well as data insufficiency issue
when training large networks.",0,1,0,0,0,0,0.957652,7.0,0.934531,42
65795dac-2d92-48a8-8053-9da5ee35d287,Recurrent babbling: evaluating the acquisition of grammar from limited input data,12,0.0171507,0.0989184,"Recurrent Neural Networks (RNNs) have been shown to capture various aspects
of syntax from raw linguistic input. In most previous experiments, however,
learning happens over unrealistic corpora, which do not reflect the type and
amount of data a child would be exposed to. This paper remedies this state of
affairs by training a Long Short-Term Memory network (LSTM) over a
realistically sized subset of child-directed input. The behaviour of the
network is analysed over time using a novel methodology which consists in
quantifying the level of grammatical abstraction in the model's generated
output (its ""babbling""), compared to the language it has been exposed to. We
show that the LSTM indeed abstracts new structuresas learning proceeds.",0,0,0,0,0,0,0.109067,6.0,0.371992,74
cd929251-e3d8-4780-b4f9-5abac880375e,Emergent Communication Pretraining for Few-Shot Machine Translation,17,0.0282583,0.349419,"While state-of-the-art models that rely upon massively multilingual
pretrained encoders achieve sample efficiency in downstream applications, they
still require abundant amounts of unlabelled text. Nevertheless, most of the
world's languages lack such resources. Hence, we investigate a more radical
form of unsupervised knowledge transfer in the absence of linguistic data. In
particular, for the first time we pretrain neural networks via emergent
communication from referential games. Our key assumption is that grounding
communication on images---as a crude approximation of real-world
environments---inductively biases the model towards learning natural languages.
On the one hand, we show that this substantially benefits machine translation
in few-shot settings. On the other hand, this also provides an extrinsic
evaluation protocol to probe the properties of emergent languages ex vitro.
Intuitively, the closer they are to natural languages, the higher the gains
from pretraining on them should be. For instance, in this work we measure the
influence of communication success and maximum sequence length on downstream
performances. Finally, we introduce a customised adapter layer and annealing
strategies for the regulariser of maximum-a-posteriori inference during
fine-tuning. These turn out to be crucial to facilitate knowledge transfer and
prevent catastrophic forgetting. Compared to a recurrent baseline, our method
yields gains of $59.0\%$$\sim$$147.6\%$ in BLEU score with only $500$ NMT
training instances and $65.1\%$$\sim$$196.7\%$ with $1,000$ NMT training
instances across four language pairs. These proof-of-concept results reveal the
potential of emergent communication pretraining for both natural language
processing tasks in resource-poor settings and extrinsic evaluation of
artificial languages.",1,0,0,0,0,0,0.290522,6.0,0.553532,94
88bbbb8e-9e59-42d4-a690-12f34e1bfb00,Template-Based Question Generation from Retrieved Sentences for Improved Unsupervised Question Answering,70,0.113945,0.414329,"Question Answering (QA) is in increasing demand as the amount of information
available online and the desire for quick access to this content grows. A
common approach to QA has been to fine-tune a pretrained language model on a
task-specific labeled dataset. This paradigm, however, relies on scarce, and
costly to obtain, large-scale human-labeled data. We propose an unsupervised
approach to training QA models with generated pseudo-training data. We show
that generating questions for QA training by applying a simple template on a
related, retrieved sentence rather than the original context sentence improves
downstream QA performance by allowing the model to learn more complex
context-question relationships. Training a QA model on this data gives a
relative improvement over a previous unsupervised model in F1 score on the
SQuAD dataset by about 14%, and 20% when the answer is a named entity,
achieving state-of-the-art performance on SQuAD for unsupervised QA.",1,1,0,0,1,0,0.885653,2.0,0.582303,14
825e0f9f-50ca-494b-b230-7dbdaddca7e2,PhraseCut: Language-based Image Segmentation in the Wild,84,0.0694652,0.515276,"We consider the problem of segmenting image regions given a natural language
phrase, and study it on a novel dataset of 77,262 images and 345,486
phrase-region pairs. Our dataset is collected on top of the Visual Genome
dataset and uses the existing annotations to generate a challenging set of
referring phrases for which the corresponding regions are manually annotated.
Phrases in our dataset correspond to multiple regions and describe a large
number of object and stuff categories as well as their attributes such as
color, shape, parts, and relationships with other entities in the image. Our
experiments show that the scale and diversity of concepts in our dataset poses
significant challenges to the existing state-of-the-art. We systematically
handle the long-tail nature of these concepts and present a modular approach to
combine category, attribute, and relationship cues that outperforms existing
approaches.",1,1,1,1,0,0,0.0918824,6.0,0.341853,43
cfc9805b-a31d-4227-b82c-1d60c69c2e6f,"""Notic My Speech"" -- Blending Speech Patterns With Multimedia",3,0.0313923,0.0606727,"Speech as a natural signal is composed of three parts - visemes (visual part
of speech), phonemes (spoken part of speech), and language (the imposed
structure). However, video as a medium for the delivery of speech and a
multimedia construct has mostly ignored the cognitive aspects of speech
delivery. For example, video applications like transcoding and compression have
till now ignored the fact how speech is delivered and heard. To close the gap
between speech understanding and multimedia video applications, in this paper,
we show the initial experiments by modelling the perception on visual speech
and showing its use case on video compression. On the other hand, in the visual
speech recognition domain, existing studies have mostly modeled it as a
classification problem, while ignoring the correlations between views,
phonemes, visemes, and speech perception. This results in solutions which are
further away from how human perception works. To bridge this gap, we propose a
view-temporal attention mechanism to model both the view dependence and the
visemic importance in speech recognition and understanding. We conduct
experiments on three public visual speech recognition datasets. The
experimental results show that our proposed method outperformed the existing
work by 4.99% in terms of the viseme error rate. Moreover, we show that there
is a strong correlation between our model's understanding of multi-view speech
and the human perception. This characteristic benefits downstream applications
such as video compression and streaming where a significant number of less
important frames can be compressed or eliminated while being able to maximally
preserve human speech understanding with good user experience.",0,0,0,0,1,0,0.251111,11.0,0.740891,50
7e782c0d-2e51-4ccc-8b4d-316821a38acd,Bipartite Graph Reasoning GANs for Person Image Generation,54,0.564409,0.479556,"We present a novel Bipartite Graph Reasoning GAN (BiGraphGAN) for the
challenging person image generation task. The proposed graph generator mainly
consists of two novel blocks that aim to model the pose-to-pose and
pose-to-image relations, respectively. Specifically, the proposed Bipartite
Graph Reasoning (BGR) block aims to reason the crossing long-range relations
between the source pose and the target pose in a bipartite graph, which
mitigates some challenges caused by pose deformation. Moreover, we propose a
new Interaction-and-Aggregation (IA) block to effectively update and enhance
the feature representation capability of both person's shape and appearance in
an interactive way. Experiments on two challenging and public datasets, i.e.,
Market-1501 and DeepFashion, show the effectiveness of the proposed BiGraphGAN
in terms of objective quantitative scores and subjective visual realness. The
source code and trained models are available at
https://github.com/Ha0Tang/BiGraphGAN.",1,1,0,0,1,0,0.951785,4.0,0.874953,45
dcee353d-55d7-423b-8cc1-745580cd2f96,Multi-level Stress Assessment Using Multi-domain Fusion of ECG Signal,19,0.216608,0.561095,"Stress analysis and assessment of affective states of mind using ECG as a
physiological signal is a burning research topic in biomedical signal
processing. However, existing literature provides only binary assessment of
stress, while multiple levels of assessment may be more beneficial for
healthcare applications. Furthermore, in present research, ECG signal for
stress analysis is examined independently in spatial domain or in transform
domains but the advantage of fusing these domains has not been fully utilized.
To get the maximum advantage of fusing diferent domains, we introduce a dataset
with multiple stress levels and then classify these levels using a novel deep
learning approach by converting ECG signal into signal images based on R-R
peaks without any feature extraction. Moreover, We made signal images
multimodal and multidomain by converting them into time-frequency and frequency
domain using Gabor wavelet transform (GWT) and Discrete Fourier Transform (DFT)
respectively. Convolutional Neural networks (CNNs) are used to extract features
from different modalities and then decision level fusion is performed for
improving the classification accuracy. The experimental results on an in-house
dataset collected with 15 users show that with proposed fusion framework and
using ECG signal to image conversion, we reach an average accuracy of 85.45%.",0,1,1,1,0,0,0.843163,2.0,0.503561,12
76f72b36-fab4-4d77-bcca-52f534a3cb95,At your Command! An Empirical Study on How LaypersonsTeach Robots New Functions,2,0.0114901,0.0624147,"Even though intelligent systems such as Siri or Google Assistant are
enjoyable (and useful) dialog partners, users can only access predefined
functionality. Enabling end-users to extend the functionality of intelligent
systems will be the next big thing. To promote research in this area we carried
out an empirical study on how laypersons teach robots new functions by means of
natural language instructions. The result is a labeled corpus consisting of
3168 submissions given by 870 subjects. The analysis of the dataset revealed
that many participants used certain wordings to express their wish to teach new
functionality; two corresponding trigrams are among the most frequent. On the
contrary, more than one third (36.93%) did not verbalize the teaching intent at
all. We labeled the semantic constituents in the utterances: declaration
(including the name of the function) and intermediate steps. The full corpus is
publicly available: http://dx.doi.org/10.21227/zecn-6c61",0,0,1,1,0,0,0.00290132,12.0,0.379119,31
a5eeb915-fa3f-4e2b-ba93-3c71dfe8b81c,FocalMix: Semi-Supervised Learning for 3D Medical Image Detection,107,0.886143,0.848645,"Applying artificial intelligence techniques in medical imaging is one of the
most promising areas in medicine. However, most of the recent success in this
area highly relies on large amounts of carefully annotated data, whereas
annotating medical images is a costly process. In this paper, we propose a
novel method, called FocalMix, which, to the best of our knowledge, is the
first to leverage recent advances in semi-supervised learning (SSL) for 3D
medical image detection. We conducted extensive experiments on two widely used
datasets for lung nodule detection, LUNA16 and NLST. Results show that our
proposed SSL methods can achieve a substantial improvement of up to 17.3% over
state-of-the-art supervised learning approaches with 400 unlabeled CT scans.",0,1,1,0,1,0,0.855375,6.0,0.841658,43
9058d012-7c5d-4fdb-a2c4-d2d35370e81c,The Holy Grail of Quantum Artificial Intelligence: Major Challenges in Accelerating the Machine Learning Pipeline,19,0.372963,0.566086,"We discuss the synergetic connection between quantum computing and artificial
intelligence. After surveying current approaches to quantum artificial
intelligence and relating them to a formal model for machine learning
processes, we deduce four major challenges for the future of quantum artificial
intelligence: (i) Replace iterative training with faster quantum algorithms,
(ii) distill the experience of larger amounts of data into the training
process, (iii) allow quantum and classical components to be easily combined and
exchanged, and (iv) build tools to thoroughly analyze whether observed benefits
really stem from quantum properties of the algorithm.",0,0,0,0,0,0,0.856269,6.0,0.842192,50
67a29b1c-efce-4b17-8b43-5812f911c8d7,Customized Handling of Unintended Interface Operation in Assistive Robots,9,0.076445,0.345033,"We present an assistance system that reasons about a human's intended actions
during robot teleoperation in order to provide appropriate corrections for
unintended behavior. We model the human's physical interaction with a control
interface during robot teleoperation and distinguish between intended and
measured physical actions explicitly. By reasoning over the unobserved
intentions using model-based inference techniques, our assistive system
provides customized corrections on a user's issued commands. We validate our
algorithm with a 10-person human subject study in which we evaluate the
performance of the proposed assistance paradigms. Our results show that the
assistance paradigms helped to significantly reduce task completion time,
number of mode switches, cognitive workload, and user frustration and improve
overall user satisfaction.",1,1,0,0,0,0,0.0416066,11.0,0.566567,31
09df4c16-eca0-4666-ab8f-3d3fc76937e6,Vector-Quantized Autoregressive Predictive Coding,101,0.556403,0.818885,"Autoregressive Predictive Coding (APC), as a self-supervised objective, has
enjoyed success in learning representations from large amounts of unlabeled
data, and the learned representations are rich for many downstream tasks.
However, the connection between low self-supervised loss and strong performance
in downstream tasks remains unclear. In this work, we propose Vector-Quantized
Autoregressive Predictive Coding (VQ-APC), a novel model that produces
quantized representations, allowing us to explicitly control the amount of
information encoded in the representations. By studying a sequence of
increasingly limited models, we reveal the constituents of the learned
representations. In particular, we confirm the presence of information with
probing tasks, while showing the absence of information with mutual
information, uncovering the model's preference in preserving speech information
as its capacity becomes constrained. We find that there exists a point where
phonetic and speaker information are amplified to maximize a self-supervised
objective. As a byproduct, the learned codes for a particular model capacity
correspond well to English phones.",1,0,0,0,0,0,0.952843,3.0,0.8357,25
a2db077f-c5d5-45a3-8988-484edfdb50ea,TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue,287,0.999544,0.998825,"The underlying difference of linguistic patterns between general text and
task-oriented dialogue makes existing pre-trained language models less useful
in practice. In this work, we unify nine human-human and multi-turn
task-oriented dialogue datasets for language modeling. To better model dialogue
behavior during pre-training, we incorporate user and system tokens into the
masked language modeling. We propose a contrastive objective function to
simulate the response selection task. Our pre-trained task-oriented dialogue
BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream
task-oriented dialogue applications, including intention recognition, dialogue
state tracking, dialogue act prediction, and response selection. We also show
that TOD-BERT has a stronger few-shot ability that can mitigate the data
scarcity problem for task-oriented dialogue.",1,1,0,1,0,0,0.988955,2.0,0.947959,49
67cac8a3-86e3-4727-a94a-d9dc8a885932,Improving Entity Linking by Modeling Latent Entity Type Information,56,0.333265,0.659993,"Existing state of the art neural entity linking models employ attention-based
bag-of-words context model and pre-trained entity embeddings bootstrapped from
word embeddings to assess topic level context compatibility. However, the
latent entity type information in the immediate context of the mention is
neglected, which causes the models often link mentions to incorrect entities
with incorrect type. To tackle this problem, we propose to inject latent entity
type information into the entity embeddings based on pre-trained BERT. In
addition, we integrate a BERT-based entity similarity score into the local
context model of a state-of-the-art model to better capture latent entity type
information. Our model significantly outperforms the state-of-the-art entity
linking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis
demonstrates that our model corrects most of the type errors produced by the
direct baseline.",1,1,0,0,1,0,0.368397,9.0,0.734771,35
78a93057-6030-4925-b7d3-03cceb72cb07,COVID-19 Image Data Collection,966,0.869823,0.999969,"This paper describes the initial COVID-19 open image data collection. It was
created by assembling medical images from websites and publications and
currently contains 123 frontal view X-rays.",1,1,0,1,0,0,0.965011,1.0,0.600335,30
7387b0a3-6837-4bbb-8485-374956818935,Image Retrieval for Structure-from-Motion via Graph Convolutional Network,16,0.0398039,0.39034,"Conventional image retrieval techniques for Structure-from-Motion (SfM)
suffer from the limit of effectively recognizing repetitive patterns and cannot
guarantee to create just enough match pairs with high precision and high
recall. In this paper, we present a novel retrieval method based on Graph
Convolutional Network (GCN) to generate accurate pairwise matches without
costly redundancy. We formulate image retrieval task as a node binary
classification problem in graph data: a node is marked as positive if it shares
the scene overlaps with the query image. The key idea is that we find that the
local context in feature space around a query image contains rich information
about the matchable relation between this image and its neighbors. By
constructing a subgraph surrounding the query image as input data, we adopt a
learnable GCN to exploit whether nodes in the subgraph have overlapping regions
with the query photograph. Experiments demonstrate that our method performs
remarkably well on the challenging dataset of highly ambiguous and duplicated
scenes. Besides, compared with state-of-the-art matchable retrieval methods,
the proposed approach significantly reduces useless attempted matches without
sacrificing the accuracy and completeness of reconstruction.",0,1,0,0,1,0,0.107185,10.0,0.621352,62
4e3e5461-62a8-46e8-84cc-62b723f776f9,Bracketing Encodings for 2-Planar Dependency Parsing,13,0.0973994,0.280937,"We present a bracketing-based encoding that can be used to represent any
2-planar dependency tree over a sentence of length n as a sequence of n labels,
hence providing almost total coverage of crossing arcs in sequence labeling
parsing. First, we show that existing bracketing encodings for parsing as
labeling can only handle a very mild extension of projective trees. Second, we
overcome this limitation by taking into account the well-known property of
2-planarity, which is present in the vast majority of dependency syntactic
structures in treebanks, i.e., the arcs of a dependency tree can be split into
two planes such that arcs in a given plane do not cross. We take advantage of
this property to design a method that balances the brackets and that encodes
the arcs belonging to each of those planes, allowing for almost unrestricted
non-projectivity (round 99.9% coverage) in sequence labeling parsing. The
experiments show that our linearizations improve over the accuracy of the
original bracketing encoding in highly non-projective treebanks (on average by
0.4 LAS), while achieving a similar speed. Also, they are especially suitable
when PoS tags are not used as input parameters to the models.",1,1,0,1,0,0,0.0757013,7.0,0.406958,28
ed9691b2-a426-4d4b-924a-4922c72f3c89,Meta-learning in natural and artificial intelligence,87,0.304109,0.820967,"Meta-learning, or learning to learn, has gained renewed interest in recent
years within the artificial intelligence community. However, meta-learning is
incredibly prevalent within nature, has deep roots in cognitive science and
psychology, and is currently studied in various forms within neuroscience. The
aim of this review is to recast previous lines of research in the study of
biological intelligence within the lens of meta-learning, placing these works
into a common framework. More recent points of interaction between AI and
neuroscience will be discussed, as well as interesting new directions that
arise under this perspective.",0,0,0,0,0,1,0.413534,10.0,0.776253,80
4716d2ae-a7c4-4086-906c-d3009681798b,Unadversarial Examples: Designing Objects for Robust Vision,49,0.106573,0.718685,"We study a class of realistic computer vision settings wherein one can
influence the design of the objects being recognized. We develop a framework
that leverages this capability to significantly improve vision models'
performance and robustness. This framework exploits the sensitivity of modern
machine learning algorithms to input perturbations in order to design ""robust
objects,"" i.e., objects that are explicitly optimized to be confidently
detected or classified. We demonstrate the efficacy of the framework on a wide
variety of vision-based tasks ranging from standard benchmarks, to
(in-simulation) robotics, to real-world experiments. Our code can be found at
https://git.io/unadversarial .",1,0,0,0,0,0,0.231773,7.0,0.579644,66
076bb7c4-72fb-4369-a69c-f37394fc1f27,Cross-lingual Word Sense Disambiguation using mBERT Embeddings with Syntactic Dependencies,6,0.371076,0.414749,"Cross-lingual word sense disambiguation (WSD) tackles the challenge of
disambiguating ambiguous words across languages given context. The pre-trained
BERT embedding model has been proven to be effective in extracting contextual
information of words, and have been incorporated as features into many
state-of-the-art WSD systems. In order to investigate how syntactic information
can be added into the BERT embeddings to result in both semantics- and
syntax-incorporated word embeddings, this project proposes the concatenated
embeddings by producing dependency parse tress and encoding the relative
relationships of words into the input embeddings. Two methods are also proposed
to reduce the size of the concatenated embeddings. The experimental results
show that the high dimensionality of the syntax-incorporated embeddings
constitute an obstacle for the classification task, which needs to be further
addressed in future studies.",0,1,0,0,0,0,0.718157,24.0,0.942781,13
4ddd4eff-4a13-45e0-a960-619508006799,ColorShapeLinks: A board game AI competition for educators and students,8,0.113058,0.604909,"ColorShapeLinks is an AI board game competition framework specially designed
for students and educators in videogame development, with openness and
accessibility in mind. The competition is based on an arbitrarily-sized version
of the Simplexity board game, the motto of which, ""simple to learn, complex to
master"", is curiously also applicable to AI agents. ColorShapeLinks offers
graphical and text-based frontends and a completely open and documented
development framework built using industry standard tools and following
software engineering best practices. ColorShapeLinks is not only a competition,
but both a game and a framework which educators and students can extend and use
to host their own competitions. It has been successfully used for running
internal competitions in AI classes, as well as for hosting an international AI
competition at the IEEE Conference on Games.",1,1,0,0,0,0,0.117254,6.0,0.38481,45
31390b58-c7c0-478b-942c-0a9fe458ff7e,Combining Federated and Active Learning for Communication-efficient Distributed Failure Prediction in Aeronautics,13,0.242602,0.291722,"Machine Learning has proven useful in the recent years as a way to achieve
failure prediction for industrial systems. However, the high computational
resources necessary to run learning algorithms are an obstacle to its
widespread application. The sub-field of Distributed Learning offers a solution
to this problem by enabling the use of remote resources but at the expense of
introducing communication costs in the application that are not always
acceptable. In this paper, we propose a distributed learning approach able to
optimize the use of computational and communication resources to achieve
excellent learning model performances through a centralized architecture. To
achieve this, we present a new centralized distributed learning algorithm that
relies on the learning paradigms of Active Learning and Federated Learning to
offer a communication-efficient method that offers guarantees of model
precision on both the clients and the central server. We evaluate this method
on a public benchmark and show that its performances in terms of precision are
very close to state-of-the-art performance level of non-distributed learning
despite additional constraints.",0,1,0,0,0,0,0.38073,11.0,0.786814,17
7b33ebf8-2f7d-4618-a52a-b061992e9cbe,Unsupervised Instance Segmentation in Microscopy Images via Panoptic Domain Adaptation and Task Re-weighting,67,0.224277,0.630455,"Unsupervised domain adaptation (UDA) for nuclei instance segmentation is
important for digital pathology, as it alleviates the burden of labor-intensive
annotation and domain shift across datasets. In this work, we propose a Cycle
Consistency Panoptic Domain Adaptive Mask R-CNN (CyC-PDAM) architecture for
unsupervised nuclei segmentation in histopathology images, by learning from
fluorescence microscopy images. More specifically, we first propose a nuclei
inpainting mechanism to remove the auxiliary generated objects in the
synthesized images. Secondly, a semantic branch with a domain discriminator is
designed to achieve panoptic-level domain adaptation. Thirdly, in order to
avoid the influence of the source-biased features, we propose a task
re-weighting mechanism to dynamically add trade-off weights for the
task-specific loss functions. Experimental results on three datasets indicate
that our proposed method outperforms state-of-the-art UDA methods
significantly, and demonstrates a similar performance as fully supervised
methods.",0,1,0,0,1,0,0.685627,6.0,0.756091,55
236c42a5-8a07-43ea-8c66-572607ba9235,Automatic Quantification of Settlement Damage using Deep Learning of Satellite Images,1,0.0247017,0.080825,"Humanitarian disasters and political violence cause significant damage to our
living space. The reparation cost to homes, infrastructure, and the ecosystem
is often difficult to quantify in real-time. Real-time quantification is
critical to both informing relief operations, but also planning ahead for
rebuilding. Here, we use satellite images before and after major crisis around
the world to train a robust baseline Residual Network (ResNet) and a disaster
quantification Pyramid Scene Parsing Network (PSPNet). ResNet offers robustness
to poor image quality and can identify areas of destruction with high accuracy
(92\%), whereas PSPNet offers contextualised quantification of built
environment damage with good accuracy (84\%). As there are multiple damage
dimensions to consider (e.g. economic loss and fatalities), we fit a
multi-linear regression model to quantify the overall damage. To validate our
combined system of deep learning and regression modeling, we successfully match
our prediction to the ongoing recovery in the 2020 Beirut port explosion. These
innovations provide a better quantification of overall disaster magnitude and
inform intelligent humanitarian systems of unfolding disasters.",0,1,0,1,0,0,0.227213,7.0,0.576401,27
9e975d32-bedd-4501-a484-e97bdc23bf56,Overview: Computer vision and machine learning for microstructural characterization and analysis,120,0.29237,0.993483,"The characterization and analysis of microstructure is the foundation of
microstructural science, connecting the materials structure to its composition,
process history, and properties. Microstructural quantification traditionally
involves a human deciding a priori what to measure and then devising a
purpose-built method for doing so. However, recent advances in data science,
including computer vision (CV) and machine learning (ML) offer new approaches
to extracting information from microstructural images. This overview surveys CV
approaches to numerically encode the visual information contained in a
microstructural image, which then provides input to supervised or unsupervised
ML algorithms that find associations and trends in the high-dimensional image
representation. CV/ML systems for microstructural characterization and analysis
span the taxonomy of image analysis tasks, including image classification,
semantic segmentation, object detection, and instance segmentation. These tools
enable new approaches to microstructural analysis, including the development of
new, rich visual metrics and the discovery of
processing-microstructure-property relationships.",0,0,0,0,0,0,0.0300329,12.0,0.575026,131
5a33a4b9-000e-4afe-926c-b45268b3e12d,Unsupervised Feature Learning by Autoencoder and Prototypical Contrastive Learning for Hyperspectral Classification,24,0.136161,0.678257,"Unsupervised learning methods for feature extraction are becoming more and
more popular. We combine the popular contrastive learning method (prototypical
contrastive learning) and the classic representation learning method
(autoencoder) to design an unsupervised feature learning network for
hyperspectral classification. Experiments have proved that our two proposed
autoencoder networks have good feature learning capabilities by themselves, and
the contrastive learning network we designed can better combine the features of
the two to learn more representative features. As a result, our method
surpasses other comparison methods in the hyperspectral classification
experiments, including some supervised methods. Moreover, our method maintains
a fast feature extraction speed than baseline methods. In addition, our method
reduces the requirements for huge computing resources, separates feature
extraction and contrastive learning, and allows more researchers to conduct
research and experiments on unsupervised contrastive learning.",0,1,0,0,1,0,0.666287,7.0,0.783368,57
47f10042-b670-43a7-82a2-6028df1518c0,Interpretability Analysis for Named Entity Recognition to Understand System Predictions and How They Can Improve,35,0.195803,0.643736,"Named Entity Recognition systems achieve remarkable performance on domains
such as English news. It is natural to ask: What are these models actually
learning to achieve this? Are they merely memorizing the names themselves? Or
are they capable of interpreting the text and inferring the correct entity type
from the linguistic context? We examine these questions by contrasting the
performance of several variants of LSTM-CRF architectures for named entity
recognition, with some provided only representations of the context as
features. We also perform similar experiments for BERT. We find that context
representations do contribute to system performance, but that the main factor
driving high performance is learning the name tokens themselves. We enlist
human annotators to evaluate the feasibility of inferring entity types from the
context alone and find that, while people are not able to infer the entity type
either for the majority of the errors made by the context-only system, there is
some room for improvement. A system should be able to recognize any name in a
predictive context correctly and our experiments indicate that current systems
may be further improved by such capability.",0,0,0,0,0,0,0.0152697,27.0,0.785791,37
cb301f71-0b9d-4fe5-89bf-b66c2fb0d1b5,Derivation of a Constant Velocity Motion Model for Visual Tracking,12,0.029119,0.350526,"Motion models play a great role in visual tracking applications for
predicting the possible locations of objects in the next frame. Unlike target
tracking in radar or aerospace domain which considers only points, object
tracking in computer vision involves sizes of objects. Constant velocity motion
model is the most widely used motion model for visual tracking, however, there
is no clear and understandable derivation involving sizes of objects specially
for new researchers joining this research field. In this document, we derive
the constant velocity motion model that incorporates sizes of objects that, we
think, can help the new researchers to adapt to it very quickly.",0,1,0,0,0,1,0.111625,7.0,0.465221,17
52b556c9-da80-46d1-86bd-85a8f8a8fa94,Trajectory Prediction in Autonomous Driving with a Lane Heading Auxiliary Loss,32,0.146516,0.506714,"Predicting a vehicle's trajectory is an essential ability for autonomous
vehicles navigating through complex urban traffic scenes. Bird's-eye-view
roadmap information provides valuable information for making trajectory
predictions, and while state-of-the-art models extract this information via
image convolution, auxiliary loss functions can augment patterns inferred from
deep learning by further encoding common knowledge of social and legal driving
behaviors. Since human driving behavior is inherently multimodal, models which
allow for multimodal output tend to outperform single-prediction models on
standard metrics. We propose a loss function which enhances such models by
enforcing expected driving rules on all predicted modes. Our contribution to
trajectory prediction is twofold; we propose a new metric which addresses
failure cases of the off-road rate metric by penalizing trajectories that
oppose the ascribed heading (flow direction) of a driving lane, and we show
this metric to be differentiable and therefore suitable as an auxiliary loss
function. We then use this auxiliary loss to extend the the standard multiple
trajectory prediction (MTP) and MultiPath models, achieving improved results on
the nuScenes prediction benchmark by predicting trajectories which better
conform to the lane-following rules of the road.",0,1,0,0,0,0,0.812743,3.0,0.635512,41
0e69a312-2dd0-4a73-9453-a0b32ccd9ee9,Multi-scale Interactive Network for Salient Object Detection,493,0.958468,0.990901,"Deep-learning based salient object detection methods achieve great progress.
However, the variable scale and unknown category of salient objects are great
challenges all the time. These are closely related to the utilization of
multi-level and multi-scale features. In this paper, we propose the aggregate
interaction modules to integrate the features from adjacent levels, in which
less noise is introduced because of only using small up-/down-sampling rates.
To obtain more efficient multi-scale features from the integrated features, the
self-interaction modules are embedded in each decoder unit. Besides, the class
imbalance issue caused by the scale variation weakens the effect of the binary
cross entropy loss and results in the spatial inconsistency of the predictions.
Therefore, we exploit the consistency-enhanced loss to highlight the
fore-/back-ground difference and preserve the intra-class consistency.
Experimental results on five benchmark datasets demonstrate that the proposed
method without any post-processing performs favorably against 23
state-of-the-art approaches. The source code will be publicly available at
https://github.com/lartpang/MINet.",1,1,0,0,1,0,0.901813,6.0,0.872085,57
66fc3f79-1748-4688-ac2d-ca0fe2774a88,POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training,78,0.258498,0.822672,"Large-scale pre-trained language models, such as BERT and GPT-2, have
achieved excellent performance in language representation learning and
free-form text generation. However, these models cannot be directly employed to
generate text under specified lexical constraints. To address this challenge,
we present POINTER (PrOgressive INsertion-based TransformER), a simple yet
novel insertion-based approach for hard-constrained text generation. The
proposed method operates by progressively inserting new tokens between existing
tokens in a parallel manner. This procedure is recursively applied until a
sequence is completed. The resulting coarse-to-fine hierarchy makes the
generation process intuitive and interpretable. We pre-train our model with the
proposed progressive insertion-based objective on a 12GB Wikipedia dataset, and
fine-tune it on downstream hard-constrained generation tasks.
Non-autoregressive decoding yields an empirically logarithmic time complexity
during inference time. Experimental results on both News and Yelp datasets
demonstrate that POINTER achieves state-of-the-art performance on constrained
text generation. We released the pre-trained models and the source code to
facilitate future research (https://github.com/dreasysnail/POINTER).",0,1,0,0,1,0,0.852881,3.0,0.680356,58
9848c018-5059-4bf9-9f20-96c567356a5c,On the impressive performance of randomly weighted encoders in summarization tasks,5,0.0316393,0.0692752,"In this work, we investigate the performance of untrained randomly
initialized encoders in a general class of sequence to sequence models and
compare their performance with that of fully-trained encoders on the task of
abstractive summarization. We hypothesize that random projections of an input
text have enough representational power to encode the hierarchical structure of
sentences and semantics of documents. Using a trained decoder to produce
abstractive text summaries, we empirically demonstrate that architectures with
untrained randomly initialized encoders perform competitively with respect to
the equivalent architectures with fully-trained encoders. We further find that
the capacity of the encoder not only improves overall model generalization but
also closes the performance gap between untrained randomly initialized and
full-trained encoders. To our knowledge, it is the first time that general
sequence to sequence models with attention are assessed for trained and
randomly projected representations on abstractive summarization.",0,0,0,0,0,1,0.801706,6.0,0.811959,35
c945c305-3aaf-4f55-91ba-0c666e92afe7,Towards unsupervised phone and word segmentation using self-supervised vector-quantized neural networks,32,0.294853,0.744355,"We investigate segmenting and clustering speech into low-bitrate phone-like
sequences without supervision. We specifically constrain pretrained
self-supervised vector-quantized (VQ) neural networks so that blocks of
contiguous feature vectors are assigned to the same code, thereby giving a
variable-rate segmentation of the speech into discrete units. Two segmentation
methods are considered. In the first, features are greedily merged until a
prespecified number of segments are reached. The second uses dynamic
programming to optimize a squared error with a penalty term to encourage fewer
but longer segments. We show that these VQ segmentation methods can be used
without alteration across a wide range of tasks: unsupervised phone
segmentation, ABX phone discrimination, same-different word discrimination, and
as inputs to a symbolic word segmentation algorithm. The penalized dynamic
programming method generally performs best. While performance on individual
tasks is only comparable to the state-of-the-art in some cases, in all tasks a
reasonable competing approach is outperformed at a substantially lower bitrate.",1,0,0,0,0,0,0.373736,5.0,0.526248,45
ea4cd35c-9011-44d4-ad43-b4e1b5c3788e,Deep reinforcement learning to detect brain lesions on MRI: a proof-of-concept application of reinforcement learning to medical images,15,0.0557675,0.283495,"Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated
data sets. 2) Non-generalizability that limits deployment to new scanners /
institutions. And 3) Inadequate explainability and interpretability. We believe
that reinforcement learning can address all three shortcomings, with robust and
intuitive algorithms trainable on small datasets. To the best of our knowledge,
reinforcement learning has not been directly applied to computer vision tasks
for radiological images. In this proof-of-principle work, we train a deep
reinforcement learning network to predict brain tumor location.
  Materials and Methods: Using the BraTS brain tumor imaging database, we
trained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We
did so in concert with image exploration, with rewards and punishments designed
to localize lesions. To compare with supervised deep learning, we trained a
keypoint detection convolutional neural network on the same 70 images. We
applied both approaches to a separate 30 image testing set.
  Results: Reinforcement learning predictions consistently improved during
training, whereas those of supervised deep learning quickly diverged.
Reinforcement learning predicted testing set lesion locations with 85%
accuracy, compared to roughly 7% accuracy for the supervised deep network.
  Conclusion: Reinforcement learning predicted lesions with high accuracy,
which is unprecedented for such a small training set. We believe that
reinforcement learning can propel radiology AI well past the inherent
limitations of supervised deep learning, with more clinician-driven research
and finally toward true clinical applicability.",0,0,0,0,0,0,0.326283,8.0,0.682694,37
e41034ed-2e8c-40cd-bbae-aa88dae4c12a,Comparison of Speech Representations for Automatic Quality Estimation in Multi-Speaker Text-to-Speech Synthesis,23,0.501624,0.608725,"We aim to characterize how different speakers contribute to the perceived
output quality of multi-speaker Text-to-Speech (TTS) synthesis. We
automatically rate the quality of TTS using a neural network (NN) trained on
human mean opinion score (MOS) ratings. First, we train and evaluate our NN
model on 13 different TTS and voice conversion (VC) systems from the ASVSpoof
2019 Logical Access (LA) Dataset. Since it is not known how best to represent
speech for this task, we compare 8 different representations alongside MOSNet
frame-based features. Our representations include image-based spectrogram
features and x-vector embeddings that explicitly model different types of noise
such as T60 reverberation time. Our NN predicts MOS with a high correlation to
human judgments. We report prediction correlation and error. A key finding is
the quality achieved for certain speakers seems consistent, regardless of the
TTS or VC system. It is widely accepted that some speakers give higher quality
than others for building a TTS system: our method provides an automatic way to
identify such speakers. Finally, to see if our quality prediction models
generalize, we predict quality scores for synthetic speech using a separate
multi-speaker TTS system that was trained on LibriTTS data, and conduct our own
MOS listening test to compare human ratings with our NN predictions.",1,1,0,0,0,0,0.838382,5.0,0.798156,30
deff61ed-22d2-4305-94ba-e917e2e9fce6,Micro-Facial Expression Recognition Based on Deep-Rooted Learning Algorithm,10,0.116649,0.494766,"Facial expressions are important cues to observe human emotions. Facial
expression recognition has attracted many researchers for years, but it is
still a challenging topic since expression features vary greatly with the head
poses, environments, and variations in the different persons involved. In this
work, three major steps are involved to improve the performance of micro-facial
expression recognition. First, an Adaptive Homomorphic Filtering is used for
face detection and rotation rectification processes. Secondly, Micro-facial
features were used to extract the appearance variations of a testing
image-spatial analysis. The features of motion information are used for
expression recognition in a sequence of facial images. An effective
Micro-Facial Expression Based Deep-Rooted Learning (MFEDRL) classifier is
proposed in this paper to better recognize spontaneous micro-expressions by
learning parameters on the optimal features. This proposed method includes two
loss functions such as cross entropy loss function and centre loss function.
Then the performance of the algorithm will be evaluated using recognition rate
and false measures. Simulation results show that the predictive performance of
the proposed method outperforms that of the existing classifiers such as
Convolutional Neural Network (CNN), Deep Neural Network (DNN), Artificial
Neural Network (ANN), Support Vector Machine (SVM), and k-Nearest Neighbours
(KNN) in terms of accuracy and Mean Absolute Error (MAE).",0,1,0,0,1,0,0.164333,11.0,0.697557,31
1f1b30d6-929a-45e4-b2a4-9e704c1c407f,Learning Object Depth from Camera Motion and Video Object Segmentation,2,0.0132275,0.0263854,"Video object segmentation, i.e., the separation of a target object from
background in video, has made significant progress on real and challenging
videos in recent years. To leverage this progress in 3D applications, this
paper addresses the problem of learning to estimate the depth of segmented
objects given some measurement of camera motion (e.g., from robot kinematics or
vehicle odometry). We achieve this by, first, introducing a diverse, extensible
dataset and, second, designing a novel deep network that estimates the depth of
objects using only segmentation masks and uncalibrated camera movement. Our
data-generation framework creates artificial object segmentations that are
scaled for changes in distance between the camera and object, and our network
learns to estimate object depth even with segmentation errors. We demonstrate
our approach across domains using a robot camera to locate objects from the YCB
dataset and a vehicle camera to locate obstacles while driving.",1,1,0,1,0,0,0.243826,9.0,0.679528,60
86f68e2d-9884-4025-8760-3ae1bdc1bebc,Keyfilter-Aware Real-Time UAV Object Tracking,37,0.773428,0.590525,"Correlation filter-based tracking has been widely applied in unmanned aerial
vehicle (UAV) with high efficiency. However, it has two imperfections, i.e.,
boundary effect and filter corruption. Several methods enlarging the search
area can mitigate boundary effect, yet introducing undesired background
distraction. Existing frame-by-frame context learning strategies for repressing
background distraction nevertheless lower the tracking speed. Inspired by
keyframe-based simultaneous localization and mapping, keyfilter is proposed in
visual tracking for the first time, in order to handle the above issues
efficiently and effectively. Keyfilters generated by periodically selected
keyframes learn the context intermittently and are used to restrain the
learning of filters, so that 1) context awareness can be transmitted to all the
filters via keyfilter restriction, and 2) filter corruption can be repressed.
Compared to the state-of-the-art results, our tracker performs better on two
challenging benchmarks, with enough speed for UAV real-time applications.",1,1,0,0,1,0,0.964411,9.0,0.955027,40
40f25036-c02c-443e-bff3-da3a11b2857f,Phase transitions in a decentralized graph-based approach to human language,2,0.00492497,0.0336577,"Zipf's law establishes a scaling behavior for word-frequencies in large text
corpora. The appearance of Zipfian properties in human language has been
previously explained as an optimization problem for the interests of speakers
and hearers. On the other hand, human-like vocabularies can be viewed as
bipartite graphs. The aim here is double: within a bipartite-graph approach to
human vocabularies, to propose a decentralized language game model for the
formation of Zipfian properties. To do this, we define a language game, in
which a population of artificial agents is involved in idealized linguistic
interactions. Numerical simulations show the appearance of a phase transition
from an initially disordered state to three possible phases for language
formation. Our results suggest that Zipfian properties in language seem to
arise partly from decentralized linguistic interactions between agents endowed
with bipartite word-meaning mappings.",0,0,0,0,0,0,3.10198e-05,17.0,0.294688,34
ad9fb75f-8f82-4ddf-a479-c365b6cbb003,Helpfulness as a Key Metric of Human-Robot Collaboration,10,0.166145,0.484605,"As robotic teammates become more common in society, people will assess the
robots' roles in their interactions along many dimensions. One such dimension
is effectiveness: people will ask whether their robotic partners are
trustworthy and effective collaborators. This begs a crucial question: how can
we quantitatively measure the helpfulness of a robotic partner for a given task
at hand? This paper seeks to answer this question with regards to the
interactive robot's decision making. We describe a clear, concise, and
task-oriented metric applicable to many different planning and execution
paradigms. The proposed helpfulness metric is fundamental to assessing the
benefit that a partner has on a team for a given task. In this paper, we define
helpfulness, illustrate it on concrete examples from a variety of domains,
discuss its properties and ramifications for planning interactions with humans,
and present preliminary results.",0,0,0,0,0,0,0.0279244,13.0,0.602034,32
76a1caef-805b-43f9-9a84-68be6725a030,Language Model Prior for Low-Resource Neural Machine Translation,48,0.11236,0.720873,"The scarcity of large parallel corpora is an important obstacle for neural
machine translation. A common solution is to exploit the knowledge of language
models (LM) trained on abundant monolingual data. In this work, we propose a
novel approach to incorporate a LM as prior in a neural translation model (TM).
Specifically, we add a regularization term, which pushes the output
distributions of the TM to be probable under the LM prior, while avoiding wrong
predictions when the TM ""disagrees"" with the LM. This objective relates to
knowledge distillation, where the LM can be viewed as teaching the TM about the
target language. The proposed approach does not compromise decoding speed,
because the LM is used only at training time, unlike previous work that
requires it during inference. We present an analysis of the effects that
different methods have on the distributions of the TM. Results on two
low-resource machine translation datasets show clear improvements even with
limited monolingual data.",1,0,0,0,0,0,0.468666,6.0,0.655379,60
5e66d5ce-e9f1-4c56-adab-0d2c712c1d47,Explaining with Counter Visual Attributes and Examples,13,0.067721,0.242189,"In this paper, we aim to explain the decisions of neural networks by
utilizing multimodal information. That is counter-intuitive attributes and
counter visual examples which appear when perturbed samples are introduced.
Different from previous work on interpreting decisions using saliency maps,
text, or visual patches we propose to use attributes and counter-attributes,
and examples and counter-examples as part of the visual explanations. When
humans explain visual decisions they tend to do so by providing attributes and
examples. Hence, inspired by the way of human explanations in this paper we
provide attribute-based and example-based explanations. Moreover, humans also
tend to explain their visual decisions by adding counter-attributes and
counter-examples to explain what is not seen. We introduce directed
perturbations in the examples to observe which attribute values change when
classifying the examples into the counter classes. This delivers intuitive
counter-attributes and counter-examples. Our experiments with both coarse and
fine-grained datasets show that attributes provide discriminating and
human-understandable intuitive and counter-intuitive explanations.",0,0,0,0,0,0,0.856637,6.0,0.842412,40
d84b053b-9558-4878-9122-a39165415e20,Learning Disentangled Feature Representation for Hybrid-distorted Image Restoration,29,0.0944513,0.695152,"Hybrid-distorted image restoration (HD-IR) is dedicated to restore real
distorted image that is degraded by multiple distortions. Existing HD-IR
approaches usually ignore the inherent interference among hybrid distortions
which compromises the restoration performance. To decompose such interference,
we introduce the concept of Disentangled Feature Learning to achieve the
feature-level divide-and-conquer of hybrid distortions. Specifically, we
propose the feature disentanglement module (FDM) to distribute feature
representations of different distortions into different channels by revising
gain-control-based normalization. We also propose a feature aggregation module
(FAM) with channel-wise attention to adaptively filter out the distortion
representations and aggregate useful content information from different
channels for the construction of raw image. The effectiveness of the proposed
scheme is verified by visualizing the correlation matrix of features and
channel responses of different distortions. Extensive experimental results also
prove superior performance of our approach compared with the latest HD-IR
schemes.",0,1,0,0,1,0,0.695462,5.0,0.712728,45
dd041ed2-3050-48fe-8568-233cf54e6eb7,Multi-View Dynamic Heterogeneous Information Network Embedding,4,0.112886,0.198982,"Most existing Heterogeneous Information Network (HIN) embedding methods focus
on static environments while neglecting the evolving characteristic of
realworld networks. Although several dynamic embedding methods have been
proposed, they are merely designed for homogeneous networks and cannot be
directly applied in heterogeneous environment. To tackle above challenges, we
propose a novel framework for incorporating temporal information into HIN
embedding, denoted as Multi-View Dynamic HIN Embedding (MDHNE), which can
efficiently preserve evolution patterns of implicit relationships from
different views in updating node representations over time. We first transform
HIN to a series of homogeneous networks corresponding to different views. Then
our proposed MDHNE applies Recurrent Neural Network (RNN) to incorporate
evolving pattern of complex network structure and semantic relationships
between nodes into latent embedding spaces, and thus the node representations
from multiple views can be learned and updated when HIN evolves over time.
Moreover, we come up with an attention based fusion mechanism, which can
automatically infer weights of latent representations corresponding to
different views by minimizing the objective function specific for different
mining tasks. Extensive experiments clearly demonstrate that our MDHNE model
outperforms state-of-the-art baselines on three real-world dynamic datasets for
different network mining tasks.",0,0,0,0,1,0,0.95492,7.0,0.931678,34
29b893c0-86a6-4e60-9cd2-39796be70f59,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,43,0.930873,0.804343,"We introduce XED, a multilingual fine-grained emotion dataset. The dataset
consists of human-annotated Finnish (25k) and English sentences (30k), as well
as projected annotations for 30 additional languages, providing new resources
for many low-resource languages. We use Plutchik's core emotions to annotate
the dataset with the addition of neutral to create a multilabel multiclass
dataset. The dataset is carefully evaluated using language-specific BERT models
and SVMs to show that XED performs on par with other similar datasets and is
therefore a useful tool for sentiment analysis and emotion detection.",0,1,1,1,0,0,0.930909,8.0,0.921689,46
db1e85de-a679-4570-8979-4f67bdd002b7,SMAP: Single-Shot Multi-Person Absolute 3D Pose Estimation,76,0.211631,0.843578,"Recovering multi-person 3D poses with absolute scales from a single RGB image
is a challenging problem due to the inherent depth and scale ambiguity from a
single view. Addressing this ambiguity requires to aggregate various cues over
the entire image, such as body sizes, scene layouts, and inter-person
relationships. However, most previous methods adopt a top-down scheme that
first performs 2D pose detection and then regresses the 3D pose and scale for
each detected person individually, ignoring global contextual cues. In this
paper, we propose a novel system that first regresses a set of 2.5D
representations of body parts and then reconstructs the 3D absolute poses based
on these 2.5D representations with a depth-aware part association algorithm.
Such a single-shot bottom-up scheme allows the system to better learn and
reason about the inter-person depth relationship, improving both 3D and 2D pose
estimation. The experiments demonstrate that the proposed approach achieves the
state-of-the-art performance on the CMU Panoptic and MuPoTS-3D datasets and is
applicable to in-the-wild videos.",1,1,0,0,1,0,0.545521,6.0,0.692179,44
43ec6764-40b2-4574-9a2b-8654cb3c17f3,CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the Wild,89,0.569223,0.906369,"Human pose estimation from single images is a challenging problem in computer
vision that requires large amounts of labeled training data to be solved
accurately. Unfortunately, for many human activities (\eg outdoor sports) such
training data does not exist and is hard or even impossible to acquire with
traditional motion capture systems. We propose a self-supervised approach that
learns a single image 3D pose estimator from unlabeled multi-view data. To this
end, we exploit multi-view consistency constraints to disentangle the observed
2D pose into the underlying 3D pose and camera rotation. In contrast to most
existing methods, we do not require calibrated cameras and can therefore learn
from moving cameras. Nevertheless, in the case of a static camera setup, we
present an optional extension to include constant relative camera rotations
over multiple views into our framework. Key to the success are new, unbiased
reconstruction objectives that mix information across views and training
samples. The proposed approach is evaluated on two benchmark datasets
(Human3.6M and MPII-INF-3DHP) and on the in-the-wild SkiPose dataset.",0,1,0,0,1,0,0.739407,5.0,0.737361,55
ab3c5dcd-dd30-4027-81e8-a7b68a5d5c2c,Beneficial Perturbation Network for designing general adaptive artificial intelligence systems,13,0.110066,0.0927939,"The human brain is the gold standard of adaptive learning. It not only can
learn and benefit from experience, but also can adapt to new situations. In
contrast, deep neural networks only learn one sophisticated but fixed mapping
from inputs to outputs. This limits their applicability to more dynamic
situations, where input to output mapping may change with different contexts. A
salient example is continual learning - learning new independent tasks
sequentially without forgetting previous tasks. Continual learning of multiple
tasks in artificial neural networks using gradient descent leads to
catastrophic forgetting, whereby a previously learned mapping of an old task is
erased when learning new mappings for new tasks. Here, we propose a new
biologically plausible type of deep neural network with extra, out-of-network,
task-dependent biasing units to accommodate these dynamic situations. This
allows, for the first time, a single network to learn potentially unlimited
parallel input to output mappings, and to switch on the fly between them at
runtime. Biasing units are programmed by leveraging beneficial perturbations
(opposite to well-known adversarial perturbations) for each task. Beneficial
perturbations for a given task bias the network toward that task, essentially
switching the network into a different mode to process that task. This largely
eliminates catastrophic interference between tasks. Our approach is
memory-efficient and parameter-efficient, can accommodate many tasks, and
achieves state-of-the-art performance across different tasks and domains.",0,0,1,0,1,1,0.767062,8.0,0.845866,57
f59a9141-8fa3-4a3a-ba05-9d5d7a327cd0,Neural Stochastic Contraction Metrics for Learning-based Control and Estimation,34,0.0909798,0.505913,"We present Neural Stochastic Contraction Metrics (NSCM), a new design
framework for provably-stable robust control and estimation for a class of
stochastic nonlinear systems. It uses a spectrally-normalized deep neural
network to construct a contraction metric, sampled via simplified convex
optimization in the stochastic setting. Spectral normalization constrains the
state-derivatives of the metric to be Lipschitz continuous, thereby ensuring
exponential boundedness of the mean squared distance of system trajectories
under stochastic disturbances. The NSCM framework allows autonomous agents to
approximate optimal stable control and estimation policies in real-time, and
outperforms existing nonlinear control and estimation techniques including the
state-dependent Riccati equation, iterative LQR, EKF, and the deterministic
neural contraction metric, as illustrated in simulation results.",1,1,0,0,0,0,0.0200582,11.0,0.499233,32
38c17877-6e46-43e1-84b2-543099c3f3ee,Efficient Second-Order TreeCRF for Neural Dependency Parsing,91,0.349041,0.869399,"In the deep learning (DL) era, parsing models are extremely simplified with
little hurt on performance, thanks to the remarkable capability of multi-layer
BiLSTMs in context representation. As the most popular graph-based dependency
parser due to its high efficiency and performance, the biaffine parser directly
scores single dependencies under the arc-factorization assumption, and adopts a
very simple local token-wise cross-entropy training loss. This paper for the
first time presents a second-order TreeCRF extension to the biaffine parser.
For a long time, the complexity and inefficiency of the inside-outside
algorithm hinder the popularity of TreeCRF. To address this issue, we propose
an effective way to batchify the inside and Viterbi algorithms for direct large
matrix operation on GPUs, and to avoid the complex outside algorithm via
efficient back-propagation. Experiments and analysis on 27 datasets from 13
languages clearly show that techniques developed before the DL era, such as
structural learning (global TreeCRF loss) and high-order modeling are still
useful, and can further boost parsing performance over the state-of-the-art
biaffine parser, especially for partially annotated training data. We release
our code at https://github.com/yzhangcs/crfpar.",1,0,0,0,0,0,0.0908921,9.0,0.559972,49
5769a0d6-da40-4ebe-8064-e035a5bb54b8,DO-Conv: Depthwise Over-parameterized Convolutional Layer,119,0.978099,0.973137,"Convolutional layers are the core building blocks of Convolutional Neural
Networks (CNNs). In this paper, we propose to augment a convolutional layer
with an additional depthwise convolution, where each input channel is convolved
with a different 2D kernel. The composition of the two convolutions constitutes
an over-parameterization, since it adds learnable parameters, while the
resulting linear operation can be expressed by a single convolution layer. We
refer to this depthwise over-parameterized convolutional layer as DO-Conv. We
show with extensive experiments that the mere replacement of conventional
convolutional layers with DO-Conv layers boosts the performance of CNNs on many
classical vision tasks, such as image classification, detection, and
segmentation. Moreover, in the inference phase, the depthwise convolution is
folded into the conventional convolution, reducing the computation to be
exactly equivalent to that of a convolutional layer without
over-parameterization. As DO-Conv introduces performance gains without
incurring any computational complexity increase for inference, we advocate it
as an alternative to the conventional convolutional layer. We open-source a
reference implementation of DO-Conv in Tensorflow, PyTorch and GluonCV at
https://github.com/yangyanli/DO-Conv.",1,1,0,0,0,1,0.977474,7.0,0.960535,36
e9ba236a-daf3-4074-80ee-1bec20c45782,Fighting an Infodemic: COVID-19 Fake News Dataset,276,0.992439,0.999971,"Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news
and rumors are rampant on social media. Believing in rumors can cause
significant harm. This is further exacerbated at the time of a pandemic. To
tackle this, we curate and release a manually annotated dataset of 10,700
social media posts and articles of real and fake news on COVID-19. We benchmark
the annotated dataset with four machine learning baselines - Decision Tree,
Logistic Regression, Gradient Boost, and Support Vector Machine (SVM). We
obtain the best performance of 93.46% F1-score with SVM. The data and code is
available at: https://github.com/parthpatwa/covid19-fake-news-dectection",1,1,0,1,1,0,0.759729,9.0,0.860603,23
fee1b4d4-81a3-4a06-abea-76f7ddb1e10b,Probabilistic Model of Narratives Over Topical Trends in Social Media: A Discrete Time Model,14,0.275051,0.613605,"Online social media platforms are turning into the prime source of news and
narratives about worldwide events. However,a systematic summarization-based
narrative extraction that can facilitate communicating the main underlying
events is lacking. To address this issue, we propose a novel event-based
narrative summary extraction framework. Our proposed framework is designed as a
probabilistic topic model, with categorical time distribution, followed by
extractive text summarization. Our topic model identifies topics' recurrence
over time with a varying time resolution. This framework not only captures the
topic distributions from the data, but also approximates the user activity
fluctuations over time. Furthermore, we define significance-dispersity
trade-off (SDT) as a comparison measure to identify the topic with the highest
lifetime attractiveness in a timestamped corpus. We evaluate our model on a
large corpus of Twitter data, including more than one million tweets in the
domain of the disinformation campaigns conducted against the White Helmets of
Syria. Our results indicate that the proposed framework is effective in
identifying topical trends, as well as extracting narrative summaries from text
corpus with timestamped data.",0,0,0,0,0,0,0.469137,7.0,0.704811,45
5ce72e96-f10d-441d-a67d-77a44a47eda2,End-to-End Facial Deep Learning Feature Compression with Teacher-Student Enhancement,5,0.0416366,0.212356,"In this paper, we propose a novel end-to-end feature compression scheme by
leveraging the representation and learning capability of deep neural networks,
towards intelligent front-end equipped analysis with promising accuracy and
efficiency. In particular, the extracted features are compactly coded in an
end-to-end manner by optimizing the rate-distortion cost to achieve
feature-in-feature representation. In order to further improve the compression
performance, we present a latent code level teacher-student enhancement model,
which could efficiently transfer the low bit-rate representation into a high
bit rate one. Such a strategy further allows us to adaptively shift the
representation cost to decoding computations, leading to more flexible feature
compression with enhanced decoding capability. We verify the effectiveness of
the proposed model with the facial feature, and experimental results reveal
better compression performance in terms of rate-accuracy compared with existing
models.",0,1,0,0,0,0,0.564633,11.0,0.83692,26
fcc43856-0efa-4fdb-bd35-7d616d68a9d0,Multi-Camera Trajectory Forecasting: Pedestrian Trajectory Prediction in a Network of Cameras,16,0.393773,0.389381,"We introduce the task of multi-camera trajectory forecasting (MCTF), where
the future trajectory of an object is predicted in a network of cameras. Prior
works consider forecasting trajectories in a single camera view. Our work is
the first to consider the challenging scenario of forecasting across multiple
non-overlapping camera views. This has wide applicability in tasks such as
re-identification and multi-target multi-camera tracking. To facilitate
research in this new area, we release the Warwick-NTU Multi-camera Forecasting
Database (WNMF), a unique dataset of multi-camera pedestrian trajectories from
a network of 15 synchronized cameras. To accurately label this large dataset
(600 hours of video footage), we also develop a semi-automated annotation
method. An effective MCTF model should proactively anticipate where and when a
person will re-appear in the camera network. In this paper, we consider the
task of predicting the next camera a pedestrian will re-appear after leaving
the view of another camera, and present several baseline approaches for this.
The labeled database is available online:
https://github.com/olly-styles/Multi-Camera-Trajectory-Forecasting.",1,0,1,1,0,0,0.983155,7.0,0.97108,16
36a3d3bb-38dc-4284-8f63-ba818f071759,Imitative Planning using Conditional Normalizing Flow,6,0.035343,0.197014,"A popular way to plan trajectories in dynamic urban scenarios for Autonomous
Vehicles is to rely on explicitly specified and hand crafted cost functions,
coupled with random sampling in the trajectory space to find the minimum cost
trajectory. Such methods require a high number of samples to find a low-cost
trajectory and might end up with a highly suboptimal trajectory given the
planning time budget. We explore the application of normalizing flows for
improving the performance of trajectory planning for autonomous vehicles (AVs).
Our key insight is to learn a sampling policy in a low-dimensional latent space
of expert-like trajectories, out of which the best sample is selected for
execution. By modeling the trajectory planner's cost manifold as an energy
function, we learn a scene conditioned mapping from the prior to a Boltzmann
distribution over the AV control space. Finally, we demonstrate the
effectiveness of our approach on real-world datasets over IL and
hand-constructed trajectory sampling techniques.",0,1,0,0,0,0,0.882917,5.0,0.830729,40
52fa66a6-70f5-41a0-9f25-2b7fa5c3a826,Towards Safe Policy Improvement for Non-Stationary MDPs,31,0.271893,0.708082,"Many real-world sequential decision-making problems involve critical systems
with financial risks and human-life risks. While several works in the past have
proposed methods that are safe for deployment, they assume that the underlying
problem is stationary. However, many real-world problems of interest exhibit
non-stationarity, and when stakes are high, the cost associated with a false
stationarity assumption may be unacceptable. We take the first steps towards
ensuring safety, with high confidence, for smoothly-varying non-stationary
decision problems. Our proposed method extends a type of safe algorithm, called
a Seldonian algorithm, through a synthesis of model-free reinforcement learning
with time-series analysis. Safety is ensured using sequential hypothesis
testing of a policy's forecasted performance, and confidence intervals are
obtained using wild bootstrap.",0,1,0,0,0,0,0.168335,11.0,0.699955,70
398bac9d-e544-4c68-aafc-b84d658c510d,LSTM Networks for Online Cross-Network Recommendations,19,0.492831,0.153466,"Cross-network recommender systems use auxiliary information from multiple
source networks to create holistic user profiles and improve recommendations in
a target network. However, we find two major limitations in existing
cross-network solutions that reduce overall recommender performance. Existing
models (1) fail to capture complex non-linear relationships in user
interactions, and (2) are designed for offline settings hence, not updated
online with incoming interactions to capture the dynamics in the recommender
environment. We propose a novel multi-layered Long Short-Term Memory (LSTM)
network based online solution to mitigate these issues. The proposed model
contains three main extensions to the standard LSTM: First, an attention gated
mechanism to capture long-term user preference changes. Second, a higher order
interaction layer to alleviate data sparsity. Third, time aware LSTM cell gates
to capture irregular time intervals between user interactions. We illustrate
our solution using auxiliary information from Twitter and Google Plus to
improve recommendations on YouTube. Extensive experiments show that the
proposed model consistently outperforms state-of-the-art in terms of accuracy,
diversity and novelty.",0,1,0,0,1,0,0.814538,6.0,0.818712,49
75f54f5c-b99a-4852-b362-80af92114313,Consensus Clustering With Unsupervised Representation Learning,17,0.145376,0.249334,"Recent advances in deep clustering and unsupervised representation learning
are based on the idea that different views of an input image (generated through
data augmentation techniques) must either be closer in the representation
space, or have a similar cluster assignment. Bootstrap Your Own Latent (BYOL)
is one such representation learning algorithm that has achieved
state-of-the-art results in self-supervised image classification on ImageNet
under the linear evaluation protocol. However, the utility of the learnt
features of BYOL to perform clustering is not explored. In this work, we study
the clustering ability of BYOL and observe that features learnt using BYOL may
not be optimal for clustering. We propose a novel consensus clustering based
loss function, and train BYOL with the proposed loss in an end-to-end way that
improves the clustering ability and outperforms similar clustering based
methods on some popular computer vision datasets.",1,1,0,0,0,0,0.960983,10.0,0.95673,57
6f4aceb8-3a03-4aff-b519-e99323a4cc32,PA-GAN: Progressive Attention Generative Adversarial Network for Facial Attribute Editing,25,0.321257,0.664587,"Facial attribute editing aims to manipulate attributes on the human face,
e.g., adding a mustache or changing the hair color. Existing approaches suffer
from a serious compromise between correct attribute generation and preservation
of the other information such as identity and background, because they edit the
attributes in the imprecise area. To resolve this dilemma, we propose a
progressive attention GAN (PA-GAN) for facial attribute editing. In our
approach, the editing is progressively conducted from high to low feature level
while being constrained inside a proper attribute area by an attention mask at
each level. This manner prevents undesired modifications to the irrelevant
regions from the beginning, and then the network can focus more on correctly
generating the attributes within a proper boundary at each level. As a result,
our approach achieves correct attribute editing with irrelevant details much
better preserved compared with the state-of-the-arts. Codes are released at
https://github.com/LynnHo/PA-GAN-Tensorflow.",1,1,0,0,1,0,0.843162,6.0,0.83452,42
513b6cce-874b-49a2-8bc3-6e69ab1c77f8,Comparison and Benchmarking of AI Models and Frameworks on Mobile Devices,47,0.231356,0.720113,"Due to increasing amounts of data and compute resources, deep learning
achieves many successes in various domains. The application of deep learning on
the mobile and embedded devices is taken more and more attentions, benchmarking
and ranking the AI abilities of mobile and embedded devices becomes an urgent
problem to be solved. Considering the model diversity and framework diversity,
we propose a benchmark suite, AIoTBench, which focuses on the evaluation of the
inference abilities of mobile and embedded devices. AIoTBench covers three
typical heavy-weight networks: ResNet50, InceptionV3, DenseNet121, as well as
three light-weight networks: SqueezeNet, MobileNetV2, MnasNet. Each network is
implemented by three frameworks which are designed for mobile and embedded
devices: Tensorflow Lite, Caffe2, Pytorch Mobile. To compare and rank the AI
capabilities of the devices, we propose two unified metrics as the AI scores:
Valid Images Per Second (VIPS) and Valid FLOPs Per Second (VOPS). Currently, we
have compared and ranked 5 mobile devices using our benchmark. This list will
be extended and updated soon after.",0,1,1,0,0,0,0.771559,8.0,0.847528,47
8d84e6e3-f860-4ede-ba61-e737ad1820ee,Trainable Structure Tensors for Autonomous Baggage Threat Detection Under Extreme Occlusion,33,0.0285509,0.209801,"Detecting baggage threats is one of the most difficult tasks, even for expert
officers. Many researchers have developed computer-aided screening systems to
recognize these threats from the baggage X-ray scans. However, all of these
frameworks are limited in identifying the contraband items under extreme
occlusion. This paper presents a novel instance segmentation framework that
utilizes trainable structure tensors to highlight the contours of the occluded
and cluttered contraband items (by scanning multiple predominant orientations),
while simultaneously suppressing the irrelevant baggage content. The proposed
framework has been extensively tested on four publicly available X-ray datasets
where it outperforms the state-of-the-art frameworks in terms of mean average
precision scores. Furthermore, to the best of our knowledge, it is the only
framework that has been validated on combined grayscale and colored scans
obtained from four different types of X-ray scanners.",1,1,0,0,1,0,0.03694,6.0,0.185144,48
73616189-86ac-4fed-92d8-739c9f7aa792,Toward Tag-free Aspect Based Sentiment Analysis: A Multiple Attention Network Approach,11,0.182371,0.29451,"Existing aspect based sentiment analysis (ABSA) approaches leverage various
neural network models to extract the aspect sentiments via learning
aspect-specific feature representations. However, these approaches heavily rely
on manual tagging of user reviews according to the predefined aspects as the
input, a laborious and time-consuming process. Moreover, the underlying methods
do not explain how and why the opposing aspect level polarities in a user
review lead to the overall polarity. In this paper, we tackle these two
problems by designing and implementing a new Multiple-Attention Network (MAN)
approach for more powerful ABSA without the need for aspect tags using two new
tag-free data sets crawled directly from TripAdvisor
({https://www.tripadvisor.com}). With the Self- and Position-Aware attention
mechanism, MAN is capable of extracting both aspect level and overall
sentiments from the text reviews using the aspect level and overall customer
ratings, and it can also detect the vital aspect(s) leading to the overall
sentiment polarity among different aspects via a new aspect ranking scheme. We
carry out extensive experiments to demonstrate the strong performance of MAN
compared to other state-of-the-art ABSA approaches and the explainability of
our approach by visualizing and interpreting attention weights in case studies.",1,1,0,1,1,0,0.777876,9.0,0.86656,48
d16797c1-3bb6-4852-ae90-cbd0893e1a31,Deep Global Registration,384,0.919247,1.0,"We present Deep Global Registration, a differentiable framework for pairwise
registration of real-world 3D scans. Deep global registration is based on three
modules: a 6-dimensional convolutional network for correspondence confidence
prediction, a differentiable Weighted Procrustes algorithm for closed-form pose
estimation, and a robust gradient-based SE(3) optimizer for pose refinement.
Experiments demonstrate that our approach outperforms state-of-the-art methods,
both learning-based and classical, on real-world data.",1,1,0,0,1,0,0.747376,9.0,0.856626,54
b41f9051-9e5e-433f-a204-47c004016afe,Video Anomaly Detection by Estimating Likelihood of Representations,12,0.222702,0.232695,"Video anomaly detection is a challenging task not only because it involves
solving many sub-tasks such as motion representation, object localization and
action recognition, but also because it is commonly considered as an
unsupervised learning problem that involves detecting outliers. Traditionally,
solutions to this task have focused on the mapping between video frames and
their low-dimensional features, while ignoring the spatial connections of those
features. Recent solutions focus on analyzing these spatial connections by
using hard clustering techniques, such as K-Means, or applying neural networks
to map latent features to a general understanding, such as action attributes.
In order to solve video anomaly in the latent feature space, we propose a deep
probabilistic model to transfer this task into a density estimation problem
where latent manifolds are generated by a deep denoising autoencoder and
clustered by expectation maximization. Evaluations on several benchmarks
datasets show the strengths of our model, achieving outstanding performance on
challenging datasets.",0,1,0,0,1,0,0.989621,7.0,0.987089,45
2dc1ff85-a4f3-4394-9c26-7e1994a7a591,Animating Pictures with Eulerian Motion Fields,45,0.349802,0.676088,"In this paper, we demonstrate a fully automatic method for converting a still
image into a realistic animated looping video. We target scenes with continuous
fluid motion, such as flowing water and billowing smoke. Our method relies on
the observation that this type of natural motion can be convincingly reproduced
from a static Eulerian motion description, i.e. a single, temporally constant
flow field that defines the immediate motion of a particle at a given 2D
location. We use an image-to-image translation network to encode motion priors
of natural scenes collected from online videos, so that for a new photo, we can
synthesize a corresponding motion field. The image is then animated using the
generated motion through a deep warping technique: pixels are encoded as deep
features, those features are warped via Eulerian motion, and the resulting
warped feature maps are decoded as images. In order to produce continuous,
seamlessly looping video textures, we propose a novel video looping technique
that flows features both forward and backward in time and then blends the
results. We demonstrate the effectiveness and robustness of our method by
applying it to a large collection of examples including beaches, waterfalls,
and flowing rivers.",0,1,0,0,0,0,0.274975,7.0,0.607994,36
4a9136f9-d332-4852-9f09-49b2897a62b9,"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention",19,0.0814055,0.420398,"Attentive video modeling is essential for action recognition in unconstrained
videos due to their rich yet redundant information over space and time.
However, introducing attention in a deep neural network for action recognition
is challenging for two reasons. First, an effective attention module needs to
learn what (objects and their local motion patterns), where (spatially), and
when (temporally) to focus on. Second, a video attention module must be
efficient because existing action recognition models already suffer from high
computational cost. To address both challenges, a novel What-Where-When (W3)
video attention module is proposed. Departing from existing alternatives, our
W3 module models all three facets of video attention jointly. Crucially, it is
extremely efficient by factorizing the high-dimensional video feature data into
low-dimensional meaningful spaces (1D channel vector for `what' and 2D spatial
tensors for `where'), followed by lightweight temporal attention reasoning.
Extensive experiments show that our attention model brings significant
improvements to existing action recognition models, achieving new
state-of-the-art performance on a number of benchmarks.",0,1,0,0,1,0,0.811955,5.0,0.780806,65
ffc50a34-251a-41b4-950a-1b26a9c4e27a,Unsupervised Neural Aspect Search with Related Terms Extraction,2,0.0174931,0.049856,"The tasks of aspect identification and term extraction remain challenging in
natural language processing. While supervised methods achieve high scores, it
is hard to use them in real-world applications due to the lack of labelled
datasets. Unsupervised approaches outperform these methods on several tasks,
but it is still a challenge to extract both an aspect and a corresponding term,
particularly in the multi-aspect setting. In this work, we present a novel
unsupervised neural network with convolutional multi-attention mechanism, that
allows extracting pairs (aspect, term) simultaneously, and demonstrate the
effectiveness on the real-world dataset. We apply a special loss aimed to
improve the quality of multi-aspect extraction. The experimental study
demonstrates, what with this loss we increase the precision not only on this
joint setting but also on aspect prediction only.",0,0,0,0,0,0,0.352221,8.0,0.694541,12
49e5bb1f-be97-4633-af20-a2f6036d1246,Finding Berries: Segmentation and Counting of Cranberries using Point Supervision and Shape Priors,21,0.333518,0.569918,"Precision agriculture has become a key factor for increasing crop yields by
providing essential information to decision makers. In this work, we present a
deep learning method for simultaneous segmentation and counting of cranberries
to aid in yield estimation and sun exposure predictions. Notably, supervision
is done using low cost center point annotations. The approach, named Triple-S
Network, incorporates a three-part loss with shape priors to promote better
fitting to objects of known shape typical in agricultural scenes. Our results
improve overall segmentation performance by more than 6.74% and counting
results by 22.91% when compared to state-of-the-art. To train and evaluate the
network, we have collected the CRanberry Aerial Imagery Dataset (CRAID), the
largest dataset of aerial drone imagery from cranberry fields. This dataset
will be made publicly available.",0,1,0,1,1,0,0.799931,10.0,0.886623,52
87c9b6d1-bb36-42b6-a282-bfc3cfa69f50,State Representation and Polyomino Placement for the Game Patchwork,1,0.0148851,0.0516434,"Modern board games are a rich source of entertainment for many people, but
also contain interesting and challenging structures for game playing research
and implementing game playing agents. This paper studies the game Patchwork, a
two player strategy game using polyomino tile drafting and placement. The core
polyomino placement mechanic is implemented in a constraint model using regular
constraints, extending and improving the model in (Lagerkvist, Pesant, 2008)
with: explicit rotation handling; optional placements; and new constraints for
resource usage. Crucial for implementing good game playing agents is to have
great heuristics for guiding the search when faced with large branching
factors. This paper divides placing tiles into two parts: a policy used for
placing parts and an evaluation used to select among different placements.
Policies are designed based on classical packing literature as well as common
standard constraint programming heuristics. For evaluation, global propagation
guided regret is introduced, choosing placements based on not ruling out later
placements. Extensive evaluations are performed, showing the importance of
using a good evaluation and that the proposed global propagation guided regret
is a very effective guide.",0,1,0,0,0,0,0.00927764,22.0,0.714321,26
ea6024ff-501a-4d22-8f22-5457282d613a,Hierarchical Image Classification using Entailment Cone Embeddings,44,0.171758,0.637672,"Image classification has been studied extensively, but there has been limited
work in using unconventional, external guidance other than traditional
image-label pairs for training. We present a set of methods for leveraging
information about the semantic hierarchy embedded in class labels. We first
inject label-hierarchy knowledge into an arbitrary CNN-based classifier and
empirically show that availability of such external semantic information in
conjunction with the visual semantics from images boosts overall performance.
Taking a step further in this direction, we model more explicitly the
label-label and label-image interactions using order-preserving embeddings
governed by both Euclidean and hyperbolic geometries, prevalent in natural
language, and tailor them to hierarchical image classification and
representation learning. We empirically validate all the models on the
hierarchical ETHEC dataset.",0,0,0,0,0,0,0.491105,6.0,0.66638,28
5b1683e7-2e9e-46c5-aa5f-093ba8db47cc,Multimodal Categorization of Crisis Events in Social Media,59,0.845357,0.780773,"Recent developments in image classification and natural language processing,
coupled with the rapid growth in social media usage, have enabled fundamental
advances in detecting breaking events around the world in real-time. Emergency
response is one such area that stands to gain from these advances. By
processing billions of texts and images a minute, events can be automatically
detected to enable emergency response workers to better assess rapidly evolving
situations and deploy resources accordingly. To date, most event detection
techniques in this area have focused on image-only or text-only approaches,
limiting detection performance and impacting the quality of information
delivered to crisis response teams. In this paper, we present a new multimodal
fusion method that leverages both images and texts as input. In particular, we
introduce a cross-attention module that can filter uninformative and misleading
components from weak modalities on a sample by sample basis. In addition, we
employ a multimodal graph-based approach to stochastically transition between
embeddings of different multimodal pairs during training to better regularize
the learning process as well as dealing with limited training data by
constructing new matched pairs from different samples. We show that our method
outperforms the unimodal approaches and strong multimodal baselines by a large
margin on three crisis-related tasks.",0,1,0,0,1,0,0.913154,6.0,0.880674,83
f4d2918e-3453-4f34-9509-c7904231f7c4,Machine Translation of Mathematical Text,9,0.0150612,0.193043,"We have implemented a machine translation system, the PolyMath Translator,
for LaTeX documents containing mathematical text. The current implementation
translates English LaTeX to French LaTeX, attaining a BLEU score of 53.5 on a
held-out test corpus of mathematical sentences. It produces LaTeX documents
that can be compiled to PDF without further editing. The system first converts
the body of an input LaTeX document into English sentences containing math
tokens, using the pandoc universal document converter to parse LaTeX input. We
have trained a Transformer-based translator model, using OpenNMT, on a combined
corpus containing a small proportion of domain-specific sentences. Our full
system uses both this Transformer model and Google Translate, the latter being
used as a backup to better handle linguistic features that do not appear in our
training dataset. If the Transformer model does not have confidence in its
translation, as determined by a high perplexity score, then we use Google
Translate with a custom glossary. This backup was used 26% of the time on our
test corpus of mathematical sentences. The PolyMath Translator is available as
a web service at www.polymathtrans.ai.",0,1,0,0,0,0,0.0698031,6.0,0.294074,33
5835a124-d8ab-4f3a-b6a0-fd1aea37e9be,Sarcasm Detection in Tweets with BERT and GloVe Embeddings,33,0.654253,0.141696,"Sarcasm is a form of communication in whichthe person states opposite of what
he actually means. It is ambiguous in nature. In this paper, we propose using
machine learning techniques with BERT and GloVe embeddings to detect sarcasm in
tweets. The dataset is preprocessed before extracting the embeddings. The
proposed model also uses the context in which the user is reacting to along
with his actual response.",0,1,0,0,0,0,0.986416,16.0,0.990557,21
42a59550-52cd-4c7d-8563-0ecd7a9a2754,Learning Regular Expressions for Interpretable Medical Text Classification Using a Pool-based Simulated Annealing and Word-vector Models,1,0.0238334,0.0169784,"In this paper, we propose a rule-based engine composed of high quality and
interpretable regular expressions for medical text classification. The regular
expressions are auto generated by a constructive heuristic method and optimized
using a Pool-based Simulated Annealing (PSA) approach. Although existing Deep
Neural Network (DNN) methods present high quality performance in most Natural
Language Processing (NLP) applications, the solutions are regarded as
uninterpretable black boxes to humans. Therefore, rule-based methods are often
introduced when interpretable solutions are needed, especially in the medical
field. However, the construction of regular expressions can be extremely
labor-intensive for large data sets. This research aims to reduce the manual
efforts while maintaining high-quality solutions",0,1,0,0,0,0,0.239086,16.0,0.818321,22
11ae1d4c-8a3b-4557-8839-2aa4738ce56a,A Deeper Look into Hybrid Images,2,0.0112046,0.0609005,"$Hybrid$ $images$ was first introduced by Olivia et al., that produced static
images with two interpretations such that the images changes as a function of
viewing distance. Hybrid images are built by studying human processing of
multiscale images and are motivated by masking studies in visual perception.
The first introduction of hybrid images showed that two images can be blend
together with a high pass filter and a low pass filter in such a way that when
the blended image is viewed from a distance, the high pass filter fades away
and the low pass filter becomes prominent. Our main aim here is to study and
review the original paper by changing and tweaking certain parameters to see
how they affect the quality of the blended image produced. We have used
exhaustively different set of images and filters to see how they function and
whether this can be used in a real time system or not.",0,1,0,0,0,0,0.944342,1.0,0.451308,15
b9085dec-fc4a-49fd-95fb-e7ef2f0dfa05,A Simple Yet Strong Pipeline for HotpotQA,37,0.0619428,0.246701,"State-of-the-art models for multi-hop question answering typically augment
large-scale language models like BERT with additional, intuitively useful
capabilities such as named entity recognition, graph-based reasoning, and
question decomposition. However, does their strong performance on popular
multi-hop datasets really justify this added design complexity? Our results
suggest that the answer may be no, because even our simple pipeline based on
BERT, named Quark, performs surprisingly well. Specifically, on HotpotQA, Quark
outperforms these models on both question answering and support identification
(and achieves performance very close to a RoBERTa model). Our pipeline has
three steps: 1) use BERT to identify potentially relevant sentences
independently of each other; 2) feed the set of selected sentences as context
into a standard BERT span prediction model to choose an answer; and 3) use the
sentence selection model, now with the chosen answer, to produce supporting
sentences. The strong performance of Quark resurfaces the importance of
carefully exploring simple model designs before using popular benchmarks to
justify the value of complex techniques.",0,1,0,0,0,0,0.841278,2.0,0.500326,18
70a22255-815d-4dab-9f4a-01a1e107d209,Fast Complete Algorithm for Multiplayer Nash Equilibrium,6,0.042743,0.373302,"We describe a new complete algorithm for computing Nash equilibrium in
multiplayer general-sum games, based on a quadratically-constrained feasibility
program formulation. We demonstrate that the algorithm runs significantly
faster than the prior fastest complete algorithm on several game classes
previously studied and that its runtimes even outperform the best incomplete
algorithms.",0,0,0,0,0,0,0.000427974,28.0,0.665512,25
65bc9cfa-2b14-4cce-9319-aa0f61a97f52,Many-Objective Software Remodularization using NSGA-III,231,0.42938,0.984854,"Software systems nowadays are complex and difficult to maintain due to
continuous changes and bad design choices. To handle the complexity of systems,
software products are, in general, decomposed in terms of packages/modules
containing classes that are dependent. However, it is challenging to
automatically remodularize systems to improve their maintainability. The
majority of existing remodularization work mainly satisfy one objective which
is improving the structure of packages by optimizing coupling and cohesion. In
addition, most of existing studies are limited to only few operation types such
as move class and split packages. Many other objectives, such as the design
semantics, reducing the number of changes and maximizing the consistency with
development change history, are important to improve the quality of the
software by remodularizing it. In this paper, we propose a novel many-objective
search-based approach using NSGA-III. The process aims at finding the optimal
remodularization solutions that improve the structure of packages, minimize the
number of changes, preserve semantics coherence, and re-use the history of
changes. We evaluate the efficiency of our approach using four different
open-source systems and one automotive industry project, provided by our
industrial partner, through a quantitative and qualitative study conducted with
software engineers.",0,1,0,0,0,0,0.0248714,9.0,0.412121,101
04c19693-aa7e-4eb2-b986-38c31a5beeae,Word Rotator's Distance,48,0.13796,0.841104,"A key principle in assessing textual similarity is measuring the degree of
semantic overlap between two texts by considering the word alignment. Such
alignment-based approaches are intuitive and interpretable; however, they are
empirically inferior to the simple cosine similarity between general-purpose
sentence vectors. To address this issue, we focus on and demonstrate the fact
that the norm of word vectors is a good proxy for word importance, and their
angle is a good proxy for word similarity. Alignment-based approaches do not
distinguish them, whereas sentence-vector approaches automatically use the norm
as the word importance. Accordingly, we propose a method that first decouples
word vectors into their norm and direction, and then computes alignment-based
similarity using earth mover's distance (i.e., optimal transport cost), which
we refer to as word rotator's distance. Besides, we find how to grow the norm
and direction of word vectors (vector converter), which is a new systematic
approach derived from sentence-vector estimation methods. On several textual
similarity datasets, the combination of these simple proposed methods
outperformed not only alignment-based approaches but also strong baselines. The
source code is available at https://github.com/eumesy/wrd",1,0,0,0,0,1,0.356877,8.0,0.6966,78
78e77522-9fd4-47cb-8009-ee8906211cc1,Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages,30,0.141657,0.477043,"Unsupervised translation has reached impressive performance on resource-rich
language pairs such as English-French and English-German. However, early
studies have shown that in more realistic settings involving low-resource, rare
languages, unsupervised translation performs poorly, achieving less than 3.0
BLEU. In this work, we show that multilinguality is critical to making
unsupervised systems practical for low-resource settings. In particular, we
present a single model for 5 low-resource languages (Gujarati, Kazakh, Nepali,
Sinhala, and Turkish) to and from English directions, which leverages
monolingual and auxiliary parallel data from other high-resource language pairs
via a three-stage training scheme. We outperform all current state-of-the-art
unsupervised baselines for these languages, achieving gains of up to 14.4 BLEU.
Additionally, we outperform a large collection of supervised WMT submissions
for various language pairs as well as match the performance of the current
state-of-the-art supervised model for Nepali-English. We conduct a series of
ablation studies to establish the robustness of our model under different
degrees of data quality, as well as to analyze the factors which led to the
superior performance of the proposed approach over traditional unsupervised
models.",0,1,0,0,1,0,0.681648,5.0,0.705123,53
e5a167c5-fedf-4f3f-8157-ed6eebf3bac6,Self-Supervised Human Depth Estimation from Monocular Videos,30,0.136764,0.654761,"Previous methods on estimating detailed human depth often require supervised
training with `ground truth' depth data. This paper presents a self-supervised
method that can be trained on YouTube videos without known depth, which makes
training data collection simple and improves the generalization of the learned
network. The self-supervised learning is achieved by minimizing a
photo-consistency loss, which is evaluated between a video frame and its
neighboring frames warped according to the estimated depth and the 3D non-rigid
motion of the human body. To solve this non-rigid motion, we first estimate a
rough SMPL model at each video frame and compute the non-rigid body motion
accordingly, which enables self-supervised learning on estimating the shape
details. Experiments demonstrate that our method enjoys better generalization
and performs much better on data in the wild.",0,1,0,0,0,0,0.842881,5.0,0.801231,54
9a69bcdf-5f88-424b-aae3-92cbc8e4012f,Scalable Backdoor Detection in Neural Networks,21,0.27909,0.0924435,"Recently, it has been shown that deep learning models are vulnerable to
Trojan attacks, where an attacker can install a backdoor during training time
to make the resultant model misidentify samples contaminated with a small
trigger patch. Current backdoor detection methods fail to achieve good
detection performance and are computationally expensive. In this paper, we
propose a novel trigger reverse-engineering based approach whose computational
complexity does not scale with the number of labels, and is based on a measure
that is both interpretable and universal across different network and patch
types. In experiments, we observe that our method achieves a perfect score in
separating Trojaned models from pure models, which is an improvement over the
current state-of-the art method.",0,1,0,0,1,0,0.959464,4.0,0.888864,23
ba9e0717-cda2-41d7-9710-3542b97b5383,"Development of a Dataset and a Deep Learning Baseline Named Entity Recognizer for Three Low Resource Languages: Bhojpuri, Maithili and Magahi",4,0.0245966,0.152659,"In Natural Language Processing (NLP) pipelines, Named Entity Recognition
(NER) is one of the preliminary problems, which marks proper nouns and other
named entities such as Location, Person, Organization, Disease etc. Such
entities, without a NER module, adversely affect the performance of a machine
translation system. NER helps in overcoming this problem by recognising and
handling such entities separately, although it can be useful in Information
Extraction systems also. Bhojpuri, Maithili and Magahi are low resource
languages, usually known as Purvanchal languages. This paper focuses on the
development of a NER benchmark dataset for the Machine Translation systems
developed to translate from these languages to Hindi by annotating parts of
their available corpora. Bhojpuri, Maithili and Magahi corpora of sizes 228373,
157468 and 56190 tokens, respectively, were annotated using 22 entity labels.
The annotation considers coarse-grained annotation labels followed by the
tagset used in one of the Hindi NER datasets. We also report a Deep Learning
based baseline that uses an LSTM-CNNs-CRF model. The lower baseline F1-scores
from the NER tool obtained by using Conditional Random Fields models are 96.73
for Bhojpuri, 93.33 for Maithili and 95.04 for Magahi. The Deep Learning-based
technique (LSTM-CNNs-CRF) achieved 96.25 for Bhojpuri, 93.33 for Maithili and
95.44 for Magahi.",0,1,1,1,1,0,0.0027432,15.0,0.499554,43
0cce0677-3ffb-4a8a-a55d-b7d2e1441ab2,Better Highlighting: Creating Sub-Sentence Summary Highlights,11,0.0425796,0.397802,"Amongst the best means to summarize is highlighting. In this paper, we aim to
generate summary highlights to be overlaid on the original documents to make it
easier for readers to sift through a large amount of text. The method allows
summaries to be understood in context to prevent a summarizer from distorting
the original meaning, of which abstractive summarizers usually fall short. In
particular, we present a new method to produce self-contained highlights that
are understandable on their own to avoid confusion. Our method combines
determinantal point processes and deep contextualized representations to
identify an optimal set of sub-sentence segments that are both important and
non-redundant to form summary highlights. To demonstrate the flexibility and
modeling power of our method, we conduct extensive experiments on summarization
datasets. Our analysis provides evidence that highlighting is a promising
avenue of research towards future summarization.",1,1,0,0,0,1,0.173475,8.0,0.591574,55
48c63cda-ff8d-4958-885f-dbc2ba611f8a,Exploit Multiple Reference Graphs for Semi-supervised Relation Extraction,8,0.0591801,0.22366,"Manual annotation of the labeled data for relation extraction is
time-consuming and labor-intensive. Semi-supervised methods can offer helping
hands for this problem and have aroused great research interests. Existing work
focuses on mapping the unlabeled samples to the classes to augment the labeled
dataset. However, it is hard to find an overall good mapping function,
especially for the samples with complicated syntactic components in one
sentence.
  To tackle this limitation, we propose to build the connection between the
unlabeled data and the labeled ones rather than directly mapping the unlabeled
samples to the classes. Specifically, we first use three kinds of information
to construct reference graphs, including entity reference, verb reference, and
semantics reference. The goal is to semantically or lexically connect the
unlabeled sample(s) to the labeled one(s). Then, we develop a Multiple
Reference Graph (MRefG) model to exploit the reference information for better
recognizing high-quality unlabeled samples. The effectiveness of our method is
demonstrated by extensive comparison experiments with the state-of-the-art
baselines on two public datasets.",0,1,0,0,1,0,0.508051,9.0,0.783022,39
2fcc04af-4f5a-4d81-ba11-b9267eeca9f6,A Transductive Approach for Video Object Segmentation,103,0.496293,0.717195,"Semi-supervised video object segmentation aims to separate a target object
from a video sequence, given the mask in the first frame. Most of current
prevailing methods utilize information from additional modules trained in other
domains like optical flow and instance segmentation, and as a result they do
not compete with other methods on common ground. To address this issue, we
propose a simple yet strong transductive method, in which additional modules,
datasets, and dedicated architectural designs are not needed. Our method takes
a label propagation approach where pixel labels are passed forward based on
feature similarity in an embedding space. Different from other propagation
methods, ours diffuses temporal information in a holistic manner which take
accounts of long-term object appearance. In addition, our method requires few
additional computational overhead, and runs at a fast $\sim$37 fps speed. Our
single model with a vanilla ResNet50 backbone achieves an overall score of 72.3
on the DAVIS 2017 validation set and 63.1 on the test set. This simple yet high
performing and efficient method can serve as a solid baseline that facilitates
future research. Code and models are available at
\url{https://github.com/microsoft/transductive-vos.pytorch}.",1,1,0,0,1,0,0.862007,7.0,0.867705,52
27a4368e-3907-440e-a598-f544f1e87c4f,Finding Sparse Structures for Domain Specific Neural Machine Translation,25,0.06019,0.696148,"Neural machine translation often adopts the fine-tuning approach to adapt to
specific domains. However, nonrestricted fine-tuning can easily degrade on the
general domain and over-fit to the target domain. To mitigate the issue, we
propose Prune-Tune, a novel domain adaptation method via gradual pruning. It
learns tiny domain-specific sub-networks during fine-tuning on new domains.
Prune-Tune alleviates the over-fitting and the degradation problem without
model modification. Furthermore, Prune-Tune is able to sequentially learn a
single network with multiple disjoint domain-specific sub-networks for multiple
domains. Empirical experiment results show that Prune-Tune outperforms several
strong competitors in the target domain test set without sacrificing the
quality on the general domain in both single and multi-domain settings. The
source code and data are available at https://github.com/ohlionel/Prune-Tune.",1,1,0,0,1,0,0.181187,8.0,0.597578,48
0735901b-8112-4a1e-9b62-d3d95a8cb844,SpotTheFake: An Initial Report on a New CNN-Enhanced Platform for Counterfeit Goods Detection,4,0.154733,0.383252,"The counterfeit goods trade represents nowadays more than 3.3% of the whole
world trade and thus it's a problem that needs now more than ever a lot of
attention and a reliable solution that would reduce the negative impact it has
over the modern society. This paper presents the design and early stage
development of a novel counterfeit goods detection platform that makes use of
the outstsanding learning capabilities of the classical VGG16 convolutional
model trained through the process of ""transfer learning"" and a multi-stage fake
detection procedure that proved to be not only reliable but also very robust in
the experiments we have conducted so far using an image dataset of various
goods which we gathered ourselves.",0,1,0,1,0,0,0.521448,12.0,0.840449,12
ce219629-d489-4edc-ac2c-f80e3e523af4,Spatial Semantic Embedding Network: Fast 3D Instance Segmentation with Deep Metric Learning,14,0.23,0.19895,"We propose spatial semantic embedding network (SSEN), a simple, yet efficient
algorithm for 3D instance segmentation using deep metric learning. The raw 3D
reconstruction of an indoor environment suffers from occlusions, noise, and is
produced without any meaningful distinction between individual entities. For
high-level intelligent tasks from a large scale scene, 3D instance segmentation
recognizes individual instances of objects. We approach the instance
segmentation by simply learning the correct embedding space that maps
individual instances of objects into distinct clusters that reflect both
spatial and semantic information. Unlike previous approaches that require
complex pre-processing or post-processing, our implementation is compact and
fast with competitive performance, maintaining scalability on large scenes with
high resolution voxels. We demonstrate the state-of-the-art performance of our
algorithm in the ScanNet 3D instance segmentation benchmark on AP score.",1,1,0,0,1,0,0.972965,6.0,0.94574,39
58e57051-edae-452b-afaa-48eceb72f526,Current Advancements on Autonomous Mission Planning and Management Systems: an AUV and UAV perspective,58,0.753299,0.90043,"Advances in hardware technology have enabled more integration of
sophisticated software, triggering progress in the development and employment
of Unmanned Vehicles (UVs), and mitigating restraints for onboard intelligence.
As a result, UVs can now take part in more complex mission where continuous
transformation in environmental condition calls for a higher level of
situational responsiveness. This paper serves as an introduction to UVs mission
planning and management systems aiming to highlight some of the recent
developments in the field of autonomous underwater and aerial vehicles in
addition to stressing some possible future directions and discussing the
learned lessons. A comprehensive survey over autonomy assessment of UVs, and
different aspects of autonomy such as situation awareness, cognition, and
decision-making has been provided in this study. The paper separately explains
the humanoid and autonomous system's performance and highlights the role and
impact of a human in UVs operations.",0,0,0,0,0,0,0.00306051,16.0,0.537683,117
4916a00b-23d3-468c-b218-c8533e9586bc,Exploiting Visual Semantic Reasoning for Video-Text Retrieval,31,0.33277,0.565548,"Video retrieval is a challenging research topic bridging the vision and
language areas and has attracted broad attention in recent years. Previous
works have been devoted to representing videos by directly encoding from
frame-level features. In fact, videos consist of various and abundant semantic
relations to which existing methods pay less attention. To address this issue,
we propose a Visual Semantic Enhanced Reasoning Network (ViSERN) to exploit
reasoning between frame regions. Specifically, we consider frame regions as
vertices and construct a fully-connected semantic correlation graph. Then, we
perform reasoning by novel random walk rule-based graph convolutional networks
to generate region features involved with semantic relations. With the benefit
of reasoning, semantic interactions between regions are considered, while the
impact of redundancy is suppressed. Finally, the region features are aggregated
to form frame-level features for further encoding to measure video-text
similarity. Extensive experiments on two public benchmark datasets validate the
effectiveness of our method by achieving state-of-the-art performance due to
the powerful semantic reasoning.",0,0,0,0,1,0,0.96623,9.0,0.956762,32
b94800b9-1026-4e9e-badb-16dc780fd059,Knowledge Patterns,103,0.28407,0.812883,"This paper describes a new technique, called ""knowledge patterns"", for
helping construct axiom-rich, formal ontologies, based on identifying and
explicitly representing recurring patterns of knowledge (theory schemata) in
the ontology, and then stating how those patterns map onto domain-specific
concepts in the ontology. From a modeling perspective, knowledge patterns
provide an important insight into the structure of a formal ontology: rather
than viewing a formal ontology simply as a list of terms and axioms, knowledge
patterns views it as a collection of abstract, modular theories (the ""knowledge
patterns"") plus a collection of modeling decisions stating how different
aspects of the world can be modeled using those theories. Knowledge patterns
make both those abstract theories and their mappings to the domain of interest
explicit, thus making modeling decisions clear, and avoiding some of the
ontological confusion that can otherwise arise. In addition, from a
computational perspective, knowledge patterns provide a simple and
computationally efficient mechanism for facilitating knowledge reuse. We
describe the technique and an application built using them, and then critique
its strengths and weaknesses. We conclude that this technique enables us to
better explicate both the structure and modeling decisions made when
constructing a formal axiom-rich ontology.",0,0,0,0,0,0,1.4877e-14,58.0,0.423275,22
5f6c5330-e243-4a92-bcd8-7e1e4b47e5ed,PolicyQA: A Reading Comprehension Dataset for Privacy Policies,33,0.898672,0.853616,"Privacy policy documents are long and verbose. A question answering (QA)
system can assist users in finding the information that is relevant and
important to them. Prior studies in this domain frame the QA task as retrieving
the most relevant text segment or a list of sentences from the policy document
given a question. On the contrary, we argue that providing users with a short
text span from policy documents reduces the burden of searching the target
information from a lengthy text segment. In this paper, we present PolicyQA, a
dataset that contains 25,017 reading comprehension style examples curated from
an existing corpus of 115 website privacy policies. PolicyQA provides 714
human-annotated questions written for a wide range of privacy practices. We
evaluate two existing neural QA models and perform rigorous analysis to reveal
the advantages and challenges offered by PolicyQA.",0,1,0,0,0,0,0.957143,9.0,0.948658,28
d172c261-8616-4d74-8bf1-3f6b17e81c22,Streaming Attention-Based Models with Augmented Memory for End-to-End Speech Recognition,7,0.0628102,0.308336,"Attention-based models have been gaining popularity recently for their strong
performance demonstrated in fields such as machine translation and automatic
speech recognition. One major challenge of attention-based models is the need
of access to the full sequence and the quadratically growing computational cost
concerning the sequence length. These characteristics pose challenges,
especially for low-latency scenarios, where the system is often required to be
streaming. In this paper, we build a compact and streaming speech recognition
system on top of the end-to-end neural transducer architecture with
attention-based modules augmented with convolution. The proposed system equips
the end-to-end models with the streaming capability and reduces the large
footprint from the streaming attention-based model using augmented memory. On
the LibriSpeech dataset, our proposed system achieves word error rates 2.7% on
test-clean and 5.8% on test-other, to our best knowledge the lowest among
streaming approaches reported so far.",0,1,0,0,0,0,0.892083,4.0,0.797736,27
157ace55-af3f-462a-9b6f-e634913e08ae,DIET: Lightweight Language Understanding for Dialogue Systems,137,0.625365,0.804272,"Large-scale pre-trained language models have shown impressive results on
language understanding benchmarks like GLUE and SuperGLUE, improving
considerably over other pre-training methods like distributed representations
(GloVe) and purely supervised approaches. We introduce the Dual Intent and
Entity Transformer (DIET) architecture, and study the effectiveness of
different pre-trained representations on intent and entity prediction, two
common dialogue language understanding tasks. DIET advances the state of the
art on a complex multi-domain NLU dataset and achieves similarly high
performance on other simpler datasets. Surprisingly, we show that there is no
clear benefit to using large pre-trained models for this task, and in fact DIET
improves upon the current state of the art even in a purely supervised setup
without any pre-trained embeddings. Our best performing model outperforms
fine-tuning BERT and is about six times faster to train.",1,1,0,0,1,0,0.92819,4.0,0.839741,49
4688b8ad-67ec-44b0-a7e1-f77f0f191051,PaStaNet: Toward Human Activity Knowledge Engine,124,0.467866,0.993355,"Existing image-based activity understanding methods mainly adopt direct
mapping, i.e. from image to activity concepts, which may encounter performance
bottleneck since the huge gap. In light of this, we propose a new path: infer
human part states first and then reason out the activities based on part-level
semantics. Human Body Part States (PaSta) are fine-grained action semantic
tokens, e.g. <hand, hold, something>, which can compose the activities and help
us step toward human activity knowledge engine. To fully utilize the power of
PaSta, we build a large-scale knowledge base PaStaNet, which contains 7M+ PaSta
annotations. And two corresponding models are proposed: first, we design a
model named Activity2Vec to extract PaSta features, which aim to be general
representations for various activities. Second, we use a PaSta-based Reasoning
method to infer activities. Promoted by PaStaNet, our method achieves
significant improvements, e.g. 6.4 and 13.9 mAP on full and one-shot sets of
HICO in supervised learning, and 3.2 and 4.2 mAP on V-COCO and images-based AVA
in transfer learning. Code and data are available at http://hake-mvig.cn/.",1,1,1,1,1,0,0.47584,10.0,0.795354,64
3f3ba75f-cdcd-48c3-bd26-e8ab2697059e,CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers,61,0.785539,0.706003,"Dialogue state trackers have made significant progress on benchmark datasets,
but their generalization capability to novel and realistic scenarios beyond the
held-out conversations is less understood. We propose controllable
counterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking
(DST) models on novel scenarios, i.e., would the system successfully tackle the
request if the user responded differently but still consistently with the
dialogue flow? CoCo leverages turn-level belief states as counterfactual
conditionals to produce novel conversation scenarios in two steps: (i)
counterfactual goal generation at turn-level by dropping and adding slots
followed by replacing slot values, (ii) counterfactual conversation generation
that is conditioned on (i) and consistent with the dialogue flow. Evaluating
state-of-the-art DST models on MultiWOZ dataset with CoCo-generated
counterfactuals results in a significant performance drop of up to 30.8% (from
49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used
techniques like paraphrasing only affect the accuracy by at most 2%. Human
evaluations show that COCO-generated conversations perfectly reflect the
underlying user goal with more than 95% accuracy and are as human-like as the
original conversations, further strengthening its reliability and promise to be
adopted as part of the robustness evaluation of DST models.",0,1,1,0,0,0,0.980979,3.0,0.922456,48
757cf0fa-99e1-477f-b63f-079a78b80f8f,Knowledge Association with Hyperbolic Knowledge Graph Embeddings,71,0.498506,0.918601,"Capturing associations for knowledge graphs (KGs) through entity alignment,
entity type inference and other related tasks benefits NLP applications with
comprehensive knowledge representations. Recent related methods built on
Euclidean embeddings are challenged by the hierarchical structures and
different scales of KGs. They also depend on high embedding dimensions to
realize enough expressiveness. Differently, we explore with low-dimensional
hyperbolic embeddings for knowledge association. We propose a hyperbolic
relational graph neural network for KG embedding and capture knowledge
associations with a hyperbolic transformation. Extensive experiments on entity
alignment and type inference demonstrate the effectiveness and efficiency of
our method.",0,1,0,0,0,0,0.829817,4.0,0.74051,69
cf298b09-708c-4480-be41-b4a89ba3b80d,Joint Spatial-Temporal Optimization for Stereo 3D Object Tracking,15,0.207682,0.555632,"Directly learning multiple 3D objects motion from sequential images is
difficult, while the geometric bundle adjustment lacks the ability to localize
the invisible object centroid. To benefit from both the powerful object
understanding skill from deep neural network meanwhile tackle precise geometry
modeling for consistent trajectory estimation, we propose a joint
spatial-temporal optimization-based stereo 3D object tracking method. From the
network, we detect corresponding 2D bounding boxes on adjacent images and
regress an initial 3D bounding box. Dense object cues (local depth and local
coordinates) that associating to the object centroid are then predicted using a
region-based network. Considering both the instant localization accuracy and
motion consistency, our optimization models the relations between the object
centroid and observed cues into a joint spatial-temporal error function. All
historic cues will be summarized to contribute to the current estimation by a
per-frame marginalization strategy without repeated computation. Quantitative
evaluation on the KITTI tracking dataset shows our approach outperforms
previous image-based 3D tracking methods by significant margins. We also report
extensive results on multiple categories and larger datasets (KITTI raw and
Argoverse Tracking) for future benchmarking.",0,1,0,0,1,0,0.975083,5.0,0.939357,54
0fac6129-d06c-4525-9e65-83ff5e9e733f,Improving Human-Labeled Data through Dynamic Automatic Conflict Resolution,10,0.147462,0.385633,"This paper develops and implements a scalable methodology for (a) estimating
the noisiness of labels produced by a typical crowdsourcing semantic annotation
task, and (b) reducing the resulting error of the labeling process by as much
as 20-30% in comparison to other common labeling strategies. Importantly, this
new approach to the labeling process, which we name Dynamic Automatic Conflict
Resolution (DACR), does not require a ground truth dataset and is instead based
on inter-project annotation inconsistencies. This makes DACR not only more
accurate but also available to a broad range of labeling tasks. In what follows
we present results from a text classification task performed at scale for a
commercial personal assistant, and evaluate the inherent ambiguity uncovered by
this annotation strategy as compared to other common labeling strategies.",0,1,0,0,0,1,0.0793171,17.0,0.758664,40
84ece8aa-51a5-4d48-b55d-ceaf0994ccbd,Medical Knowledge-enriched Textual Entailment Framework,7,0.0850517,0.0901526,"One of the cardinal tasks in achieving robust medical question answering
systems is textual entailment. The existing approaches make use of an ensemble
of pre-trained language models or data augmentation, often to clock higher
numbers on the validation metrics. However, two major shortcomings impede
higher success in identifying entailment: (1) understanding the focus/intent of
the question and (2) ability to utilize the real-world background knowledge to
capture the context beyond the sentence. In this paper, we present a novel
Medical Knowledge-Enriched Textual Entailment framework that allows the model
to acquire a semantic and global representation of the input medical text with
the help of a relevant domain-specific knowledge graph. We evaluate our
framework on the benchmark MEDIQA-RQE dataset and manifest that the use of
knowledge enriched dual-encoding mechanism help in achieving an absolute
improvement of 8.27% over SOTA language models. We have made the source code
available here.",1,1,0,0,1,0,0.693897,4.0,0.63983,27
06996112-a99c-4599-a887-ce3895ec062e,Explainable CNN-attention Networks (C-Attention Network) for Automated Detection of Alzheimer's Disease,20,0.415922,0.292744,"In this work, we propose three explainable deep learning architectures to
automatically detect patients with Alzheimer`s disease based on their language
abilities. The architectures use: (1) only the part-of-speech features; (2)
only language embedding features and (3) both of these feature classes via a
unified architecture. We use self-attention mechanisms and interpretable
1-dimensional ConvolutionalNeural Network (CNN) to generate two types of
explanations of the model`s action: intra-class explanation and inter-class
explanation. The inter-class explanation captures the relative importance of
each of the different features in that class, while the inter-class explanation
captures the relative importance between the classes. Note that although we
have considered two classes of features in this paper, the architecture is
easily expandable to more classes because of its modularity. Extensive
experimentation and comparison with several recent models show that our method
outperforms these methods with an accuracy of 92.2% and F1 score of 0.952on the
DementiaBank dataset while being able to generate explanations. We show by
examples, how to generate these explanations using attention values.",0,1,0,0,1,0,0.90288,8.0,0.904651,46
622e46e4-85bb-4f98-9c73-dcfcd7167b72,Multi-task Learning for Multilingual Neural Machine Translation,63,0.244495,0.8939,"While monolingual data has been shown to be useful in improving bilingual
neural machine translation (NMT), effectively and efficiently leveraging
monolingual data for Multilingual NMT (MNMT) systems is a less explored area.
In this work, we propose a multi-task learning (MTL) framework that jointly
trains the model with the translation task on bitext data and two denoising
tasks on the monolingual data. We conduct extensive empirical studies on MNMT
systems with 10 language pairs from WMT datasets. We show that the proposed
approach can effectively improve the translation quality for both high-resource
and low-resource languages with large margin, achieving significantly better
results than the individual bilingual models. We also demonstrate the efficacy
of the proposed approach in the zero-shot setup for language pairs without
bitext training data. Furthermore, we show the effectiveness of MTL over
pre-training approaches for both NMT and cross-lingual transfer learning NLU
tasks; the proposed approach outperforms massive scale models trained on single
task.",0,1,0,0,0,0,0.679431,7.0,0.788505,56
48d834ac-0bf7-49c5-a2fb-a63f2a8b2b17,PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization,539,0.867466,0.999994,"We present a new framework for Patch Distribution Modeling, PaDiM, to
concurrently detect and localize anomalies in images in a one-class learning
setting. PaDiM makes use of a pretrained convolutional neural network (CNN) for
patch embedding, and of multivariate Gaussian distributions to get a
probabilistic representation of the normal class. It also exploits correlations
between the different semantic levels of CNN to better localize anomalies.
PaDiM outperforms current state-of-the-art approaches for both anomaly
detection and localization on the MVTec AD and STC datasets. To match
real-world visual industrial inspection, we extend the evaluation protocol to
assess performance of anomaly localization algorithms on non-aligned dataset.
The state-of-the-art performance and low complexity of PaDiM make it a good
candidate for many industrial applications.",0,1,0,0,1,0,0.863313,4.0,0.769682,32
c6b037ee-239e-4805-a290-10da02ac481f,DaNetQA: a yes/no Question Answering Dataset for the Russian Language,10,0.0171338,0.0936418,"DaNetQA, a new question-answering corpus, follows (Clark et. al, 2019)
design: it comprises natural yes/no questions. Each question is paired with a
paragraph from Wikipedia and an answer, derived from the paragraph. The task is
to take both the question and a paragraph as input and come up with a yes/no
answer, i.e. to produce a binary output. In this paper, we present a
reproducible approach to DaNetQA creation and investigate transfer learning
methods for task and language transferring. For task transferring we leverage
three similar sentence modelling tasks: 1) a corpus of paraphrases,
Paraphraser, 2) an NLI task, for which we use the Russian part of XNLI, 3)
another question answering task, SberQUAD. For language transferring we use
English to Russian translation together with multilingual language fine-tuning.",1,1,1,1,0,0,0.37213,5.0,0.52515,25
43e6eec8-4432-4883-a460-4ddb60ec719e,ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for Mobile Manipulation,72,0.672141,0.99125,"Many Reinforcement Learning (RL) approaches use joint control signals
(positions, velocities, torques) as action space for continuous control tasks.
We propose to lift the action space to a higher level in the form of subgoals
for a motion generator (a combination of motion planner and trajectory
executor). We argue that, by lifting the action space and by leveraging
sampling-based motion planners, we can efficiently use RL to solve complex,
long-horizon tasks that could not be solved with existing RL methods in the
original action space. We propose ReLMoGen -- a framework that combines a
learned policy to predict subgoals and a motion generator to plan and execute
the motion needed to reach these subgoals. To validate our method, we apply
ReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation
problems where interactions with the environment are required to reach the
destination, and 2) Mobile Manipulation tasks, manipulation tasks that require
moving the robot base. These problems are challenging because they are usually
long-horizon, hard to explore during training, and comprise alternating phases
of navigation and interaction. Our method is benchmarked on a diverse set of
seven robotics tasks in photo-realistic simulation environments. In all
settings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and
Hierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding
transferability between different motion generators at test time, indicating a
great potential to transfer to real robots.",0,1,0,0,1,0,0.906995,5.0,0.851121,59
e6995fbe-4b79-42d9-86d7-ea3f48900b54,Automatically Identifying Gender Issues in Machine Translation using Perturbations,33,0.0557181,0.4281,"The successful application of neural methods to machine translation has
realized huge quality advances for the community. With these improvements, many
have noted outstanding challenges, including the modeling and treatment of
gendered language. While previous studies have identified issues using
synthetic examples, we develop a novel technique to mine examples from real
world data to explore challenges for deployed systems. We use our method to
compile an evaluation benchmark spanning examples for four languages from three
language families, which we publicly release to facilitate research. The
examples in our benchmark expose where model representations are gendered, and
the unintended consequences these gendered representations can have in
downstream application.",0,1,0,1,0,0,0.557962,4.0,0.546916,15
a150c1bc-d2ad-4a4c-a027-ce087249c4ca,PRover: Proof Generation for Interpretable Reasoning over Rules,72,0.269577,0.998208,"Recent work by Clark et al. (2020) shows that transformers can act as 'soft
theorem provers' by answering questions over explicitly provided knowledge in
natural language. In our work, we take a step closer to emulating formal
theorem provers, by proposing PROVER, an interpretable transformer-based model
that jointly answers binary questions over rule-bases and generates the
corresponding proofs. Our model learns to predict nodes and edges corresponding
to proof graphs in an efficient constrained training paradigm. During
inference, a valid proof, satisfying a set of global constraints is generated.
We conduct experiments on synthetic, hand-authored, and human-paraphrased
rule-bases to show promising results for QA and proof generation, with strong
generalization performance. First, PROVER generates proofs with an accuracy of
87%, while retaining or improving performance on the QA task, compared to
RuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trained
on questions requiring lower depths of reasoning, it generalizes significantly
better to higher depths (up to 15% improvement). Third, PROVER obtains near
perfect QA accuracy of 98% using only 40% of the training data. However,
generating proofs for questions requiring higher depths of reasoning becomes
challenging, and the accuracy drops to 65% for 'depth 5', indicating
significant scope for future work. Our code and models are publicly available
at https://github.com/swarnaHub/PRover",1,0,0,0,0,0,0.603414,5.0,0.662491,49
a4445499-fb06-4e46-96c7-ab48248efcc6,UPB at SemEval-2020 Task 9: Identifying Sentiment in Code-Mixed Social Media Texts using Transformers and Multi-Task Learning,9,0.0958644,0.330586,"Sentiment analysis is a process widely used in opinion mining campaigns
conducted today. This phenomenon presents applications in a variety of fields,
especially in collecting information related to the attitude or satisfaction of
users concerning a particular subject. However, the task of managing such a
process becomes noticeably more difficult when it is applied in cultures that
tend to combine two languages in order to express ideas and thoughts. By
interleaving words from two languages, the user can express with ease, but at
the cost of making the text far less intelligible for those who are not
familiar with this technique, but also for standard opinion mining algorithms.
In this paper, we describe the systems developed by our team for SemEval-2020
Task 9 that aims to cover two well-known code-mixed languages: Hindi-English
and Spanish-English.
  We intend to solve this issue by introducing a solution that takes advantage
of several neural network approaches, as well as pre-trained word embeddings.
Our approach (multlingual BERT) achieves promising performance on the
Hindi-English task, with an average F1-score of 0.6850, registered on the
competition leaderboard, ranking our team 16th out of 62 participants. For the
Spanish-English task, we obtained an average F1-score of 0.7064 ranking our
team 17th out of 29 participants by using another multilingual
Transformer-based model, XLM-RoBERTa.",0,1,0,0,0,0,0.578466,7.0,0.749173,27
6dd596e3-b5cc-4738-9591-2ee7d9814d12,A Methodological Approach to Model CBR-based Systems,2,0.014355,0.111915,"Artificial intelligence (AI) has been used in various areas to support system
optimization and find solutions where the complexity makes it challenging to
use algorithmic and heuristics. Case-based Reasoning (CBR) is an AI technique
intensively exploited in domains like management, medicine, design,
construction, retail and smart grid. CBR is a technique for problem-solving and
captures new knowledge by using past experiences. One of the main CBR
deployment challenges is the target system modeling process. This paper
presents a straightforward methodological approach to model CBR-based
applications using the concepts of abstract and concrete models. Splitting the
modeling process with two models facilitates the allocation of expertise
between the application domain and the CBR technology. The methodological
approach intends to facilitate the CBR modeling process and to foster CBR use
in various areas outside computer science.",0,1,0,0,0,1,0.175864,5.0,0.349533,32
fff1df6f-c12f-4af3-8f55-49e05898d688,Glottal Source Estimation using an Automatic Chirp Decomposition,7,0.0171452,0.152803,"In a previous work, we showed that the glottal source can be estimated from
speech signals by computing the Zeros of the Z-Transform (ZZT). Decomposition
was achieved by separating the roots inside (causal contribution) and outside
(anticausal contribution) the unit circle. In order to guarantee a correct
deconvolution, time alignment on the Glottal Closure Instants (GCIs) was shown
to be essential. This paper extends the formalism of ZZT by evaluating the
Z-transform on a contour possibly different from the unit circle. A method is
proposed for determining automatically this contour by inspecting the root
distribution. The derived Zeros of the Chirp Z-Transform (ZCZT)-based technique
turns out to be much more robust to GCI location errors.",0,1,0,0,0,0,1.85607e-06,20.0,0.259676,20
97374895-05ce-4124-ac72-4e55539623b4,A Semi-Supervised Assessor of Neural Architectures,58,0.211374,0.660491,"Neural architecture search (NAS) aims to automatically design deep neural
networks of satisfactory performance. Wherein, architecture performance
predictor is critical to efficiently value an intermediate neural architecture.
But for the training of this predictor, a number of neural architectures and
their corresponding real performance often have to be collected. In contrast
with classical performance predictor optimized in a fully supervised way, this
paper suggests a semi-supervised assessor of neural architectures. We employ an
auto-encoder to discover meaningful representations of neural architectures.
Taking each neural architecture as an individual instance in the search space,
we construct a graph to capture their intrinsic similarities, where both
labeled and unlabeled architectures are involved. A graph convolutional neural
network is introduced to predict the performance of architectures based on the
learned representations and their relation modeled by the graph. Extensive
experimental results on the NAS-Benchmark-101 dataset demonstrated that our
method is able to make a significant reduction on the required fully trained
architectures for finding efficient architectures.",0,0,0,0,0,0,0.761347,5.0,0.750031,54
ca72722e-5f4f-4e49-8058-4eac27e75e67,Robust Detection of Objects under Periodic Motion with Gaussian Process Filtering,5,0.00437924,0.0350484,"Object Detection (OD) is an important task in Computer Vision with many
practical applications. For some use cases, OD must be done on videos, where
the object of interest has a periodic motion. In this paper, we formalize the
problem of periodic OD, which consists in improving the performance of an OD
model in the specific case where the object of interest is repeating similar
spatio-temporal trajectories with respect to the video frames. The proposed
approach is based on training a Gaussian Process to model the periodic motion,
and use it to filter out the erroneous predictions of the OD model. By
simulating various OD models and periodic trajectories, we demonstrate that
this filtering approach, which is entirely data-driven, improves the detection
performance by a large margin.",0,1,0,0,0,0,0.101341,7.0,0.450608,25
776d4608-7c73-4b20-ba95-f6171edee474,Miss the Point: Targeted Adversarial Attack on Multiple Landmark Detection,29,0.284019,0.362101,"Recent methods in multiple landmark detection based on deep convolutional
neural networks (CNNs) reach high accuracy and improve traditional clinical
workflow. However, the vulnerability of CNNs to adversarial-example attacks can
be easily exploited to break classification and segmentation tasks. This paper
is the first to study how fragile a CNN-based model on multiple landmark
detection to adversarial perturbations. Specifically, we propose a novel
Adaptive Targeted Iterative FGSM (ATI-FGSM) attack against the state-of-the-art
models in multiple landmark detection. The attacker can use ATI-FGSM to
precisely control the model predictions of arbitrarily selected landmarks,
while keeping other stationary landmarks still, by adding imperceptible
perturbations to the original image. A comprehensive evaluation on a public
dataset for cephalometric landmark detection demonstrates that the adversarial
examples generated by ATI-FGSM break the CNN-based network more effectively and
efficiently, compared with the original Iterative FGSM attack. Our work reveals
serious threats to patients' health. Furthermore, we discuss the limitations of
our method and provide potential defense directions, by investigating the
coupling effect of nearby landmarks, i.e., a major source of divergence in our
experiments. Our source code is available at
https://github.com/qsyao/attack_landmark_detection.",1,1,0,0,1,0,0.409543,8.0,0.718717,32
9b58961d-da1e-4dc1-b89e-2a9f9cd99126,Design and Implementation of TAG: A Tabletop Games Framework,8,0.172114,0.598455,"This document describes the design and implementation of the Tabletop Games
framework (TAG), a Java-based benchmark for developing modern board games for
AI research. TAG provides a common skeleton for implementing tabletop games
based on a common API for AI agents, a set of components and classes to easily
add new games and an import module for defining data in JSON format. At
present, this platform includes the implementation of seven different tabletop
games that can also be used as an example for further developments.
Additionally, TAG also incorporates logging functionality that allows the user
to perform a detailed analysis of the game, in terms of action space, branching
factor, hidden information, and other measures of interest for Game AI
research. The objective of this document is to serve as a central point where
the framework can be described at length. TAG can be downloaded at:
https://github.com/GAIGResearch/TabletopGames",0,1,0,0,0,0,0.0310698,12.0,0.577899,14
687e55a6-8a6c-45d2-836a-26a78eec6c4c,Neural gradients are near-lognormal: improved quantized and sparse training,34,0.0199759,0.192381,"While training can mostly be accelerated by reducing the time needed to
propagate neural gradients back throughout the model, most previous works focus
on the quantization/pruning of weights and activations. These methods are often
not applicable to neural gradients, which have very different statistical
properties. Distinguished from weights and activations, we find that the
distribution of neural gradients is approximately lognormal. Considering this,
we suggest two closed-form analytical methods to reduce the computational and
memory burdens of neural gradients. The first method optimizes the
floating-point format and scale of the gradients. The second method accurately
sets sparsity thresholds for gradient pruning. Each method achieves
state-of-the-art results on ImageNet. To the best of our knowledge, this paper
is the first to (1) quantize the gradients to 6-bit floating-point formats, or
(2) achieve up to 85% gradient sparsity -- in each case without accuracy
degradation. Reference implementation accompanies the paper.",0,1,0,0,1,0,0.137278,5.0,0.295547,37
04416950-68eb-4d6a-b14f-dac0174a89ef,What they do when in doubt: a study of inductive biases in seq2seq learners,21,0.105003,0.25709,"Sequence-to-sequence (seq2seq) learners are widely used, but we still have
only limited knowledge about what inductive biases shape the way they
generalize. We address that by investigating how popular seq2seq learners
generalize in tasks that have high ambiguity in the training data. We use SCAN
and three new tasks to study learners' preferences for memorization,
arithmetic, hierarchical, and compositional reasoning. Further, we connect to
Solomonoff's theory of induction and propose to use description length as a
principled and sensitive measure of inductive biases.
  In our experimental study, we find that LSTM-based learners can learn to
perform counting, addition, and multiplication by a constant from a single
training example. Furthermore, Transformer and LSTM-based learners show a bias
toward the hierarchical induction over the linear one, while CNN-based learners
prefer the opposite. On the SCAN dataset, we find that CNN-based, and, to a
lesser degree, Transformer- and LSTM-based learners have a preference for
compositional generalization over memorization. Finally, across all our
experiments, description length proved to be a sensitive measure of inductive
biases.",1,0,0,0,0,0,0.713794,5.0,0.722908,54
18326449-1695-4c15-9832-92fe2bed5b5e,Towards Achieving Adversarial Robustness by Enforcing Feature Consistency Across Bit Planes,29,0.113171,0.384342,"As humans, we inherently perceive images based on their predominant features,
and ignore noise embedded within lower bit planes. On the contrary, Deep Neural
Networks are known to confidently misclassify images corrupted with
meticulously crafted perturbations that are nearly imperceptible to the human
eye. In this work, we attempt to address this problem by training networks to
form coarse impressions based on the information in higher bit planes, and use
the lower bit planes only to refine their prediction. We demonstrate that, by
imposing consistency on the representations learned across differently
quantized images, the adversarial robustness of networks improves significantly
when compared to a normally trained model. Present state-of-the-art defenses
against adversarial attacks require the networks to be explicitly trained using
adversarial samples that are computationally expensive to generate. While such
methods that use adversarial training continue to achieve the best results,
this work paves the way towards achieving robustness without having to
explicitly train on adversarial samples. The proposed approach is therefore
faster, and also closer to the natural learning process in humans.",1,1,0,0,0,0,0.8965,6.0,0.868257,44
0cc54005-1f6b-4e39-9660-9c6cdc765780,Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning,60,0.416195,0.284279,"Continual learning studies agents that learn from streams of tasks without
forgetting previous ones while adapting to new ones. Two recent
continual-learning scenarios have opened new avenues of research. In
meta-continual learning, the model is pre-trained to minimize catastrophic
forgetting of previous tasks. In continual-meta learning, the aim is to train
agents for faster remembering of previous tasks through adaptation. In their
original formulations, both methods have limitations. We stand on their
shoulders to propose a more general scenario, OSAKA, where an agent must
quickly solve new (out-of-distribution) tasks, while also requiring fast
remembering. We show that current continual learning, meta-learning,
meta-continual learning, and continual-meta learning techniques fail in this
new scenario. We propose Continual-MAML, an online extension of the popular
MAML algorithm as a strong baseline for this scenario. We empirically show that
Continual-MAML is better suited to the new scenario than the aforementioned
methodologies, as well as standard continual learning and meta-learning
approaches.",1,0,0,0,0,0,0.920843,4.0,0.830319,84
cb118896-0b23-4fe2-a46e-1c4da41b6de9,Finding Universal Grammatical Relations in Multilingual BERT,134,0.531474,0.698268,"Recent work has found evidence that Multilingual BERT (mBERT), a
transformer-based multilingual masked language model, is capable of zero-shot
cross-lingual transfer, suggesting that some aspects of its representations are
shared cross-lingually. To better understand this overlap, we extend recent
work on finding syntactic trees in neural networks' internal representations to
the multilingual setting. We show that subspaces of mBERT representations
recover syntactic tree distances in languages other than English, and that
these subspaces are approximately shared across languages. Motivated by these
results, we present an unsupervised analysis method that provides evidence
mBERT learns representations of syntactic dependency labels, in the form of
clusters which largely agree with the Universal Dependencies taxonomy. This
evidence suggests that even without explicit supervision, multilingual masked
language models learn certain linguistic universals.",1,0,0,0,0,0,0.963243,2.0,0.79276,33
89598b0f-56ec-4537-b6cf-a47a77669b67,Harmonic Convolutional Networks based on Discrete Cosine Transform,25,0.0221222,0.199358,"Convolutional neural networks (CNNs) learn filters in order to capture local
correlation patterns in feature space. We propose to learn these filters as
combinations of preset spectral filters defined by the Discrete Cosine
Transform (DCT). Our proposed DCT-based harmonic blocks replace conventional
convolutional layers to produce partially or fully harmonic versions of new or
existing CNN architectures. Using DCT energy compaction properties, we
demonstrate how the harmonic networks can be efficiently compressed by
truncating high-frequency information in harmonic blocks thanks to the
redundancies in the spectral domain. We report extensive experimental
validation demonstrating benefits of the introduction of harmonic blocks into
state-of-the-art CNN models in image classification, object detection and
semantic segmentation applications.",0,0,0,0,0,0,0.124169,7.0,0.48143,77
8278e729-d6da-44ad-8546-a658a38f18d7,Exercise Hierarchical Feature Enhanced Knowledge Tracing,13,0.203766,0.354164,"Knowledge tracing is a fundamental task in the computer-aid educational
system. In this paper, we propose a hierarchical exercise feature enhanced
knowledge tracing framework, which could enhance the ability of knowledge
tracing by incorporating knowledge distribution, semantic features, and
difficulty features from exercise text. Extensive experiments show the high
performance of our framework.",0,1,0,0,0,0,0.418889,23.0,0.90346,10
641f70f9-0b2f-49be-a402-583229ca8ffd,"Writing Polishment with Simile: Task, Dataset and A Neural Approach",16,0.0595053,0.304925,"A simile is a figure of speech that directly makes a comparison, showing
similarities between two different things, e.g. ""Reading papers can be dull
sometimes,like watching grass grow"". Human writers often interpolate
appropriate similes into proper locations of the plain text to vivify their
writings. However, none of existing work has explored neural simile
interpolation, including both locating and generation. In this paper, we
propose a new task of Writing Polishment with Simile (WPS) to investigate
whether machines are able to polish texts with similes as we human do.
Accordingly, we design a two-staged Locate&Gen model based on transformer
architecture. Our model firstly locates where the simile interpolation should
happen, and then generates a location-specific simile. We also release a
large-scale Chinese Simile (CS) dataset containing 5 million similes with
context. The experimental results demonstrate the feasibility of WPS task and
shed light on the future research directions towards better automatic text
polishment.",1,0,1,1,0,0,0.586633,4.0,0.566651,44
11b1023a-3aa5-49d5-8193-8f0491b4b9a7,HeteGCN: Heterogeneous Graph Convolutional Networks for Text Classification,70,0.342981,0.659824,"We consider the problem of learning efficient and inductive graph
convolutional networks for text classification with a large number of examples
and features. Existing state-of-the-art graph embedding based methods such as
predictive text embedding (PTE) and TextGCN have shortcomings in terms of
predictive performance, scalability and inductive capability. To address these
limitations, we propose a heterogeneous graph convolutional network (HeteGCN)
modeling approach that unites the best aspects of PTE and TextGCN together. The
main idea is to learn feature embeddings and derive document embeddings using a
HeteGCN architecture with different graphs used across layers. We simplify
TextGCN by dissecting into several HeteGCN models which (a) helps to study the
usefulness of individual models and (b) offers flexibility in fusing learned
embeddings from different models. In effect, the number of model parameters is
reduced significantly, enabling faster training and improving performance in
small labeled training set scenario. Our detailed experimental studies
demonstrate the efficacy of the proposed approach.",1,1,0,0,0,0,0.833035,12.0,0.914397,40
585546ae-61b7-490a-a0ab-e8c9276de94b,Learning to Decouple Relations: Few-Shot Relation Classification with Entity-Guided Attention and Confusion-Aware Training,34,0.291309,0.658722,"This paper aims to enhance the few-shot relation classification especially
for sentences that jointly describe multiple relations. Due to the fact that
some relations usually keep high co-occurrence in the same context, previous
few-shot relation classifiers struggle to distinguish them with few annotated
instances. To alleviate the above relation confusion problem, we propose CTEG,
a model equipped with two mechanisms to learn to decouple these easily-confused
relations. On the one hand, an Entity-Guided Attention (EGA) mechanism, which
leverages the syntactic relations and relative positions between each word and
the specified entity pair, is introduced to guide the attention to filter out
information causing confusion. On the other hand, a Confusion-Aware Training
(CAT) method is proposed to explicitly learn to distinguish relations by
playing a pushing-away game between classifying a sentence into a true relation
and its confusing relation. Extensive experiments are conducted on the FewRel
dataset, and the results show that our proposed model achieves comparable and
even much better results to strong baselines in terms of accuracy. Furthermore,
the ablation test and case study verify the effectiveness of our proposed EGA
and CAT, especially in addressing the relation confusion problem.",0,1,0,0,0,0,0.612729,7.0,0.762546,29
0fa95fba-e61b-40f8-a2b9-f8e019617b06,Learning Perception and Planning with Deep Active Inference,29,0.303195,0.267571,"Active inference is a process theory of the brain that states that all living
organisms infer actions in order to minimize their (expected) free energy.
However, current experiments are limited to predefined, often discrete, state
spaces. In this paper we use recent advances in deep learning to learn the
state space and approximate the necessary probability distributions to engage
in active inference.",0,0,0,0,0,0,0.263526,13.0,0.785077,12
045c42e6-4b06-43b9-b42a-f39de8ec4389,StressGAN: A Generative Deep Learning Model for 2D Stress Distribution Prediction,17,0.617052,0.798396,"Using deep learning to analyze mechanical stress distributions has been
gaining interest with the demand for fast stress analysis methods. Deep
learning approaches have achieved excellent outcomes when utilized to speed up
stress computation and learn the physics without prior knowledge of underlying
equations. However, most studies restrict the variation of geometry or boundary
conditions, making these methods difficult to be generalized to unseen
configurations. We propose a conditional generative adversarial network (cGAN)
model for predicting 2D von Mises stress distributions in solid structures. The
cGAN learns to generate stress distributions conditioned by geometries, load,
and boundary conditions through a two-player minimax game between two neural
networks with no prior knowledge. By evaluating the generative network on two
stress distribution datasets under multiple metrics, we demonstrate that our
model can predict more accurate high-resolution stress distributions than a
baseline convolutional neural network model, given various and complex cases of
geometry, load and boundary conditions.",0,1,0,1,0,0,0.92383,7.0,0.90519,50
c3d7a35f-b38d-430e-8eee-4d9a2f017fdf,Once Upon A Time In Visualization: Understanding the Use of Textual Narratives for Causality,18,0.109805,0.35284,"Causality visualization can help people understand temporal chains of events,
such as messages sent in a distributed system, cause and effect in a historical
conflict, or the interplay between political actors over time. However, as the
scale and complexity of these event sequences grows, even these visualizations
can become overwhelming to use. In this paper, we propose the use of textual
narratives as a data-driven storytelling method to augment causality
visualization. We first propose a design space for how textual narratives can
be used to describe causal data. We then present results from a crowdsourced
user study where participants were asked to recover causality information from
two causality visualizations--causal graphs and Hasse diagrams--with and
without an associated textual narrative. Finally, we describe CAUSEWORKS, a
causality visualization system for understanding how specific interventions
influence a causal model. The system incorporates an automatic textual
narrative mechanism based on our design space. We validate CAUSEWORKS through
interviews with experts who used the system for understanding complex events.",0,0,0,0,0,0,0.00616592,16.0,0.581558,68
b39e30f9-d8cb-4449-bb08-be4512d6aafc,Multi-hop Inference for Question-driven Summarization,20,0.120915,0.471222,"Question-driven summarization has been recently studied as an effective
approach to summarizing the source document to produce concise but informative
answers for non-factoid questions. In this work, we propose a novel
question-driven abstractive summarization method, Multi-hop Selective Generator
(MSG), to incorporate multi-hop reasoning into question-driven summarization
and, meanwhile, provide justifications for the generated summaries.
Specifically, we jointly model the relevance to the question and the
interrelation among different sentences via a human-like multi-hop inference
module, which captures important sentences for justifying the summarized
answer. A gated selective pointer generator network with a multi-view coverage
mechanism is designed to integrate diverse information from different
perspectives. Experimental results show that the proposed method consistently
outperforms state-of-the-art methods on two non-factoid QA datasets, namely
WikiHow and PubMedQA.",0,0,0,0,1,0,0.0861687,8.0,0.497979,37
67056ef8-d16d-494a-90f6-5fb60d95b98a,Does Social Support Expressed in Post Titles Elicit Comments in Online Substance Use Recovery Forums?,9,0.292705,0.581454,"Individuals recovering from substance use often seek social support
(emotional and informational) on online recovery forums, where they can both
write and comment on posts, expressing their struggles and successes. A common
challenge in these forums is that certain posts (some of which may be support
seeking) receive no comments. In this work, we use data from two Reddit
substance recovery forums:/r/Leaves and/r/OpiatesRecovery, to determine the
relationship between the social supports expressed in the titles of posts and
the number of comments they receive. We show that the types of social support
expressed in post titles that elicit comments vary from one substance use
recovery forum to the other.",0,1,0,0,0,0,0.844854,11.0,0.910269,20
a84612be-5655-44d2-b1e1-e22142f45980,FLIC: Fast Lidar Image Clustering,10,0.122025,0.270581,"Lidar sensors are widely used in various applications, ranging from
scientific fields over industrial use to integration in consumer products. With
an ever growing number of different driver assistance systems, they have been
introduced to automotive series production in recent years and are considered
an important building block for the practical realisation of autonomous
driving. However, due to the potentially large amount of Lidar points per scan,
tailored algorithms are required to identify objects (e.g. pedestrians or
vehicles) with high precision in a very short time. In this work, we propose an
algorithmic approach for real-time instance segmentation of Lidar sensor data.
We show how our method leverages the properties of the Euclidean distance to
retain three-dimensional measurement information, while being narrowed down to
a two-dimensional representation for fast computation. We further introduce
what we call ""skip connections"", to make our approach robust against
over-segmentation and improve assignment in cases of partial occlusion. Through
detailed evaluation on public data and comparison with established methods, we
show how these aspects enable state-of-the-art performance and runtime on a
single CPU core.",0,1,0,0,1,0,0.71081,4.0,0.651554,38
bbad38f1-46ae-4048-b388-f684bc530f30,Towards Zero-shot Cross-lingual Image Retrieval,17,0.277548,0.413608,"There has been a recent spike in interest in multi-modal Language and Vision
problems. On the language side, most of these models primarily focus on English
since most multi-modal datasets are monolingual. We try to bridge this gap with
a zero-shot approach for learning multi-modal representations using
cross-lingual pre-training on the text side. We present a simple yet practical
approach for building a cross-lingual image retrieval model which trains on a
monolingual training dataset but can be used in a zero-shot cross-lingual
fashion during inference. We also introduce a new objective function which
tightens the text embedding clusters by pushing dissimilar texts from each
other. Finally, we introduce a new 1K multi-lingual MSCOCO2014 caption test
dataset (XTD10) in 7 languages that we collected using a crowdsourcing
platform. We use this as the test set for evaluating zero-shot model
performance across languages. XTD10 dataset is made publicly available here:
https://github.com/adobe-research/Cross-lingual-Test-Dataset-XTD10",1,1,1,1,0,0,0.579781,8.0,0.780978,38
1ae72834-23e5-4172-a41a-7c7fd7ddb1b9,Assessment and Linear Programming under Fuzzy Conditions,5,0.0699279,0.182675,"A new fuzzy method is developed using triangular/trapezoidal fuzzy numbers
for evaluating a group's mean performance, when qualitative grades instead of
numerical scores are used for assessing its members' individual performance.
Also, a new technique is developed for solving Linear Programming problems with
fuzzy coefficients and everyday life applications are presented to illustrate
our results.",0,0,0,0,0,0,0.00205899,30.0,0.740202,33
933e17c3-620f-4969-826b-da14ff2e5be0,LT@Helsinki at SemEval-2020 Task 12: Multilingual or language-specific BERT?,10,0.22052,0.427187,"This paper presents the different models submitted by the LT@Helsinki team
for the SemEval 2020 Shared Task 12. Our team participated in sub-tasks A and
C; titled offensive language identification and offense target identification,
respectively. In both cases we used the so-called Bidirectional Encoder
Representation from Transformer (BERT), a model pre-trained by Google and
fine-tuned by us on the OLID and SOLID datasets. The results show that
offensive tweet classification is one of several language-based tasks where
BERT can achieve state-of-the-art results.",0,1,0,0,0,0,0.948967,5.0,0.89618,31
f1052209-5a9e-4d95-bfe0-24f6354c4062,Faster Transformer Decoding: N-gram Masked Self-Attention,13,0.0657763,0.235103,"Motivated by the fact that most of the information relevant to the prediction
of target tokens is drawn from the source sentence $S=s_1, \ldots, s_S$, we
propose truncating the target-side window used for computing self-attention by
making an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show
that the $N$-gram masked self-attention model loses very little in BLEU score
for $N$ values in the range $4, \ldots, 8$, depending on the task.",0,1,0,0,0,0,0.761862,4.0,0.687915,8
ccc18003-19d9-4532-99b6-bbc1dada9d76,REALab: An Embedded Perspective on Tampering,10,0.0138093,0.101919,"This paper describes REALab, a platform for embedded agency research in
reinforcement learning (RL). REALab is designed to model the structure of
tampering problems that may arise in real-world deployments of RL. Standard
Markov Decision Process (MDP) formulations of RL and simulated environments
mirroring the MDP structure assume secure access to feedback (e.g., rewards).
This may be unrealistic in settings where agents are embedded and can corrupt
the processes producing feedback (e.g., human supervisors, or an implemented
reward function). We describe an alternative Corrupt Feedback MDP formulation
and the REALab environment platform, which both avoid the secure feedback
assumption. We hope the design of REALab provides a useful perspective on
tampering problems, and that the platform may serve as a unit test for the
presence of tampering incentives in RL agent designs.",0,0,0,0,0,0,0.0443077,8.0,0.412067,87
c873f56f-04bf-4e81-bf7f-20032fd7849d,Moire Image Restoration using Multi Level Hyper Vision Net,6,0.0543828,0.307467,"A moire pattern in the images is resulting from high frequency patterns
captured by the image sensor (colour filter array) that appear after
demosaicing. These Moire patterns would appear in natural images of scenes with
high frequency content. The Moire pattern can also vary intensely due to a
minimal change in the camera direction/positioning. Thus the Moire pattern
depreciates the quality of photographs. An important issue in demoireing
pattern is that the Moireing patterns have dynamic structure with varying
colors and forms. These challenges makes the demoireing more difficult than
many other image restoration tasks. Inspired by these challenges in demoireing,
a multilevel hyper vision net is proposed to remove the Moire pattern to
improve the quality of the images. As a key aspect, in this network we involved
residual channel attention block that can be used to extract and adaptively
fuse hierarchical features from all the layers efficiently. The proposed
algorithms has been tested with the NTIRE 2020 challenge dataset and thus
achieved 36.85 and 0.98 Peak to Signal Noise Ratio (PSNR) and Structural
Similarity (SSIM) Index respectively.",0,1,0,0,0,0,0.450984,9.0,0.764346,29
1a1b9ff7-dc1d-4c9e-8479-8532ad3e7a62,Variational Model-based Policy Optimization,9,0.0330458,0.164592,"Model-based reinforcement learning (RL) algorithms allow us to combine
model-generated data with those collected from interaction with the real system
in order to alleviate the data efficiency problem in RL. However, designing
such algorithms is often challenging because the bias in simulated data may
overshadow the ease of data generation. A potential solution to this challenge
is to jointly learn and improve model and policy using a universal objective
function. In this paper, we leverage the connection between RL and
probabilistic inference, and formulate such an objective function as a
variational lower-bound of a log-likelihood. This allows us to use expectation
maximization (EM) and iteratively fix a baseline policy and learn a variational
distribution, consisting of a model and a policy (E-step), followed by
improving the baseline policy given the learned variational distribution
(M-step). We propose model-based and model-free policy iteration (actor-critic)
style algorithms for the E-step and show how the variational distribution
learned by them can be used to optimize the M-step in a fully model-based
fashion. Our experiments on a number of continuous control tasks show that
despite being more complex, our model-based (E-step) algorithm, called {\em
variational model-based policy optimization} (VMBPO), is more sample-efficient
and robust to hyper-parameter tuning than its model-free (E-step) counterpart.
Using the same control tasks, we also compare VMBPO with several
state-of-the-art model-based and model-free RL algorithms and show its sample
efficiency and performance.",0,0,0,0,0,0,0.0429967,13.0,0.635833,48
6daf1e69-d070-4f2b-a49f-b2fa036d48a6,Dissecting Span Identification Tasks with Performance Prediction,14,0.207953,0.210094,"Span identification (in short, span ID) tasks such as chunking, NER, or
code-switching detection, ask models to identify and classify relevant spans in
a text. Despite being a staple of NLP, and sharing a common structure, there is
little insight on how these tasks' properties influence their difficulty, and
thus little guidance on what model families work well on span ID tasks, and
why. We analyze span ID tasks via performance prediction, estimating how well
neural architectures do on different tasks. Our contributions are: (a) we
identify key properties of span ID tasks that can inform performance
prediction; (b) we carry out a large-scale experiment on English data, building
a model to predict performance for unseen span ID tasks that can support
architecture choices; (c), we investigate the parameters of the meta model,
yielding new insights on how model and task properties interact to affect span
ID performance. We find, e.g., that span frequency is especially important for
LSTMs, and that CRFs help when spans are infrequent and boundaries
non-distinctive.",1,0,0,0,0,1,0.770781,12.0,0.89816,67
d0933e71-16fa-4997-b860-8cfe970a6607,Placement in Integrated Circuits using Cyclic Reinforcement Learning and Simulated Annealing,23,0.577031,0.69846,"Physical design and production of Integrated Circuits (IC) is becoming
increasingly more challenging as the sophistication in IC technology is
steadily increasing. Placement has been one of the most critical steps in IC
physical design. Through decades of research, partition-based, analytical-based
and annealing-based placers have been enriching the placement solution toolbox.
However, open challenges including long run time and lack of ability to
generalize continue to restrict wider applications of existing placement tools.
We devise a learning-based placement tool based on cyclic application of
Reinforcement Learning (RL) and Simulated Annealing (SA) by leveraging the
advancement of RL. Results show that the RL module is able to provide a better
initialization for SA and thus leads to a better final placement design.
Compared to other recent learning-based placers, our method is majorly
different with its combination of RL and SA. It leverages the RL model's
ability to quickly get a good rough solution after training and the heuristic's
ability to realize greedy improvements in the solution.",0,1,0,0,0,0,0.302743,17.0,0.845328,22
38d665bb-d0ae-48eb-a4ff-8dde77b3d18c,Privacy-Preserving Eye Videos using Rubber Sheet Model,10,0.41194,0.506752,"Video-based eye trackers estimate gaze based on eye images/videos. As
security and privacy concerns loom over technological advancements, tackling
such challenges is crucial. We present a new approach to handle privacy issues
in eye videos by replacing the current identifiable iris texture with a
different iris template in the video capture pipeline based on the Rubber Sheet
Model. We extend to image blending and median-value representations to
demonstrate that videos can be manipulated without significantly degrading
segmentation and pupil detection accuracy.",0,1,0,0,0,0,0.96259,3.0,0.860059,26
771e6618-3f82-4805-b280-525555dd58fc,Cyclopean Geometry of Binocular Vision,37,0.595136,0.375063,"The geometry of binocular projection is analyzed, with reference to the
primate visual system. In particular, the effects of coordinated eye movements
on the retinal images are investigated. An appropriate oculomotor
parameterization is defined, and is shown to complement the classical version
and vergence angles. The midline horopter is identified, and subsequently used
to construct the epipolar geometry of the system. It is shown that the
Essential matrix can be obtained by combining the epipoles with the projection
of the midline horopter. A local model of the scene is adopted, in which depth
is measured relative to a plane containing the fixation point. The binocular
disparity field is given a symmetric parameterization, in which the unknown
scene-depths determine the location of corresponding image-features. The
resulting Cyclopean depth-map can be combined with the estimated oculomotor
parameters, to produce a local representation of the scene. The recovery of
visual direction and depth from retinal images is discussed, with reference to
the relevant psychophysical and neurophysiological literature.",0,0,0,0,0,0,0.0469172,32.0,0.854848,63
0cabdec4-6084-4489-98be-c6b33625ce21,Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization,48,0.496887,0.530504,"Sequence-to-sequence (seq2seq) network is a well-established model for text
summarization task. It can learn to produce readable content; however, it falls
short in effectively identifying key regions of the source. In this paper, we
approach the content selection problem for clinical abstractive summarization
by augmenting salient ontological terms into the summarizer. Our experiments on
two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and
3,366 reports of OpenI) show that our model statistically significantly boosts
state-of-the-art results in terms of Rouge metrics (with improvements: 2.9%
RG-1, 2.5% RG-2, 1.9% RG-L), in the healthcare domain where any range of
improvement impacts patients' welfare.",1,1,0,0,1,0,0.861392,4.0,0.767923,29
86fe0eac-794d-4fd7-9c90-e27601b62897,Detecting Hateful Memes Using a Multimodal Deep Ensemble,34,0.571171,0.76722,"While significant progress has been made using machine learning algorithms to
detect hate speech, important technical challenges still remain to be solved in
order to bring their performance closer to human accuracy. We investigate
several of the most recent visual-linguistic Transformer architectures and
propose improvements to increase their performance for this task. The proposed
model outperforms the baselines by a large margin and ranks 5$^{th}$ on the
leaderboard out of 3,100+ participants.",1,1,0,0,1,0,0.990875,3.0,0.979143,15
b4f4e268-1177-48cf-b63b-2d566ad96bb5,Majority Voting and the Condorcet's Jury Theorem,1,0.00189621,0.0143352,"There is a striking relationship between a three hundred years old Political
Science theorem named ""Condorcet's jury theorem"" (1785), which states that
majorities are more likely to choose correctly when individual votes are often
correct and independent, and a modern Machine Learning concept called ""Strength
of Weak Learnability"" (1990), which describes a method for converting a weak
learning algorithm into one that achieves arbitrarily high accuracy and stands
in the basis of Ensemble Learning. Albeit the intuitive statement of
Condorcet's theorem, we could not find a compact and simple rigorous
mathematical proof of the theorem neither in classical handbooks of Machine
Learning nor in published papers. By all means we do not claim to discover or
reinvent a theory nor a result. We humbly want to offer a more publicly
available simple derivation of the theorem. We will find joy in seeing more
teachers of introduction-to-machine-learning courses use the proof we provide
here as an exercise to explain the motivation of ensemble learning.",0,0,0,0,0,0,2.10346e-07,41.0,0.585757,15
4636724e-6fc8-4c6b-8c31-9c8f8a2fac3e,On Filter Generalization for Music Bandwidth Extension Using Deep Neural Networks,20,0.269029,0.889531,"In this paper, we address a sub-topic of the broad domain of audio
enhancement, namely musical audio bandwidth extension. We formulate the
bandwidth extension problem using deep neural networks, where a band-limited
signal is provided as input to the network, with the goal of reconstructing a
full-bandwidth output. Our main contribution centers on the impact of the
choice of low pass filter when training and subsequently testing the network.
For two different state of the art deep architectures, ResNet and U-Net, we
demonstrate that when the training and testing filters are matched,
improvements in signal-to-noise ratio (SNR) of up to 7dB can be obtained.
However, when these filters differ, the improvement falls considerably and
under some training conditions results in a lower SNR than the band-limited
input. To circumvent this apparent overfitting to filter shape, we propose a
data augmentation strategy which utilizes multiple low pass filters during
training and leads to improved generalization to unseen filtering conditions at
test time.",0,1,0,0,0,0,0.216451,9.0,0.664406,67
a130834b-f88c-4ad5-9dc1-a6c998d72972,An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction,83,0.475883,0.682003,"Decisions of complex language understanding models can be rationalized by
limiting their inputs to a relevant subsequence of the original text. A
rationale should be as concise as possible without significantly degrading task
performance, but this balance can be difficult to achieve in practice. In this
paper, we show that it is possible to better manage this trade-off by
optimizing a bound on the Information Bottleneck (IB) objective. Our fully
unsupervised approach jointly learns an explainer that predicts sparse binary
masks over sentences, and an end-task predictor that considers only the
extracted rationale. Using IB, we derive a learning objective that allows
direct control of mask sparsity levels through a tunable sparse prior.
Experiments on ERASER benchmark tasks demonstrate significant gains over
norm-minimization techniques for both task performance and agreement with human
rationales. Furthermore, we find that in the semi-supervised setting, a modest
amount of gold rationales (25% of training examples) closes the gap with a
model that uses the full input.",1,1,0,0,0,0,0.911844,3.0,0.759299,42
6fe15a7a-260f-4d5d-a2cd-9a6119f73a89,C-DLinkNet: considering multi-level semantic features for human parsing,3,0.0278707,0.0984739,"Human parsing is an essential branch of semantic segmentation, which is a
fine-grained semantic segmentation task to identify the constituent parts of
human. The challenge of human parsing is to extract effective semantic features
to resolve deformation and multi-scale variations. In this work, we proposed an
end-to-end model called C-DLinkNet based on LinkNet, which contains a new
module named Smooth Module to combine the multi-level features in Decoder part.
C-DLinkNet is capable of producing competitive parsing performance compared
with the state-of-the-art methods with smaller input sizes and no additional
information, i.e., achiving mIoU=53.05 on the validation set of LIP dataset.",0,1,0,0,1,0,0.917647,6.0,0.884258,22
88f43c03-d842-4b83-acd4-638e78b20be0,The 1st Challenge on Remote Physiological Signal Sensing (RePSS),24,0.44905,0.788872,"Remote measurement of physiological signals from videos is an emerging topic.
The topic draws great interests, but the lack of publicly available benchmark
databases and a fair validation platform are hindering its further development.
For this concern, we organize the first challenge on Remote Physiological
Signal Sensing (RePSS), in which two databases of VIPL and OBF are provided as
the benchmark for kin researchers to evaluate their approaches. The 1st
challenge of RePSS focuses on measuring the average heart rate from facial
videos, which is the basic problem of remote physiological measurement. This
paper presents an overview of the challenge, including data, protocol, analysis
of results and discussion. The top ranked solutions are highlighted to provide
insights for researchers, and future directions are outlined for this topic and
this challenge.",0,1,1,1,0,0,0.947312,6.0,0.911686,25
0ee16aa1-7e05-4a86-9bc6-2f0888dbba0e,3D Multi-bodies: Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data,56,0.411337,0.786824,"We consider the problem of obtaining dense 3D reconstructions of humans from
single and partially occluded views. In such cases, the visual evidence is
usually insufficient to identify a 3D reconstruction uniquely, so we aim at
recovering several plausible reconstructions compatible with the input data. We
suggest that ambiguities can be modelled more effectively by parametrizing the
possible body shapes and poses via a suitable 3D model, such as SMPL for
humans. We propose to learn a multi-hypothesis neural network regressor using a
best-of-M loss, where each of the M hypotheses is constrained to lie on a
manifold of plausible human poses by means of a generative model. We show that
our method outperforms alternative approaches in ambiguous pose recovery on
standard benchmarks for 3D humans, and in heavily occluded versions of these
benchmarks.",0,1,0,0,0,0,0.967491,7.0,0.946003,49
594be0a9-d018-469f-8747-011277822d2b,"The Person Index Challenge: Extraction of Persons from Messy, Short Texts",3,0.0403008,0.0650522,"When persons are mentioned in texts with their first name, last name and/or
middle names, there can be a high variation which of their names are used, how
their names are ordered and if their names are abbreviated. If multiple persons
are mentioned consecutively in very different ways, especially short texts can
be perceived as ""messy"". Once ambiguous names occur, associations to persons
may not be inferred correctly. Despite these eventualities, in this paper we
ask how well an unsupervised algorithm can build a person index from short
texts. We define a person index as a structured table that distinctly catalogs
individuals by their names. First, we give a formal definition of the problem
and describe a procedure to generate ground truth data for future evaluations.
To give a first solution to this challenge, a baseline approach is implemented.
By using our proposed evaluation strategy, we test the performance of the
baseline and suggest further improvements. For future research the source code
is publicly available.",0,0,0,0,0,0,0.0297058,17.0,0.699364,13
00932161-e72a-43c6-8732-cb953f15755d,Joint Verification and Reranking for Open Fact Checking Over Tables,19,0.16509,0.536703,"Structured information is an important knowledge source for automatic
verification of factual claims. Nevertheless, the majority of existing research
into this task has focused on textual data, and the few recent inquiries into
structured data have been for the closed-domain setting where appropriate
evidence for each claim is assumed to have already been retrieved. In this
paper, we investigate verification over structured data in the open-domain
setting, introducing a joint reranking-and-verification model which fuses
evidence documents in the verification component. Our open-domain model
achieves performance comparable to the closed-domain state-of-the-art on the
TabFact dataset, and demonstrates performance gains from the inclusion of
multiple tables as well as a significant improvement over a heuristic retrieval
baseline.",1,1,0,0,1,0,0.697498,6.0,0.761544,47
33ecaebd-48c4-4e4f-a27b-29b9c538cb44,"Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases",198,0.777012,0.817593,"Self-supervised representation learning approaches have recently surpassed
their supervised learning counterparts on downstream tasks like object
detection and image classification. Somewhat mysteriously the recent gains in
performance come from training instance classification models, treating each
image and it's augmented versions as samples of a single class. In this work,
we first present quantitative experiments to demystify these gains. We
demonstrate that approaches like MOCO and PIRL learn occlusion-invariant
representations. However, they fail to capture viewpoint and category instance
invariance which are crucial components for object recognition. Second, we
demonstrate that these approaches obtain further gains from access to a clean
object-centric training dataset like Imagenet. Finally, we propose an approach
to leverage unstructured videos to learn representations that possess higher
viewpoint invariance. Our results show that the learned representations
outperform MOCOv2 trained on the same data in terms of invariances encoded and
the performance on downstream image classification and semantic segmentation
tasks.",0,0,0,0,0,0,0.945959,8.0,0.932683,47
97a6757a-33ee-43ec-9cd4-f953c8d6b879,Photon: A Robust Cross-Domain Text-to-SQL System,49,0.812871,0.834864,"Natural language interfaces to databases (NLIDB) democratize end user access
to relational data. Due to fundamental differences between natural language
communication and programming, it is common for end users to issue questions
that are ambiguous to the system or fall outside the semantic scope of its
underlying query language. We present Photon, a robust, modular, cross-domain
NLIDB that can flag natural language input to which a SQL mapping cannot be
immediately determined. Photon consists of a strong neural semantic parser
(63.2\% structure accuracy on the Spider dev benchmark), a human-in-the-loop
question corrector, a SQL executor and a response generator. The question
corrector is a discriminative neural sequence editor which detects confusion
span(s) in the input question and suggests rephrasing until a translatable
input is given by the user or a maximum number of iterations are conducted.
Experiments on simulated data show that the proposed method effectively
improves the robustness of text-to-SQL system against untranslatable user
input. The live demo of our system is available at http://naturalsql.com.",0,1,0,0,0,0,0.937526,5.0,0.882099,52
4de69be3-7b16-4ade-90ce-dc70b7498456,Tensor completion via nonconvex tensor ring rank minimization with guaranteed convergence,18,0.422578,0.387715,"In recent studies, the tensor ring (TR) rank has shown high effectiveness in
tensor completion due to its ability of capturing the intrinsic structure
within high-order tensors. A recently proposed TR rank minimization method is
based on the convex relaxation by penalizing the weighted sum of nuclear norm
of TR unfolding matrices. However, this method treats each singular value
equally and neglects their physical meanings, which usually leads to suboptimal
solutions in practice. In this paper, we propose to use the logdet-based
function as a nonconvex smooth relaxation of the TR rank for tensor completion,
which can more accurately approximate the TR rank and better promote the
low-rankness of the solution. To solve the proposed nonconvex model
efficiently, we develop an alternating direction method of multipliers
algorithm and theoretically prove that, under some mild assumptions, our
algorithm converges to a stationary point. Extensive experiments on color
images, multispectral images, and color videos demonstrate that the proposed
method outperforms several state-of-the-art competitors in both visual and
quantitative comparison. Key words: nonconvex optimization, tensor ring rank,
logdet function, tensor completion, alternating direction method of
multipliers.",0,0,0,0,1,0,0.877569,5.0,0.82652,72
298e110e-2cb6-49fe-a9f5-2aee0c8d492b,Will we ever have Conscious Machines?,22,0.0388103,0.358279,"The question of whether artificial beings or machines could become self-aware
or consciousness has been a philosophical question for centuries. The main
problem is that self-awareness cannot be observed from an outside perspective
and the distinction of whether something is really self-aware or merely a
clever program that pretends to do so cannot be answered without access to
accurate knowledge about the mechanism's inner workings. We review the current
state-of-the-art regarding these developments and investigate common machine
learning approaches with respect to their potential ability to become
self-aware. We realise that many important algorithmic steps towards machines
with a core consciousness have already been devised. For human-level
intelligence, however, many additional techniques have to be discovered.",0,0,0,0,0,0,0.00541231,13.0,0.474938,158
1e22ca84-9e93-41d0-b1e8-0d36b902d0cc,An LSTM-Based Autonomous Driving Model Using Waymo Open Dataset,32,0.146516,0.417296,"The Waymo Open Dataset has been released recently, providing a platform to
crowdsource some fundamental challenges for automated vehicles (AVs), such as
3D detection and tracking. While~the dataset provides a large amount of
high-quality and multi-source driving information, people in academia are more
interested in the underlying driving policy programmed in Waymo self-driving
cars, which is inaccessible due to AV manufacturers' proprietary protection.
Accordingly, academic researchers have to make various assumptions to implement
AV components in their models or simulations, which may not represent the
realistic interactions in real-world traffic. Thus, this paper introduces an
approach to learn a long short-term memory (LSTM)-based model for imitating the
behavior of Waymo's self-driving model. The proposed model has been evaluated
based on Mean Absolute Error (MAE). The experimental results show that our
model outperforms several baseline models in driving action prediction. In
addition, a visualization tool is presented for verifying the performance of
the model.",0,1,0,0,0,0,0.667355,9.0,0.831832,22
2feab1bd-8384-424d-8c42-2cc7d90f2b2d,"Detection in Crowded Scenes: One Proposal, Multiple Predictions",138,0.479979,0.996098,"We propose a simple yet effective proposal-based object detector, aiming at
detecting highly-overlapped instances in crowded scenes. The key of our
approach is to let each proposal predict a set of correlated instances rather
than a single one in previous proposal-based frameworks. Equipped with new
techniques such as EMD Loss and Set NMS, our detector can effectively handle
the difficulty of detecting highly overlapped objects. On a FPN-Res50 baseline,
our detector can obtain 4.9\% AP gains on challenging CrowdHuman dataset and
1.0\% $\text{MR}^{-2}$ improvements on CityPersons dataset, without bells and
whistles. Moreover, on less crowed datasets like COCO, our approach can still
achieve moderate improvement, suggesting the proposed method is robust to
crowdedness. Code and pre-trained models will be released at
https://github.com/megvii-model/CrowdDetection.",1,1,0,0,1,0,0.819503,7.0,0.846893,46
3a52ad77-2dbc-4a64-93aa-2d4e00fa1f68,Towards Improved Human Action Recognition Using Convolutional Neural Networks and Multimodal Fusion of Depth and Inertial Sensor Data,16,0.0706063,0.364723,"This paper attempts at improving the accuracy of Human Action Recognition
(HAR) by fusion of depth and inertial sensor data. Firstly, we transform the
depth data into Sequential Front view Images(SFI) and fine-tune the pre-trained
AlexNet on these images. Then, inertial data is converted into Signal Images
(SI) and another convolutional neural network (CNN) is trained on these images.
Finally, learned features are extracted from both CNN, fused together to make a
shared feature layer, and these features are fed to the classifier. We
experiment with two classifiers, namely Support Vector Machines (SVM) and
softmax classifier and compare their performances. The recognition accuracies
of each modality, depth data alone and sensor data alone are also calculated
and compared with fusion based accuracies to highlight the fact that fusion of
modalities yields better results than individual modalities. Experimental
results on UTD-MHAD and Kinect 2D datasets show that proposed method achieves
state of the art results when compared to other recently proposed
visual-inertial action recognition methods.",0,1,0,0,1,0,0.238926,7.0,0.584624,42
fc546fa6-d7f4-4946-b122-4a00729bd687,Trajectory Forecasts in Unknown Environments Conditioned on Grid-Based Plans,126,0.929998,0.838553,"We address the problem of forecasting pedestrian and vehicle trajectories in
unknown environments, conditioned on their past motion and scene structure.
Trajectory forecasting is a challenging problem due to the large variation in
scene structure and the multimodal distribution of future trajectories. Unlike
prior approaches that directly learn one-to-many mappings from observed context
to multiple future trajectories, we propose to condition trajectory forecasts
on plans sampled from a grid based policy learned using maximum entropy inverse
reinforcement learning (MaxEnt IRL). We reformulate MaxEnt IRL to allow the
policy to jointly infer plausible agent goals, and paths to those goals on a
coarse 2-D grid defined over the scene. We propose an attention based
trajectory generator that generates continuous valued future trajectories
conditioned on state sequences sampled from the MaxEnt policy. Quantitative and
qualitative evaluation on the publicly available Stanford drone and NuScenes
datasets shows that our model generates trajectories that are diverse,
representing the multimodal predictive distribution, and precise, conforming to
the underlying scene structure over long prediction horizons.",1,1,0,0,0,0,0.971302,3.0,0.885922,47
8e69f6ff-b83e-4584-be9c-d2b98c650b3b,Maximum Entropy Multi-Task Inverse RL,4,0.0465328,0.109086,"Multi-task IRL allows for the possibility that the expert could be switching
between multiple ways of solving the same problem, or interleaving
demonstrations of multiple tasks. The learner aims to learn the multiple reward
functions that guide these ways of solving the problem. We present a new method
for multi-task IRL that generalizes the well-known maximum entropy approach to
IRL by combining it with the Dirichlet process based clustering of the observed
input. This yields a single nonlinear optimization problem, called MaxEnt
Multi-task IRL, which can be solved using the Lagrangian relaxation and
gradient descent methods. We evaluate MaxEnt Multi-task IRL in simulation on
the robotic task of sorting onions on a processing line where the expert
utilizes multiple ways of detecting and removing blemished onions. The method
is able to learn the underlying reward functions to a high level of accuracy
and it improves on the previous approaches to multi-task IRL.",0,0,0,0,0,0,0.120912,13.0,0.718586,33
1d00f1fc-9102-4aae-a1b9-209af6620993,Cascaded deep monocular 3D human pose estimation with evolutionary training data,135,0.72125,0.972867,"End-to-end deep representation learning has achieved remarkable accuracy for
monocular 3D human pose estimation, yet these models may fail for unseen poses
with limited and fixed training data. This paper proposes a novel data
augmentation method that: (1) is scalable for synthesizing massive amount of
training data (over 8 million valid 3D human poses with corresponding 2D
projections) for training 2D-to-3D networks, (2) can effectively reduce dataset
bias. Our method evolves a limited dataset to synthesize unseen 3D human
skeletons based on a hierarchical human representation and heuristics inspired
by prior knowledge. Extensive experiments show that our approach not only
achieves state-of-the-art accuracy on the largest public benchmark, but also
generalizes significantly better to unseen and rare poses. Code, pre-trained
models and tools are available at this HTTPS URL.",0,1,0,1,1,0,0.916185,6.0,0.88308,77
2315564b-32df-450c-b766-ce8cb18e3430,CYPUR-NN: Crop Yield Prediction Using Regression and Neural Networks,1,0.0267908,0.0246682,"Our recent study using historic data of paddy yield and associated conditions
include humidity, luminescence, and temperature. By incorporating regression
models and neural networks (NN), one can produce highly satisfactory
forecasting of paddy yield. Simulations indicate that our model can predict
paddy yield with high accuracy while concurrently detecting diseases that may
exist and are oblivious to the human eye. Crop Yield Prediction Using
Regression and Neural Networks (CYPUR-NN) is developed here as a system that
will facilitate agriculturists and farmers to predict yield from a picture or
by entering values via a web interface. CYPUR-NN has been tested on stock
images and the experimental results are promising.",0,1,0,0,0,1,0.119424,29.0,0.873393,11
0600815f-db85-4c38-b8d4-571fd4c90e48,Region adaptive graph fourier transform for 3d point clouds,22,0.187215,0.369167,"We introduce the Region Adaptive Graph Fourier Transform (RA-GFT) for
compression of 3D point cloud attributes. The RA-GFT is a multiresolution
transform, formed by combining spatially localized block transforms. We assume
the points are organized by a family of nested partitions represented by a
rooted tree. At each resolution level, attributes are processed in clusters
using block transforms. Each block transform produces a single approximation
(DC) coefficient, and various detail (AC) coefficients. The DC coefficients are
promoted up the tree to the next (lower resolution) level, where the process
can be repeated until reaching the root. Since clusters may have a different
numbers of points, each block transform must incorporate the relative
importance of each coefficient. For this, we introduce the
$\mathbf{Q}$-normalized graph Laplacian, and propose using its eigenvectors as
the block transform. The RA-GFT achieves better complexity-performance
trade-offs than previous approaches. In particular, it outperforms the Region
Adaptive Haar Transform (RAHT) by up to 2.5 dB, with a small complexity
overhead.",1,0,0,0,0,0,0.175381,10.0,0.674464,20
b34bf38c-269e-474d-b1c7-10a65352fcca,Extracting Daily Dosage from Medication Instructions in EHRs: An Automated Approach and Lessons Learned,7,0.274789,0.559382,"Medication timelines have been shown to be effective in helping physicians
visualize complex patient medication information. A key feature in many such
designs is a longitudinal representation of a medication's daily dosage and its
changes over time. However, daily dosage as a discrete value is generally not
provided and needs to be derived from free text instructions (Sig). Existing
works in daily dosage extraction are narrow in scope, targeting dosage
extraction for a single drug from clinical notes. Here, we present an automated
approach to calculate daily dosage for all medications, combining deep
learning-based named entity extractor with lexicon dictionaries and regular
expressions, achieving 0.98 precision and 0.95 recall on an expert-generated
dataset of 1,000 Sigs. We also analyze our expert-generated dataset, discuss
the challenges in understanding the complex information contained in Sigs, and
provide insights to guide future work in the general-purpose daily dosage
calculation task.",0,1,0,0,0,0,0.98291,3.0,0.931342,21
7f267e16-7983-40e5-b6a7-c48eb8000206,Generation-Augmented Retrieval for Open-domain Question Answering,172,0.927664,0.935454,"We propose Generation-Augmented Retrieval (GAR) for answering open-domain
questions, which augments a query through text generation of heuristically
discovered relevant contexts without external resources as supervision. We
demonstrate that the generated contexts substantially enrich the semantics of
the queries and GAR with sparse representations (BM25) achieves comparable or
better performance than state-of-the-art dense retrieval methods such as DPR.
We show that generating diverse contexts for a query is beneficial as fusing
their results consistently yields better retrieval accuracy. Moreover, as
sparse and dense representations are often complementary, GAR can be easily
combined with DPR to achieve even better performance. GAR achieves
state-of-the-art performance on Natural Questions and TriviaQA datasets under
the extractive QA setup when equipped with an extractive reader, and
consistently outperforms other retrieval methods when the same generative
reader is used.",1,1,1,0,1,1,0.980288,2.0,0.879156,43
5dd51066-4098-4b36-bcc4-6c3b30a67fb5,Sentiment and Knowledge Based Algorithmic Trading with Deep Reinforcement Learning,23,0.0750243,0.470208,"Algorithmic trading, due to its inherent nature, is a difficult problem to
tackle; there are too many variables involved in the real world which make it
almost impossible to have reliable algorithms for automated stock trading. The
lack of reliable labelled data that considers physical and physiological
factors that dictate the ups and downs of the market, has hindered the
supervised learning attempts for dependable predictions. To learn a good policy
for trading, we formulate an approach using reinforcement learning which uses
traditional time series stock price data and combines it with news headline
sentiments, while leveraging knowledge graphs for exploiting news about
implicit relationships.",0,1,0,0,0,0,0.0020221,18.0,0.565997,29
8843b06b-790d-4f09-973b-31234dac6bac,Public Announcement Logic in HOL,2,0.0143738,0.0601245,"A shallow semantical embedding for public announcement logic with relativized
common knowledge is presented. This embedding enables the first-time automation
of this logic with off-the-shelf theorem provers for classical higher-order
logic. It is demonstrated (i) how meta-theoretical studies can be automated
this way, and (ii) how non-trivial reasoning in the target logic (public
announcement logic), required e.g. to obtain a convincing encoding and
automation of the wise men puzzle, can be realized. Key to the presented
semantical embedding -- in contrast, e.g., to related work on the semantical
embedding of normal modal logics -- is that evaluation domains are modeled
explicitly and treated as additional parameter in the encodings of the
constituents of the embedded target logic, while they were previously
implicitly shared between meta logic and target logic.",0,0,0,0,0,0,3.76915e-05,27.0,0.56313,27
35b48b3f-3a32-4200-bfd6-a58d9e3d5f72,MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction,94,0.504275,0.975036,"Autonomous vehicles are expected to drive in complex scenarios with several
independent non cooperating agents. Path planning for safely navigating in such
environments can not just rely on perceiving present location and motion of
other agents. It requires instead to predict such variables in a far enough
future. In this paper we address the problem of multimodal trajectory
prediction exploiting a Memory Augmented Neural Network. Our method learns past
and future trajectory embeddings using recurrent neural networks and exploits
an associative external memory to store and retrieve such embeddings.
Trajectory prediction is then performed by decoding in-memory future encodings
conditioned with the observed past. We incorporate scene knowledge in the
decoding state by learning a CNN on top of semantic scene maps. Memory growth
is limited by learning a writing controller based on the predictive capability
of existing embeddings. We show that our method is able to natively perform
multi-modal trajectory prediction obtaining state-of-the art results on three
datasets. Moreover, thanks to the non-parametric nature of the memory module,
we show how once trained our system can continuously improve by ingesting novel
patterns.",0,0,0,0,1,0,0.786846,7.0,0.832295,55
51a7fbe1-3ac7-43bf-85e2-5d1c9a0d0cb4,"Fast, Self Supervised, Fully Convolutional Color Normalization of H&E Stained Images",12,0.226273,0.39489,"Performance of deep learning algorithms decreases drastically if the data
distributions of the training and testing sets are different. Due to variations
in staining protocols, reagent brands, and habits of technicians, color
variation in digital histopathology images is quite common. Color variation
causes problems for the deployment of deep learning-based solutions for
automatic diagnosis system in histopathology. Previously proposed color
normalization methods consider a small patch as a reference for normalization,
which creates artifacts on out-of-distribution source images. These methods are
also slow as most of the computation is performed on CPUs instead of the GPUs.
We propose a color normalization technique, which is fast during its
self-supervised training as well as inference. Our method is based on a
lightweight fully-convolutional neural network and can be easily attached to a
deep learning-based pipeline as a pre-processing block. For classification and
segmentation tasks on CAMELYON17 and MoNuSeg datasets respectively, the
proposed method is faster and gives a greater increase in accuracy than the
state of the art methods.",0,1,0,0,1,0,0.923974,6.0,0.88951,24
5545ad0b-f8bf-4317-8ad8-6a59e2faf84b,Human Action Performance using Deep Neuro-Fuzzy Recurrent Attention Model,22,0.294745,0.725297,"A great number of computer vision publications have focused on distinguishing
between human action recognition and classification rather than the intensity
of actions performed. Indexing the intensity which determines the performance
of human actions is a challenging task due to the uncertainty and information
deficiency that exists in the video inputs. To remedy this uncertainty, in this
paper we coupled fuzzy logic rules with the neural-based action recognition
model to rate the intensity of a human action as intense or mild. In our
approach, we used a Spatio-Temporal LSTM to generate the weights of the
fuzzy-logic model, and then demonstrate through experiments that indexing of
the action intensity is possible. We analyzed the integrated model by applying
it to videos of human actions with different action intensities and were able
to achieve an accuracy of 89.16% on our intensity indexing generated dataset.
The integrated model demonstrates the ability of a neuro-fuzzy inference module
to effectively estimate the intensity index of human actions.",0,1,0,0,0,0,0.70706,7.0,0.799397,71
7039f171-7bc8-45d7-b706-376877121cd8,Multi-Task Image-Based Dietary Assessment for Food Recognition and Portion Size Estimation,41,0.745544,0.59054,"Deep learning based methods have achieved impressive results in many
applications for image-based diet assessment such as food classification and
food portion size estimation. However, existing methods only focus on one task
at a time, making it difficult to apply in real life when multiple tasks need
to be processed together. In this work, we propose an end-to-end multi-task
framework that can achieve both food classification and food portion size
estimation. We introduce a food image dataset collected from a nutrition study
where the groundtruth food portion is provided by registered dietitians. The
multi-task learning uses L2-norm based soft parameter sharing to train the
classification and regression tasks simultaneously. We also propose the use of
cross-domain feature adaptation together with normalization to further improve
the performance of food portion size estimation. Our results outperforms the
baseline methods for both classification accuracy and mean absolute error for
portion estimation, which shows great potential for advancing the field of
image-based dietary assessment.",0,1,0,1,0,0,0.960868,9.0,0.95182,28
1d9d97da-78fd-489a-816e-1cf2b554b9fe,Text as Neural Operator: Image Manipulation by Text Instruction,36,0.273325,0.824153,"In recent years, text-guided image manipulation has gained increasing
attention in the multimedia and computer vision community. The input to
conditional image generation has evolved from image-only to multimodality. In
this paper, we study a setting that allows users to edit an image with multiple
objects using complex text instructions to add, remove, or change the objects.
The inputs of the task are multimodal including (1) a reference image and (2)
an instruction in natural language that describes desired modifications to the
image. We propose a GAN-based method to tackle this problem. The key idea is to
treat text as neural operators to locally modify the image feature. We show
that the proposed model performs favorably against recent strong baselines on
three public datasets. Specifically, it generates images of greater fidelity
and semantic relevance, and when used as a image query, leads to better
retrieval performance.",1,0,0,0,0,0,0.693648,5.0,0.711727,87
e2e1a380-25f4-46ff-92e7-1171baeabaf5,Indoor Scene Recognition in 3D,16,0.140101,0.37221,"Recognising in what type of environment one is located is an important
perception task. For instance, for a robot operating in indoors it is helpful
to be aware whether it is in a kitchen, a hallway or a bedroom. Existing
approaches attempt to classify the scene based on 2D images or 2.5D range
images. Here, we study scene recognition from 3D point cloud (or voxel) data,
and show that it greatly outperforms methods based on 2D birds-eye views.
Moreover, we advocate multi-task learning as a way of improving scene
recognition, building on the fact that the scene type is highly correlated with
the objects in the scene, and therefore with its semantic segmentation into
different object classes. In a series of ablation studies, we show that
successful scene recognition is not just the recognition of individual objects
unique to some scene type (such as a bathtub), but depends on several different
cues, including coarse 3D geometry, colour, and the (implicit) distribution of
object categories. Moreover, we demonstrate that surprisingly sparse 3D data is
sufficient to classify indoor scenes with good accuracy.",0,1,0,0,1,0,0.803078,8.0,0.859505,46
35508845-0645-4bc1-ae3b-57b9a813a6eb,Unsupervised Learning of Video Representations via Dense Trajectory Clustering,22,0.077912,0.405748,"This paper addresses the task of unsupervised learning of representations for
action recognition in videos. Previous works proposed to utilize future
prediction, or other domain-specific objectives to train a network, but
achieved only limited success. In contrast, in the relevant field of image
representation learning, simpler, discrimination-based methods have recently
bridged the gap to fully-supervised performance. We first propose to adapt two
top performing objectives in this class - instance recognition and local
aggregation, to the video domain. In particular, the latter approach iterates
between clustering the videos in the feature space of a network and updating it
to respect the cluster with a non-parametric classification loss. We observe
promising performance, but qualitative analysis shows that the learned
representations fail to capture motion patterns, grouping the videos based on
appearance. To mitigate this issue, we turn to the heuristic-based IDT
descriptors, that were manually designed to encode motion patterns in videos.
We form the clusters in the IDT space, using these descriptors as a an
unsupervised prior in the iterative local aggregation algorithm. Our
experiments demonstrates that this approach outperform prior work on UCF101 and
HMDB51 action recognition benchmarks. We also qualitatively analyze the learned
representations and show that they successfully capture video dynamics.",1,1,0,0,0,0,0.820039,8.0,0.866248,50
1ae5d150-f8ea-44ec-890f-1a9fc336f291,"Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation",56,0.508308,0.973417,"Despite being the seventh most widely spoken language in the world, Bengali
has received much less attention in machine translation literature due to being
low in resources. Most publicly available parallel corpora for Bengali are not
large enough; and have rather poor quality, mostly because of incorrect
sentence alignments resulting from erroneous sentence segmentation, and also
because of a high volume of noise present in them. In this work, we build a
customized sentence segmenter for Bengali and propose two novel methods for
parallel corpus creation on low-resource setups: aligner ensembling and batch
filtering. With the segmenter and the two methods combined, we compile a
high-quality Bengali-English parallel corpus comprising of 2.75 million
sentence pairs, more than 2 million of which were not available before.
Training on neural models, we achieve an improvement of more than 9 BLEU score
over previous approaches to Bengali-English machine translation. We also
evaluate on a new test set of 1000 pairs made with extensive quality control.
We release the segmenter, parallel corpus, and the evaluation set, thus
elevating Bengali from its low-resource status. To the best of our knowledge,
this is the first ever large scale study on Bengali-English machine
translation. We believe our study will pave the way for future research on
Bengali-English machine translation as well as other low-resource languages.
Our data and code are available at https://github.com/csebuetnlp/banglanmt.",1,1,0,1,1,0,0.433617,8.0,0.728223,57
b60f55d4-f854-4101-b6ce-db81c7e45e35,Facial Expression Retargeting from Human to Avatar Made Easy,33,0.17758,0.729505,"Facial expression retargeting from humans to virtual characters is a useful
technique in computer graphics and animation. Traditional methods use markers
or blendshapes to construct a mapping between the human and avatar faces.
However, these approaches require a tedious 3D modeling process, and the
performance relies on the modelers' experience. In this paper, we propose a
brand-new solution to this cross-domain expression transfer problem via
nonlinear expression embedding and expression domain translation. We first
build low-dimensional latent spaces for the human and avatar facial expressions
with variational autoencoder. Then we construct correspondences between the two
latent spaces guided by geometric and perceptual constraints. Specifically, we
design geometric correspondences to reflect geometric matching and utilize a
triplet data structure to express users' perceptual preference of avatar
expressions. A user-friendly method is proposed to automatically generate
triplets for a system allowing users to easily and efficiently annotate the
correspondences. Using both geometric and perceptual correspondences, we
trained a network for expression domain translation from human to avatar.
Extensive experimental results and user studies demonstrate that even
nonprofessional users can apply our method to generate high-quality facial
expression retargeting results with less time and effort.",0,1,0,0,0,0,0.0362037,13.0,0.622334,53
702cf100-9dfd-4219-9da0-e667bf9f6c40,Decomposition of Longitudinal Deformations via Beltrami Descriptors,1,0.00854506,0.0468823,"We present a mathematical model to decompose a longitudinal deformation into
normal and abnormal components. The goal is to detect and extract subtle
quivers from periodic motions in a video sequence. It has important
applications in medical image analysis. To achieve this goal, we consider a
representation of the longitudinal deformation, called the Beltrami descriptor,
based on quasiconformal theories. The Beltrami descriptor is a complex-valued
matrix. Each longitudinal deformation is associated to a Beltrami descriptor
and vice versa. To decompose the longitudinal deformation, we propose to carry
out the low rank and sparse decomposition of the Beltrami descriptor. The low
rank component corresponds to the periodic motions, whereas the sparse part
corresponds to the abnormal motions of a longitudinal deformation. Experiments
have been carried out on both synthetic and real video sequences. Results
demonstrate the efficacy of our proposed model to decompose a longitudinal
deformation into regular and irregular components.",0,0,1,0,0,0,0.00281805,17.0,0.560016,65
2d7af783-8b32-41a4-b044-d7c4f7951e7e,NODIS: Neural Ordinary Differential Scene Understanding,16,0.0505959,0.320222,"Semantic image understanding is a challenging topic in computer vision. It
requires to detect all objects in an image, but also to identify all the
relations between them. Detected objects, their labels and the discovered
relations can be used to construct a scene graph which provides an abstract
semantic interpretation of an image. In previous works, relations were
identified by solving an assignment problem formulated as Mixed-Integer Linear
Programs. In this work, we interpret that formulation as Ordinary Differential
Equation (ODE). The proposed architecture performs scene graph inference by
solving a neural variant of an ODE by end-to-end learning. It achieves
state-of-the-art results on all three benchmark tasks: scene graph generation
(SGGen), classification (SGCls) and visual relationship detection (PredCls) on
Visual Genome benchmark.",0,0,0,0,1,0,0.509187,5.0,0.61009,55
b000745b-e42f-4953-90dc-0e97ffa3ecb4,Time Efficiency in Optimization with a Bayesian-Evolutionary Algorithm,59,0.0371481,0.421062,"Not all generate-and-test search algorithms are created equal. Bayesian
Optimization (BO) invests a lot of computation time to generate the candidate
solution that best balances the predicted value and the uncertainty given all
previous data, taking increasingly more time as the number of evaluations
performed grows. Evolutionary Algorithms (EA) on the other hand rely on search
heuristics that typically do not depend on all previous data and can be done in
constant time. Both the BO and EA community typically assess their performance
as a function of the number of evaluations. However, this is unfair once we
start to compare the efficiency of these classes of algorithms, as the overhead
times to generate candidate solutions are significantly different. We suggest
to measure the efficiency of generate-and-test search algorithms as the
expected gain in the objective value per unit of computation time spent. We
observe that the preference of an algorithm to be used can change after a
number of function evaluations. We therefore propose a new algorithm, a
combination of Bayesian optimization and an Evolutionary Algorithm, BEA for
short, that starts with BO, then transfers knowledge to an EA, and subsequently
runs the EA. We compare the BEA with BO and the EA. The results show that BEA
outperforms both BO and the EA in terms of time efficiency, and ultimately
leads to better performance on well-known benchmark objective functions with
many local optima. Moreover, we test the three algorithms on nine test cases of
robot learning problems and here again we find that BEA outperforms the other
algorithms.",0,1,0,0,0,0,0.0229797,7.0,0.232717,51
277e7cde-baed-4724-a31c-21f5a26f1b1e,Unsupervised Cross-lingual Representation Learning for Speech Recognition,593,0.63364,0.999979,"This paper presents XLSR which learns cross-lingual speech representations by
pretraining a single model from the raw waveform of speech in multiple
languages. We build on wav2vec 2.0 which is trained by solving a contrastive
task over masked latent speech representations and jointly learns a
quantization of the latents shared across languages. The resulting model is
fine-tuned on labeled data and experiments show that cross-lingual pretraining
significantly outperforms monolingual pretraining. On the CommonVoice
benchmark, XLSR shows a relative phoneme error rate reduction of 72% compared
to the best known results. On BABEL, our approach improves word error rate by
16% relative compared to a comparable system. Our approach enables a single
multilingual speech recognition model which is competitive to strong individual
models. Analysis shows that the latent discrete speech representations are
shared across languages with increased sharing for related languages. We hope
to catalyze research in low-resource speech understanding by releasing XLSR-53,
a large model pretrained in 53 languages.",0,1,0,0,1,0,0.471276,4.0,0.485008,53
f89d3cb5-7fa4-496c-8351-71b33bbc6d99,"Real-time, Universal, and Robust Adversarial Attacks Against Speaker Recognition Systems",85,0.335458,0.854982,"As the popularity of voice user interface (VUI) exploded in recent years,
speaker recognition system has emerged as an important medium of identifying a
speaker in many security-required applications and services. In this paper, we
propose the first real-time, universal, and robust adversarial attack against
the state-of-the-art deep neural network (DNN) based speaker recognition
system. Through adding an audio-agnostic universal perturbation on arbitrary
enrolled speaker's voice input, the DNN-based speaker recognition system would
identify the speaker as any target (i.e., adversary-desired) speaker label. In
addition, we improve the robustness of our attack by modeling the sound
distortions caused by the physical over-the-air propagation through estimating
room impulse response (RIR). Experiment using a public dataset of 109 English
speakers demonstrates the effectiveness and robustness of our proposed attack
with a high attack success rate of over 90%. The attack launching time also
achieves a 100X speedup over contemporary non-universal attacks.",0,1,0,0,1,0,0.818396,5.0,0.784934,18
292a8051-0a36-48b5-bb41-b1daac67600a,Talking-head Generation with Rhythmic Head Motion,145,0.608622,0.997218,"When people deliver a speech, they naturally move heads, and this rhythmic
head motion conveys prosodic information. However, generating a lip-synced
video while moving head naturally is challenging. While remarkably successful,
existing works either generate still talkingface videos or rely on
landmark/video frames as sparse/dense mapping guidance to generate head
movements, which leads to unrealistic or uncontrollable video synthesis. To
overcome the limitations, we propose a 3D-aware generative network along with a
hybrid embedding module and a non-linear composition module. Through modeling
the head motion and facial expressions1 explicitly, manipulating 3D animation
carefully, and embedding reference images dynamically, our approach achieves
controllable, photo-realistic, and temporally coherent talking-head videos with
natural head movements. Thoughtful experiments on several standard benchmarks
demonstrate that our method achieves significantly better results than the
state-of-the-art methods in both quantitative and qualitative comparisons. The
code is available on https://github.com/
lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion.",1,1,0,0,1,0,0.905928,5.0,0.850157,43
65a10aff-fa62-42fb-8d76-2386ce95ee18,A Probabilistic Simulator of Spatial Demand for Product Allocation,6,0.0881614,0.119556,"Connecting consumers with relevant products is a very important problem in
both online and offline commerce. In physical retail, product placement is an
effective way to connect consumers with products. However, selecting product
locations within a store can be a tedious process. Moreover, learning important
spatial patterns in offline retail is challenging due to the scarcity of data
and the high cost of exploration and experimentation in the physical world. To
address these challenges, we propose a stochastic model of spatial demand in
physical retail. We show that the proposed model is more predictive of demand
than existing baselines. We also perform a preliminary study into different
automation techniques and show that an optimal product allocation policy can be
learned through Deep Q-Learning.",0,1,0,0,0,0,0.894062,9.0,0.911025,24
66202350-5254-4dbd-930b-7398bcd3a3c9,GeLaTO: Generative Latent Textured Objects,12,0.0166911,0.102224,"Accurate modeling of 3D objects exhibiting transparency, reflections and thin
structures is an extremely challenging problem. Inspired by billboards and
geometric proxies used in computer graphics, this paper proposes Generative
Latent Textured Objects (GeLaTO), a compact representation that combines a set
of coarse shape proxies defining low frequency geometry with learned neural
textures, to encode both medium and fine scale geometry as well as
view-dependent appearance. To generate the proxies' textures, we learn a joint
latent space allowing category-level appearance and geometry interpolation. The
proxies are independently rasterized with their corresponding neural texture
and composited using a U-Net, which generates an output photorealistic image
including an alpha map. We demonstrate the effectiveness of our approach by
reconstructing complex objects from a sparse set of views. We show results on a
dataset of real images of eyeglasses frames, which are particularly challenging
to reconstruct using classical methods. We also demonstrate that these coarse
proxies can be handcrafted when the underlying object geometry is easy to
model, like eyeglasses, or generated using a neural network for more complex
categories, such as cars.",0,0,0,0,0,0,0.407751,5.0,0.548794,51
406f2d88-97ff-4b1d-bb7d-102837dc48e0,Deep Relational Reasoning Graph Network for Arbitrary Shape Text Detection,154,0.882143,0.996142,"Arbitrary shape text detection is a challenging task due to the high variety
and complexity of scenes texts. In this paper, we propose a novel unified
relational reasoning graph network for arbitrary shape text detection. In our
method, an innovative local graph bridges a text proposal model via
Convolutional Neural Network (CNN) and a deep relational reasoning network via
Graph Convolutional Network (GCN), making our network end-to-end trainable. To
be concrete, every text instance will be divided into a series of small
rectangular components, and the geometry attributes (e.g., height, width, and
orientation) of the small components will be estimated by our text proposal
model. Given the geometry attributes, the local graph construction model can
roughly establish linkages between different text components. For further
reasoning and deducing the likelihood of linkages between the component and its
neighbors, we adopt a graph-based network to perform deep relational reasoning
on local graphs. Experiments on public available datasets demonstrate the
state-of-the-art performance of our method.",1,1,0,0,1,0,0.965413,5.0,0.920755,44
a419b9a1-f52e-4fe6-bf86-a45caeb859c1,Improving Face Recognition by Clustering Unlabeled Faces in the Wild,15,0.0287589,0.341923,"While deep face recognition has benefited significantly from large-scale
labeled data, current research is focused on leveraging unlabeled data to
further boost performance, reducing the cost of human annotation. Prior work
has mostly been in controlled settings, where the labeled and unlabeled data
sets have no overlapping identities by construction. This is not realistic in
large-scale face recognition, where one must contend with such overlaps, the
frequency of which increases with the volume of data. Ignoring identity overlap
leads to significant labeling noise, as data from the same identity is split
into multiple clusters. To address this, we propose a novel identity separation
method based on extreme value theory. It is formulated as an
out-of-distribution detection algorithm, and greatly reduces the problems
caused by overlapping-identity label noise. Considering cluster assignments as
pseudo-labels, we must also overcome the labeling noise from clustering errors.
We propose a modulation of the cosine loss, where the modulation weights
correspond to an estimate of clustering uncertainty. Extensive experiments on
both controlled and real settings demonstrate our method's consistent
improvements over supervised baselines, e.g., 11.6% improvement on IJB-A
verification.",0,1,1,0,0,0,0.303215,8.0,0.671557,47
1481072a-977a-41a5-8966-63c75b34545d,Learned Initializations for Optimizing Coordinate-Based Neural Representations,227,0.625881,0.984219,"Coordinate-based neural representations have shown significant promise as an
alternative to discrete, array-based representations for complex low
dimensional signals. However, optimizing a coordinate-based network from
randomly initialized weights for each new signal is inefficient. We propose
applying standard meta-learning algorithms to learn the initial weight
parameters for these fully-connected networks based on the underlying class of
signals being represented (e.g., images of faces or 3D models of chairs).
Despite requiring only a minor change in implementation, using these learned
initial weights enables faster convergence during optimization and can serve as
a strong prior over the signal class being modeled, resulting in better
generalization when only partial observations of a given signal are available.
We explore these benefits across a variety of tasks, including representing 2D
images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D
image observations.",0,1,0,0,0,0,0.956266,4.0,0.882869,39
0674d539-9d1b-4230-83ba-41f0b5df693a,Learning Branching Heuristics for Propositional Model Counting,12,0.0526514,0.290274,"Propositional model counting, or #SAT, is the problem of computing the number
of satisfying assignments of a Boolean formula. Many problems from different
application areas, including many discrete probabilistic inference problems,
can be translated into model counting problems to be solved by #SAT solvers.
Exact #SAT solvers, however, are often not scalable to industrial size
instances. In this paper, we present Neuro#, an approach for learning branching
heuristics to improve the performance of exact #SAT solvers on instances from a
given family of problems. We experimentally show that our method reduces the
step count on similarly distributed held-out instances and generalizes to much
larger instances from the same problem family. It is able to achieve these
results on a number of different problem families having very different
structures. In addition to step count improvements, Neuro# can also achieve
orders of magnitude wall-clock speedups over the vanilla solver on larger
instances in some problem families, despite the runtime overhead of querying
the model.",1,0,0,0,0,0,0.0132216,13.0,0.543947,52
56eeebfa-b45d-43ab-ab6c-23ac0d089281,Lightweight Photometric Stereo for Facial Details Recovery,23,0.36753,0.567482,"Recently, 3D face reconstruction from a single image has achieved great
success with the help of deep learning and shape prior knowledge, but they
often fail to produce accurate geometry details. On the other hand, photometric
stereo methods can recover reliable geometry details, but require dense inputs
and need to solve a complex optimization problem. In this paper, we present a
lightweight strategy that only requires sparse inputs or even a single image to
recover high-fidelity face shapes with images captured under near-field lights.
To this end, we construct a dataset containing 84 different subjects with 29
expressions under 3 different lights. Data augmentation is applied to enrich
the data in terms of diversity in identity, lighting, expression, etc. With
this constructed dataset, we propose a novel neural network specially designed
for photometric stereo based 3D face reconstruction. Extensive experiments and
comparisons demonstrate that our method can generate high-quality
reconstruction results with one to three facial images captured under
near-field lights. Our full framework is available at
https://github.com/Juyong/FacePSNet.",1,1,0,1,0,0,0.846672,6.0,0.836544,49
65c88955-8773-44ed-afcd-b43f67596bb7,Unsupervised and Interpretable Domain Adaptation to Rapidly Filter Tweets for Emergency Services,5,0.0529983,0.233507,"During the onset of a disaster event, filtering relevant information from the
social web data is challenging due to its sparse availability and practical
limitations in labeling datasets of an ongoing crisis. In this paper, we
hypothesize that unsupervised domain adaptation through multi-task learning can
be a useful framework to leverage data from past crisis events for training
efficient information filtering models during the sudden onset of a new crisis.
We present a novel method to classify relevant tweets during an ongoing crisis
without seeing any new examples, using the publicly available dataset of TREC
incident streams. Specifically, we construct a customized multi-task
architecture with a multi-domain discriminator for crisis analytics: multi-task
domain adversarial attention network. This model consists of dedicated
attention layers for each task to provide model interpretability; critical for
real-word applications. As deep networks struggle with sparse datasets, we show
that this can be improved by sharing a base layer for multi-task learning and
domain adversarial training. Evaluation of domain adaptation for crisis events
is performed by choosing a target event as the test set and training on the
rest. Our results show that the multi-task model outperformed its single task
counterpart. For the qualitative evaluation of interpretability, we show that
the attention layer can be used as a guide to explain the model predictions and
empower emergency services for exploring accountability of the model, by
showcasing the words in a tweet that are deemed important in the classification
process. Finally, we show a practical implication of our work by providing a
use-case for the COVID-19 pandemic.",1,1,0,0,0,0,0.396821,11.0,0.791676,41
9fb07a52-6218-4d38-80dc-3fa608a8d47b,Cross-Domain Latent Modulation for Variational Transfer Learning,1,0.0178245,0.0159603,"We propose a cross-domain latent modulation mechanism within a variational
autoencoders (VAE) framework to enable improved transfer learning. Our key idea
is to procure deep representations from one data domain and use it as
perturbation to the reparameterization of the latent variable in another
domain. Specifically, deep representations of the source and target domains are
first extracted by a unified inference model and aligned by employing gradient
reversal. Second, the learned deep representations are cross-modulated to the
latent encoding of the alternate domain. The consistency between the
reconstruction from the modulated latent encoding and the generation using deep
representation samples is then enforced in order to produce inter-class
alignment in the latent space. We apply the proposed model to a number of
transfer learning tasks including unsupervised domain adaptation and
image-toimage translation. Experimental results show that our model gives
competitive performance.",0,0,0,0,0,0,0.95473,8.0,0.940048,47
3504b6a8-8c92-4196-a139-14ae68dd9f33,Unsupervised Embedding-based Detection of Lexical Semantic Changes,7,0.122407,0.387789,"This paper describes EmbLexChange, a system introduced by the ""Life-Language""
team for SemEval-2020 Task 1, on unsupervised detection of lexical-semantic
changes. EmbLexChange is defined as the divergence between the embedding based
profiles of word w (calculated with respect to a set of reference words) in the
source and the target domains (source and target domains can be simply two time
frames t1 and t2). The underlying assumption is that the lexical-semantic
change of word w would affect its co-occurring words and subsequently alters
the neighborhoods in the embedding spaces. We show that using a resampling
framework for the selection of reference words, we can reliably detect
lexical-semantic changes in English, German, Swedish, and Latin. EmbLexChange
achieved second place in the binary detection of semantic changes in the
SemEval-2020.",0,1,0,0,0,0,0.304956,9.0,0.708817,19
c6762892-d073-4e49-8ca8-c661c96dd8bc,Age-Aware Status Update Control for Energy Harvesting IoT Sensors via Reinforcement Learning,29,0.57897,0.725182,"We consider an IoT sensing network with multiple users, multiple energy
harvesting sensors, and a wireless edge node acting as a gateway between the
users and sensors. The users request for updates about the value of physical
processes, each of which is measured by one sensor. The edge node has a cache
storage that stores the most recently received measurements from each sensor.
Upon receiving a request, the edge node can either command the corresponding
sensor to send a status update, or use the data in the cache. We aim to find
the best action of the edge node to minimize the average long-term cost which
trade-offs between the age of information and energy consumption. We propose a
practical reinforcement learning approach that finds an optimal policy without
knowing the exact battery levels of the sensors.",0,1,0,0,0,0,0.960199,6.0,0.926857,20
1a2b2506-7f2d-4e54-aff9-809126e04e76,UPB at SemEval-2020 Task 11: Propaganda Detection with Domain-Specific Trained BERT,12,0.242,0.0571448,"Manipulative and misleading news have become a commodity for some online news
outlets and these news have gained a significant impact on the global mindset
of people. Propaganda is a frequently employed manipulation method having as
goal to influence readers by spreading ideas meant to distort or manipulate
their opinions. This paper describes our participation in the SemEval-2020,
Task 11: Detection of Propaganda Techniques in News Articles competition. Our
approach considers specializing a pre-trained BERT model on propagandistic and
hyperpartisan news articles, enabling it to create more adequate
representations for the two subtasks, namely propaganda Span Identification
(SI) and propaganda Technique Classification (TC). Our proposed system achieved
a F1-score of 46.060% in subtask SI, ranking 5th in the leaderboard from 36
teams and a micro-averaged F1 score of 54.302% for subtask TC, ranking 19th
from 32 teams.",0,1,0,0,0,0,0.904414,4.0,0.811002,17
745ff4f6-b369-4f16-b8c5-a21e4a9048b1,Multi-hop Question Generation with Graph Convolutional Network,34,0.157079,0.746293,"Multi-hop Question Generation (QG) aims to generate answer-related questions
by aggregating and reasoning over multiple scattered evidence from different
paragraphs. It is a more challenging yet under-explored task compared to
conventional single-hop QG, where the questions are generated from the sentence
containing the answer or nearby sentences in the same paragraph without complex
reasoning. To address the additional challenges in multi-hop QG, we propose
Multi-Hop Encoding Fusion Network for Question Generation (MulQG), which does
context encoding in multiple hops with Graph Convolutional Network and encoding
fusion via an Encoder Reasoning Gate. To the best of our knowledge, we are the
first to tackle the challenge of multi-hop reasoning over paragraphs without
any sentence-level information. Empirical results on HotpotQA dataset
demonstrate the effectiveness of our method, in comparison with baselines on
automatic evaluation metrics. Moreover, from the human evaluation, our proposed
model is able to generate fluent questions with high completeness and
outperforms the strongest baseline by 20.8% in the multi-hop evaluation. The
code is publicly available at
https://github.com/HLTCHKUST/MulQG}{https://github.com/HLTCHKUST/MulQG .",1,0,1,0,0,0,0.477823,7.0,0.708484,38
dd901fb0-1bab-4f99-8388-90b917521358,Automatic Estimation of Self-Reported Pain by Interpretable Representations of Motion Dynamics,8,0.0821767,0.537351,"We propose an automatic method for pain intensity measurement from video. For
each video, pain intensity was measured using the dynamics of facial movement
using 66 facial points. Gram matrices formulation was used for facial points
trajectory representations on the Riemannian manifold of symmetric positive
semi-definite matrices of fixed rank. Curve fitting and temporal alignment were
then used to smooth the extracted trajectories. A Support Vector Regression
model was then trained to encode the extracted trajectories into ten pain
intensity levels consistent with the Visual Analogue Scale for pain intensity
measurement. The proposed approach was evaluated using the UNBC McMaster
Shoulder Pain Archive and was compared to the state-of-the-art on the same
data. Using both 5-fold cross-validation and leave-one-subject-out
cross-validation, our results are competitive with respect to state-of-the-art
methods.",0,0,0,0,0,0,0.00930376,19.0,0.669363,33
10c334dc-e38c-41de-960a-4a682ffe7483,VStreamDRLS: Dynamic Graph Representation Learning with Self-Attention for Enterprise Distributed Video Streaming Solutions,5,0.0964762,0.230278,"Live video streaming has become a mainstay as a standard communication
solution for several enterprises worldwide. To efficiently stream high-quality
live video content to a large amount of offices, companies employ distributed
video streaming solutions which rely on prior knowledge of the underlying
evolving enterprise network. However, such networks are highly complex and
dynamic. Hence, to optimally coordinate the live video distribution, the
available network capacity between viewers has to be accurately predicted. In
this paper we propose a graph representation learning technique on weighted and
dynamic graphs to predict the network capacity, that is the weights of
connections/links between viewers/nodes. We propose VStreamDRLS, a graph neural
network architecture with a self-attention mechanism to capture the evolution
of the graph structure of live video streaming events. VStreamDRLS employs the
graph convolutional network (GCN) model over the duration of a live video
streaming event and introduces a self-attention mechanism to evolve the GCN
parameters. In doing so, our model focuses on the GCN weights that are relevant
to the evolution of the graph and generate the node representation,
accordingly. We evaluate our proposed approach on the link prediction task on
two real-world datasets, generated by enterprise live video streaming events.
The duration of each event lasted an hour. The experimental results demonstrate
the effectiveness of VStreamDRLS when compared with state-of-the-art
strategies. Our evaluation datasets and implementation are publicly available
at https://github.com/stefanosantaris/vstreamdrls",1,1,0,0,1,0,0.458505,7.0,0.700266,32
862081f5-4a39-4072-a6e2-c4a29a535fb0,Long-Term Prediction of Lane Change Maneuver Through a Multilayer Perceptron,19,0.0693786,0.326768,"Behavior prediction plays an essential role in both autonomous driving
systems and Advanced Driver Assistance Systems (ADAS), since it enhances
vehicle's awareness of the imminent hazards in the surrounding environment.
Many existing lane change prediction models take as input lateral or angle
information and make short-term (< 5 seconds) maneuver predictions. In this
study, we propose a longer-term (5~10 seconds) prediction model without any
lateral or angle information. Three prediction models are introduced, including
a logistic regression model, a multilayer perceptron (MLP) model, and a
recurrent neural network (RNN) model, and their performances are compared by
using the real-world NGSIM dataset. To properly label the trajectory data, this
study proposes a new time-window labeling scheme by adding a time gap between
positive and negative samples. Two approaches are also proposed to address the
unstable prediction issue, where the aggressive approach propagates each
positive prediction for certain seconds, while the conservative approach adopts
a roll-window average to smooth the prediction. Evaluation results show that
the developed prediction model is able to capture 75% of real lane change
maneuvers with an average advanced prediction time of 8.05 seconds.",0,0,0,0,0,0,0.0022287,15.0,0.485689,21
7c8cda86-c102-4b26-8295-16772689e456,CPM R-CNN: Calibrating Point-guided Misalignment in Object Detection,15,0.0130803,0.0993806,"In object detection, offset-guided and point-guided regression dominate
anchor-based and anchor-free method separately. Recently, point-guided approach
is introduced to anchor-based method. However, we observe points predicted by
this way are misaligned with matched region of proposals and score of
localization, causing a notable gap in performance. In this paper, we propose
CPM R-CNN which contains three efficient modules to optimize anchor-based
point-guided method. According to sufficient evaluations on the COCO dataset,
CPM R-CNN is demonstrated efficient to improve the localization accuracy by
calibrating mentioned misalignment. Compared with Faster R-CNN and Grid R-CNN
based on ResNet-101 with FPN, our approach can substantially improve detection
mAP by 3.3% and 1.5% respectively without whistles and bells. Moreover, our
best model achieves improvement by a large margin to 49.9% on COCO test-dev.
Code and models will be publicly available.",1,1,0,0,1,0,0.553524,6.0,0.695891,36
a59bb6b8-cc68-4ded-b4aa-27a6d0bba50b,Neural Text Classification by Jointly Learning to Cluster and Align,1,0.00495254,0.0352896,"Distributional text clustering delivers semantically informative
representations and captures the relevance between each word and semantic
clustering centroids. We extend the neural text clustering approach to text
classification tasks by inducing cluster centers via a latent variable model
and interacting with distributional word embeddings, to enrich the
representation of tokens and measure the relatedness between tokens and each
learnable cluster centroid. The proposed method jointly learns word clustering
centroids and clustering-token alignments, achieving the state of the art
results on multiple benchmark datasets and proving that the proposed
cluster-token alignment mechanism is indeed favorable to text classification.
Notably, our qualitative analysis has conspicuously illustrated that text
representations learned by the proposed model are in accord well with our
intuition.",0,0,0,0,1,1,0.275176,9.0,0.695202,50
be6ebe7d-99d5-45ce-9e31-15f74caa92f3,Efficient adjustment sets in causal graphical models with hidden variables,26,0.31909,0.467123,"We study the selection of covariate adjustment sets for estimating the value
of point exposure dynamic policies, also known as dynamic treatment regimes,
assuming a non-parametric causal graphical model with hidden variables, in
which at least one adjustment set is fully observable. We show that recently
developed criteria, for graphs without hidden variables, to compare the
asymptotic variance of non-parametric estimators of static policy values that
control for certain adjustment sets, are also valid under dynamic policies and
graphs with hidden variables. We show that there exist adjustment sets that are
optimal minimal (minimum), in the sense of yielding estimators with the
smallest variance among those that control for adjustment sets that are minimal
(of minimum cardinality). Moreover, we show that if either no variables are
hidden or if all the observable variables are ancestors of either treatment,
outcome, or the variables that are used to decide treatment, a globally optimal
adjustment set exists. We provide polynomial time algorithms to compute the
globally optimal (when it exists), optimal minimal, and optimal minimum
adjustment sets. Our results are based on the construction of an undirected
graph in which vertex cuts between the treatment and outcome variables
correspond to adjustment sets. In this undirected graph, a partial order
between minimal vertex cuts can be defined that makes the set of minimal cuts a
lattice. This partial order corresponds directly to the ordering of the
asymptotic variances of the corresponding non-parametrically adjusted
estimators.",0,0,0,0,0,0,0.143743,16.0,0.782964,43
e7dd531b-67bb-4d80-b47f-af7d7b9cf87f,How to marry a star: probabilistic constraints for meaning in context,7,0.0476225,0.13007,"In this paper, we derive a notion of 'word meaning in context' that
characterizes meaning as both intensional and conceptual. We introduce a
framework for specifying local as well as global constraints on word meaning in
context, together with their interactions, thus modelling the wide range of
lexical shifts and ambiguities observed in utterance interpretation. We
represent sentence meaning as a 'situation description system', a probabilistic
model which takes utterance understanding to be the mental process of
describing to oneself one or more situations that would account for an observed
utterance. We show how the system can be implemented in practice, and apply it
to examples containing various contextualisation phenomena.",0,0,0,0,0,0,0.00610663,14.0,0.521089,98
357c2b34-0d66-47c8-bc4e-4069a57dbde1,"Aggressive, Repetitive, Intentional, Visible, and Imbalanced: Refining Representations for Cyberbullying Classification",27,0.467574,0.115056,"Cyberbullying is a pervasive problem in online communities. To identify
cyberbullying cases in large-scale social networks, content moderators depend
on machine learning classifiers for automatic cyberbullying detection. However,
existing models remain unfit for real-world applications, largely due to a
shortage of publicly available training data and a lack of standard criteria
for assigning ground truth labels. In this study, we address the need for
reliable data using an original annotation framework. Inspired by social
sciences research into bullying behavior, we characterize the nuanced problem
of cyberbullying using five explicit factors to represent its social and
linguistic aspects. We model this behavior using social network and
language-based features, which improve classifier performance. These results
demonstrate the importance of representing and modeling cyberbullying as a
social phenomenon.",0,1,0,1,0,0,0.823561,11.0,0.903768,42
04cf786d-a6cf-4b18-9d07-b6edbb86755f,Statistical stability indices for LIME: obtaining reliable explanations for Machine Learning models,116,0.397787,0.863747,"Nowadays we are witnessing a transformation of the business processes towards
a more computation driven approach. The ever increasing usage of Machine
Learning techniques is the clearest example of such trend.
  This sort of revolution is often providing advantages, such as an increase in
prediction accuracy and a reduced time to obtain the results. However, these
methods present a major drawback: it is very difficult to understand on what
grounds the algorithm took the decision.
  To address this issue we consider the LIME method. We give a general
background on LIME then, we focus on the stability issue: employing the method
repeated times, under the same conditions, may yield to different explanations.
  Two complementary indices are proposed, to measure LIME stability. It is
important for the practitioner to be aware of the issue, as well as to have a
tool for spotting it. Stability guarantees LIME explanations to be reliable,
therefore a stability assessment, made through the proposed indices, is
crucial.
  As a case study, we apply both Machine Learning and classical statistical
techniques to Credit Risk data. We test LIME on the Machine Learning algorithm
and check its stability. Eventually, we examine the goodness of the
explanations returned.",1,1,0,0,0,0,0.462123,7.0,0.701818,38
153c3ef1-9004-496b-9ec4-2d7dcba6f07c,Profile Consistency Identification for Open-domain Dialogue Agents,25,0.164029,0.282343,"Maintaining a consistent attribute profile is crucial for dialogue agents to
naturally converse with humans. Existing studies on improving attribute
consistency mainly explored how to incorporate attribute information in the
responses, but few efforts have been made to identify the consistency relations
between response and attribute profile. To facilitate the study of profile
consistency identification, we create a large-scale human-annotated dataset
with over 110K single-turn conversations and their key-value attribute
profiles. Explicit relation between response and profile is manually labeled.
We also propose a key-value structure information enriched BERT model to
identify the profile consistency, and it gained improvements over strong
baselines. Further evaluations on downstream tasks demonstrate that the profile
consistency identification model is conducive for improving dialogue
consistency.",1,1,1,1,0,0,0.782437,5.0,0.762546,30
c1da52ef-8994-442d-b482-9c8cbd21b0f9,Paranoid Transformer: Reading Narrative of Madness as Computational Approach to Creativity,14,0.297398,0.410642,"This papers revisits the receptive theory in context of computational
creativity. It presents a case study of a Paranoid Transformer - a fully
autonomous text generation engine with raw output that could be read as the
narrative of a mad digital persona without any additional human post-filtering.
We describe technical details of the generative system, provide examples of
output and discuss the impact of receptive theory, chance discovery and
simulation of fringe mental state on the understanding of computational
creativity.",0,0,0,0,0,0,0.374874,8.0,0.70439,52
e840a22e-587a-46a0-a4f2-e96f1e06735c,Differentiable Reasoning over a Virtual Knowledge Base,81,0.295512,0.966386,"We consider the task of answering complex multi-hop questions using a corpus
as a virtual knowledge base (KB). In particular, we describe a neural module,
DrKIT, that traverses textual data like a KB, softly following paths of
relations between mentions of entities in the corpus. At each step the module
uses a combination of sparse-matrix TFIDF indices and a maximum inner product
search (MIPS) on a special index of contextual representations of the mentions.
This module is differentiable, so the full system can be trained end-to-end
using gradient based methods, starting from natural language inputs. We also
describe a pretraining scheme for the contextual representation encoder by
generating hard negative examples using existing knowledge bases. We show that
DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset,
cutting the gap between text-based and KB-based state-of-the-art by 70%. On
HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking
approach to retrieving the relevant passages required to answer a question.
DrKIT is also very efficient, processing 10-100x more queries per second than
existing multi-hop systems.",0,0,0,0,1,0,0.761868,4.0,0.68792,49
96cf26ee-7aea-4a05-9e1f-a279c3aca36a,"Closed Loop Neural-Symbolic Learning via Integrating Neural Perception, Grammar Parsing, and Symbolic Reasoning",67,0.248353,0.568394,"The goal of neural-symbolic computation is to integrate the connectionist and
symbolist paradigms. Prior methods learn the neural-symbolic models using
reinforcement learning (RL) approaches, which ignore the error propagation in
the symbolic reasoning module and thus converge slowly with sparse rewards. In
this paper, we address these issues and close the loop of neural-symbolic
learning by (1) introducing the \textbf{grammar} model as a \textit{symbolic
prior} to bridge neural perception and symbolic reasoning, and (2) proposing a
novel \textbf{back-search} algorithm which mimics the top-down human-like
learning procedure to propagate the error through the symbolic reasoning module
efficiently. We further interpret the proposed learning framework as maximum
likelihood estimation using Markov chain Monte Carlo sampling and the
back-search algorithm as a Metropolis-Hastings sampler. The experiments are
conducted on two weakly-supervised neural-symbolic tasks: (1) handwritten
formula recognition on the newly introduced HWF dataset; (2) visual question
answering on the CLEVR dataset. The results show that our approach
significantly outperforms the RL methods in terms of performance, converging
speed, and data efficiency. Our code and data are released at
\url{https://liqing-ustc.github.io/NGS}.",0,0,0,0,0,0,0.421662,6.0,0.631391,69
0ebf557d-587e-448c-88c4-29f838eadeb8,HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification,102,0.587858,0.840338,"We introduce HoVer (HOppy VERification), a dataset for many-hop evidence
extraction and fact verification. It challenges models to extract facts from
several Wikipedia articles that are relevant to a claim and classify whether
the claim is Supported or Not-Supported by the facts. In HoVer, the claims
require evidence to be extracted from as many as four English Wikipedia
articles and embody reasoning graphs of diverse shapes. Moreover, most of the
3/4-hop claims are written in multiple sentences, which adds to the complexity
of understanding long-range dependency relations such as coreference. We show
that the performance of an existing state-of-the-art semantic-matching model
degrades significantly on our dataset as the number of reasoning hops
increases, hence demonstrating the necessity of many-hop reasoning to achieve
strong results. We hope that the introduction of this challenging dataset and
the accompanying evaluation task will encourage research in many-hop fact
retrieval and information verification. We make the HoVer dataset publicly
available at https://hover-nlp.github.io",1,1,1,1,0,0,0.906442,3.0,0.751034,56
93a17dea-bd44-410c-be6c-832c3f802d75,A Self-Refinement Strategy for Noise Reduction in Grammatical Error Correction,13,0.408155,0.440592,"Existing approaches for grammatical error correction (GEC) largely rely on
supervised learning with manually created GEC datasets. However, there has been
little focus on verifying and ensuring the quality of the datasets, and on how
lower-quality data might affect GEC performance. We indeed found that there is
a non-negligible amount of ""noise"" where errors were inappropriately edited or
left uncorrected. To address this, we designed a self-refinement method where
the key idea is to denoise these datasets by leveraging the prediction
consistency of existing models, and outperformed strong denoising baseline
methods. We further applied task-specific techniques and achieved
state-of-the-art performance on the CoNLL-2014, JFLEG, and BEA-2019 benchmarks.
We then analyzed the effect of the proposed denoising method, and found that
our approach leads to improved coverage of corrections and facilitated fluency
edits which are reflected in higher recall and overall performance.",0,1,0,0,1,0,0.963157,6.0,0.930803,57
d4826477-4553-4d57-8907-496cb05a3888,Knowing What You Know: Calibrating Dialogue Belief State Distributions via Ensembles,6,0.0981601,0.270096,"The ability to accurately track what happens during a conversation is
essential for the performance of a dialogue system. Current state-of-the-art
multi-domain dialogue state trackers achieve just over 55% accuracy on the
current go-to benchmark, which means that in almost every second dialogue turn
they place full confidence in an incorrect dialogue state. Belief trackers, on
the other hand, maintain a distribution over possible dialogue states. However,
they lack in performance compared to dialogue state trackers, and do not
produce well calibrated distributions. In this work we present state-of-the-art
performance in calibration for multi-domain dialogue belief trackers using a
calibrated ensemble of models. Our resulting dialogue belief tracker also
outperforms previous dialogue belief tracking models in terms of accuracy.",0,1,0,0,1,0,0.962112,4.0,0.894076,26
85cdbad6-2549-4333-a6f7-c25d0c5410e9,Efficient Pedestrian Detection in Top-View Fisheye Images Using Compositions of Perspective View Patches,24,0.123932,0.574033,"Pedestrian detection in images is a topic that has been studied extensively,
but existing detectors designed for perspective images do not perform as
successfully on images taken with top-view fisheye cameras, mainly due to the
orientation variation of people in such images. In our proposed approach,
several perspective views are generated from a fisheye image and then
concatenated to form a composite image. As pedestrians in this composite image
are more likely to be upright, existing detectors designed and trained for
perspective images can be applied directly without additional training. We also
describe a new method of mapping detection bounding boxes from the perspective
views to the fisheye frame. The detection performance on several public
datasets compare favorably with state-of-the-art results.",1,1,0,0,1,0,0.016969,11.0,0.483886,35
0d76de6e-6e0c-4df0-b9fb-6847ae7e1f2d,Evaluating Sentence Segmentation and Word Tokenization Systems on Estonian Web Texts,4,0.00574989,0.0332029,"Texts obtained from web are noisy and do not necessarily follow the
orthographic sentence and word boundary rules. Thus, sentence segmentation and
word tokenization systems that have been developed on well-formed texts might
not perform so well on unedited web texts. In this paper, we first describe the
manual annotation of sentence boundaries of an Estonian web dataset and then
present the evaluation results of three existing sentence segmentation and word
tokenization systems on this corpus: EstNLTK, Stanza and UDPipe. While EstNLTK
obtains the highest performance compared to other systems on sentence
segmentation on this dataset, the sentence segmentation performance of Stanza
and UDPipe remains well below the results obtained on the more well-formed
Estonian UD test set.",0,1,0,1,0,0,0.00541868,9.0,0.241708,16
f00a29ba-b48c-4b7d-9155-3ca71e4c1f11,Deep Learning based Automated Forest Health Diagnosis from Aerial Images,44,0.789285,0.588939,"Global climate change has had a drastic impact on our environment. Previous
study showed that pest disaster occured from global climate change may cause a
tremendous number of trees died and they inevitably became a factor of forest
fire. An important portent of the forest fire is the condition of forests.
Aerial image-based forest analysis can give an early detection of dead trees
and living trees. In this paper, we applied a synthetic method to enlarge
imagery dataset and present a new framework for automated dead tree detection
from aerial images using a re-trained Mask RCNN (Mask Region-based
Convolutional Neural Network) approach, with a transfer learning scheme. We
apply our framework to our aerial imagery datasets,and compare eight fine-tuned
models. The mean average precision score (mAP) for the best of these models
reaches 54%. Following the automated detection, we are able to automatically
produce and calculate number of dead tree masks to label the dead trees in an
image, as an indicator of forest health that could be linked to the causal
analysis of environmental changes and the predictive likelihood of forest fire.",0,1,0,0,0,0,0.810126,8.0,0.862278,59
dd982d3e-f54c-453a-9ca3-65338c61c45a,Extracting Semantic Indoor Maps from Occupancy Grids,36,0.348504,0.410829,"The primary challenge for any autonomous system operating in realistic,
rather unconstrained scenarios is to manage the complexity and uncertainty of
the real world. While it is unclear how exactly humans and other higher animals
master these problems, it seems evident, that abstraction plays an important
role. The use of abstract concepts allows to define the system behavior on
higher levels. In this paper we focus on the semantic mapping of indoor
environments. We propose a method to extract an abstracted floor plan from
typical grid maps using Bayesian reasoning. The result of this procedure is a
probabilistic generative model of the environment defined over abstract
concepts. It is well suited for higher-level reasoning and communication
purposes. We demonstrate the effectiveness of the approach using real-world
data.",0,0,0,0,0,0,0.0124087,15.0,0.600496,36
5b8d5851-40fa-43ef-97f8-233fc003d360,AxCell: Automatic Extraction of Results from Machine Learning Papers,52,0.118084,0.540522,"Tracking progress in machine learning has become increasingly difficult with
the recent explosion in the number of papers. In this paper, we present AxCell,
an automatic machine learning pipeline for extracting results from papers.
AxCell uses several novel components, including a table segmentation subtask,
to learn relevant structural knowledge that aids extraction. When compared with
existing methods, our approach significantly improves the state of the art for
results extraction. We also release a structured, annotated dataset for
training models for results extraction, and a dataset for evaluating the
performance of models on this task. Lastly, we show the viability of our
approach enables it to be used for semi-automated results extraction in
production, suggesting our improvements make this task practically viable for
the first time. Code is available on GitHub.",0,1,0,1,1,0,0.483766,5.0,0.595371,15
e0686eb2-e2ce-49d5-b67a-554ef710b70a,ONION: A Simple and Effective Defense Against Textual Backdoor Attacks,165,0.997685,0.909749,"Backdoor attacks are a kind of emergent training-time threat to deep neural
networks (DNNs). They can manipulate the output of DNNs and possess high
insidiousness. In the field of natural language processing, some attack methods
have been proposed and achieve very high attack success rates on multiple
popular models. Nevertheless, there are few studies on defending against
textual backdoor attacks. In this paper, we propose a simple and effective
textual backdoor defense named ONION, which is based on outlier word detection
and, to the best of our knowledge, is the first method that can handle all the
textual backdoor attack situations. Experiments demonstrate the effectiveness
of our model in defending BiLSTM and BERT against five different backdoor
attacks. All the code and data of this paper can be obtained at
https://github.com/thunlp/ONION.",1,1,0,0,0,0,0.992792,4.0,0.996602,30
bff0b436-aa3d-41bc-810e-c3be30092f7f,Drug Repurposing for COVID-19 via Knowledge Graph Completion,113,0.86341,0.935665,"Objective: To discover candidate drugs to repurpose for COVID-19 using
literature-derived knowledge and knowledge graph completion methods. Methods:
We propose a novel, integrative, and neural network-based literature-based
discovery (LBD) approach to identify drug candidates from both PubMed and
COVID-19-focused research literature. Our approach relies on semantic triples
extracted using SemRep (via SemMedDB). We identified an informative subset of
semantic triples using filtering rules and an accuracy classifier developed on
a BERT variant, and used this subset to construct a knowledge graph. Five SOTA,
neural knowledge graph completion algorithms were used to predict drug
repurposing candidates. The models were trained and assessed using a time
slicing approach and the predicted drugs were compared with a list of drugs
reported in the literature and evaluated in clinical trials. These models were
complemented by a discovery pattern-based approach. Results: Accuracy
classifier based on PubMedBERT achieved the best performance (F1= 0.854) in
classifying semantic predications. Among five knowledge graph completion
models, TransE outperformed others (MR = 0.923, Hits@1=0.417). Some known drugs
linked to COVID-19 in the literature were identified, as well as some candidate
drugs that have not yet been studied. Discovery patterns enabled generation of
plausible hypotheses regarding the relationships between the candidate drugs
and COVID-19. Among them, five highly ranked and novel drugs (paclitaxel, SB
203580, alpha 2-antiplasmin, pyrrolidine dithiocarbamate, and butylated
hydroxytoluene) with their mechanistic explanations were further discussed.
Conclusion: We show that an LBD approach can be feasible for discovering drug
candidates for COVID-19, and for generating mechanistic explanations. Our
approach can be generalized to other diseases as well as to other clinical
questions.",1,1,0,0,0,0,0.748847,6.0,0.785645,130
3ff7d34d-d1a1-469e-84f7-fdfe5f3cd72a,Causal Effects of Linguistic Properties,33,0.137643,0.517155,"We consider the problem of using observational data to estimate the causal
effects of linguistic properties. For example, does writing a complaint
politely lead to a faster response time? How much will a positive product
review increase sales? This paper addresses two technical challenges related to
the problem before developing a practical method. First, we formalize the
causal quantity of interest as the effect of a writer's intent, and establish
the assumptions necessary to identify this from observational data. Second, in
practice, we only have access to noisy proxies for the linguistic properties of
interest -- e.g., predictions from classifiers and lexicons. We propose an
estimator for this setting and prove that its bias is bounded when we perform
an adjustment for the text. Based on these results, we introduce TextCause, an
algorithm for estimating causal effects of linguistic properties. The method
leverages (1) distant supervision to improve the quality of noisy proxies, and
(2) a pre-trained language model (BERT) to adjust for the text. We show that
the proposed method outperforms related approaches when estimating the effect
of Amazon review sentiment on semi-simulated sales figures. Finally, we present
an applied case study investigating the effects of complaint politeness on
bureaucratic response times.",1,0,0,0,0,0,0.108589,9.0,0.580811,63
b7decabb-2636-4624-85a0-aab93fe97a0e,Quantifying Intimacy in Language,46,0.227882,0.78107,"Intimacy is a fundamental aspect of how we relate to others in social
settings. Language encodes the social information of intimacy through both
topics and other more subtle cues (such as linguistic hedging and swearing).
Here, we introduce a new computational framework for studying expressions of
the intimacy in language with an accompanying dataset and deep learning model
for accurately predicting the intimacy level of questions (Pearson's r=0.87).
Through analyzing a dataset of 80.5M questions across social media, books, and
films, we show that individuals employ interpersonal pragmatic moves in their
language to align their intimacy with social settings. Then, in three studies,
we further demonstrate how individuals modulate their intimacy to match social
norms around gender, social distance, and audience, each validating key
findings from studies in social psychology. Our work demonstrates that intimacy
is a pervasive and impactful social dimension of language.",1,0,1,1,0,0,0.00420978,20.0,0.646116,134
6cc05d44-c79f-4d88-b310-67d867ad90f8,Generating Plausible Counterfactual Explanations for Deep Transformers in Financial Text Classification,54,0.400709,0.819124,"Corporate mergers and acquisitions (M&A) account for billions of dollars of
investment globally every year, and offer an interesting and challenging domain
for artificial intelligence. However, in these highly sensitive domains, it is
crucial to not only have a highly robust and accurate model, but be able to
generate useful explanations to garner a user's trust in the automated system.
Regrettably, the recent research regarding eXplainable AI (XAI) in financial
text classification has received little to no attention, and many current
methods for generating textual-based explanations result in highly implausible
explanations, which damage a user's trust in the system. To address these
issues, this paper proposes a novel methodology for producing plausible
counterfactual explanations, whilst exploring the regularization benefits of
adversarial training on language models in the domain of FinTech. Exhaustive
quantitative experiments demonstrate that not only does this approach improve
the model accuracy when compared to the current state-of-the-art and human
performance, but it also generates counterfactual explanations which are
significantly more plausible based on human trials.",0,1,0,0,1,0,0.72311,5.0,0.72813,37
6061d535-19d0-4de7-bc9b-8710718b4e4d,Image Restoration for Under-Display Camera,51,0.155207,0.817296,"The new trend of full-screen devices encourages us to position a camera
behind a screen. Removing the bezel and centralizing the camera under the
screen brings larger display-to-body ratio and enhances eye contact in video
chat, but also causes image degradation. In this paper, we focus on a
newly-defined Under-Display Camera (UDC), as a novel real-world single image
restoration problem. First, we take a 4k Transparent OLED (T-OLED) and a phone
Pentile OLED (P-OLED) and analyze their optical systems to understand the
degradation. Second, we design a Monitor-Camera Imaging System (MCIS) for
easier real pair data acquisition, and a model-based data synthesizing pipeline
to generate Point Spread Function (PSF) and UDC data only from display pattern
and camera measurements. Finally, we resolve the complicated degradation using
deconvolution-based pipeline and learning-based methods. Our model demonstrates
a real-time high-quality restoration. The presented methods and results reveal
the promising research values and directions of UDC.",0,1,1,1,0,0,0.550838,4.0,0.541971,52
bebb2889-628a-4d84-9113-953d5223ed32,Cascaded Refinement Network for Point Cloud Completion,196,0.82831,0.960048,"Point clouds are often sparse and incomplete. Existing shape completion
methods are incapable of generating details of objects or learning the complex
point distributions. To this end, we propose a cascaded refinement network
together with a coarse-to-fine strategy to synthesize the detailed object
shapes. Considering the local details of partial input with the global shape
information together, we can preserve the existing details in the incomplete
point set and generate the missing parts with high fidelity. We also design a
patch discriminator that guarantees every local area has the same pattern with
the ground truth to learn the complicated point distribution. Quantitative and
qualitative experiments on different datasets show that our method achieves
superior results compared to existing state-of-the-art approaches on the 3D
point cloud completion task. Our source code is available at
https://github.com/xiaogangw/cascaded-point-completion.git.",1,1,0,0,1,0,0.960663,5.0,0.912955,54
2dc11be9-1f84-48f6-9019-1e1efb5ae15f,Rumor Detection on Twitter Using Multiloss Hierarchical BiLSTM with an Attenuation Factor,9,0.146982,0.057654,"Social media platforms such as Twitter have become a breeding ground for
unverified information or rumors. These rumors can threaten people's health,
endanger the economy, and affect the stability of a country. Many researchers
have developed models to classify rumors using traditional machine learning or
vanilla deep learning models. However, previous studies on rumor detection have
achieved low precision and are time consuming. Inspired by the hierarchical
model and multitask learning, a multiloss hierarchical BiLSTM model with an
attenuation factor is proposed in this paper. The model is divided into two
BiLSTM modules: post level and event level. By means of this hierarchical
structure, the model can extract deep in-formation from limited quantities of
text. Each module has a loss function that helps to learn bilateral features
and reduce the training time. An attenuation fac-tor is added at the post level
to increase the accuracy. The results on two rumor datasets demonstrate that
our model achieves better performance than that of state-of-the-art machine
learning and vanilla deep learning models.",0,1,0,0,1,0,0.706054,8.0,0.824123,32
5bc0897a-76fa-41a9-a661-c2dcb85e2375,Named Entities in Medical Case Reports: Corpus and Experiments,9,0.12622,0.292478,"We present a new corpus comprising annotations of medical entities in case
reports, originating from PubMed Central's open access library. In the case
reports, we annotate cases, conditions, findings, factors and negation
modifiers. Moreover, where applicable, we annotate relations between these
entities. As such, this is the first corpus of this kind made available to the
scientific community in English. It enables the initial investigation of
automatic information extraction from case reports through tasks like Named
Entity Recognition, Relation Extraction and (sentence/paragraph) relevance
detection. Additionally, we present four strong baseline systems for the
detection of medical entities made available through the annotated dataset.",0,1,1,1,0,0,0.801217,6.0,0.811705,30
f8ecac98-7c34-4fb3-b9bb-3e0c7967ac7a,Towards Maximizing the Representation Gap between In-Domain & Out-of-Distribution Examples,47,0.165506,0.799453,"Among existing uncertainty estimation approaches, Dirichlet Prior Network
(DPN) distinctly models different predictive uncertainty types. However, for
in-domain examples with high data uncertainties among multiple classes, even a
DPN model often produces indistinguishable representations from the
out-of-distribution (OOD) examples, compromising their OOD detection
performance. We address this shortcoming by proposing a novel loss function for
DPN to maximize the \textit{representation gap} between in-domain and OOD
examples. Experimental results demonstrate that our proposed approach
consistently improves OOD detection performance.",1,1,0,0,0,0,0.745391,8.0,0.837991,40
d466471a-d21f-4071-8f93-c495457fff38,AViD Dataset: Anonymized Videos from Diverse Countries,30,0.0868772,0.546596,"We introduce a new public video dataset for action recognition: Anonymized
Videos from Diverse countries (AViD). Unlike existing public video datasets,
AViD is a collection of action videos from many different countries. The
motivation is to create a public dataset that would benefit training and
pretraining of action recognition models for everybody, rather than making it
useful for limited countries. Further, all the face identities in the AViD
videos are properly anonymized to protect their privacy. It also is a static
dataset where each video is licensed with the creative commons license. We
confirm that most of the existing video datasets are statistically biased to
only capture action videos from a limited number of countries. We
experimentally illustrate that models trained with such biased datasets do not
transfer perfectly to action videos from the other countries, and show that
AViD addresses such problem. We also confirm that the new AViD dataset could
serve as a good dataset for pretraining the models, performing comparably or
better than prior datasets.",1,1,1,1,0,0,0.28267,7.0,0.612658,32
67ae1264-5593-44c1-a43e-2c85bab5512f,Response-Anticipated Memory for On-Demand Knowledge Integration in Response Generation,25,0.138374,0.556525,"Neural conversation models are known to generate appropriate but
non-informative responses in general. A scenario where informativeness can be
significantly enhanced is Conversing by Reading (CbR), where conversations take
place with respect to a given external document. In previous work, the external
document is utilized by (1) creating a context-aware document memory that
integrates information from the document and the conversational context, and
then (2) generating responses referring to the memory. In this paper, we
propose to create the document memory with some anticipated responses in mind.
This is achieved using a teacher-student framework. The teacher is given the
external document, the context, and the ground-truth response, and learns how
to build a response-aware document memory from three sources of information.
The student learns to construct a response-anticipated document memory from the
first two sources, and the teacher's insight on memory creation. Empirical
results show that our model outperforms the previous state-of-the-art for the
CbR task.",1,1,0,0,1,0,0.623499,7.0,0.766732,39
aa981536-a6e7-47fa-b76b-e2adcda558d5,Neural Network Activation Quantization with Bitwise Information Bottlenecks,1,0.00933918,0.0178465,"Recent researches on information bottleneck shed new light on the continuous
attempts to open the black box of neural signal encoding. Inspired by the
problem of lossy signal compression for wireless communication, this paper
presents a Bitwise Information Bottleneck approach for quantizing and encoding
neural network activations. Based on the rate-distortion theory, the Bitwise
Information Bottleneck attempts to determine the most significant bits in
activation representation by assigning and approximating the sparse coefficient
associated with each bit. Given the constraint of a limited average code rate,
the information bottleneck minimizes the rate-distortion for optimal activation
quantization in a flexible layer-by-layer manner. Experiments over ImageNet and
other datasets show that, by minimizing the quantization rate-distortion of
each layer, the neural network with information bottlenecks achieves the
state-of-the-art accuracy with low-precision activation. Meanwhile, by reducing
the code rate, the proposed method can improve the memory and computational
efficiency by over six times compared with the deep neural network with
standard single-precision representation. Codes will be available on GitHub
when the paper is accepted \url{https://github.com/BitBottleneck/PublicCode}.",1,0,1,0,1,0,0.673812,8.0,0.813018,37
79561ffe-0fca-4885-9e2b-0f460531dc5f,Advancing Non-Contact Vital Sign Measurement using Synthetic Avatars,22,0.774149,0.652317,"Non-contact physiological measurement has the potential to provide low-cost,
non-invasive health monitoring. However, machine vision approaches are often
limited by the availability and diversity of annotated video datasets resulting
in poor generalization to complex real-life conditions. To address these
challenges, this work proposes the use of synthetic avatars that display facial
blood flow changes and allow for systematic generation of samples under a wide
variety of conditions. Our results show that training on both simulated and
real video data can lead to performance gains under challenging conditions. We
show state-of-the-art performance on three large benchmark datasets and
improved robustness to skin type and motion.",0,1,0,1,1,0,0.927479,10.0,0.935522,56
d08ae239-33d9-40e2-a871-5422d8213ad2,Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning,33,0.251042,0.706868,"We consider the problem of learning fair policies in (deep) cooperative
multi-agent reinforcement learning (MARL). We formalize it in a principled way
as the problem of optimizing a welfare function that explicitly encodes two
important aspects of fairness: efficiency and equity. As a solution method, we
propose a novel neural network architecture, which is composed of two
sub-networks specifically designed for taking into account the two aspects of
fairness. In experiments, we demonstrate the importance of the two sub-networks
for fair optimization. Our overall approach is general as it can accommodate
any (sub)differentiable welfare function. Therefore, it is compatible with
various notions of fairness that have been proposed in the literature (e.g.,
lexicographic maximin, generalized Gini social welfare function, proportional
fairness). Our solution method is generic and can be implemented in various
MARL settings: centralized training and decentralized execution, or fully
decentralized. Finally, we experimentally validate our approach in various
domains and show that it can perform much better than previous methods.",1,0,0,0,1,0,0.394933,8.0,0.71278,61
16e1d96c-c19f-4207-a473-77b6deeb4ebf,Impact of News on the Commodity Market: Dataset and Results,42,0.808069,0.851451,"Over the last few years, machine learning based methods have been applied to
extract information from news flow in the financial domain. However, this
information has mostly been in the form of the financial sentiments contained
in the news headlines, primarily for the stock prices. In our current work, we
propose that various other dimensions of information can be extracted from news
headlines, which will be of interest to investors, policy-makers and other
practitioners. We propose a framework that extracts information such as past
movements and expected directionality in prices, asset comparison and other
general information that the news is referring to. We apply this framework to
the commodity ""Gold"" and train the machine learning models using a dataset of
11,412 human-annotated news headlines (released with this study), collected
from the period 2000-2019. We experiment to validate the causal effect of news
flow on gold prices and observe that the information produced from our
framework significantly impacts the future gold price.",0,1,0,1,0,0,0.216124,18.0,0.832108,32
32e3aae3-c81a-4427-bb4d-783ad6413aae,"Multi-talker ASR for an unknown number of sources: Joint training of source counting, separation and ASR",37,0.600701,0.857828,"Most approaches to multi-talker overlapped speech separation and recognition
assume that the number of simultaneously active speakers is given, but in
realistic situations, it is typically unknown. To cope with this, we extend an
iterative speech extraction system with mechanisms to count the number of
sources and combine it with a single-talker speech recognizer to form the first
end-to-end multi-talker automatic speech recognition system for an unknown
number of active speakers. Our experiments show very promising performance in
counting accuracy, source separation and speech recognition on simulated clean
mixtures from WSJ0-2mix and WSJ0-3mix. Among others, we set a new
state-of-the-art word error rate on the WSJ0-2mix database. Furthermore, our
system generalizes well to a larger number of speakers than it ever saw during
training, as shown in experiments with the WSJ0-4mix database.",0,1,0,0,1,0,0.940395,5.0,0.885461,32
b137c3dc-c9c5-4c3b-97cf-8dd7c611ff78,Real-time single image depth perception in the wild with handheld devices,35,0.39738,0.664138,"Depth perception is paramount to tackle real-world problems, ranging from
autonomous driving to consumer applications. For the latter, depth estimation
from a single image represents the most versatile solution, since a standard
camera is available on almost any handheld device. Nonetheless, two main issues
limit its practical deployment: i) the low reliability when deployed
in-the-wild and ii) the demanding resource requirements to achieve real-time
performance, often not compatible with such devices. Therefore, in this paper,
we deeply investigate these issues showing how they are both addressable
adopting appropriate network design and training strategies -- also outlining
how to map the resulting networks on handheld devices to achieve real-time
performance. Our thorough evaluation highlights the ability of such fast
networks to generalize well to new environments, a crucial feature required to
tackle the extremely varied contexts faced in real applications. Indeed, to
further support this evidence, we report experimental results concerning
real-time depth-aware augmented reality and image blurring with smartphones
in-the-wild.",1,1,0,0,0,0,0.94306,5.0,0.888679,56
46ecb6dc-dadb-450a-8d98-14d45e8f9a6c,On the Mutual Information between Source and Filter Contributions for Voice Pathology Detection,26,0.364242,0.798819,"This paper addresses the problem of automatic detection of voice pathologies
directly from the speech signal. For this, we investigate the use of the
glottal source estimation as a means to detect voice disorders. Three sets of
features are proposed, depending on whether they are related to the speech or
the glottal signal, or to prosody. The relevancy of these features is assessed
through mutual information-based measures. This allows an intuitive
interpretation in terms of discrimation power and redundancy between the
features, independently of any subsequent classifier. It is discussed which
characteristics are interestingly informative or complementary for detecting
voice pathologies.",0,1,0,0,0,0,0.0351529,42.0,0.882389,21
52c82bcf-04f6-42fb-a255-fd25f9e03a22,UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation,59,0.422438,0.925626,"Despite the success of existing referenced metrics (e.g., BLEU and
MoverScore), they correlate poorly with human judgments for open-ended text
generation including story or dialog generation because of the notorious
one-to-many issue: there are many plausible outputs for the same input, which
may differ substantially in literal or semantics from the limited number of
given references. To alleviate this issue, we propose UNION, a learnable
unreferenced metric for evaluating open-ended story generation, which measures
the quality of a generated story without any reference. Built on top of BERT,
UNION is trained to distinguish human-written stories from negative samples and
recover the perturbation in negative stories. We propose an approach of
constructing negative samples by mimicking the errors commonly observed in
existing NLG models, including repeated plots, conflicting logic, and
long-range incoherence. Experiments on two story datasets demonstrate that
UNION is a reliable measure for evaluating the quality of generated stories,
which correlates better with human judgments and is more generalizable than
existing state-of-the-art metrics.",1,0,0,0,1,0,0.892152,5.0,0.838247,38
9f6af0dd-7e25-44e0-aca7-540545676d33,Deep Active Learning for Biased Datasets via Fisher Kernel Self-Supervision,51,0.114692,0.608671,"Active learning (AL) aims to minimize labeling efforts for data-demanding
deep neural networks (DNNs) by selecting the most representative data points
for annotation. However, currently used methods are ill-equipped to deal with
biased data. The main motivation of this paper is to consider a realistic
setting for pool-based semi-supervised AL, where the unlabeled collection of
train data is biased. We theoretically derive an optimal acquisition function
for AL in this setting. It can be formulated as distribution shift minimization
between unlabeled train data and weakly-labeled validation dataset. To
implement such acquisition function, we propose a low-complexity method for
feature density matching using self-supervised Fisher kernel (FK) as well as
several novel pseudo-label estimators. Our FK-based method outperforms
state-of-the-art methods on MNIST, SVHN, and ImageNet classification while
requiring only 1/10th of processing. The conducted experiments show at least
40% drop in labeling efforts for the biased class-imbalanced data compared to
existing methods.",1,1,0,0,1,0,0.845019,6.0,0.835588,29
a2737532-cd61-4f29-bb2d-c9a8fc2e447c,ConvBERT: Improving BERT with Span-based Dynamic Convolution,134,0.262933,0.951924,"Pre-trained language models like BERT and its variants have recently achieved
impressive performance in various natural language understanding tasks.
However, BERT heavily relies on the global self-attention block and thus
suffers large memory footprint and computation cost. Although all its attention
heads query on the whole input sequence for generating the attention map from a
global perspective, we observe some heads only need to learn local
dependencies, which means the existence of computation redundancy. We therefore
propose a novel span-based dynamic convolution to replace these self-attention
heads to directly model local dependencies. The novel convolution heads,
together with the rest self-attention heads, form a new mixed attention block
that is more efficient at both global and local context learning. We equip BERT
with this mixed attention design and build a ConvBERT model. Experiments have
shown that ConvBERT significantly outperforms BERT and its variants in various
downstream tasks, with lower training cost and fewer model parameters.
Remarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than
ELECTRAbase, while using less than 1/4 training cost. Code and pre-trained
models will be released.",1,1,0,0,1,0,0.92495,4.0,0.835517,78
1b86f215-962b-44ac-8c48-06b84938918e,How important are faces for person re-identification?,21,0.114492,0.559468,"This paper investigates the dependence of existing state-of-the-art person
re-identification models on the presence and visibility of human faces. We
apply a face detection and blurring algorithm to create anonymized versions of
several popular person re-identification datasets including Market1501,
DukeMTMC-reID, CUHK03, Viper, and Airport. Using a cross-section of existing
state-of-the-art models that range in accuracy and computational efficiency, we
evaluate the effect of this anonymization on re-identification performance
using standard metrics. Perhaps surprisingly, the effect on mAP is very small,
and accuracy is recovered by simply training on the anonymized versions of the
data rather than the original data. These findings are consistent across
multiple models and datasets. These results indicate that datasets can be
safely anonymized by blurring faces without significantly impacting the
performance of person reidentification systems, and may allow for the release
of new richer re-identification datasets where previously there were privacy or
data protection concerns.",1,1,0,0,0,0,0.477943,6.0,0.659958,44
f43ce27c-7dfb-49a7-bd09-bb59ca09c290,Deep Q-Network-based Adaptive Alert Threshold Selection Policy for Payment Fraud Systems in Retail Banking,17,0.412952,0.757271,"Machine learning models have widely been used in fraud detection systems.
Most of the research and development efforts have been concentrated on
improving the performance of the fraud scoring models. Yet, the downstream
fraud alert systems still have limited to no model adoption and rely on manual
steps. Alert systems are pervasively used across all payment channels in retail
banking and play an important role in the overall fraud detection process.
Current fraud detection systems end up with large numbers of dropped alerts due
to their inability to account for the alert processing capacity. Ideally, alert
threshold selection enables the system to maximize the fraud detection while
balancing the upstream fraud scores and the available bandwidth of the alert
processing teams. However, in practice, fixed thresholds that are used for
their simplicity do not have this ability. In this paper, we propose an
enhanced threshold selection policy for fraud alert systems. The proposed
approach formulates the threshold selection as a sequential decision making
problem and uses Deep Q-Network based reinforcement learning. Experimental
results show that this adaptive approach outperforms the current static
solutions by reducing the fraud losses as well as improving the operational
efficiency of the alert system.",0,1,0,0,0,0,0.821078,10.0,0.893335,37
84c69859-c214-4556-ae95-6f12c5a6c433,Modeling Online Behavior in Recommender Systems: The Importance of Temporal Context,8,0.0265655,0.171463,"Recommender systems research tends to evaluate model performance offline and
on randomly sampled targets, yet the same systems are later used to predict
user behavior sequentially from a fixed point in time. Simulating online
recommender system performance is notoriously difficult and the discrepancy
between online and offline behaviors is typically not accounted for in offline
evaluations. This disparity permits weaknesses to go unnoticed until the model
is deployed in a production setting. In this paper, we first demonstrate how
omitting temporal context when evaluating recommender system performance leads
to false confidence. To overcome this, we postulate that offline evaluation
protocols can only model real-life use-cases if they account for temporal
context. Next, we propose a training procedure to further embed the temporal
context in existing models. We use a multi-objective approach to introduce
temporal context into traditionally time-unaware recommender systems and
confirm its advantage via the proposed evaluation protocol. Finally, we
validate that the Pareto Fronts obtained with the added objective dominate
those produced by state-of-the-art models that are only optimized for accuracy
on three real-world publicly available datasets. The results show that
including our temporal objective can improve recall@20 by up to 20%.",1,0,0,0,0,0,0.252514,8.0,0.644533,28
c2354029-83b6-4bc9-a68c-cbd92d82289a,Spending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection,8,0.134114,0.44591,"Online electronic coupon (e-coupon) is becoming a primary tool for e-commerce
platforms to attract users to place orders. E-coupons are the digital
equivalent of traditional paper coupons which provide customers with discounts
or gifts. One of the fundamental problems related is how to deliver e-coupons
with minimal cost while users' willingness to place an order is maximized. We
call this problem the coupon allocation problem. This is a non-trivial problem
since the number of regular users on a mature e-platform often reaches hundreds
of millions and the types of e-coupons to be allocated are often multiple. The
policy space is extremely large and the online allocation has to satisfy a
budget constraint. Besides, one can never observe the responses of one user
under different policies which increases the uncertainty of the policy making
process. Previous work fails to deal with these challenges. In this paper, we
decompose the coupon allocation task into two subtasks: the user intent
detection task and the allocation task. Accordingly, we propose a two-stage
solution: at the first stage (detection stage), we put forward a novel
Instantaneous Intent Detection Network (IIDN) which takes the user-coupon
features as input and predicts user real-time intents; at the second stage
(allocation stage), we model the allocation problem as a Multiple-Choice
Knapsack Problem (MCKP) and provide a computational efficient allocation method
using the intents predicted at the detection stage. We conduct extensive online
and offline experiments and the results show the superiority of our proposed
framework, which has brought great profits to the platform and continues to
function online.",0,1,0,0,0,0,0.423982,8.0,0.724458,37
793d1b32-ac1b-4f3e-9167-06dae41b717f,Multilingual Evidence Retrieval and Fact Verification to Combat Global Disinformation: The Power of Polyglotism,3,0.0060287,0.0946884,"This article investigates multilingual evidence retrieval and fact
verification as a step to combat global disinformation, a first effort of this
kind, to the best of our knowledge. The goal is building multilingual systems
that retrieve in evidence-rich languages to verify claims in evidence-poor
languages that are more commonly targeted by disinformation. To this end, our
EnmBERT fact verification system shows evidence of transfer learning ability
and 400 example mixed English-Romanian dataset is made available for
cross-lingual transfer learning evaluation.",0,1,0,1,0,0,0.440431,5.0,0.56937,44
97cc6b68-80aa-4faa-a694-f6c8a30c6119,Domain Adaptive Person Re-Identification via Coupling Optimization,35,0.183441,0.76179,"Domain adaptive person Re-Identification (ReID) is challenging owing to the
domain gap and shortage of annotations on target scenarios. To handle those two
challenges, this paper proposes a coupling optimization method including the
Domain-Invariant Mapping (DIM) method and the Global-Local distance
Optimization (GLO), respectively. Different from previous methods that transfer
knowledge in two stages, the DIM achieves a more efficient one-stage knowledge
transfer by mapping images in labeled and unlabeled datasets to a shared
feature space. GLO is designed to train the ReID model with unsupervised
setting on the target domain. Instead of relying on existing optimization
strategies designed for supervised training, GLO involves more images in
distance optimization, and achieves better robustness to noisy label
prediction. GLO also integrates distance optimizations in both the global
dataset and local training batch, thus exhibits better training efficiency.
Extensive experiments on three large-scale datasets, i.e., Market-1501,
DukeMTMC-reID, and MSMT17, show that our coupling optimization outperforms
state-of-the-art methods by a large margin. Our method also works well in
unsupervised training, and even outperforms several recent domain adaptive
methods.",0,1,0,0,1,0,0.656563,5.0,0.691411,63
6c94cb81-2cd7-4bed-87c0-e2014e933281,Resonance: Replacing Software Constants with Context-Aware Models in Real-time Communication,1,0.00540545,0.0326107,"Large software systems tune hundreds of 'constants' to optimize their runtime
performance. These values are commonly derived through intuition, lab tests, or
A/B tests. A 'one-size-fits-all' approach is often sub-optimal as the best
value depends on runtime context. In this paper, we provide an experimental
approach to replace constants with learned contextual functions for Skype - a
widely used real-time communication (RTC) application. We present Resonance, a
system based on contextual bandits (CB). We describe experiences from three
real-world experiments: applying it to the audio, video, and transport
components in Skype. We surface a unique and practical challenge of performing
machine learning (ML) inference in large software systems written using
encapsulation principles. Finally, we open-source FeatureBroker, a library to
reduce the friction in adopting ML models in such development environments",0,1,0,0,0,0,0.393275,5.0,0.539355,20
a442b959-39f6-47d6-8888-8407d1913a7d,"BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking Scalar Adjectives with Contextualised Representations",17,0.0891718,0.689057,"Adjectives like pretty, beautiful and gorgeous describe positive properties
of the nouns they modify but with different intensity. These differences are
important for natural language understanding and reasoning. We propose a novel
BERT-based approach to intensity detection for scalar adjectives. We model
intensity by vectors directly derived from contextualised representations and
show they can successfully rank scalar adjectives. We evaluate our models both
intrinsically, on gold standard datasets, and on an Indirect Question Answering
task. Our results demonstrate that BERT encodes rich knowledge about the
semantics of scalar adjectives, and is able to provide better quality intensity
rankings than static embeddings and previous models with access to dedicated
resources.",1,0,0,0,0,0,0.187698,9.0,0.646643,56
de6deadb-c7a4-4464-9c34-54f30b909990,Choice functions based on sets of strict partial orders: an axiomatic characterisation,4,0.00982571,0.154822,"Methods for choosing from a set of options are often based on a strict
partial order on these options, or on a set of such partial orders. I here
provide a very general axiomatic characterisation for choice functions of this
form. It includes as special cases axiomatic characterisations for choice
functions based on (sets of) total orders, (sets of) weak orders, (sets of)
coherent lower previsions and (sets of) probability measures.",0,0,0,0,0,0,0.0490929,6.0,0.233597,13
22d11a4a-fb17-4c98-9d3a-cf731d8c03cc,TernaryBERT: Distillation-aware Ultra-low Bit BERT,172,0.219608,0.765891,"Transformer-based pre-training models like BERT have achieved remarkable
performance in many natural language processing tasks.However, these models are
both computation and memory expensive, hindering their deployment to
resource-constrained devices. In this work, we propose TernaryBERT, which
ternarizes the weights in a fine-tuned BERT model. Specifically, we use both
approximation-based and loss-aware ternarization methods and empirically
investigate the ternarization granularity of different parts of BERT. Moreover,
to reduce the accuracy degradation caused by the lower capacity of low bits, we
leverage the knowledge distillation technique in the training process.
Experiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT
outperforms the other BERT quantization methods, and even achieves comparable
performance as the full-precision model while being 14.9x smaller.",1,1,0,0,1,0,0.7545,3.0,0.576738,40
5ce561ab-1680-4650-9b25-12094535b9c3,Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach,67,0.84327,0.833365,"A critical concern in data-driven decision making is to build models whose
outcomes do not discriminate against some demographic groups, including gender,
ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of
the sensitive attributes is essential, while, in practice, these attributes may
not be available due to legal and ethical requirements. To address this
challenge, this paper studies a model that protects the privacy of the
individuals sensitive information while also allowing it to learn
non-discriminatory predictors. The method relies on the notion of differential
privacy and the use of Lagrangian duality to design neural networks that can
accommodate fairness constraints while guaranteeing the privacy of sensitive
attributes. The paper analyses the tension between accuracy, privacy, and
fairness and the experimental evaluation illustrates the benefits of the
proposed model on several prediction tasks.",0,0,0,0,0,0,0.960232,6.0,0.926899,47
50c658bd-cd9c-4bf1-8e9c-20391fe8aff7,"How do Data Science Workers Collaborate? Roles, Workflows, and Tools",210,0.888646,0.99772,"Today, the prominence of data science within organizations has given rise to
teams of data science workers collaborating on extracting insights from data,
as opposed to individual data scientists working alone. However, we still lack
a deep understanding of how data science workers collaborate in practice. In
this work, we conducted an online survey with 183 participants who work in
various aspects of data science. We focused on their reported interactions with
each other (e.g., managers with engineers) and with different tools (e.g.,
Jupyter Notebook). We found that data science teams are extremely collaborative
and work with a variety of stakeholders and tools during the six common steps
of a data science workflow (e.g., clean data and train model). We also found
that the collaborative practices workers employ, such as documentation, vary
according to the kinds of tools they use. Based on these findings, we discuss
design implications for supporting data science team collaborations and future
research directions.",0,1,0,0,0,1,0.200836,8.0,0.611912,105
03e348e3-5ca9-4195-8fd6-672a4f16f523,DenserNet: Weakly Supervised Visual Localization Using Multi-scale Feature Aggregation,87,0.517796,0.721516,"In this work, we introduce a Denser Feature Network (DenserNet) for visual
localization. Our work provides three principal contributions. First, we
develop a convolutional neural network (CNN) architecture which aggregates
feature maps at different semantic levels for image representations. Using
denser feature maps, our method can produce more keypoint features and increase
image retrieval accuracy. Second, our model is trained end-to-end without
pixel-level annotation other than positive and negative GPS-tagged image pairs.
We use a weakly supervised triplet ranking loss to learn discriminative
features and encourage keypoint feature repeatability for image representation.
Finally, our method is computationally efficient as our architecture has shared
features and parameters during computation. Our method can perform accurate
large-scale localization under challenging conditions while remaining the
computational constraint. Extensive experiment results indicate that our method
sets a new state-of-the-art on four challenging large-scale localization
benchmarks and three image retrieval benchmarks.",1,1,0,0,1,0,0.436389,8.0,0.729297,38
09b22d05-9bc0-4990-b240-ccdb105b3cf2,Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics,30,0.52498,0.841924,"A fundamental question in neuroscience is how the brain creates an internal
model of the world to guide actions using sequences of ambiguous sensory
information. This is naturally formulated as a reinforcement learning problem
under partial observations, where an agent must estimate relevant latent
variables in the world from its evidence, anticipate possible future states,
and choose actions that optimize total expected reward. This problem can be
solved by control theory, which allows us to find the optimal actions for a
given system dynamics and objective function. However, animals often appear to
behave suboptimally. Why? We hypothesize that animals have their own flawed
internal model of the world, and choose actions with the highest expected
subjective reward according to that flawed model. We describe this behavior as
rational but not optimal. The problem of Inverse Rational Control (IRC) aims to
identify which internal model would best explain an agent's actions. Our
contribution here generalizes past work on Inverse Rational Control which
solved this problem for discrete control in partially observable Markov
decision processes. Here we accommodate continuous nonlinear dynamics and
continuous actions, and impute sensory observations corrupted by unknown noise
that is private to the animal. We first build an optimal Bayesian agent that
learns an optimal policy generalized over the entire model space of dynamics
and subjective rewards using deep reinforcement learning. Crucially, this
allows us to compute a likelihood over models for experimentally observable
action trajectories acquired from a suboptimal agent. We then find the model
parameters that maximize the likelihood using gradient ascent.",0,0,1,0,0,0,0.539716,12.0,0.844737,70
244bf540-b7e9-47cc-8c6d-05cac3a357b9,Transformer on a Diet,6,0.142647,0.0329993,"Transformer has been widely used thanks to its ability to capture sequence
information in an efficient way. However, recent developments, such as BERT and
GPT-2, deliver only heavy architectures with a focus on effectiveness. In this
paper, we explore three carefully-designed light Transformer architectures to
figure out whether the Transformer with less computations could produce
competitive results. Experimental results on language model benchmark datasets
hint that such trade-off is promising, and the light Transformer reduces 70%
parameters at best, while obtains competitive perplexity compared to standard
Transformer. The source code is publicly available.",0,1,0,0,0,0,0.987278,6.0,0.97734,29
b20a619b-8d9f-4a97-8f14-ff0a400c12c2,Weakly Supervised Instance Segmentation by Deep Community Learning,19,0.17752,0.348786,"We present a weakly supervised instance segmentation algorithm based on deep
community learning with multiple tasks. This task is formulated as a
combination of weakly supervised object detection and semantic segmentation,
where individual objects of the same class are identified and segmented
separately. We address this problem by designing a unified deep neural network
architecture, which has a positive feedback loop of object detection with
bounding box regression, instance mask generation, instance segmentation, and
feature extraction. Each component of the network makes active interactions
with others to improve accuracy, and the end-to-end trainability of our model
makes our results more robust and reproducible. The proposed algorithm achieves
state-of-the-art performance in the weakly supervised setting without any
additional training such as Fast R-CNN and Mask R-CNN on the standard benchmark
dataset. The implementation of our algorithm is available on the project
webpage: https://cv.snu.ac.kr/research/WSIS_CL.",0,1,0,0,1,0,0.920352,7.0,0.902691,54
3833e9d2-bf91-4dec-8155-5ee8b8636682,Generative Multi-Stream Architecture For American Sign Language Recognition,3,0.0717933,0.15794,"With advancements in deep model architectures, tasks in computer vision can
reach optimal convergence provided proper data preprocessing and model
parameter initialization. However, training on datasets with low
feature-richness for complex applications limit and detriment optimal
convergence below human performance. In past works, researchers have provided
external sources of complementary data at the cost of supplementary hardware,
which are fed in streams to counteract this limitation and boost performance.
We propose a generative multi-stream architecture, eliminating the need for
additional hardware with the intent to improve feature richness without risking
impracticability. We also introduce the compact spatio-temporal residual block
to the standard 3-dimensional convolutional model, C3D. Our rC3D model performs
comparatively to the top C3D residual variant architecture, the pseudo-3D
model, on the FASL-RGB dataset. Our methods have achieved 95.62% validation
accuracy with a variance of 1.42% from training, outperforming past models by
0.45% in validation accuracy and 5.53% in variance.",0,1,0,0,0,0,0.969915,10.0,0.964439,14
f301adda-ad26-4a8e-9894-653e042fa798,A Neural Architecture for Detecting Confusion in Eye-tracking Data,2,0.0236194,0.142566,"Encouraged by the success of deep learning in a variety of domains, we
investigate a novel application of its methods on the effectiveness of
detecting user confusion in eye-tracking data. We introduce an architecture
that uses RNN and CNN sub-models in parallel to take advantage of the temporal
and visuospatial aspects of our data. Experiments with a dataset of user
interactions with the ValueChart visualization tool show that our model
outperforms an existing model based on Random Forests resulting in a 22%
improvement in combined sensitivity & specificity.",0,1,0,0,1,0,0.360676,11.0,0.780558,31
73dcce55-01d4-48b9-a84f-d24d793564a8,End-to-End Object Detection with Adaptive Clustering Transformer,162,0.132551,0.730349,"End-to-end Object Detection with Transformer (DETR)proposes to perform object
detection with Transformer and achieve comparable performance with two-stage
object detection like Faster-RCNN. However, DETR needs huge computational
resources for training and inference due to the high-resolution spatial input.
In this paper, a novel variant of transformer named Adaptive Clustering
Transformer(ACT) has been proposed to reduce the computation cost for
high-resolution input. ACT cluster the query features adaptively using Locality
Sensitive Hashing (LSH) and ap-proximate the query-key interaction using the
prototype-key interaction. ACT can reduce the quadratic O(N2) complexity inside
self-attention into O(NK) where K is the number of prototypes in each layer.
ACT can be a drop-in module replacing the original self-attention module
without any training. ACT achieves a good balance between accuracy and
computation cost (FLOPs). The code is available as supplementary for the ease
of experiment replication and verification. Code is released at
\url{https://github.com/gaopengcuhk/SMCA-DETR/}",1,1,0,0,0,0,0.501485,7.0,0.718333,48
0fdfa08f-24c6-4d5a-9eda-83d6dba9837a,Hitachi at SemEval-2020 Task 12: Offensive Language Identification with Noisy Labels using Statistical Sampling and Post-Processing,7,0.16003,0.296054,"In this paper, we present our participation in SemEval-2020 Task-12 Subtask-A
(English Language) which focuses on offensive language identification from
noisy labels. To this end, we developed a hybrid system with the BERT
classifier trained with tweets selected using Statistical Sampling Algorithm
(SA) and Post-Processed (PP) using an offensive wordlist. Our developed system
achieved 34 th position with Macro-averaged F1-score (Macro-F1) of 0.90913 over
both offensive and non-offensive classes. We further show comprehensive results
and error analysis to assist future research in offensive language
identification with noisy labels.",0,1,0,0,0,1,0.929098,5.0,0.872756,33
13b96f94-4dd0-4e42-a138-6c2a2a7af15a,Pain Intensity Estimation from Mobile Video Using 2D and 3D Facial Keypoints,4,0.0405163,0.330549,"Managing post-surgical pain is critical for successful surgical outcomes. One
of the challenges of pain management is accurately assessing the pain level of
patients. Self-reported numeric pain ratings are limited because they are
subjective, can be affected by mood, and can influence the patient's perception
of pain when making comparisons. In this paper, we introduce an approach that
analyzes 2D and 3D facial keypoints of post-surgical patients to estimate their
pain intensity level. Our approach leverages the previously unexplored
capabilities of a smartphone to capture a dense 3D representation of a person's
face as input for pain intensity level estimation. Our contributions are adata
collection study with post-surgical patients to collect ground-truth labeled
sequences of 2D and 3D facial keypoints for developing a pain estimation
algorithm, a pain estimation model that uses multiple instance learning to
overcome inherent limitations in facial keypoint sequences, and the preliminary
results of the pain estimation model using 2D and 3D features with comparisons
of alternate approaches.",0,1,0,1,0,0,0.108652,14.0,0.730565,43
2513ea32-45f9-4ee7-a5de-0c64584c2d5a,Towards Intelligent Robotic Process Automation for BPMers,23,0.743396,0.801093,"Robotic Process Automation (RPA) is a fast-emerging automation technology
that sits between the fields of Business Process Management (BPM) and
Artificial Intelligence (AI), and allows organizations to automate high volume
routines. RPA tools are able to capture the execution of such routines
previously performed by a human users on the interface of a computer system,
and then emulate their enactment in place of the user by means of a software
robot. Nowadays, in the BPM domain, only simple, predictable business processes
involving routine work can be automated by RPA tools in situations where there
is no room for interpretation, while more sophisticated work is still left to
human experts. In this paper, starting from an in-depth experimentation of the
RPA tools available on the market, we provide a classification framework to
categorize them on the basis of some key dimensions. Then, based on this
analysis, we derive four research challenges and discuss prospective approaches
necessary to inject intelligence into current RPA technology, in order to
achieve more widespread adoption of RPA in the BPM domain.",0,1,0,0,0,0,0.964502,8.0,0.949502,40
db5cb118-0184-43f6-bedf-8387194a6c26,The Struggles of Feature-Based Explanations: Shapley Values vs. Minimal Sufficient Subsets,23,0.0580845,0.429833,"For neural models to garner widespread public trust and ensure fairness, we
must have human-intelligible explanations for their predictions. Recently, an
increasing number of works focus on explaining the predictions of neural models
in terms of the relevance of the input features. In this work, we show that
feature-based explanations pose problems even for explaining trivial models. We
show that, in certain cases, there exist at least two ground-truth
feature-based explanations, and that, sometimes, neither of them is enough to
provide a complete view of the decision-making process of the model. Moreover,
we show that two popular classes of explainers, Shapley explainers and minimal
sufficient subsets explainers, target fundamentally different types of
ground-truth explanations, despite the apparently implicit assumption that
explainers should look for one specific feature-based explanation. These
findings bring an additional dimension to consider in both developing and
choosing explainers.",0,0,0,0,0,0,0.664205,6.0,0.746315,16
bfc23cb0-f295-4ddd-bc4e-663f4b685a8f,Adjusting Image Attributes of Localized Regions with Low-level Dialogue,2,0.00851584,0.0704462,"Natural Language Image Editing (NLIE) aims to use natural language
instructions to edit images. Since novices are inexperienced with image editing
techniques, their instructions are often ambiguous and contain high-level
abstractions that tend to correspond to complex editing steps to accomplish.
Motivated by this inexperience aspect, we aim to smooth the learning curve by
teaching the novices to edit images using low-level commanding terminologies.
Towards this end, we develop a task-oriented dialogue system to investigate
low-level instructions for NLIE. Our system grounds language on the level of
edit operations, and suggests options for a user to choose from. Though
compelled to express in low-level terms, a user evaluation shows that 25% of
users found our system easy-to-use, resonating with our motivation. An analysis
shows that users generally adapt to utilizing the proposed low-level language
interface. In this study, we identify that object segmentation as the key
factor to the user satisfaction. Our work demonstrates the advantages of the
low-level, direct language-action mapping approach that can be applied to other
problem domains beyond image editing such as audio editing or industrial
design.",0,1,0,0,0,0,0.45106,5.0,0.575869,32
65fa09c0-4879-4197-86d5-c47e0fe4d2c3,PodSumm -- Podcast Audio Summarization,9,0.193984,0.504155,"The diverse nature, scale, and specificity of podcasts present a unique
challenge to content discovery systems. Listeners often rely on text
descriptions of episodes provided by the podcast creators to discover new
content. Some factors like the presentation style of the narrator and
production quality are significant indicators of subjective user preference but
are difficult to quantify and not reflected in the text descriptions provided
by the podcast creators. We propose the automated creation of podcast audio
summaries to aid in content discovery and help listeners to quickly preview
podcast content before investing time in listening to an entire episode. In
this paper, we present a method to automatically construct a podcast summary
via guidance from the text-domain. Our method performs two key steps, namely,
audio to text transcription and text summary generation. Motivated by a lack of
datasets for this task, we curate an internal dataset, find an effective scheme
for data augmentation, and design a protocol to gather summaries from
annotators. We fine-tune a PreSumm[10] model with our augmented dataset and
perform an ablation study. Our method achieves ROUGE-F(1/2/L) scores of
0.63/0.53/0.63 on our dataset. We hope these results may inspire future
research in this direction.",0,1,0,1,0,0,0.747839,7.0,0.815853,18
28fcd4a7-fef5-4a25-8111-06858cc6754b,Salvaging Federated Learning by Local Adaptation,221,0.659416,0.743505,"Federated learning (FL) is a heavily promoted approach for training ML models
on sensitive data, e.g., text typed by users on their smartphones. FL is
expressly designed for training on data that are unbalanced and non-iid across
the participants. To ensure privacy and integrity of the fedeated model, latest
FL approaches use differential privacy or robust aggregation.
  We look at FL from the \emph{local} viewpoint of an individual participant
and ask: (1) do participants have an incentive to participate in FL? (2) how
can participants \emph{individually} improve the quality of their local models,
without re-designing the FL framework and/or involving other participants?
  First, we show that on standard tasks such as next-word prediction, many
participants gain no benefit from FL because the federated model is less
accurate on their data than the models they can train locally on their own.
Second, we show that differential privacy and robust aggregation make this
problem worse by further destroying the accuracy of the federated model for
many participants.
  Then, we evaluate three techniques for local adaptation of federated models:
fine-tuning, multi-task learning, and knowledge distillation. We analyze where
each is applicable and demonstrate that all participants benefit from local
adaptation. Participants whose local models are poor obtain big accuracy
improvements over conventional FL. Participants whose local models are better
than the federated model\textemdash and who have no incentive to participate in
FL today\textemdash improve less, but sufficiently to make the adapted
federated model better than their local models.",0,1,0,0,0,0,0.8606,4.0,0.767201,48
05e217c1-6aa7-4cb8-82ac-c99ee80c802d,ClimaText: A Dataset for Climate Change Topic Detection,28,0.335641,0.887574,"Climate change communication in the mass media and other textual sources may
affect and shape public perception. Extracting climate change information from
these sources is an important task, e.g., for filtering content and
e-discovery, sentiment analysis, automatic summarization, question-answering,
and fact-checking. However, automating this process is a challenge, as climate
change is a complex, fast-moving, and often ambiguous topic with scarce
resources for popular text-based AI tasks. In this paper, we introduce
\textsc{ClimaText}, a dataset for sentence-based climate change topic
detection, which we make publicly available. We explore different approaches to
identify the climate change topic in various text sources. We find that popular
keyword-based models are not adequate for such a complex and evolving task.
Context-based algorithms like BERT \cite{devlin2018bert} can detect, in
addition to many trivial cases, a variety of complex and implicit topic
patterns. Nevertheless, our analysis reveals a great potential for improvement
in several directions, such as, e.g., capturing the discussion on indirect
effects of climate change. Hence, we hope this work can serve as a good
starting point for further research on this topic.",0,1,1,1,0,0,0.163857,17.0,0.804114,20
bf4d003d-5adc-4508-8641-cbbbc7f3bb25,Space-time Neural Irradiance Fields for Free-Viewpoint Video,370,1.0,1.0,"We present a method that learns a spatiotemporal neural irradiance field for
dynamic scenes from a single video. Our learned representation enables
free-viewpoint rendering of the input video. Our method builds upon recent
advances in implicit representations. Learning a spatiotemporal irradiance
field from a single video poses significant challenges because the video
contains only one observation of the scene at any point in time. The 3D
geometry of a scene can be legitimately represented in numerous ways since
varying geometry (motion) can be explained with varying appearance and vice
versa. We address this ambiguity by constraining the time-varying geometry of
our dynamic scene representation using the scene depth estimated from video
depth estimation methods, aggregating contents from individual frames into a
single global representation. We provide an extensive quantitative evaluation
and demonstrate compelling free-viewpoint rendering results.",1,0,0,0,0,0,0.989374,4.0,0.976117,84
816137e9-6ac2-42d9-81f5-c431c956da61,SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and Synonym Discovery,19,0.117311,0.568483,"Entity set expansion and synonym discovery are two critical NLP tasks.
Previous studies accomplish them separately, without exploring their
interdependencies. In this work, we hypothesize that these two tasks are
tightly coupled because two synonymous entities tend to have similar
likelihoods of belonging to various semantic classes. This motivates us to
design SynSetExpan, a novel framework that enables two tasks to mutually
enhance each other. SynSetExpan uses a synonym discovery model to include
popular entities' infrequent synonyms into the set, which boosts the set
expansion recall. Meanwhile, the set expansion model, being able to determine
whether an entity belongs to a semantic class, can generate pseudo training
data to fine-tune the synonym discovery model towards better accuracy. To
facilitate the research on studying the interplays of these two tasks, we
create the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via
crowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks
demonstrate the effectiveness of SynSetExpan for both entity set expansion and
synonym discovery tasks.",0,1,0,1,0,0,0.0707395,7.0,0.396896,45
39b1cae8-25d5-4758-820b-6b275325b9ad,Least squares surface reconstruction on arbitrary domains,10,0.0445831,0.434105,"Almost universally in computer vision, when surface derivatives are required,
they are computed using only first order accurate finite difference
approximations. We propose a new method for computing numerical derivatives
based on 2D Savitzky-Golay filters and K-nearest neighbour kernels. The
resulting derivative matrices can be used for least squares surface
reconstruction over arbitrary (even disconnected) domains in the presence of
large noise and allowing for higher order polynomial local surface
approximations. They are useful for a range of tasks including
normal-from-depth (i.e. surface differentiation), height-from-normals (i.e.
surface integration) and shape-from-x. We show how to write both orthographic
or perspective height-from-normals as a linear least squares problem using the
same formulation and avoiding a nonlinear change of variables in the
perspective case. We demonstrate improved performance relative to
state-of-the-art across these tasks on both synthetic and real data and make
available an open source implementation of our method.",0,1,0,0,1,0,0.000141114,23.0,0.544552,31
deaabc34-2ae4-4a49-8828-110f6e1831dd,Learning to Match Jobs with Resumes from Sparse Interaction Data using Multi-View Co-Teaching Network,36,0.619527,0.988453,"With the ever-increasing growth of online recruitment data, job-resume
matching has become an important task to automatically match jobs with suitable
resumes. This task is typically casted as a supervised text matching problem.
Supervised learning is powerful when the labeled data is sufficient. However,
on online recruitment platforms, job-resume interaction data is sparse and
noisy, which affects the performance of job-resume match algorithms. To
alleviate these problems, in this paper, we propose a novel multi-view
co-teaching network from sparse interaction data for job-resume matching. Our
network consists of two major components, namely text-based matching model and
relation-based matching model. The two parts capture semantic compatibility in
two different views, and complement each other. In order to address the
challenges from sparse and noisy data, we design two specific strategies to
combine the two components. First, two components share the learned parameters
or representations, so that the original representations of each component can
be enhanced. More importantly, we adopt a co-teaching mechanism to reduce the
influence of noise in training data. The core idea is to let the two components
help each other by selecting more reliable training instances. The two
strategies focus on representation enhancement and data enhancement,
respectively. Compared with pure text-based matching models, the proposed
approach is able to learn better data representations from limited or even
sparse interaction data, which is more resistible to noise in training data.
Experiment results have demonstrated that our model is able to outperform
state-of-the-art methods for job-resume matching.",1,1,0,0,1,0,0.819288,7.0,0.846793,32
2ee2973a-f9ec-49ca-a2bb-ff9472c2dc4e,Lite Transformer with Long-Short Range Attention,251,0.974021,0.86532,"Transformer has become ubiquitous in natural language processing (e.g.,
machine translation, question answering); however, it requires enormous amount
of computations to achieve high performance, which makes it not suitable for
mobile applications that are tightly constrained by the hardware resources and
battery. In this paper, we present an efficient mobile NLP architecture, Lite
Transformer to facilitate deploying mobile NLP applications on edge devices.
The key primitive is the Long-Short Range Attention (LSRA), where one group of
heads specializes in the local context modeling (by convolution) while another
group specializes in the long-distance relationship modeling (by attention).
Such specialization brings consistent improvement over the vanilla transformer
on three well-established language tasks: machine translation, abstractive
summarization, and language modeling. Under constrained resources (500M/100M
MACs), Lite Transformer outperforms transformer on WMT'14 English-French by
1.2/1.7 BLEU, respectively. Lite Transformer reduces the computation of
transformer base model by 2.5x with 0.3 BLEU score degradation. Combining with
pruning and quantization, we further compressed the model size of Lite
Transformer by 18.2x. For language modeling, Lite Transformer achieves 1.8
lower perplexity than the transformer at around 500M MACs. Notably, Lite
Transformer outperforms the AutoML-based Evolved Transformer by 0.5 higher BLEU
for the mobile NLP setting without the costly architecture search that requires
more than 250 GPU years. Code has been made available at
https://github.com/mit-han-lab/lite-transformer.",1,1,0,0,1,0,0.988656,5.0,0.977997,57
2047df64-ba0a-4958-8e9a-93ee7b4955b5,Interpretable Deep Learning Model for Online Multi-touch Attribution,7,0.484214,0.514621,"In online advertising, users may be exposed to a range of different
advertising campaigns, such as natural search or referral or organic search,
before leading to a final transaction. Estimating the contribution of
advertising campaigns on the user's journey is very meaningful and crucial. A
marketer could observe each customer's interaction with different marketing
channels and modify their investment strategies accordingly. Existing methods
including both traditional last-clicking methods and recent data-driven
approaches for the multi-touch attribution (MTA) problem lack enough
interpretation on why the methods work. In this paper, we propose a novel model
called DeepMTA, which combines deep learning model and additive feature
explanation model for interpretable online multi-touch attribution. DeepMTA
mainly contains two parts, the phased-LSTMs based conversion prediction model
to catch different time intervals, and the additive feature attribution model
combined with shaley values. Additive feature attribution is explanatory that
contains a linear function of binary variables. As the first interpretable deep
learning model for MTA, DeepMTA considers three important features in the
customer journey: event sequence order, event frequency and time-decay effect
of the event. Evaluation on a real dataset shows the proposed conversion
prediction model achieves 91\% accuracy.",1,1,0,0,0,0,0.967538,12.0,0.968537,48
ddabf3c8-55b0-4ba8-95cf-da34d241b65e,Hierarchical Transformer for Task Oriented Dialog Systems,25,0.404972,0.829824,"Generative models for dialog systems have gained much interest because of the
recent success of RNN and Transformer based models in tasks like question
answering and summarization. Although the task of dialog response generation is
generally seen as a sequence-to-sequence (Seq2Seq) problem, researchers in the
past have found it challenging to train dialog systems using the standard
Seq2Seq models. Therefore, to help the model learn meaningful utterance and
conversation level features, Sordoni et al. (2015b); Serban et al. (2016)
proposed Hierarchical RNN architecture, which was later adopted by several
other RNN based dialog systems. With the transformer-based models dominating
the seq2seq problems lately, the natural question to ask is the applicability
of the notion of hierarchy in transformer based dialog systems. In this paper,
we propose a generalized framework for Hierarchical Transformer Encoders and
show how a standard transformer can be morphed into any hierarchical encoder,
including HRED and HIBERT like models, by using specially designed attention
masks and positional encodings. We demonstrate that Hierarchical Encoding helps
achieve better natural language understanding of the contexts in
transformer-based models for task-oriented dialog systems through a wide range
of experiments.",1,0,0,0,0,0,0.962484,4.0,0.89483,29
11718e66-d617-4ed5-a14d-35bf6edf7e8a,Opening the Software Engineering Toolbox for the Assessment of Trustworthy AI,7,0.228392,0.106379,"Trustworthiness is a central requirement for the acceptance and success of
human-centered artificial intelligence (AI). To deem an AI system as
trustworthy, it is crucial to assess its behaviour and characteristics against
a gold standard of Trustworthy AI, consisting of guidelines, requirements, or
only expectations. While AI systems are highly complex, their implementations
are still based on software. The software engineering community has a
long-established toolbox for the assessment of software systems, especially in
the context of software testing. In this paper, we argue for the application of
software engineering and testing practices for the assessment of trustworthy
AI. We make the connection between the seven key requirements as defined by the
European Commission's AI high-level expert group and established procedures
from software engineering and raise questions for future work.",0,0,0,0,0,0,0.881018,5.0,0.829223,31
b03f9769-85c0-4954-a759-e5746b136369,JASS: Japanese-specific Sequence to Sequence Pre-training for Neural Machine Translation,4,0.00988325,0.1281,"Neural machine translation (NMT) needs large parallel corpora for
state-of-the-art translation quality. Low-resource NMT is typically addressed
by transfer learning which leverages large monolingual or parallel corpora for
pre-training. Monolingual pre-training approaches such as MASS (MAsked Sequence
to Sequence) are extremely effective in boosting NMT quality for languages with
small parallel corpora. However, they do not account for linguistic information
obtained using syntactic analyzers which is known to be invaluable for several
Natural Language Processing (NLP) tasks. To this end, we propose JASS,
Japanese-specific Sequence to Sequence, as a novel pre-training alternative to
MASS for NMT involving Japanese as the source or target language. JASS is joint
BMASS (Bunsetsu MASS) and BRSS (Bunsetsu Reordering Sequence to Sequence)
pre-training which focuses on Japanese linguistic units called bunsetsus. In
our experiments on ASPEC Japanese--English and News Commentary
Japanese--Russian translation we show that JASS can give results that are
competitive with if not better than those given by MASS. Furthermore, we show
for the first time that joint MASS and JASS pre-training gives results that
significantly surpass the individual methods indicating their complementary
nature. We will release our code, pre-trained models and bunsetsu annotated
data as resources for researchers to use in their own NLP tasks.",0,1,0,0,1,0,0.348366,6.0,0.590428,38
6b44c907-4d78-4f07-bab1-e5a4c0742e7c,Learning Locomotion Skills in Evolvable Robots,26,0.248238,0.45199,"The challenge of robotic reproduction -- making of new robots by recombining
two existing ones -- has been recently cracked and physically evolving robot
systems have come within reach. Here we address the next big hurdle: producing
an adequate brain for a newborn robot. In particular, we address the task of
targeted locomotion which is arguably a fundamental skill in any practical
implementation. We introduce a controller architecture and a generic learning
method to allow a modular robot with an arbitrary shape to learn to walk
towards a target and follow this target if it moves. Our approach is validated
on three robots, a spider, a gecko, and their offspring, in three real-world
scenarios.",0,0,0,0,0,0,0.0201311,14.0,0.606802,53
5b345e51-62e2-47c7-a8ac-a0efb8a652f1,MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention,30,0.270901,0.683642,"This paper presents MAST, a new model for Multimodal Abstractive Text
Summarization that utilizes information from all three modalities -- text,
audio and video -- in a multimodal video. Prior work on multimodal abstractive
text summarization only utilized information from the text and video
modalities. We examine the usefulness and challenges of deriving information
from the audio modality and present a sequence-to-sequence trimodal
hierarchical attention-based model that overcomes these challenges by letting
the model pay more attention to the text modality. MAST outperforms the current
state of the art model (video-text) by 2.51 points in terms of Content F1 score
and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal
language understanding.",0,1,0,0,1,0,0.461268,10.0,0.791017,32
18d9d031-e5b3-42bb-a479-2e6ea14a223a,When Humans Aren't Optimal: Robots that Collaborate with Risk-Aware Humans,74,0.351682,0.905316,"In order to collaborate safely and efficiently, robots need to anticipate how
their human partners will behave. Some of today's robots model humans as if
they were also robots, and assume users are always optimal. Other robots
account for human limitations, and relax this assumption so that the human is
noisily rational. Both of these models make sense when the human receives
deterministic rewards: i.e., gaining either $100 or $130 with certainty. But in
real world scenarios, rewards are rarely deterministic. Instead, we must make
choices subject to risk and uncertainty--and in these settings, humans exhibit
a cognitive bias towards suboptimal behavior. For example, when deciding
between gaining $100 with certainty or $130 only 80% of the time, people tend
to make the risk-averse choice--even though it leads to a lower expected gain!
In this paper, we adopt a well-known Risk-Aware human model from behavioral
economics called Cumulative Prospect Theory and enable robots to leverage this
model during human-robot interaction (HRI). In our user studies, we offer
supporting evidence that the Risk-Aware model more accurately predicts
suboptimal human behavior. We find that this increased modeling accuracy
results in safer and more efficient human-robot collaboration. Overall, we
extend existing rational human models so that collaborative robots can
anticipate and plan around suboptimal human behavior during HRI.",0,0,0,0,0,0,0.0440881,11.0,0.571951,51
5d2e7dee-bccd-4387-9a0f-727aaf2ea1c7,What makes instance discrimination good for transfer learning?,156,0.985664,0.876161,"Contrastive visual pretraining based on the instance discrimination pretext
task has made significant progress. Notably, recent work on unsupervised
pretraining has shown to surpass the supervised counterpart for finetuning
downstream applications such as object detection and segmentation. It comes as
a surprise that image annotations would be better left unused for transfer
learning. In this work, we investigate the following problems: What makes
instance discrimination pretraining good for transfer learning? What knowledge
is actually learned and transferred from these models? From this understanding
of instance discrimination, how can we better exploit human annotation labels
for pretraining? Our findings are threefold. First, what truly matters for the
transfer is low-level and mid-level representations, not high-level
representations. Second, the intra-category invariance enforced by the
traditional supervised model weakens transferability by increasing task
misalignment. Finally, supervised pretraining can be strengthened by following
an exemplar-based approach without explicit constraints among the instances
within the same category.",1,0,0,0,0,1,0.989956,6.0,0.986131,55
e53bba64-a112-447b-bc03-222c22094950,Retinal vessel segmentation by probing adaptive to lighting variations,3,0.0477234,0.18066,"We introduce a novel method to extract the vessels in eye fun-dus images
which is adaptive to lighting variations. In the Logarithmic Image Processing
framework, a 3-segment probe detects the vessels by probing the topographic
surface of an image from below. A map of contrasts between the probe and the
image allows to detect the vessels by a threshold. In a lowly contrasted image,
results show that our method better extract the vessels than another state-of
the-art method. In a highly contrasted image database (DRIVE) with a reference
, ours has an accuracy of 0.9454 which is similar or better than three
state-of-the-art methods and below three others. The three best methods have a
higher accuracy than a manual segmentation by another expert. Importantly, our
method automatically adapts to the lighting conditions of the image
acquisition.",0,1,0,0,1,0,0.778665,11.0,0.891036,9
dd2e225c-e787-46b9-b577-a76af14b876c,Self-Supervised Learning for Large-Scale Unsupervised Image Clustering,8,0.0568234,0.130454,"Unsupervised learning has always been appealing to machine learning
researchers and practitioners, allowing them to avoid an expensive and
complicated process of labeling the data. However, unsupervised learning of
complex data is challenging, and even the best approaches show much weaker
performance than their supervised counterparts. Self-supervised deep learning
has become a strong instrument for representation learning in computer vision.
However, those methods have not been evaluated in a fully unsupervised setting.
In this paper, we propose a simple scheme for unsupervised classification based
on self-supervised representations. We evaluate the proposed approach with
several recent self-supervised methods showing that it achieves competitive
results for ImageNet classification (39% accuracy on ImageNet with 1000
clusters and 46% with overclustering). We suggest adding the unsupervised
evaluation to a set of standard benchmarks for self-supervised learning. The
code is available at https://github.com/Randl/kmeans_selfsuper",0,1,0,0,0,0,0.98605,3.0,0.947571,42
88948901-2768-4524-b440-2cb14c092dcb,Global Attention for Name Tagging,17,0.147522,0.335933,"Many name tagging approaches use local contextual information with much
success, but fail when the local context is ambiguous or limited. We present a
new framework to improve name tagging by utilizing local, document-level, and
corpus-level contextual information. We retrieve document-level context from
other sentences within the same document and corpus-level context from
sentences in other topically related documents. We propose a model that learns
to incorporate document-level and corpus-level contextual information alongside
local contextual information via global attentions, which dynamically weight
their respective contextual information, and gating mechanisms, which determine
the influence of this information. Extensive experiments on benchmark datasets
show the effectiveness of our approach, which achieves state-of-the-art results
for Dutch, German, and Spanish on the CoNLL-2002 and CoNLL-2003 datasets.",1,1,0,0,1,0,0.362759,10.0,0.75934,42
47b078d7-ddc2-4135-b5bb-0cb859d86ba9,Multilingual BERT Post-Pretraining Alignment,32,0.389821,0.723774,"We propose a simple method to align multilingual contextual embeddings as a
post-pretraining step for improved zero-shot cross-lingual transferability of
the pretrained models. Using parallel data, our method aligns embeddings on the
word level through the recently proposed Translation Language Modeling
objective as well as on the sentence level via contrastive learning and random
input shuffling. We also perform sentence-level code-switching with English
when finetuning on downstream tasks. On XNLI, our best model (initialized from
mBERT) improves over mBERT by 4.7% in the zero-shot setting and achieves
comparable result to XLM for translate-train while using less than 18% of the
same parallel data and 31% less model parameters. On MLQA, our model
outperforms XLM-R_Base that has 57% more parameters than ours.",0,1,0,0,1,0,0.989293,3.0,0.9676,30
a133c18c-dbbc-47f5-b3f9-57dec1284877,Generative causal explanations of black-box classifiers,61,0.523336,0.656132,"We develop a method for generating causal post-hoc explanations of black-box
classifiers based on a learned low-dimensional representation of the data. The
explanation is causal in the sense that changing learned latent factors
produces a change in the classifier output statistics. To construct these
explanations, we design a learning framework that leverages a generative model
and information-theoretic measures of causal influence. Our objective function
encourages both the generative model to faithfully represent the data
distribution and the latent factors to have a large causal influence on the
classifier output. Our method learns both global and local explanations, is
compatible with any classifier that admits class probabilities and a gradient,
and does not require labeled attributes or knowledge of causal structure. Using
carefully controlled test cases, we provide intuition that illuminates the
function of our objective. We then demonstrate the practical utility of our
method on image recognition tasks.",0,0,0,0,0,0,0.897922,5.0,0.843124,84
4a2a9b15-dbdb-427d-b346-d7257a9292be,Certified Monotonic Neural Networks,60,0.406812,0.542376,"Learning monotonic models with respect to a subset of the inputs is a
desirable feature to effectively address the fairness, interpretability, and
generalization issues in practice. Existing methods for learning monotonic
neural networks either require specifically designed model structures to ensure
monotonicity, which can be too restrictive/complicated, or enforce monotonicity
by adjusting the learning process, which cannot provably guarantee the learned
model is monotonic on selected features. In this work, we propose to certify
the monotonicity of the general piece-wise linear neural networks by solving a
mixed integer linear programming problem.This provides a new general approach
for learning monotonic neural networks with arbitrary model structures. Our
method allows us to train neural networks with heuristic monotonicity
regularizations, and we can gradually increase the regularization magnitude
until the learned network is certified monotonic. Compared to prior works, our
approach does not require human-designed constraints on the weight space and
also yields more accurate approximation. Empirical studies on various datasets
demonstrate the efficiency of our approach over the state-of-the-art methods,
such as Deep Lattice Networks.",0,0,0,0,1,0,0.377518,6.0,0.60735,40
65e92267-109e-4445-bbaf-2be00a0bc23d,Unsupervised Paraphrasing via Deep Reinforcement Learning,52,0.147887,0.433811,"Paraphrasing is expressing the meaning of an input sentence in different
wording while maintaining fluency (i.e., grammatical and syntactical
correctness). Most existing work on paraphrasing use supervised models that are
limited to specific domains (e.g., image captions). Such models can neither be
straightforwardly transferred to other domains nor generalize well, and
creating labeled training data for new domains is expensive and laborious. The
need for paraphrasing across different domains and the scarcity of labeled
training data in many such domains call for exploring unsupervised paraphrase
generation methods. We propose Progressive Unsupervised Paraphrasing (PUP): a
novel unsupervised paraphrase generation method based on deep reinforcement
learning (DRL). PUP uses a variational autoencoder (trained using a
non-parallel corpus) to generate a seed paraphrase that warm-starts the DRL
model. Then, PUP progressively tunes the seed paraphrase guided by our novel
reward function which combines semantic adequacy, language fluency, and
expression diversity measures to quantify the quality of the generated
paraphrases in each iteration without needing parallel sentences. Our extensive
experimental evaluation shows that PUP outperforms unsupervised
state-of-the-art paraphrasing techniques in terms of both automatic metrics and
user studies on four real datasets. We also show that PUP outperforms
domain-adapted supervised algorithms on several datasets. Our evaluation also
shows that PUP achieves a great trade-off between semantic similarity and
diversity of expression.",0,0,0,0,1,1,0.0287571,17.0,0.697426,53
83605910-9914-4338-8fce-17979de8bdee,Comparison of Model Predictive and Reinforcement Learning Methods for Fault Tolerant Control,17,0.139262,0.632467,"A desirable property in fault-tolerant controllers is adaptability to system
changes as they evolve during systems operations. An adaptive controller does
not require optimal control policies to be enumerated for possible faults.
Instead it can approximate one in real-time. We present two adaptive
fault-tolerant control schemes for a discrete time system based on hierarchical
reinforcement learning. We compare their performance against a model predictive
controller in presence of sensor noise and persistent faults. The controllers
are tested on a fuel tank model of a C-130 plane. Our experiments demonstrate
that reinforcement learning-based controllers perform more robustly than model
predictive controllers under faults, partially observable system models, and
varying sensor noise levels.",0,1,0,0,0,0,0.00142199,41.0,0.800868,17
38bd8ca4-c4df-4e74-a510-a26bc20dee5d,Improving Dialog Evaluation with a Multi-reference Adversarial Dataset and Large Scale Pretraining,67,0.700683,0.874897,"There is an increasing focus on model-based dialog evaluation metrics such as
ADEM, RUBER, and the more recent BERT-based metrics. These models aim to assign
a high score to all relevant responses and a low score to all irrelevant
responses. Ideally, such models should be trained using multiple relevant and
irrelevant responses for any given context. However, no such data is publicly
available, and hence existing models are usually trained using a single
relevant response and multiple randomly selected responses from other contexts
(random negatives). To allow for better training and robust evaluation of
model-based metrics, we introduce the DailyDialog++ dataset, consisting of (i)
five relevant responses for each context and (ii) five adversarially crafted
irrelevant responses for each context. Using this dataset, we first show that
even in the presence of multiple correct references, n-gram based metrics and
embedding based metrics do not perform well at separating relevant responses
from even random negatives. While model-based metrics perform better than
n-gram and embedding based metrics on random negatives, their performance drops
substantially when evaluated on adversarial examples. To check if large scale
pretraining could help, we propose a new BERT-based evaluation metric called
DEB, which is pretrained on 727M Reddit conversations and then finetuned on our
dataset. DEB significantly outperforms existing models, showing better
correlation with human judgements and better performance on random negatives
(88.27% accuracy). However, its performance again drops substantially, when
evaluated on adversarial responses, thereby highlighting that even large-scale
pretrained evaluation models are not robust to the adversarial examples in our
dataset. The dataset and code are publicly available.",1,1,1,1,1,0,0.931927,8.0,0.922382,43
41ed29e3-da82-432f-9079-34014604b2da,From Natural Language Instructions to Complex Processes: Issues in Chaining Trigger Action Rules,7,0.193902,0.462124,"Automation services for complex business processes usually require a high
level of information technology literacy. There is a strong demand for a
smartly assisted process automation (IPA: intelligent process automation)
service that enables even general users to easily use advanced automation. A
natural language interface for such automation is expected as an elemental
technology for the IPA realization. The workflow targeted by IPA is generally
composed of a combination of multiple tasks. However, semantic parsing, one of
the natural language processing methods, for such complex workflows has not yet
been fully studied. The reasons are that (1) the formal expression and grammar
of the workflow required for semantic analysis have not been sufficiently
examined and (2) the dataset of the workflow formal expression with its
corresponding natural language description required for learning workflow
semantics did not exist. This paper defines a new grammar for complex workflows
with chaining machine-executable meaning representations for semantic parsing.
The representations are at a high abstraction level. Additionally, an approach
to creating datasets is proposed based on this grammar.",0,0,1,1,0,0,0.875774,5.0,0.825129,14
264b61ba-7c1c-4768-af2e-543c71da7a50,Counterfactually-Augmented SNLI Training Data Does Not Yield Better Generalization Than Unaugmented Data,36,0.0786918,0.569028,"A growing body of work shows that models exploit annotation artifacts to
achieve state-of-the-art performance on standard crowdsourced
benchmarks---datasets collected from crowdworkers to create an evaluation
task---while still failing on out-of-domain examples for the same task. Recent
work has explored the use of counterfactually-augmented data---data built by
minimally editing a set of seed examples to yield counterfactual labels---to
augment training data associated with these benchmarks and build more robust
classifiers that generalize better. However, Khashabi et al. (2020) find that
this type of augmentation yields little benefit on reading comprehension tasks
when controlling for dataset size and cost of collection. We build upon this
work by using English natural language inference data to test model
generalization and robustness and find that models trained on a
counterfactually-augmented SNLI dataset do not generalize better than
unaugmented datasets of similar size and that counterfactual augmentation can
hurt performance, yielding models that are less robust to challenge examples.
Counterfactual augmentation of natural language understanding data through
standard crowdsourcing techniques does not appear to be an effective way of
collecting training data and further innovation is required to make this
general line of work viable.",0,0,0,0,0,0,0.580328,5.0,0.649865,17
f20c4ce0-06b6-4617-b86d-14499c7adb6a,Improved Speech Representations with Multi-Target Autoregressive Predictive Coding,54,0.201688,0.753774,"Training objectives based on predictive coding have recently been shown to be
very effective at learning meaningful representations from unlabeled speech.
One example is Autoregressive Predictive Coding (Chung et al., 2019), which
trains an autoregressive RNN to generate an unseen future frame given a context
such as recent past frames. The basic hypothesis of these approaches is that
hidden states that can accurately predict future frames are a useful
representation for many downstream tasks. In this paper we extend this
hypothesis and aim to enrich the information encoded in the hidden states by
training the model to make more accurate future predictions. We propose an
auxiliary objective that serves as a regularization to improve generalization
of the future frame prediction task. Experimental results on phonetic
classification, speech recognition, and speech translation not only support the
hypothesis, but also demonstrate the effectiveness of our approach in learning
representations that contain richer phonetic content.",0,0,0,0,0,0,0.693264,5.0,0.711515,31
0d000214-35f1-4157-8b03-3c35f52d4bd8,Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing,50,0.496609,0.644007,"Prior work has explored directly regularizing the output distributions of
probabilistic models to alleviate peaky (i.e. over-confident) predictions, a
common sign of overfitting. This class of techniques, of which label smoothing
is one, has a connection to entropy regularization. Despite the consistent
success of label smoothing across architectures and data sets in language
generation tasks, two problems remain open: (1) there is little understanding
of the underlying effects entropy regularizers have on models, and (2) the full
space of entropy regularization techniques is largely unexplored. We introduce
a parametric family of entropy regularizers, which includes label smoothing as
a special case, and use it to gain a better understanding of the relationship
between the entropy of a model and its performance on language generation
tasks. We also find that variance in model performance can be explained largely
by the resulting entropy of the model. Lastly, we find that label smoothing
provably does not allow for sparsity in an output distribution, an undesirable
property for language generation models, and therefore advise the use of other
entropy regularization methods in its place.",1,0,0,0,0,0,0.907059,9.0,0.917321,45
c9e851e1-2396-4c76-b3b3-68b0fc1690fb,Graph-based Multi-hop Reasoning for Long Text Generation,9,0.146982,0.131298,"Long text generation is an important but challenging task.The main problem
lies in learning sentence-level semantic dependencies which traditional
generative models often suffer from. To address this problem, we propose a
Multi-hop Reasoning Generation (MRG) approach that incorporates multi-hop
reasoning over a knowledge graph to learn semantic dependencies among
sentences. MRG consists of twoparts, a graph-based multi-hop reasoning module
and a path-aware sentence realization module. The reasoning module is
responsible for searching skeleton paths from a knowledge graph to imitate the
imagination process in the human writing for semantic transfer. Based on the
inferred paths, the sentence realization module then generates a complete
sentence. Unlike previous black-box models, MRG explicitly infers the skeleton
path, which provides explanatory views tounderstand how the proposed model
works. We conduct experiments on three representative tasks, including story
generation, review generation, and product description generation. Automatic
and manual evaluation show that our proposed method can generate more
informative and coherentlong text than strong baselines, such as pre-trained
models(e.g. GPT-2) and knowledge-enhanced models.",0,0,0,0,1,1,0.948805,5.0,0.895968,50
7bf3d582-10f9-47b7-8b71-62eb7bf63c8a,NYTWIT: A Dataset of Novel Words in the New York Times,13,0.183992,0.300231,"We present the New York Times Word Innovation Types dataset, or NYTWIT, a
collection of over 2,500 novel English words published in the New York Times
between November 2017 and March 2019, manually annotated for their class of
novelty (such as lexical derivation, dialectal variation, blending, or
compounding). We present baseline results for both uncontextual and contextual
prediction of novelty class, showing that there is room for improvement even
for state-of-the-art NLP systems. We hope this resource will prove useful for
linguists and NLP practitioners by providing a real-world environment of novel
word appearance.",1,0,1,1,0,0,0.208937,8.0,0.617468,25
3f1dbe32-349e-4337-8645-84aa3e23812a,Exponential Negation of a Probability Distribution,30,0.0466716,0.668975,"Negation operation is important in intelligent information processing.
Different with existing arithmetic negation, an exponential negation is
presented in this paper. The new negation can be seen as a kind of geometry
negation. Some basic properties of the proposed negation is investigated, we
find that the fix point is the uniform probability distribution. The negation
is an entropy increase operation and all the probability distributions will
converge to the uniform distribution after multiple negation iterations. The
number of iterations of convergence is inversely proportional to the number of
elements in the distribution. Some numerical examples are used to illustrate
the efficiency of the proposed negation.",0,0,0,0,0,0,0.638687,2.0,0.204206,75
abf7a98c-864f-434c-bd25-595760635431,Full Reference Screen Content Image Quality Assessment by Fusing Multi-level Structure Similarity,13,0.0559228,0.512232,"The screen content images (SCIs) usually comprise various content types with
sharp edges, in which the artifacts or distortions can be well sensed by the
vanilla structure similarity measurement in a full reference manner.
Nonetheless, almost all of the current SOTA structure similarity metrics are
""locally"" formulated in a single-level manner, while the true human visual
system (HVS) follows the multi-level manner, and such mismatch could eventually
prevent these metrics from achieving trustworthy quality assessment. To
ameliorate, this paper advocates a novel solution to measure structure
similarity ""globally"" from the perspective of sparse representation. To perform
multi-level quality assessment in accordance with the real HVS, the
above-mentioned global metric will be integrated with the conventional local
ones by resorting to the newly devised selective deep fusion network. To
validate its efficacy and effectiveness, we have compared our method with 12
SOTA methods over two widely-used large-scale public SCI datasets, and the
quantitative results indicate that our method yields significantly higher
consistency with subjective quality score than the currently leading works.
Both the source code and data are also publicly available to gain widespread
acceptance and facilitate new advancement and its validation.",1,0,0,0,1,0,0.060418,7.0,0.373585,65
fb69b7d4-398d-425f-878d-041f628cacdc,Jump Operator Planning: Goal-Conditioned Policy Ensembles and Zero-Shot Transfer,2,0.0081097,0.0772577,"In Hierarchical Control, compositionality, abstraction, and task-transfer are
crucial for designing versatile algorithms which can solve a variety of
problems with maximal representational reuse. We propose a novel hierarchical
and compositional framework called Jump-Operator Dynamic Programming for
quickly computing solutions within a super-exponential space of sequential
sub-goal tasks with ordering constraints, while also providing a fast
linearly-solvable algorithm as an implementation. This approach involves
controlling over an ensemble of reusable goal-conditioned polices functioning
as temporally extended actions, and utilizes transition operators called
feasibility functions, which are used to summarize initial-to-final state
dynamics of the polices. Consequently, the added complexity of grounding a
high-level task space onto a larger ambient state-space can be mitigated by
optimizing in a lower-dimensional subspace defined by the grounding,
substantially improving the scalability of the algorithm while effecting
transferable solutions. We then identify classes of objective functions on this
subspace whose solutions are invariant to the grounding, resulting in optimal
zero-shot transfer.",0,0,0,0,0,0,0.3522,5.0,0.51125,29
89627490-3254-48fe-b913-b51e3cd3de00,Fact-Enhanced Synthetic News Generation,25,0.0914071,0.433533,"The advanced text generation methods have witnessed great success in text
summarization, language translation, and synthetic news generation. However,
these techniques can be abused to generate disinformation and fake news. To
better understand the potential threats of synthetic news, we develop a new
generation method FactGen to generate high-quality news content. The existing
text generation methods either afford limited supplementary information or lose
consistency between the input and output which makes the synthetic news less
trustworthy. To address these issues, FactGen retrieves external facts to
enrich the output and reconstructs the input claim from the generated content
to improve the consistency among the input and the output. Experiment results
on real-world datasets show that the generated news contents of FactGen are
consistent and contain rich facts. We also discuss the possible defending
method to identify these synthetic news pieces if FactGen is used to generate
synthetic news.",1,1,0,0,0,0,0.658325,5.0,0.692371,44
19e86868-da7e-4bda-9925-c8f790b28460,Discovering New Intents with Deep Aligned Clustering,91,0.479074,0.870442,"Discovering new intents is a crucial task in dialogue systems. Most existing
methods are limited in transferring the prior knowledge from known intents to
new intents. They also have difficulties in providing high-quality supervised
signals to learn clustering-friendly features for grouping unlabeled intents.
In this work, we propose an effective method, Deep Aligned Clustering, to
discover new intents with the aid of the limited known intent data. Firstly, we
leverage a few labeled known intent samples as prior knowledge to pre-train the
model. Then, we perform k-means to produce cluster assignments as
pseudo-labels. Moreover, we propose an alignment strategy to tackle the label
inconsistency problem during clustering assignments. Finally, we learn the
intent representations under the supervision of the aligned pseudo-labels. With
an unknown number of new intents, we predict the number of intent categories by
eliminating low-confidence intent-wise clusters. Extensive experiments on two
benchmark datasets show that our method is more robust and achieves substantial
improvements over the state-of-the-art methods. The codes are released at
https://github.com/thuiar/DeepAligned-Clustering.",1,1,0,0,1,0,0.594186,6.0,0.714544,41
cd21c2b7-35e8-472a-961c-f6ef7cae6ae2,Few-shot Scene-adaptive Anomaly Detection,103,0.321923,0.87242,"We address the problem of anomaly detection in videos. The goal is to
identify unusual behaviours automatically by learning exclusively from normal
videos. Most existing approaches are usually data-hungry and have limited
generalization abilities. They usually need to be trained on a large number of
videos from a target scene to achieve good results in that scene. In this
paper, we propose a novel few-shot scene-adaptive anomaly detection problem to
address the limitations of previous approaches. Our goal is to learn to detect
anomalies in a previously unseen scene with only a few frames. A reliable
solution for this new problem will have huge potential in real-world
applications since it is expensive to collect a massive amount of data for each
target scene. We propose a meta-learning based approach for solving this new
problem; extensive experimental results demonstrate the effectiveness of our
proposed method.",1,1,1,0,0,0,0.724354,8.0,0.830518,40
c28e5140-df84-4e59-919f-a0f7f13cb471,"See, Hear, Explore: Curiosity via Audio-Visual Association",57,0.708068,0.961137,"Exploration is one of the core challenges in reinforcement learning. A common
formulation of curiosity-driven exploration uses the difference between the
real future and the future predicted by a learned model. However, predicting
the future is an inherently difficult task which can be ill-posed in the face
of stochasticity. In this paper, we introduce an alternative form of curiosity
that rewards novel associations between different senses. Our approach exploits
multiple modalities to provide a stronger signal for more efficient
exploration. Our method is inspired by the fact that, for humans, both sight
and sound play a critical role in exploration. We present results on several
Atari environments and Habitat (a photorealistic navigation simulator), showing
the benefits of using an audio-visual association model for intrinsically
guiding learning agents in the absence of external rewards. For videos and
code, see https://vdean.github.io/audio-curiosity.html.",1,0,0,0,0,0,0.970346,5.0,0.9297,45
